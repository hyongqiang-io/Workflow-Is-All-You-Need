#!/usr/bin/env python3
"""
Agent Processor è¿è¡Œæµç¨‹æ¼”ç¤º
Agent Processor Flow Demonstration
"""

import asyncio
import uuid
from datetime import datetime

from workflow_framework.utils.database import initialize_database, close_database
from workflow_framework.services.agent_task_service import agent_task_service
from workflow_framework.utils.openai_client import openai_client
from workflow_framework.repositories.instance.task_instance_repository import TaskInstanceRepository
from workflow_framework.models.instance import TaskInstanceCreate, TaskInstanceType, TaskInstanceStatus


async def demonstrate_agent_processor_flow():
    """æ¼”ç¤ºAgent Processorçš„å®Œæ•´è¿è¡Œæµç¨‹"""
    
    await initialize_database()
    
    try:
        print("=== Agent Processor è¿è¡Œæµç¨‹æ¼”ç¤º ===")
        print()
        
        # 1. æ¨¡æ‹Ÿåˆ›å»ºä¸€ä¸ªAgentä»»åŠ¡
        print("1. åˆ›å»ºAgentä»»åŠ¡å®ä¾‹...")
        task_repo = TaskInstanceRepository()
        
        # åˆ›å»ºä»»åŠ¡æ•°æ®
        task_data = TaskInstanceCreate(
            node_instance_id=uuid.uuid4(),
            workflow_instance_id=uuid.uuid4(),
            processor_id=uuid.uuid4(),
            task_type=TaskInstanceType.AGENT,
            task_title="AIæ•°æ®åˆ†æä»»åŠ¡",
            task_description="åˆ†æç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œè¯†åˆ«å…³é”®æ¨¡å¼å’Œè¶‹åŠ¿",
            input_data={
                "user_data": [
                    {"user_id": 1, "action": "login", "timestamp": "2024-01-15 09:00:00"},
                    {"user_id": 1, "action": "view_product", "timestamp": "2024-01-15 09:05:00"},
                    {"user_id": 1, "action": "add_to_cart", "timestamp": "2024-01-15 09:10:00"},
                    {"user_id": 2, "action": "login", "timestamp": "2024-01-15 10:00:00"},
                    {"user_id": 2, "action": "search", "timestamp": "2024-01-15 10:05:00"}
                ],
                "analysis_type": "behavior_pattern",
                "time_range": "last_30_days"
            },
            instructions="è¯·è¯†åˆ«ç”¨æˆ·è¡Œä¸ºæ¨¡å¼ï¼Œåˆ†æè½¬åŒ–ç‡ï¼Œå¹¶æä¾›ä¼˜åŒ–å»ºè®®",
            priority=1,
            assigned_agent_id=uuid.uuid4(),
            estimated_duration=10
        )
        
        # åˆ›å»ºä»»åŠ¡å®ä¾‹
        task_instance = await task_repo.create_task(task_data)
        task_id = task_instance['task_instance_id']
        print(f"âœ… ä»»åŠ¡å®ä¾‹åˆ›å»ºæˆåŠŸ: {task_id}")
        print(f"   ä»»åŠ¡æ ‡é¢˜: {task_instance['task_title']}")
        print(f"   ä»»åŠ¡ç±»å‹: {task_instance['task_type']}")
        print()
        
        # 2. æ¼”ç¤ºAgentTaskServiceå¤„ç†æµç¨‹
        print("2. AgentTaskServiceå¤„ç†æµç¨‹...")
        print("   æ­¥éª¤2.1: å¯åŠ¨Agentä»»åŠ¡æœåŠ¡")
        await agent_task_service.start_service()
        print("   âœ… Agentä»»åŠ¡æœåŠ¡å·²å¯åŠ¨")
        
        print("   æ­¥éª¤2.2: æäº¤ä»»åŠ¡åˆ°å¤„ç†é˜Ÿåˆ—")
        submit_result = await agent_task_service.submit_task_to_agent(task_id, priority=1)
        print(f"   âœ… ä»»åŠ¡æäº¤ç»“æœ: {submit_result['status']}")
        print(f"   æ¶ˆæ¯: {submit_result['message']}")
        print()
        
        # 3. ç­‰å¾…å¹¶è§‚å¯Ÿä»»åŠ¡å¤„ç†
        print("3. è§‚å¯Ÿä»»åŠ¡å¤„ç†è¿‡ç¨‹...")
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©æœåŠ¡å¤„ç†ä»»åŠ¡
        print("   ç­‰å¾…AgentæœåŠ¡å¤„ç†ä»»åŠ¡...")
        await asyncio.sleep(5)
        
        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        final_task = await task_repo.get_task_by_id(task_id)
        print(f"   æœ€ç»ˆä»»åŠ¡çŠ¶æ€: {final_task['status']}")
        
        if final_task['status'] == TaskInstanceStatus.COMPLETED.value:
            print("   âœ… ä»»åŠ¡å¤„ç†å®Œæˆ!")
            print("   å¤„ç†ç»“æœ:")
            output_data = final_task.get('output_data', {})
            if output_data:
                print(f"     - åˆ†æç»“æœ: {output_data.get('analysis', 'N/A')}")
                print(f"     - ç½®ä¿¡åº¦: {output_data.get('confidence_score', 'N/A')}")
                print(f"     - å»ºè®®æ•°é‡: {len(output_data.get('recommendations', []))}")
                print(f"     - ä½¿ç”¨çš„æ¨¡å‹: {output_data.get('model_used', 'N/A')}")
        else:
            print(f"   âš ï¸ ä»»åŠ¡çŠ¶æ€: {final_task['status']}")
            if final_task.get('error_message'):
                print(f"   é”™è¯¯ä¿¡æ¯: {final_task['error_message']}")
        
        print()
        
        # 4. æ¼”ç¤ºç›´æ¥çš„OpenAIå®¢æˆ·ç«¯è°ƒç”¨
        print("4. ç›´æ¥æ¼”ç¤ºOpenAIå®¢æˆ·ç«¯è°ƒç”¨...")
        
        # æ„å»ºä»»åŠ¡æ•°æ®
        openai_task_data = {
            'task_id': str(task_id),
            'task_title': 'ç”¨æˆ·è¡Œä¸ºåˆ†æ',
            'task_description': 'åˆ†æç”µå•†ç”¨æˆ·çš„è´­ä¹°è¡Œä¸ºæ¨¡å¼',
            'input_data': {
                'sessions': 150,
                'conversions': 23,
                'bounce_rate': 0.65,
                'avg_session_duration': 245
            },
            'instructions': 'è¯·åˆ†æè¿™äº›æŒ‡æ ‡å¹¶æä¾›ä¼˜åŒ–å»ºè®®',
            'context': {
                'business_type': 'e-commerce',
                'analysis_period': '30_days'
            }
        }
        
        print("   è°ƒç”¨OpenAIå®¢æˆ·ç«¯å¤„ç†ä»»åŠ¡...")
        ai_result = await openai_client.process_task(openai_task_data)
        
        if ai_result['success']:
            print("   âœ… OpenAIå¤„ç†æˆåŠŸ!")
            print(f"   ä½¿ç”¨æ¨¡å‹: {ai_result['model']}")
            result_data = ai_result['result']
            print(f"   åˆ†ææ‘˜è¦: {result_data['analysis']}")
            print(f"   ç½®ä¿¡åº¦: {result_data['confidence']}")
            print(f"   å»ºè®®æ•°é‡: {len(result_data['recommendations'])}")
            print("   ä¸»è¦å»ºè®®:")
            for i, rec in enumerate(result_data['recommendations'][:3], 1):
                print(f"     {i}. {rec}")
            
            # æ˜¾ç¤ºtokenä½¿ç”¨æƒ…å†µ
            usage = ai_result.get('usage', {})
            print(f"   Tokenä½¿ç”¨: {usage.get('total_tokens', 0)} (æç¤º: {usage.get('prompt_tokens', 0)}, å®Œæˆ: {usage.get('completion_tokens', 0)})")
        else:
            print(f"   âŒ OpenAIå¤„ç†å¤±è´¥: {ai_result['error']}")
        
        print()
        
        # 5. æ¼”ç¤ºä¸åŒç±»å‹çš„AIå¤„ç†èƒ½åŠ›
        print("5. æ¼”ç¤ºå…¶ä»–AIå¤„ç†èƒ½åŠ›...")
        
        # æƒ…æ„Ÿåˆ†æ
        print("   5.1 æƒ…æ„Ÿåˆ†æ:")
        sentiment_text = "è¿™ä¸ªäº§å“éå¸¸å¥½ç”¨ï¼Œç•Œé¢è®¾è®¡å¾ˆæ£’ï¼ŒåŠŸèƒ½ä¹Ÿå¾ˆå®Œå–„ï¼Œæˆ‘å¾ˆæ»¡æ„è¿™æ¬¡è´­ä¹°ä½“éªŒï¼"
        sentiment_result = await openai_client.analyze_sentiment(sentiment_text)
        print(f"   âœ… æƒ…æ„Ÿ: {sentiment_result['sentiment']}, ç½®ä¿¡åº¦: {sentiment_result['confidence']}")
        
        # æ–‡æœ¬æ‘˜è¦
        print("   5.2 æ–‡æœ¬æ‘˜è¦:")
        long_text = """
        åœ¨ç°ä»£æ•°å­—åŒ–ä¸šåŠ¡ç¯å¢ƒä¸­ï¼Œæ•°æ®åˆ†æå·²æˆä¸ºä¼ä¸šå†³ç­–çš„é‡è¦ä¾æ®ã€‚é€šè¿‡å¯¹ç”¨æˆ·è¡Œä¸ºæ•°æ®çš„æ·±å…¥åˆ†æï¼Œ
        ä¼ä¸šå¯ä»¥æ›´å¥½åœ°ç†è§£å®¢æˆ·éœ€æ±‚ï¼Œä¼˜åŒ–äº§å“è®¾è®¡ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•ï¼Œ
        ä¸ºæ•°æ®åˆ†ææä¾›äº†æ›´å¼ºå¤§çš„å·¥å…·å’Œæ–¹æ³•ã€‚ä¼ä¸šåº”è¯¥å»ºç«‹å®Œå–„çš„æ•°æ®æ”¶é›†ã€å¤„ç†å’Œåˆ†æä½“ç³»ï¼Œ
        ä»¥æ”¯æŒæ•°æ®é©±åŠ¨çš„å†³ç­–åˆ¶å®šè¿‡ç¨‹ã€‚
        """
        summary_result = await openai_client.summarize_text(long_text.strip())
        print(f"   âœ… æ‘˜è¦: {summary_result['summary']}")
        print(f"   å‹ç¼©æ¯”: {summary_result['compression_ratio']:.2f}")
        
        # ä»£ç ç”Ÿæˆ
        print("   5.3 ä»£ç ç”Ÿæˆ:")
        code_desc = "åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—æ•°ç»„çš„å¹³å‡å€¼"
        code_result = await openai_client.generate_code(code_desc, 'python')
        print(f"   âœ… ç”Ÿæˆäº† {code_result['lines_of_code']} è¡Œ {code_result['language']} ä»£ç ")
        print("   ç”Ÿæˆçš„ä»£ç ç¤ºä¾‹:")
        print("   " + "\n   ".join(code_result['code'].split('\n')[:5]))  # æ˜¾ç¤ºå‰5è¡Œ
        print("   ...")
        
        print()
        print("=== Agent Processor æµç¨‹æ¼”ç¤ºå®Œæˆ ===")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        await agent_task_service.stop_service()
        await close_database()


async def show_agent_api_integration():
    """å±•ç¤ºAgentä¸APIé›†æˆçš„è¯¦ç»†ä¿¡æ¯"""
    
    print("\n=== Agent APIé›†æˆè¯¦ç»†è¯´æ˜ ===")
    print()
    
    print("ğŸ“ 1. Agentä»»åŠ¡å¤„ç†æµç¨‹:")
    print("   ExecutionService._process_agent_task()")
    print("   â†“")
    print("   AgentTaskService.submit_task_to_agent()")
    print("   â†“")
    print("   AgentTaskService.process_agent_task()")
    print("   â†“")
    print("   AgentTaskService._call_agent_api()")
    print("   â†“")
    print("   æ ¹æ®Agentç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼:")
    print("   â€¢ OpenAI: _process_with_openai()")
    print("   â€¢ Claude: _process_with_claude()")
    print("   â€¢ HTTP API: _process_with_http_api()")
    print()
    
    print("ğŸ“ 2. OpenAI APIè°ƒç”¨æµç¨‹:")
    print("   OpenAIClient.process_task()")
    print("   â†“")
    print("   _build_prompt() - æ„å»ºæç¤ºè¯")
    print("   â†“")
    print("   _simulate_openai_request() - å‘é€APIè¯·æ±‚")
    print("   â†“")
    print("   è¿”å›ç»“æ„åŒ–ç»“æœ")
    print()
    
    print("ğŸ“ 3. ä»»åŠ¡çŠ¶æ€ç®¡ç†:")
    print("   PENDING â†’ IN_PROGRESS â†’ COMPLETED/FAILED")
    print("   â†“")
    print("   å›è°ƒé€šçŸ¥ExecutionService")
    print("   â†“")
    print("   ç»§ç»­å·¥ä½œæµæ‰§è¡Œ")
    print()
    
    print("ğŸ“ 4. APIå“åº”ç»“æ„:")
    print("""
   {
     "success": true,
     "model": "gpt-4",
     "result": {
       "analysis": "ä»»åŠ¡åˆ†æç»“æœ",
       "result": { ... },
       "recommendations": [...],
       "confidence": 0.85,
       "next_steps": [...]
     },
     "usage": {
       "prompt_tokens": 150,
       "completion_tokens": 200,
       "total_tokens": 350
     }
   }
   """)
    
    print("ğŸ“ 5. é”™è¯¯å¤„ç†æœºåˆ¶:")
    print("   â€¢ APIè°ƒç”¨è¶…æ—¶ â†’ ä»»åŠ¡æ ‡è®°ä¸ºå¤±è´¥")
    print("   â€¢ ç½‘ç»œé”™è¯¯ â†’ è‡ªåŠ¨é‡è¯•æœºåˆ¶")
    print("   â€¢ è§£æé”™è¯¯ â†’ é™çº§åˆ°ç®€å•å¤„ç†")
    print("   â€¢ æ‰€æœ‰é”™è¯¯éƒ½ä¼šé€šè¿‡å›è°ƒé€šçŸ¥æ‰§è¡Œå¼•æ“")


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    try:
        print("Agent Processor è¿è¡Œæœºåˆ¶è¯¦è§£")
        print("=" * 50)
        
        # 1. å±•ç¤ºç†è®ºè¯´æ˜
        await show_agent_api_integration()
        
        # 2. è¿è¡Œå®é™…æ¼”ç¤º
        success = await demonstrate_agent_processor_flow()
        
        if success:
            print("\nğŸ‰ Agent Processoræ¼”ç¤ºæˆåŠŸå®Œæˆ!")
            print("\nğŸ“š å…³é”®è¦ç‚¹æ€»ç»“:")
            print("â€¢ Agentä»»åŠ¡é€šè¿‡é˜Ÿåˆ—å¼‚æ­¥å¤„ç†")
            print("â€¢ æ”¯æŒå¤šç§AIæœåŠ¡(OpenAI, Claudeç­‰)")
            print("â€¢ å®Œæ•´çš„çŠ¶æ€è·Ÿè¸ªå’Œå›è°ƒæœºåˆ¶")
            print("â€¢ ç»“æ„åŒ–çš„APIå“åº”å’Œé”™è¯¯å¤„ç†")
            print("â€¢ ä¸å·¥ä½œæµæ‰§è¡Œå¼•æ“å®Œå…¨é›†æˆ")
        else:
            print("\nğŸ’¥ Agent Processoræ¼”ç¤ºå¤±è´¥!")
        
    except Exception as e:
        print(f"\né”™è¯¯: {e}")
        return False
    
    return True


if __name__ == "__main__":
    asyncio.run(main())