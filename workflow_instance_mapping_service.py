"""
å·¥ä½œæµå®ä¾‹æ˜ å°„å…³ç³»æŸ¥è¯¢æœåŠ¡
Workflow Instance Mapping Service
"""

import uuid
from typing import Optional, Dict, Any, List, Set
from loguru import logger
from backend.repositories.base import BaseRepository


class WorkflowInstanceMappingService:
    """å·¥ä½œæµå®ä¾‹æ˜ å°„å…³ç³»æŸ¥è¯¢æœåŠ¡"""
    
    def __init__(self):
        self.db = BaseRepository("workflow_mapping").db
    
    async def get_complete_workflow_mapping(self, workflow_instance_id: uuid.UUID, 
                                          max_depth: int = 10) -> Dict[str, Any]:
        """
        è·å–å·¥ä½œæµå®ä¾‹çš„å®Œæ•´æ˜ å°„å…³ç³»
        
        Args:
            workflow_instance_id: æ ¹å·¥ä½œæµå®ä¾‹ID
            max_depth: æœ€å¤§é€’å½’æ·±åº¦ï¼Œé˜²æ­¢æ— é™é€’å½’
            
        Returns:
            å®Œæ•´çš„å·¥ä½œæµ-èŠ‚ç‚¹-å­å·¥ä½œæµæ˜ å°„å…³ç³»
        """
        try:
            logger.info(f"ğŸ” å¼€å§‹æŸ¥è¯¢å·¥ä½œæµå®ä¾‹å®Œæ•´æ˜ å°„: {workflow_instance_id}")
            
            # å­˜å‚¨å·²å¤„ç†çš„å·¥ä½œæµå®ä¾‹ï¼Œé˜²æ­¢å¾ªç¯å¼•ç”¨
            processed_workflows: Set[str] = set()
            
            # é€’å½’æŸ¥è¯¢æ ¹å·¥ä½œæµåŠå…¶æ‰€æœ‰å­å·¥ä½œæµ
            root_mapping = await self._get_workflow_mapping_recursive(
                workflow_instance_id, 0, max_depth, processed_workflows
            )
            
            # æ„å»ºå®Œæ•´çš„æ˜ å°„ç»“æ„
            complete_mapping = {
                "root_workflow_instance_id": str(workflow_instance_id),
                "mapping_data": root_mapping,
                "metadata": {
                    "total_workflows": len(processed_workflows),
                    "max_depth_reached": root_mapping.get("depth", 0),
                    "query_timestamp": self._get_current_timestamp()
                }
            }
            
            logger.info(f"âœ… å·¥ä½œæµæ˜ å°„æŸ¥è¯¢å®Œæˆ: æ€»å…± {len(processed_workflows)} ä¸ªå·¥ä½œæµ")
            return complete_mapping
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å·¥ä½œæµæ˜ å°„å¤±è´¥: {e}")
            raise
    
    async def _get_workflow_mapping_recursive(self, workflow_instance_id: uuid.UUID, 
                                            current_depth: int, max_depth: int,
                                            processed_workflows: Set[str]) -> Dict[str, Any]:
        """
        é€’å½’è·å–å·¥ä½œæµæ˜ å°„å…³ç³»
        
        Args:
            workflow_instance_id: å½“å‰å·¥ä½œæµå®ä¾‹ID
            current_depth: å½“å‰é€’å½’æ·±åº¦
            max_depth: æœ€å¤§é€’å½’æ·±åº¦
            processed_workflows: å·²å¤„ç†çš„å·¥ä½œæµå®ä¾‹é›†åˆ
            
        Returns:
            å½“å‰å·¥ä½œæµåŠå…¶å­å·¥ä½œæµçš„æ˜ å°„å…³ç³»
        """
        try:
            workflow_id_str = str(workflow_instance_id)
            
            # é˜²æ­¢å¾ªç¯å¼•ç”¨å’Œæ·±åº¦è¶…é™
            if workflow_id_str in processed_workflows:
                logger.warning(f"æ£€æµ‹åˆ°å¾ªç¯å¼•ç”¨ï¼Œè·³è¿‡: {workflow_instance_id}")
                return {"error": "circular_reference", "workflow_instance_id": workflow_id_str}
            
            if current_depth > max_depth:
                logger.warning(f"è¾¾åˆ°æœ€å¤§é€’å½’æ·±åº¦ {max_depth}ï¼Œåœæ­¢é€’å½’")
                return {"error": "max_depth_reached", "workflow_instance_id": workflow_id_str}
            
            processed_workflows.add(workflow_id_str)
            
            # 1. è·å–å·¥ä½œæµå®ä¾‹åŸºæœ¬ä¿¡æ¯
            workflow_info = await self._get_workflow_instance_info(workflow_instance_id)
            if not workflow_info:
                return {"error": "workflow_not_found", "workflow_instance_id": workflow_id_str}
            
            # 2. è·å–å·¥ä½œæµçš„æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹
            node_instances = await self._get_workflow_node_instances(workflow_instance_id)
            
            # 3. ä¸ºæ¯ä¸ªèŠ‚ç‚¹å®ä¾‹æŸ¥è¯¢å…¶subdivisionå…³ç³»
            nodes_with_subdivisions = []
            
            for node_instance in node_instances:
                node_mapping = await self._get_node_subdivision_mapping(
                    node_instance, current_depth, max_depth, processed_workflows
                )
                nodes_with_subdivisions.append(node_mapping)
            
            # 4. æ„å»ºå½“å‰å·¥ä½œæµçš„å®Œæ•´æ˜ å°„
            mapping = {
                "workflow_instance_id": workflow_id_str,
                "workflow_instance_name": workflow_info["workflow_instance_name"],
                "workflow_base_id": str(workflow_info["workflow_base_id"]),
                "workflow_name": workflow_info["workflow_name"],
                "status": workflow_info["status"],
                "depth": current_depth,
                "total_nodes": len(node_instances),
                "nodes": nodes_with_subdivisions,
                "created_at": str(workflow_info["created_at"]),
                "has_subdivisions": any(node.get("subdivisions") for node in nodes_with_subdivisions)
            }
            
            return mapping
            
        except Exception as e:
            logger.error(f"é€’å½’æŸ¥è¯¢å·¥ä½œæµæ˜ å°„å¤±è´¥: {e}")
            raise
    
    async def _get_workflow_instance_info(self, workflow_instance_id: uuid.UUID) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµå®ä¾‹åŸºæœ¬ä¿¡æ¯"""
        try:
            query = """
            SELECT 
                wi.workflow_instance_id,
                wi.workflow_instance_name,
                wi.workflow_base_id,
                wi.status,
                wi.created_at,
                wi.started_at,
                wi.completed_at,
                w.name as workflow_name,
                w.workflow_description
            FROM workflow_instance wi
            JOIN workflow w ON wi.workflow_base_id = w.workflow_base_id 
                AND w.is_current_version = TRUE
            WHERE wi.workflow_instance_id = $1 
                AND wi.is_deleted = FALSE
            """
            
            result = await self.db.fetch_one(query, workflow_instance_id)
            return dict(result) if result else None
            
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµå®ä¾‹ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    async def _get_workflow_node_instances(self, workflow_instance_id: uuid.UUID) -> List[Dict[str, Any]]:
        """è·å–å·¥ä½œæµçš„æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹"""
        try:
            query = """
            SELECT 
                ni.node_instance_id,
                ni.node_instance_name,
                ni.node_id,
                ni.node_base_id,
                ni.status as node_instance_status,
                ni.created_at as node_instance_created_at,
                n.name as node_name,
                n.type as node_type,
                n.task_description,
                n.position_x,
                n.position_y
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 
                AND ni.is_deleted = FALSE
            ORDER BY ni.created_at ASC
            """
            
            results = await self.db.fetch_all(query, workflow_instance_id)
            return [dict(result) for result in results]
            
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµèŠ‚ç‚¹å®ä¾‹å¤±è´¥: {e}")
            return []
    
    async def _get_node_subdivision_mapping(self, node_instance: Dict[str, Any], 
                                          current_depth: int, max_depth: int,
                                          processed_workflows: Set[str]) -> Dict[str, Any]:
        """è·å–èŠ‚ç‚¹çš„subdivisionæ˜ å°„å…³ç³»"""
        try:
            node_instance_id = node_instance["node_instance_id"]
            
            # åŸºæœ¬èŠ‚ç‚¹ä¿¡æ¯
            node_mapping = {
                "node_instance_id": str(node_instance_id),
                "node_instance_name": node_instance["node_instance_name"],
                "node_base_id": str(node_instance["node_base_id"]),
                "node_name": node_instance["node_name"],
                "node_type": node_instance["node_type"],
                "task_description": node_instance["task_description"],
                "status": node_instance["node_instance_status"],
                "position": {
                    "x": node_instance.get("position_x"),
                    "y": node_instance.get("position_y")
                },
                "subdivisions": []
            }
            
            # æŸ¥è¯¢è¯¥èŠ‚ç‚¹çš„ä»»åŠ¡å®ä¾‹
            tasks = await self._get_node_task_instances(node_instance_id)
            
            if tasks:
                node_mapping["tasks"] = []
                
                for task in tasks:
                    task_mapping = {
                        "task_instance_id": str(task["task_instance_id"]),
                        "task_title": task["task_title"],
                        "task_type": task["task_type"],
                        "status": task["status"],
                        "subdivisions": []
                    }
                    
                    # æŸ¥è¯¢è¯¥ä»»åŠ¡çš„subdivisions
                    subdivisions = await self._get_task_subdivisions(task["task_instance_id"])
                    
                    for subdivision in subdivisions:
                        subdivision_mapping = await self._get_subdivision_mapping(
                            subdivision, current_depth, max_depth, processed_workflows
                        )
                        task_mapping["subdivisions"].append(subdivision_mapping)
                    
                    node_mapping["tasks"].append(task_mapping)
                
                # å°†ä»»åŠ¡çº§åˆ«çš„subdivisionsæå‡åˆ°èŠ‚ç‚¹çº§åˆ«
                all_subdivisions = []
                for task in node_mapping["tasks"]:
                    all_subdivisions.extend(task["subdivisions"])
                node_mapping["subdivisions"] = all_subdivisions
            
            return node_mapping
            
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹subdivisionæ˜ å°„å¤±è´¥: {e}")
            return {
                "node_instance_id": str(node_instance.get("node_instance_id", "")),
                "error": str(e),
                "subdivisions": []
            }
    
    async def _get_node_task_instances(self, node_instance_id: uuid.UUID) -> List[Dict[str, Any]]:
        """è·å–èŠ‚ç‚¹çš„ä»»åŠ¡å®ä¾‹"""
        try:
            query = """
            SELECT 
                ti.task_instance_id,
                ti.task_title,
                ti.task_type,
                ti.status,
                ti.created_at,
                ti.assigned_at,
                ti.completed_at
            FROM task_instance ti
            WHERE ti.node_instance_id = $1 
                AND ti.is_deleted = FALSE
            ORDER BY ti.created_at ASC
            """
            
            results = await self.db.fetch_all(query, node_instance_id)
            return [dict(result) for result in results]
            
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹ä»»åŠ¡å®ä¾‹å¤±è´¥: {e}")
            return []
    
    async def _get_task_subdivisions(self, task_instance_id: uuid.UUID) -> List[Dict[str, Any]]:
        """è·å–ä»»åŠ¡çš„subdivisions"""
        try:
            query = """
            SELECT 
                ts.subdivision_id,
                ts.subdivision_name,
                ts.subdivision_description,
                ts.status as subdivision_status,
                ts.sub_workflow_base_id,
                ts.sub_workflow_instance_id,
                ts.context_passed,
                ts.created_at as subdivision_created_at,
                sw.name as sub_workflow_name,
                sw.workflow_description as sub_workflow_description
            FROM task_subdivision ts
            LEFT JOIN workflow sw ON ts.sub_workflow_base_id = sw.workflow_base_id 
                AND sw.is_current_version = TRUE
            WHERE ts.original_task_id = $1 
                AND ts.is_deleted = FALSE
            ORDER BY ts.subdivision_created_at DESC
            """
            
            results = await self.db.fetch_all(query, task_instance_id)
            return [dict(result) for result in results]
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡subdivisionså¤±è´¥: {e}")
            return []
    
    async def _get_subdivision_mapping(self, subdivision: Dict[str, Any], 
                                     current_depth: int, max_depth: int,
                                     processed_workflows: Set[str]) -> Dict[str, Any]:
        """è·å–subdivisionçš„å®Œæ•´æ˜ å°„å…³ç³»"""
        try:
            subdivision_mapping = {
                "subdivision_id": str(subdivision["subdivision_id"]),
                "subdivision_name": subdivision["subdivision_name"],
                "subdivision_description": subdivision["subdivision_description"],
                "status": subdivision["subdivision_status"],
                "sub_workflow_base_id": str(subdivision["sub_workflow_base_id"]) if subdivision["sub_workflow_base_id"] else None,
                "sub_workflow_name": subdivision["sub_workflow_name"],
                "sub_workflow_description": subdivision["sub_workflow_description"],
                "context_passed": subdivision["context_passed"],
                "created_at": str(subdivision["subdivision_created_at"]),
                "sub_workflow_mapping": None
            }
            
            # å¦‚æœæœ‰å­å·¥ä½œæµå®ä¾‹ï¼Œé€’å½’æŸ¥è¯¢å…¶æ˜ å°„å…³ç³»
            sub_workflow_instance_id = subdivision["sub_workflow_instance_id"]
            if sub_workflow_instance_id:
                subdivision_mapping["sub_workflow_instance_id"] = str(sub_workflow_instance_id)
                
                # é€’å½’æŸ¥è¯¢å­å·¥ä½œæµæ˜ å°„
                sub_mapping = await self._get_workflow_mapping_recursive(
                    sub_workflow_instance_id, current_depth + 1, max_depth, processed_workflows
                )
                subdivision_mapping["sub_workflow_mapping"] = sub_mapping
            
            return subdivision_mapping
            
        except Exception as e:
            logger.error(f"è·å–subdivisionæ˜ å°„å¤±è´¥: {e}")
            return {
                "subdivision_id": str(subdivision.get("subdivision_id", "")),
                "error": str(e),
                "sub_workflow_mapping": None
            }
    
    async def get_workflow_node_subdivision_summary(self, workflow_instance_id: uuid.UUID) -> Dict[str, Any]:
        """
        è·å–å·¥ä½œæµèŠ‚ç‚¹subdivisionæ‘˜è¦ä¿¡æ¯ï¼ˆä¸é€’å½’ï¼ŒåªæŸ¥è¯¢ç›´æ¥å­å·¥ä½œæµï¼‰
        
        Returns:
            èŠ‚ç‚¹subdivisionæ‘˜è¦ä¿¡æ¯
        """
        try:
            query = """
            SELECT 
                -- èŠ‚ç‚¹ä¿¡æ¯
                ni.node_instance_id,
                ni.node_instance_name,
                ni.node_base_id,
                n.name as node_name,
                n.type as node_type,
                
                -- ä»»åŠ¡ä¿¡æ¯
                ti.task_instance_id,
                ti.task_title,
                ti.task_type,
                ti.status as task_status,
                
                -- Subdivisionä¿¡æ¯
                ts.subdivision_id,
                ts.subdivision_name,
                ts.status as subdivision_status,
                ts.sub_workflow_base_id,
                ts.sub_workflow_instance_id,
                
                -- å­å·¥ä½œæµä¿¡æ¯
                sw.name as sub_workflow_name,
                swi.workflow_instance_name as sub_workflow_instance_name,
                swi.status as sub_workflow_instance_status,
                
                -- ç»Ÿè®¡ä¿¡æ¯
                (SELECT COUNT(*) FROM node n2 
                 WHERE n2.workflow_base_id = ts.sub_workflow_base_id 
                 AND n2.is_deleted = FALSE) as sub_workflow_total_nodes,
                 
                (SELECT COUNT(*) FROM node_instance ni2 
                 JOIN node n2 ON ni2.node_id = n2.node_id
                 WHERE n2.workflow_base_id = ts.sub_workflow_base_id 
                 AND ni2.workflow_instance_id = ts.sub_workflow_instance_id
                 AND ni2.status = 'completed'
                 AND ni2.is_deleted = FALSE) as sub_workflow_completed_nodes
                 
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            LEFT JOIN task_instance ti ON ni.node_instance_id = ti.node_instance_id 
                AND ti.is_deleted = FALSE
            LEFT JOIN task_subdivision ts ON ti.task_instance_id = ts.original_task_id 
                AND ts.is_deleted = FALSE
            LEFT JOIN workflow sw ON ts.sub_workflow_base_id = sw.workflow_base_id 
                AND sw.is_current_version = TRUE
            LEFT JOIN workflow_instance swi ON ts.sub_workflow_instance_id = swi.workflow_instance_id
            WHERE ni.workflow_instance_id = $1 
                AND ni.is_deleted = FALSE
            ORDER BY ni.created_at ASC, ti.created_at ASC, ts.subdivision_created_at DESC
            """
            
            results = await self.db.fetch_all(query, workflow_instance_id)
            
            # ç»„ç»‡æ•°æ®ç»“æ„
            nodes_map = {}
            
            for result in results:
                node_id = str(result["node_instance_id"])
                
                if node_id not in nodes_map:
                    nodes_map[node_id] = {
                        "node_instance_id": node_id,
                        "node_instance_name": result["node_instance_name"],
                        "node_base_id": str(result["node_base_id"]),
                        "node_name": result["node_name"],
                        "node_type": result["node_type"],
                        "tasks": {},
                        "total_subdivisions": 0
                    }
                
                # å¦‚æœæœ‰ä»»åŠ¡å®ä¾‹
                if result["task_instance_id"]:
                    task_id = str(result["task_instance_id"])
                    
                    if task_id not in nodes_map[node_id]["tasks"]:
                        nodes_map[node_id]["tasks"][task_id] = {
                            "task_instance_id": task_id,
                            "task_title": result["task_title"],
                            "task_type": result["task_type"],
                            "task_status": result["task_status"],
                            "subdivisions": []
                        }
                    
                    # å¦‚æœæœ‰subdivision
                    if result["subdivision_id"]:
                        subdivision_info = {
                            "subdivision_id": str(result["subdivision_id"]),
                            "subdivision_name": result["subdivision_name"],
                            "subdivision_status": result["subdivision_status"],
                            "sub_workflow_base_id": str(result["sub_workflow_base_id"]) if result["sub_workflow_base_id"] else None,
                            "sub_workflow_name": result["sub_workflow_name"],
                            "sub_workflow_instance_id": str(result["sub_workflow_instance_id"]) if result["sub_workflow_instance_id"] else None,
                            "sub_workflow_instance_name": result["sub_workflow_instance_name"],
                            "sub_workflow_instance_status": result["sub_workflow_instance_status"],
                            "sub_workflow_total_nodes": result["sub_workflow_total_nodes"],
                            "sub_workflow_completed_nodes": result["sub_workflow_completed_nodes"]
                        }
                        
                        nodes_map[node_id]["tasks"][task_id]["subdivisions"].append(subdivision_info)
                        nodes_map[node_id]["total_subdivisions"] += 1
            
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
            nodes_list = []
            for node_data in nodes_map.values():
                # å°†tasksä»å­—å…¸è½¬æ¢ä¸ºåˆ—è¡¨
                node_data["tasks"] = list(node_data["tasks"].values())
                nodes_list.append(node_data)
            
            return {
                "workflow_instance_id": str(workflow_instance_id),
                "nodes": nodes_list,
                "total_nodes": len(nodes_list),
                "total_subdivisions": sum(node.get("total_subdivisions", 0) for node in nodes_list)
            }
            
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµèŠ‚ç‚¹subdivisionæ‘˜è¦å¤±è´¥: {e}")
            raise
    
    async def get_node_subdivision_bindings(self, node_base_id: uuid.UUID, 
                                          workflow_base_id: uuid.UUID) -> List[Dict[str, Any]]:
        """
        è·å–ç‰¹å®šèŠ‚ç‚¹çš„æ‰€æœ‰subdivisionç»‘å®šå…³ç³»
        
        Args:
            node_base_id: èŠ‚ç‚¹åŸºç¡€ID
            workflow_base_id: å·¥ä½œæµåŸºç¡€ID
            
        Returns:
            èŠ‚ç‚¹çš„æ‰€æœ‰subdivisionç»‘å®šå…³ç³»
        """
        try:
            query = """
            SELECT 
                -- èŠ‚ç‚¹ä¿¡æ¯
                n.node_base_id,
                n.name as node_name,
                n.type as node_type,
                n.workflow_base_id,
                
                -- èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯
                ni.node_instance_id,
                ni.node_instance_name,
                ni.status as node_instance_status,
                ni.workflow_instance_id,
                wi.workflow_instance_name,
                
                -- ä»»åŠ¡å®ä¾‹ä¿¡æ¯
                ti.task_instance_id,
                ti.task_title,
                ti.task_type,
                ti.status as task_status,
                
                -- Subdivisionä¿¡æ¯
                ts.subdivision_id,
                ts.subdivision_name,
                ts.subdivision_description,
                ts.status as subdivision_status,
                ts.sub_workflow_base_id,
                ts.sub_workflow_instance_id,
                ts.context_passed,
                ts.subdivision_created_at,
                
                -- å­å·¥ä½œæµä¿¡æ¯
                sw.name as sub_workflow_name,
                sw.workflow_description as sub_workflow_description,
                swi.workflow_instance_name as sub_workflow_instance_name,
                swi.status as sub_workflow_instance_status
                
            FROM node n
            JOIN node_instance ni ON n.node_id = ni.node_id
            JOIN workflow_instance wi ON ni.workflow_instance_id = wi.workflow_instance_id
            LEFT JOIN task_instance ti ON ni.node_instance_id = ti.node_instance_id 
                AND ti.is_deleted = FALSE
            LEFT JOIN task_subdivision ts ON ti.task_instance_id = ts.original_task_id 
                AND ts.is_deleted = FALSE
            LEFT JOIN workflow sw ON ts.sub_workflow_base_id = sw.workflow_base_id 
                AND sw.is_current_version = TRUE
            LEFT JOIN workflow_instance swi ON ts.sub_workflow_instance_id = swi.workflow_instance_id
            WHERE n.node_base_id = $1 
                AND n.workflow_base_id = $2
                AND n.is_current_version = TRUE
                AND n.is_deleted = FALSE
                AND ni.is_deleted = FALSE
                AND wi.is_deleted = FALSE
            ORDER BY wi.created_at DESC, ni.created_at ASC, ti.created_at ASC, ts.subdivision_created_at DESC
            """
            
            results = await self.db.fetch_all(query, node_base_id, workflow_base_id)
            return [dict(result) for result in results]
            
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹subdivisionç»‘å®šå…³ç³»å¤±è´¥: {e}")
            raise
    
    def _get_current_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.utcnow().isoformat()


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å‡½æ•°
async def test_workflow_mapping_service():
    """æµ‹è¯•å·¥ä½œæµæ˜ å°„æœåŠ¡"""
    service = WorkflowInstanceMappingService()
    
    # æµ‹è¯•å®Œæ•´æ˜ å°„æŸ¥è¯¢
    try:
        # éœ€è¦æä¾›ä¸€ä¸ªçœŸå®çš„workflow_instance_idè¿›è¡Œæµ‹è¯•
        test_workflow_id = uuid.uuid4()  # æ›¿æ¢ä¸ºçœŸå®ID
        
        print("=== æµ‹è¯•å®Œæ•´å·¥ä½œæµæ˜ å°„æŸ¥è¯¢ ===")
        complete_mapping = await service.get_complete_workflow_mapping(test_workflow_id)
        print(f"æ˜ å°„ç»“æœ: {complete_mapping}")
        
        print("\\n=== æµ‹è¯•èŠ‚ç‚¹subdivisionæ‘˜è¦æŸ¥è¯¢ ===")
        summary = await service.get_workflow_node_subdivision_summary(test_workflow_id)
        print(f"æ‘˜è¦ç»“æœ: {summary}")
        
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    import asyncio
    asyncio.run(test_workflow_mapping_service())