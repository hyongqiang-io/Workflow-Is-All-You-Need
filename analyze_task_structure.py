#!/usr/bin/env python3
"""
è§£æçœŸå®Taskå®ä¾‹ç»“æ„
Analyze Real Task Instance Structure
"""

import asyncio
import uuid
import json
from datetime import datetime
from pprint import pprint

from workflow_framework.utils.database import initialize_database, close_database
from workflow_framework.services.auth_service import AuthService
from workflow_framework.services.workflow_service import WorkflowService
from workflow_framework.services.node_service import NodeService
from workflow_framework.repositories.processor.processor_repository import ProcessorRepository
from workflow_framework.repositories.instance.task_instance_repository import TaskInstanceRepository
from workflow_framework.models.user import UserCreate
from workflow_framework.models.workflow import WorkflowCreate
from workflow_framework.models.node import NodeCreate, NodeType, NodeConnectionCreate
from workflow_framework.models.processor import ProcessorCreate, ProcessorType
from workflow_framework.models.instance import TaskInstanceCreate, TaskInstanceType, TaskInstanceStatus


async def create_and_analyze_task():
    """åˆ›å»ºå¹¶è§£æçœŸå®çš„taskå®ä¾‹"""
    
    await initialize_database()
    
    try:
        print("=== çœŸå®Taskå®ä¾‹ç»“æ„è§£æ ===")
        print()
        
        # 1. å‡†å¤‡åŸºç¡€æ•°æ®
        print("1. åˆ›å»ºåŸºç¡€æ•°æ®...")
        auth_service = AuthService()
        workflow_service = WorkflowService()
        node_service = NodeService()
        processor_repo = ProcessorRepository()
        task_repo = TaskInstanceRepository()
        
        # åˆ›å»ºç”¨æˆ·
        user_data = UserCreate(
            username=f"task_analyzer_{datetime.now().strftime('%H%M%S')}",
            email=f"task_{datetime.now().strftime('%H%M%S')}@test.com",
            password="test123456",
            role="admin",
            description="ä»»åŠ¡åˆ†ææµ‹è¯•ç”¨æˆ·"
        )
        user = await auth_service.register_user(user_data)
        print(f"åˆ›å»ºç”¨æˆ·: {user.username}")
        
        # åˆ›å»ºå·¥ä½œæµ
        workflow_data = WorkflowCreate(
            name=f"ä»»åŠ¡åˆ†ææµ‹è¯•å·¥ä½œæµ_{datetime.now().strftime('%H%M%S')}",
            description="ç”¨äºåˆ†æTaskå®ä¾‹ç»“æ„çš„æµ‹è¯•å·¥ä½œæµ",
            creator_id=user.user_id
        )
        workflow = await workflow_service.create_workflow(workflow_data)
        print(f"åˆ›å»ºå·¥ä½œæµ: {workflow.name}")
        
        # åˆ›å»ºå¤„ç†èŠ‚ç‚¹
        node_data = NodeCreate(
            name="æ•°æ®åˆ†æèŠ‚ç‚¹",
            type=NodeType.PROCESSOR,
            task_description="æ‰§è¡Œå¤æ‚çš„æ•°æ®åˆ†æä»»åŠ¡ï¼ŒåŒ…å«è¾“å…¥æ•°æ®å¤„ç†ã€AIæ¨¡å‹è°ƒç”¨å’Œç»“æœè¾“å‡º",
            workflow_base_id=workflow.workflow_base_id,
            position_x=200,
            position_y=150
        )
        node = await node_service.create_node(node_data, user.user_id)
        print(f"åˆ›å»ºèŠ‚ç‚¹: {node.name}")
        
        # å…ˆåˆ›å»ºAgent
        from workflow_framework.repositories.agent.agent_repository import AgentRepository
        from workflow_framework.models.agent import AgentCreate
        
        agent_repo = AgentRepository()
        agent_data = AgentCreate(
            agent_name="GPT-4æ•°æ®åˆ†æå¸ˆ",
            description="ä¸“ä¸šçš„æ•°æ®åˆ†æAIåŠ©æ‰‹",
            base_url="https://api.openai.com/v1",
            api_key="test-key",
            model_name="gpt-4",
            is_autonomous=False
        )
        agent = await agent_repo.create_agent(agent_data)
        print(f"åˆ›å»ºAgent: {agent['agent_name']}")
        
        # åˆ›å»ºAgentå¤„ç†å™¨
        agent_processor_data = ProcessorCreate(
            name="GPTæ•°æ®åˆ†æå¸ˆ",
            type=ProcessorType.AGENT,
            agent_id=agent['agent_id']
        )
        processor = await processor_repo.create_processor(agent_processor_data)
        print(f"åˆ›å»ºå¤„ç†å™¨: {processor['name']}")
        
        # å…³è”å¤„ç†å™¨åˆ°èŠ‚ç‚¹
        await node_service.assign_processor_to_node(
            node.node_base_id,
            workflow.workflow_base_id,
            processor['processor_id'],
            user.user_id
        )
        print("å¤„ç†å™¨å·²å…³è”åˆ°èŠ‚ç‚¹")
        print()
        
        # 2. åˆ›å»ºå¤æ‚çš„Taskå®ä¾‹
        print("2. åˆ›å»ºå¤æ‚çš„Taskå®ä¾‹...")
        
        task_data = TaskInstanceCreate(
            node_instance_id=uuid.uuid4(),
            workflow_instance_id=uuid.uuid4(),
            processor_id=processor['processor_id'],
            task_type=TaskInstanceType.AGENT,
            task_title="ç”µå•†ç”¨æˆ·è¡Œä¸ºæ•°æ®æ·±åº¦åˆ†æ",
            task_description="""
            å¯¹ç”µå•†å¹³å°çš„ç”¨æˆ·è¡Œä¸ºæ•°æ®è¿›è¡Œæ·±åº¦åˆ†æï¼ŒåŒ…æ‹¬ï¼š
            1. ç”¨æˆ·è®¿é—®è·¯å¾„åˆ†æ
            2. è´­ä¹°è½¬åŒ–ç‡è®¡ç®—
            3. ç”¨æˆ·ç”»åƒæ„å»º
            4. å•†å“æ¨èä¼˜åŒ–å»ºè®®
            5. å­£èŠ‚æ€§è¶‹åŠ¿è¯†åˆ«
            """,
            input_data={
                "raw_data": {
                    "user_sessions": [
                        {
                            "session_id": "sess_001",
                            "user_id": "user_12345",
                            "start_time": "2024-01-15T09:00:00Z",
                            "end_time": "2024-01-15T09:25:00Z",
                            "pages_visited": [
                                {"page": "/home", "duration": 30},
                                {"page": "/category/electronics", "duration": 120},
                                {"page": "/product/laptop-abc", "duration": 180},
                                {"page": "/cart", "duration": 60},
                                {"page": "/checkout", "duration": 90}
                            ],
                            "actions": [
                                {"action": "view_product", "product_id": "laptop-abc", "timestamp": "2024-01-15T09:05:00Z"},
                                {"action": "add_to_cart", "product_id": "laptop-abc", "quantity": 1, "timestamp": "2024-01-15T09:15:00Z"},
                                {"action": "purchase", "order_id": "order_789", "amount": 1299.99, "timestamp": "2024-01-15T09:22:00Z"}
                            ]
                        }
                    ],
                    "products": {
                        "laptop-abc": {
                            "name": "é«˜æ€§èƒ½ç¬”è®°æœ¬ç”µè„‘",
                            "category": "electronics",
                            "price": 1299.99,
                            "tags": ["laptop", "gaming", "high-performance"],
                            "inventory": 50
                        }
                    },
                    "user_profiles": {
                        "user_12345": {
                            "age_range": "25-34",
                            "location": "åŒ—äº¬",
                            "purchase_history": 15,
                            "avg_order_value": 850.00,
                            "preferred_categories": ["electronics", "books", "sports"]
                        }
                    }
                },
                "analysis_parameters": {
                    "time_window": "last_30_days",
                    "min_confidence_threshold": 0.8,
                    "include_predictive_modeling": True,
                    "export_format": "json",
                    "generate_visualizations": False
                },
                "business_context": {
                    "company": "TechStoreç”µå•†å¹³å°",
                    "industry": "ç”µå­å•†åŠ¡",
                    "goals": ["æå‡è½¬åŒ–ç‡", "ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ", "å¢åŠ å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼"],
                    "constraints": ["æ•°æ®éšç§åˆè§„", "å®æ—¶æ€§è¦æ±‚", "æˆæœ¬æ§åˆ¶"]
                }
            },
            output_data={},
            instructions="""
            è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œåˆ†æï¼š
            1. æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
            2. ç”¨æˆ·è¡Œä¸ºæ¨¡å¼è¯†åˆ«
            3. è½¬åŒ–æ¼æ–—åˆ†æ
            4. å¼‚å¸¸è¡Œä¸ºæ£€æµ‹
            5. å•†ä¸šä»·å€¼è¯„ä¼°
            6. å¯æ“ä½œçš„ä¼˜åŒ–å»ºè®®
            
            è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
            - æä¾›æ‰§è¡Œæ‘˜è¦
            - åŒ…å«å…³é”®æŒ‡æ ‡å’ŒKPI
            - ç»™å‡ºç½®ä¿¡åº¦è¯„ä¼°
            - æä¾›å…·ä½“çš„è¡ŒåŠ¨å»ºè®®
            """,
            context_data={
                "execution_context": {
                    "triggered_by": "scheduled_analysis",
                    "execution_environment": "production",
                    "resource_allocation": {
                        "cpu_limit": "2 cores",
                        "memory_limit": "4GB",
                        "timeout": "300 seconds"
                    }
                },
                "workflow_metadata": {
                    "workflow_version": "v1.2.3",
                    "node_position": 2,
                    "total_nodes": 5,
                    "upstream_results": {
                        "data_validation": "passed",
                        "preprocessing": "completed"
                    }
                },
                "ai_configuration": {
                    "model_preferences": ["gpt-4", "claude-3"],
                    "temperature": 0.3,
                    "max_tokens": 2000,
                    "use_system_prompt": True
                }
            },
            priority=2,
            assigned_user_id=None,
            assigned_agent_id=uuid.uuid4(),
            estimated_duration=15,
            dependencies=["task_001", "task_002"],
            tags=["data-analysis", "user-behavior", "e-commerce", "ai-processing"],
            metadata={
                "created_by_system": "workflow_engine_v2",
                "cost_center": "analytics_department",
                "compliance_flags": ["gdpr", "ccpa"],
                "performance_requirements": {
                    "max_processing_time": 900,
                    "accuracy_threshold": 0.95,
                    "resource_efficiency": "high"
                }
            }
        )
        
        # åˆ›å»ºTaskå®ä¾‹
        task_instance = await task_repo.create_task(task_data)
        print(f"åˆ›å»ºTaskå®ä¾‹: {task_instance['task_instance_id']}")
        print()
        
        # 3. è¯¦ç»†è§£æTaskå®ä¾‹ç»“æ„
        print("3. Taskå®ä¾‹ç»“æ„è¯¦ç»†è§£æ...")
        print("=" * 60)
        
        # è·å–å®Œæ•´çš„Taskå®ä¾‹æ•°æ®
        full_task = await task_repo.get_task_by_id(task_instance['task_instance_id'])
        
        print("ğŸ” åŸºç¡€æ ‡è¯†ä¿¡æ¯:")
        print(f"  Task ID: {full_task['task_instance_id']}")
        print(f"  Node Instance ID: {full_task['node_instance_id']}")
        print(f"  Workflow Instance ID: {full_task['workflow_instance_id']}")
        print(f"  Processor ID: {full_task['processor_id']}")
        print()
        
        print("ğŸ“‹ ä»»åŠ¡åŸºæœ¬ä¿¡æ¯:")
        print(f"  æ ‡é¢˜: {full_task['task_title']}")
        print(f"  ç±»å‹: {full_task['task_type']}")
        print(f"  çŠ¶æ€: {full_task['status']}")
        print(f"  ä¼˜å…ˆçº§: {full_task['priority']}")
        print(f"  é¢„ä¼°æ—¶é•¿: {full_task['estimated_duration']} åˆ†é’Ÿ")
        print()
        
        print("ğŸ“ ä»»åŠ¡æè¿°:")
        description_lines = full_task['task_description'].strip().split('\n')
        for line in description_lines[:3]:  # æ˜¾ç¤ºå‰3è¡Œ
            print(f"  {line.strip()}")
        if len(description_lines) > 3:
            print(f"  ... (å…±{len(description_lines)}è¡Œ)")
        print()
        
        print("ğŸ“Š è¾“å…¥æ•°æ®ç»“æ„:")
        input_data = full_task['input_data']
        if isinstance(input_data, dict):
            print(f"  ä¸»è¦é”®: {list(input_data.keys())}")
            for key, value in input_data.items():
                if isinstance(value, dict):
                    print(f"  {key}: {{å­—å…¸, {len(value)} ä¸ªå­—æ®µ}}")
                elif isinstance(value, list):
                    print(f"  {key}: [åˆ—è¡¨, {len(value)} ä¸ªå…ƒç´ ]")
                else:
                    print(f"  {key}: {type(value).__name__}")
        print()
        
        print("ğŸ¯ å¤„ç†æŒ‡ä»¤:")
        instructions_lines = full_task['instructions'].strip().split('\n')
        for line in instructions_lines[:5]:
            if line.strip():
                print(f"  {line.strip()}")
        print()
        
        print("ğŸ”§ ä¸Šä¸‹æ–‡æ•°æ®:")
        context_data = full_task['context_data']
        if isinstance(context_data, dict):
            for key, value in context_data.items():
                if isinstance(value, dict):
                    print(f"  {key}: {{åŒ…å« {len(value)} ä¸ªé…ç½®é¡¹}}")
                else:
                    print(f"  {key}: {type(value).__name__}")
        print()
        
        print("ğŸ·ï¸ å…ƒæ•°æ®å’Œæ ‡ç­¾:")
        print(f"  æ ‡ç­¾: {full_task.get('tags', [])}")
        metadata = full_task.get('metadata', {})
        if isinstance(metadata, dict):
            for key, value in metadata.items():
                print(f"  {key}: {value}")
        print()
        
        print("â° æ—¶é—´ä¿¡æ¯:")
        print(f"  åˆ›å»ºæ—¶é—´: {full_task['created_at']}")
        print(f"  æ›´æ–°æ—¶é—´: {full_task.get('updated_at', 'N/A')}")
        print(f"  å¼€å§‹æ—¶é—´: {full_task.get('started_at', 'N/A')}")
        print(f"  å®Œæˆæ—¶é—´: {full_task.get('completed_at', 'N/A')}")
        print()
        
        print("ğŸ“ˆ æ‰§è¡Œç»Ÿè®¡:")
        print(f"  é‡è¯•æ¬¡æ•°: {full_task.get('retry_count', 0)}")
        print(f"  å®é™…è€—æ—¶: {full_task.get('actual_duration', 'N/A')} åˆ†é’Ÿ")
        print(f"  é”™è¯¯ä¿¡æ¯: {full_task.get('error_message', 'N/A')}")
        print()
        
        # 4. å±•ç¤ºTaskåœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„å…³è”å…³ç³»
        print("4. Taskå®ä¾‹çš„ç³»ç»Ÿå…³è”å…³ç³»...")
        print("=" * 60)
        
        print("ğŸ”— æ•°æ®åº“å…³è”:")
        print(f"  task_instance â†â†’ node_instance (èŠ‚ç‚¹å®ä¾‹)")
        print(f"  task_instance â†â†’ workflow_instance (å·¥ä½œæµå®ä¾‹)")
        print(f"  task_instance â†â†’ processor (å¤„ç†å™¨)")
        print(f"  processor â†â†’ user/agent (æ‰§è¡Œè€…)")
        print()
        
        print("ğŸ”„ ç”Ÿå‘½å‘¨æœŸçŠ¶æ€æµè½¬:")
        status_flow = [
            "PENDING (å¾…å¤„ç†)",
            "ASSIGNED (å·²åˆ†é…)", 
            "IN_PROGRESS (æ‰§è¡Œä¸­)",
            "COMPLETED (å·²å®Œæˆ)",
            "FAILED (å¤±è´¥)",
            "CANCELLED (å·²å–æ¶ˆ)"
        ]
        for i, status in enumerate(status_flow):
            if i < len(status_flow) - 1:
                print(f"  {status} â†’ ")
            else:
                print(f"  {status}")
        print()
        
        print("âš¡ å¤„ç†æµç¨‹:")
        process_steps = [
            "1. ExecutionService åˆ›å»ºTaskå®ä¾‹",
            "2. æ ¹æ®processor_typeè·¯ç”±åˆ°å¯¹åº”æœåŠ¡",
            "3. AgentTaskService æ¥æ”¶å¹¶æ’é˜Ÿ",
            "4. å·¥ä½œåç¨‹ä»é˜Ÿåˆ—å–å‡ºä»»åŠ¡",
            "5. è°ƒç”¨OpenAI APIè¿›è¡Œå¤„ç†",
            "6. æ›´æ–°TaskçŠ¶æ€å’Œç»“æœ",
            "7. é€šè¿‡å›è°ƒé€šçŸ¥ExecutionService",
            "8. ç»§ç»­å·¥ä½œæµä¸‹ä¸€æ­¥éª¤"
        ]
        for step in process_steps:
            print(f"  {step}")
        print()
        
        # 5. JSONæ ¼å¼å®Œæ•´è¾“å‡º
        print("5. å®Œæ•´Taskå®ä¾‹JSONç»“æ„ (ç¤ºä¾‹):")
        print("=" * 60)
        
        # åˆ›å»ºä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ç”¨äºæ¼”ç¤º
        sample_task = {
            "task_instance_id": str(full_task['task_instance_id']),
            "task_title": full_task['task_title'][:30] + "...",
            "task_type": full_task['task_type'],
            "status": full_task['status'],
            "input_data": {
                "raw_data": "{ ... å¤æ‚çš„ä¸šåŠ¡æ•°æ® ... }",
                "analysis_parameters": "{ ... åˆ†æé…ç½® ... }",
                "business_context": "{ ... ä¸šåŠ¡ä¸Šä¸‹æ–‡ ... }"
            },
            "context_data": {
                "execution_context": "{ ... æ‰§è¡Œç¯å¢ƒé…ç½® ... }",
                "workflow_metadata": "{ ... å·¥ä½œæµå…ƒæ•°æ® ... }",
                "ai_configuration": "{ ... AIæ¨¡å‹é…ç½® ... }"
            },
            "metadata": {
                "performance_requirements": "{ ... æ€§èƒ½è¦æ±‚ ... }",
                "compliance_flags": ["gdpr", "ccpa"]
            },
            "created_at": str(full_task['created_at']),
            "relationships": {
                "node_instance_id": str(full_task['node_instance_id']),
                "workflow_instance_id": str(full_task['workflow_instance_id']),
                "processor_id": str(full_task['processor_id'])
            }
        }
        
        print(json.dumps(sample_task, indent=2, ensure_ascii=False))
        print()
        
        print("=== Taskå®ä¾‹ç»“æ„è§£æå®Œæˆ ===")
        
        return task_instance
        
    except Exception as e:
        print(f"è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    finally:
        await close_database()


async def main():
    """ä¸»å‡½æ•°"""
    print("Taskå®ä¾‹ç»“æ„åˆ†æå·¥å…·")
    print("=" * 40)
    print()
    
    try:
        task = await create_and_analyze_task()
        
        if task:
            print(f"\nâœ… æˆåŠŸåˆ›å»ºå¹¶è§£æTaskå®ä¾‹: {task['task_instance_id']}")
            print("\nğŸ“š å…³é”®è¦ç‚¹:")
            print("â€¢ Taskå®ä¾‹åŒ…å«å®Œæ•´çš„ä¸šåŠ¡æ•°æ®å’Œæ‰§è¡Œä¸Šä¸‹æ–‡")
            print("â€¢ æ”¯æŒå¤æ‚çš„è¾“å…¥æ•°æ®ç»“æ„å’Œå¤„ç†æŒ‡ä»¤")
            print("â€¢ å…·å¤‡å®Œæ•´çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†å’ŒçŠ¶æ€è·Ÿè¸ª")
            print("â€¢ ä¸å·¥ä½œæµç³»ç»Ÿçš„å…¶ä»–ç»„ä»¶æ·±åº¦é›†æˆ")
            print("â€¢ æä¾›çµæ´»çš„å…ƒæ•°æ®å’Œæ ‡ç­¾ç³»ç»Ÿ")
        else:
            print("\nâŒ Taskå®ä¾‹åˆ›å»ºå¤±è´¥")
        
    except Exception as e:
        print(f"æ‰§è¡Œå¼‚å¸¸: {e}")
        return False
    
    return True


if __name__ == "__main__":
    asyncio.run(main())