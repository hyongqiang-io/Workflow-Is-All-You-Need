#!/usr/bin/env python3
"""
æµ‹è¯•æ–°å·¥ä½œæµæ¶æ„
Test script for the new workflow architecture
"""

import sys
import os
import uuid
import asyncio
import time
from datetime import datetime
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.abspath('.'))

# å¯¼å…¥æ–°æ¶æ„ç»„ä»¶
from workflow_framework.services.workflow_instance_context import WorkflowInstanceContext
from workflow_framework.services.workflow_instance_manager import get_instance_manager, cleanup_instance_manager
from workflow_framework.services.resource_cleanup_manager import ResourceCleanupManager
from workflow_framework.services.node_dependency_tracker import NodeDependencyTracker

# é¢œè‰²è¾“å‡º
class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    PURPLE = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    END = '\033[0m'

def print_test_header(test_name: str):
    """æ‰“å°æµ‹è¯•æ ‡é¢˜"""
    print(f"\n{Colors.BOLD}{Colors.BLUE}{'='*60}{Colors.END}")
    print(f"{Colors.BOLD}{Colors.BLUE}ğŸ§ª æµ‹è¯•: {test_name}{Colors.END}")
    print(f"{Colors.BOLD}{Colors.BLUE}{'='*60}{Colors.END}")

def print_success(message: str):
    """æ‰“å°æˆåŠŸæ¶ˆæ¯"""
    print(f"{Colors.GREEN}âœ… {message}{Colors.END}")

def print_error(message: str):
    """æ‰“å°é”™è¯¯æ¶ˆæ¯"""
    print(f"{Colors.RED}âŒ {message}{Colors.END}")

def print_info(message: str):
    """æ‰“å°ä¿¡æ¯æ¶ˆæ¯"""
    print(f"{Colors.CYAN}â„¹ï¸  {message}{Colors.END}")

def print_warning(message: str):
    """æ‰“å°è­¦å‘Šæ¶ˆæ¯"""
    print(f"{Colors.YELLOW}âš ï¸  {message}{Colors.END}")

async def test_workflow_instance_context():
    """æµ‹è¯• WorkflowInstanceContext åŸºæœ¬åŠŸèƒ½"""
    print_test_header("WorkflowInstanceContext åŸºæœ¬åŠŸèƒ½æµ‹è¯•")
    
    try:
        # åˆ›å»ºæµ‹è¯•å®ä¾‹
        workflow_instance_id = uuid.uuid4()
        workflow_base_id = uuid.uuid4()
        
        print_info(f"åˆ›å»ºå·¥ä½œæµå®ä¾‹ä¸Šä¸‹æ–‡: {workflow_instance_id}")
        context = WorkflowInstanceContext(workflow_instance_id, workflow_base_id)
        
        # æµ‹è¯•åŸºæœ¬å±æ€§
        assert context.workflow_instance_id == workflow_instance_id
        assert context.workflow_base_id == workflow_base_id
        assert context.execution_start_time is not None
        print_success("åŸºæœ¬å±æ€§åˆå§‹åŒ–æ­£ç¡®")
        
        # æµ‹è¯•èŠ‚ç‚¹ä¾èµ–æ³¨å†Œ
        node_instance_id = uuid.uuid4()
        node_base_id = uuid.uuid4()
        upstream_nodes = [uuid.uuid4(), uuid.uuid4()]
        
        result = await context.register_node_dependencies(
            node_instance_id, node_base_id, upstream_nodes
        )
        assert result == True
        print_success("èŠ‚ç‚¹ä¾èµ–æ³¨å†ŒæˆåŠŸ")
        
        # æµ‹è¯•ä¾èµ–ä¿¡æ¯æŸ¥è¯¢
        dep_info = context.get_node_dependency_info(node_instance_id)
        assert dep_info is not None
        assert dep_info['node_base_id'] == node_base_id
        assert len(dep_info['upstream_nodes']) == 2
        print_success("ä¾èµ–ä¿¡æ¯æŸ¥è¯¢æ­£ç¡®")
        
        # æµ‹è¯•èŠ‚ç‚¹æ‰§è¡ŒçŠ¶æ€ç®¡ç†
        result = await context.mark_node_executing(node_base_id, node_instance_id)
        assert result == True
        assert node_base_id in context.current_executing_nodes
        print_success("èŠ‚ç‚¹æ‰§è¡ŒçŠ¶æ€ç®¡ç†æ­£ç¡®")
        
        # æµ‹è¯•èŠ‚ç‚¹å®Œæˆ
        output_data = {"result": "test_output", "timestamp": datetime.utcnow().isoformat()}
        triggered_nodes = await context.mark_node_completed(
            node_base_id, node_instance_id, output_data
        )
        assert node_base_id in context.completed_nodes
        assert node_base_id not in context.current_executing_nodes
        print_success("èŠ‚ç‚¹å®ŒæˆçŠ¶æ€ç®¡ç†æ­£ç¡®")
        
        # æµ‹è¯•å·¥ä½œæµçŠ¶æ€æŸ¥è¯¢
        status = await context.get_workflow_status()
        assert status['workflow_instance_id'] == str(workflow_instance_id)
        assert status['completed_nodes'] == 1
        assert status['total_nodes'] == 1
        print_success("å·¥ä½œæµçŠ¶æ€æŸ¥è¯¢æ­£ç¡®")
        
        # æµ‹è¯•ä¸Šä¸‹æ–‡æ¸…ç†
        await context.cleanup()
        print_success("ä¸Šä¸‹æ–‡æ¸…ç†æˆåŠŸ")
        
        print_success("WorkflowInstanceContext æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print_error(f"WorkflowInstanceContext æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        return False

async def test_workflow_instance_manager():
    """æµ‹è¯• WorkflowInstanceManager ç®¡ç†åŠŸèƒ½"""
    print_test_header("WorkflowInstanceManager ç®¡ç†åŠŸèƒ½æµ‹è¯•")
    
    try:
        # è·å–å®ä¾‹ç®¡ç†å™¨
        print_info("è·å–å·¥ä½œæµå®ä¾‹ç®¡ç†å™¨")
        manager = await get_instance_manager()
        assert manager is not None
        print_success("å®ä¾‹ç®¡ç†å™¨è·å–æˆåŠŸ")
        
        # åˆ›å»ºå¤šä¸ªå·¥ä½œæµå®ä¾‹
        instances = []
        for i in range(3):
            workflow_instance_id = uuid.uuid4()
            workflow_base_id = uuid.uuid4()
            executor_id = uuid.uuid4()
            instance_name = f"test_workflow_{i}"
            
            context = await manager.create_instance(
                workflow_instance_id, workflow_base_id, executor_id, instance_name
            )
            instances.append((workflow_instance_id, context))
            print_success(f"åˆ›å»ºå®ä¾‹ {i+1}: {instance_name}")
        
        # æµ‹è¯•å®ä¾‹æŸ¥è¯¢
        for workflow_instance_id, expected_context in instances:
            retrieved_context = await manager.get_instance(workflow_instance_id)
            assert retrieved_context is not None
            assert retrieved_context.workflow_instance_id == workflow_instance_id
        print_success("å®ä¾‹æŸ¥è¯¢åŠŸèƒ½æ­£ç¡®")
        
        # æµ‹è¯•å®ä¾‹åˆ—è¡¨
        instance_list = await manager.list_instances()
        assert len(instance_list) >= 3
        print_success(f"å®ä¾‹åˆ—è¡¨æŸ¥è¯¢æ­£ç¡®: {len(instance_list)} ä¸ªå®ä¾‹")
        
        # æµ‹è¯•å®ä¾‹çŠ¶æ€æ›´æ–°
        test_instance_id = instances[0][0]
        result = await manager.update_instance_status(test_instance_id, 'COMPLETED')
        assert result == True
        print_success("å®ä¾‹çŠ¶æ€æ›´æ–°æˆåŠŸ")
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        stats = await manager.get_manager_stats()
        assert stats['total_created'] >= 3
        assert stats['instances_count'] >= 3
        print_success(f"ç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯æ­£ç¡®: å·²åˆ›å»º {stats['total_created']} ä¸ªå®ä¾‹")
        
        # æµ‹è¯•å®ä¾‹ç§»é™¤
        removed_count = 0
        for workflow_instance_id, context in instances:
            # å…ˆæ ‡è®°ä¸ºå®ŒæˆçŠ¶æ€
            status = await context.get_workflow_status()
            if status['status'] != 'COMPLETED':
                await manager.update_instance_status(workflow_instance_id, 'COMPLETED')
            
            result = await manager.remove_instance(workflow_instance_id)
            if result:
                removed_count += 1
        
        print_success(f"å®ä¾‹ç§»é™¤æˆåŠŸ: {removed_count} ä¸ªå®ä¾‹")
        
        print_success("WorkflowInstanceManager æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print_error(f"WorkflowInstanceManager æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        return False

async def test_concurrent_safety():
    """æµ‹è¯•å¹¶å‘å®‰å…¨æ€§"""
    print_test_header("å¹¶å‘å®‰å…¨æ€§æµ‹è¯•")
    
    try:
        # åˆ›å»ºä¸€ä¸ªå·¥ä½œæµå®ä¾‹ä¸Šä¸‹æ–‡
        workflow_instance_id = uuid.uuid4()
        workflow_base_id = uuid.uuid4()
        context = WorkflowInstanceContext(workflow_instance_id, workflow_base_id)
        
        # å¹¶å‘æ³¨å†ŒèŠ‚ç‚¹ä¾èµ–
        async def register_nodes_concurrently():
            tasks = []
            for i in range(10):
                node_instance_id = uuid.uuid4()
                node_base_id = uuid.uuid4()
                upstream_nodes = [uuid.uuid4() for _ in range(2)]
                
                task = context.register_node_dependencies(
                    node_instance_id, node_base_id, upstream_nodes
                )
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            success_count = sum(1 for r in results if r is True)
            return success_count
        
        print_info("æ‰§è¡Œå¹¶å‘èŠ‚ç‚¹æ³¨å†Œæµ‹è¯• (10ä¸ªèŠ‚ç‚¹)")
        success_count = await register_nodes_concurrently()
        assert success_count == 10
        print_success(f"å¹¶å‘èŠ‚ç‚¹æ³¨å†ŒæˆåŠŸ: {success_count}/10")
        
        # å¹¶å‘çŠ¶æ€æ›´æ–°æµ‹è¯•
        async def concurrent_status_updates():
            node_ids = list(context.node_dependencies.keys())[:5]  # å–å‰5ä¸ªèŠ‚ç‚¹
            tasks = []
            
            for i, node_instance_id in enumerate(node_ids):
                dep_info = context.get_node_dependency_info(node_instance_id)
                node_base_id = dep_info['node_base_id']
                
                # äº¤æ›¿æ‰§è¡Œä¸åŒçš„çŠ¶æ€æ›´æ–°
                if i % 2 == 0:
                    task = context.mark_node_executing(node_base_id, node_instance_id)
                else:
                    task = context.mark_node_completed(
                        node_base_id, node_instance_id, {"result": f"test_{i}"}
                    )
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            success_count = sum(1 for r in results if r not in [False, None] and not isinstance(r, Exception))
            return success_count
        
        print_info("æ‰§è¡Œå¹¶å‘çŠ¶æ€æ›´æ–°æµ‹è¯•")
        success_count = await concurrent_status_updates()
        print_success(f"å¹¶å‘çŠ¶æ€æ›´æ–°æˆåŠŸ: {success_count} ä¸ªæ“ä½œ")
        
        # å¹¶å‘æŸ¥è¯¢æµ‹è¯•
        async def concurrent_queries():
            tasks = []
            for _ in range(20):
                task = context.get_workflow_status()
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            success_count = sum(1 for r in results if isinstance(r, dict))
            return success_count
        
        print_info("æ‰§è¡Œå¹¶å‘æŸ¥è¯¢æµ‹è¯• (20ä¸ªå¹¶å‘æŸ¥è¯¢)")
        success_count = await concurrent_queries()
        assert success_count == 20
        print_success(f"å¹¶å‘æŸ¥è¯¢æˆåŠŸ: {success_count}/20")
        
        await context.cleanup()
        print_success("å¹¶å‘å®‰å…¨æ€§æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print_error(f"å¹¶å‘å®‰å…¨æ€§æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        return False

async def test_resource_cleanup():
    """æµ‹è¯•èµ„æºæ¸…ç†æœºåˆ¶"""
    print_test_header("èµ„æºæ¸…ç†æœºåˆ¶æµ‹è¯•")
    
    try:
        # åˆ›å»ºèµ„æºæ¸…ç†ç®¡ç†å™¨
        cleanup_manager = ResourceCleanupManager()
        
        # æµ‹è¯•è‡ªå®šä¹‰æ¸…ç†å™¨æ³¨å†Œ
        cleanup_count = 0
        
        def custom_cleaner():
            nonlocal cleanup_count
            cleanup_count += 1
        
        result = cleanup_manager.register_cleaner("test_cleaner", custom_cleaner, 1)
        assert result == True
        print_success("è‡ªå®šä¹‰æ¸…ç†å™¨æ³¨å†ŒæˆåŠŸ")
        
        # æµ‹è¯•ä¸´æ—¶æ–‡ä»¶è·Ÿè¸ª
        import tempfile
        temp_file = tempfile.NamedTemporaryFile(delete=False, prefix="workflow_test_")
        temp_file.write(b"test data")
        temp_file.close()
        
        cleanup_manager.track_temp_file(temp_file.name)
        print_success(f"ä¸´æ—¶æ–‡ä»¶è·Ÿè¸ª: {temp_file.name}")
        
        # å¯åŠ¨æ¸…ç†ç®¡ç†å™¨
        await cleanup_manager.start_manager()
        print_success("æ¸…ç†ç®¡ç†å™¨å¯åŠ¨æˆåŠŸ")
        
        # ç­‰å¾…æ¸…ç†å™¨è¿è¡Œ
        await asyncio.sleep(2)
        
        # è¿è¡Œè‡ªå®šä¹‰æ¸…ç†å™¨
        await cleanup_manager.run_custom_cleaners()
        assert cleanup_count > 0
        print_success(f"è‡ªå®šä¹‰æ¸…ç†å™¨æ‰§è¡ŒæˆåŠŸ: {cleanup_count} æ¬¡")
        
        # å¼ºåˆ¶æ‰§è¡Œå…¨é¢æ¸…ç†
        await cleanup_manager.force_cleanup_all()
        print_success("å¼ºåˆ¶æ¸…ç†æ‰§è¡ŒæˆåŠŸ")
        
        # è·å–æ¸…ç†ç»Ÿè®¡
        stats = cleanup_manager.get_cleanup_stats()
        assert stats['total_cleanups'] >= 0
        print_success(f"æ¸…ç†ç»Ÿè®¡ä¿¡æ¯æ­£ç¡®: æ€»æ¸…ç†æ¬¡æ•° {stats['total_cleanups']}")
        
        # åœæ­¢æ¸…ç†ç®¡ç†å™¨
        await cleanup_manager.stop_manager()
        print_success("æ¸…ç†ç®¡ç†å™¨åœæ­¢æˆåŠŸ")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        try:
            os.unlink(temp_file.name)
        except:
            pass
        
        print_success("èµ„æºæ¸…ç†æœºåˆ¶æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print_error(f"èµ„æºæ¸…ç†æœºåˆ¶æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        return False

async def test_dependency_tracker():
    """æµ‹è¯•èŠ‚ç‚¹ä¾èµ–è·Ÿè¸ªå™¨"""
    print_test_header("NodeDependencyTracker åŠŸèƒ½æµ‹è¯•")
    
    try:
        # åˆ›å»ºä¾èµ–è·Ÿè¸ªå™¨
        tracker = NodeDependencyTracker()
        
        # æµ‹è¯•ç¼“å­˜ç»Ÿè®¡
        cache_stats = await tracker.get_cache_stats()
        assert 'cache_hits' in cache_stats
        assert 'cache_misses' in cache_stats
        print_success("ç¼“å­˜ç»Ÿè®¡åŠŸèƒ½æ­£ç¡®")
        
        # æµ‹è¯•ç¼“å­˜æ¸…ç†
        await tracker.clear_cache()
        print_success("ç¼“å­˜æ¸…ç†åŠŸèƒ½æ­£ç¡®")
        
        # æ³¨æ„ï¼šç”±äºæ²¡æœ‰å®é™…çš„æ•°æ®åº“è¿æ¥ï¼Œä¸Šæ¸¸/ä¸‹æ¸¸èŠ‚ç‚¹æŸ¥è¯¢ä¼šè¿”å›ç©ºç»“æœ
        # ä½†æˆ‘ä»¬å¯ä»¥æµ‹è¯•æ–¹æ³•è°ƒç”¨ä¸ä¼šå‡ºé”™
        workflow_base_id = uuid.uuid4()
        node_base_id = uuid.uuid4()
        
        upstream_nodes = await tracker.get_immediate_upstream_nodes(workflow_base_id, node_base_id)
        assert isinstance(upstream_nodes, list)
        print_success("ä¸Šæ¸¸èŠ‚ç‚¹æŸ¥è¯¢æ–¹æ³•æ­£å¸¸")
        
        downstream_nodes = await tracker.get_immediate_downstream_nodes(workflow_base_id, node_base_id)
        assert isinstance(downstream_nodes, list)
        print_success("ä¸‹æ¸¸èŠ‚ç‚¹æŸ¥è¯¢æ–¹æ³•æ­£å¸¸")
        
        # æµ‹è¯•å·¥ä½œæµä¾èµ–å›¾æ„å»º
        dependency_graph = await tracker.build_workflow_dependency_graph(workflow_base_id)
        assert isinstance(dependency_graph, dict)
        print_success("ä¾èµ–å›¾æ„å»ºæ–¹æ³•æ­£å¸¸")
        
        # æµ‹è¯•ä¾èµ–éªŒè¯
        validation_result = await tracker.validate_workflow_dependencies(workflow_base_id)
        assert isinstance(validation_result, dict)
        assert 'is_valid' in validation_result
        print_success("ä¾èµ–éªŒè¯æ–¹æ³•æ­£å¸¸")
        
        print_success("NodeDependencyTracker åŠŸèƒ½æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print_error(f"NodeDependencyTracker æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        return False

async def test_performance_comparison():
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    print_test_header("æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    
    try:
        print_info("æµ‹è¯•æ–°æ¶æ„çš„æ€§èƒ½ç‰¹å¾...")
        
        # æµ‹è¯•å·¥ä½œæµå®ä¾‹åˆ›å»ºæ€§èƒ½
        start_time = time.time()
        instances = []
        
        for i in range(100):
            workflow_instance_id = uuid.uuid4()
            workflow_base_id = uuid.uuid4()
            context = WorkflowInstanceContext(workflow_instance_id, workflow_base_id)
            instances.append(context)
        
        create_time = time.time() - start_time
        print_success(f"åˆ›å»º100ä¸ªå·¥ä½œæµå®ä¾‹è€—æ—¶: {create_time:.3f}ç§’")
        
        # æµ‹è¯•èŠ‚ç‚¹æ³¨å†Œæ€§èƒ½
        start_time = time.time()
        for i, context in enumerate(instances[:10]):  # åªæµ‹è¯•å‰10ä¸ª
            for j in range(10):  # æ¯ä¸ªå®ä¾‹10ä¸ªèŠ‚ç‚¹
                node_instance_id = uuid.uuid4()
                node_base_id = uuid.uuid4()
                upstream_nodes = [uuid.uuid4() for _ in range(2)]
                await context.register_node_dependencies(
                    node_instance_id, node_base_id, upstream_nodes
                )
        
        register_time = time.time() - start_time
        print_success(f"æ³¨å†Œ1000ä¸ªèŠ‚ç‚¹ä¾èµ–è€—æ—¶: {register_time:.3f}ç§’")
        
        # æµ‹è¯•çŠ¶æ€æŸ¥è¯¢æ€§èƒ½
        start_time = time.time()
        for context in instances[:10]:
            for _ in range(10):
                await context.get_workflow_status()
        
        query_time = time.time() - start_time
        print_success(f"æ‰§è¡Œ100æ¬¡çŠ¶æ€æŸ¥è¯¢è€—æ—¶: {query_time:.3f}ç§’")
        
        # æ¸…ç†æµ‹è¯•å®ä¾‹
        for context in instances:
            await context.cleanup()
        
        print_success("æ€§èƒ½æµ‹è¯•å®Œæˆ!")
        print_info(f"æ€§èƒ½æ‘˜è¦:")
        print_info(f"  - å®ä¾‹åˆ›å»º: {create_time/100*1000:.2f}ms/å®ä¾‹")
        print_info(f"  - èŠ‚ç‚¹æ³¨å†Œ: {register_time/1000*1000:.2f}ms/èŠ‚ç‚¹")
        print_info(f"  - çŠ¶æ€æŸ¥è¯¢: {query_time/100*1000:.2f}ms/æŸ¥è¯¢")
        
        return True
        
    except Exception as e:
        print_error(f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print(f"{Colors.BOLD}{Colors.PURPLE}")
    print("ğŸš€ æ–°å·¥ä½œæµæ¶æ„æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    print(f"{Colors.END}")
    
    test_results = []
    
    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("WorkflowInstanceContextåŸºæœ¬åŠŸèƒ½", test_workflow_instance_context),
        ("WorkflowInstanceManagerç®¡ç†åŠŸèƒ½", test_workflow_instance_manager),
        ("å¹¶å‘å®‰å…¨æ€§", test_concurrent_safety),
        ("èµ„æºæ¸…ç†æœºåˆ¶", test_resource_cleanup),
        ("NodeDependencyTrackeråŠŸèƒ½", test_dependency_tracker),
        ("æ€§èƒ½å¯¹æ¯”", test_performance_comparison),
    ]
    
    for test_name, test_func in tests:
        try:
            result = await test_func()
            test_results.append((test_name, result))
        except Exception as e:
            print_error(f"æµ‹è¯• {test_name} æ‰§è¡Œå¼‚å¸¸: {e}")
            test_results.append((test_name, False))
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print(f"\n{Colors.BOLD}{Colors.PURPLE}ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“{Colors.END}")
    print("=" * 60)
    
    passed = sum(1 for _, result in test_results if result)
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        color = Colors.GREEN if result else Colors.RED
        print(f"{color}{status}{Colors.END} - {test_name}")
    
    print("=" * 60)
    success_rate = (passed / total) * 100
    if success_rate == 100:
        print(f"{Colors.GREEN}{Colors.BOLD}ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! ({passed}/{total}, {success_rate:.1f}%){Colors.END}")
    else:
        print(f"{Colors.YELLOW}{Colors.BOLD}âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ ({passed}/{total}, {success_rate:.1f}%){Colors.END}")
    
    # æ¸…ç†èµ„æº
    try:
        await cleanup_instance_manager()
        print_info("å…¨å±€èµ„æºæ¸…ç†å®Œæˆ")
    except Exception as e:
        print_warning(f"å…¨å±€èµ„æºæ¸…ç†æ—¶å‡ºç°è­¦å‘Š: {e}")
    
    return success_rate == 100

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­{Colors.END}")
        sys.exit(1)
    except Exception as e:
        print(f"{Colors.RED}æµ‹è¯•æ‰§è¡Œå‡ºç°å¼‚å¸¸: {e}{Colors.END}")
        sys.exit(1)