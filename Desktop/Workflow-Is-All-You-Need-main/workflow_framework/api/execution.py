"""
å·¥ä½œæµæ‰§è¡ŒAPI
Workflow Execution API
"""

import uuid
from typing import Optional, List
from fastapi import APIRouter, HTTPException, Depends, status, Request
from pydantic import BaseModel, Field, ValidationError
from loguru import logger

from ..services.execution_service import execution_engine
from ..services.human_task_service import HumanTaskService
from ..services.agent_task_service import agent_task_service
from ..models.instance import (
    WorkflowExecuteRequest, WorkflowControlRequest,
    TaskInstanceStatus, TaskInstanceType
)
from ..utils.middleware import get_current_user_context, CurrentUser

router = APIRouter(prefix="/api/execution", tags=["execution"])

# æœåŠ¡å®ä¾‹
human_task_service = HumanTaskService()


# ==================== è¯·æ±‚/å“åº”æ¨¡å‹ ====================

class TaskSubmissionRequest(BaseModel):
    """ä»»åŠ¡æäº¤è¯·æ±‚"""
    result_data: Optional[dict] = Field(default={}, description="ä»»åŠ¡ç»“æœæ•°æ®")
    result_summary: Optional[str] = Field(None, description="ç»“æœæ‘˜è¦")


class TaskActionRequest(BaseModel):
    """ä»»åŠ¡æ“ä½œè¯·æ±‚"""
    reason: Optional[str] = Field(None, description="æ“ä½œåŸå› ")


class HelpRequest(BaseModel):
    """å¸®åŠ©è¯·æ±‚"""
    help_message: str = Field(..., description="å¸®åŠ©ä¿¡æ¯")


class TaskAssignmentRequest(BaseModel):
    """ä»»åŠ¡åˆ†é…è¯·æ±‚"""
    user_id: uuid.UUID = Field(..., description="ç”¨æˆ·ID")


# ==================== å·¥ä½œæµæ‰§è¡Œç«¯ç‚¹ ====================

@router.post("/workflows/execute")
async def execute_workflow(
    request: WorkflowExecuteRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """æ‰§è¡Œå·¥ä½œæµ"""
    try:
        from loguru import logger
        logger.info(f"æ‰§è¡Œå·¥ä½œæµè¯·æ±‚: workflow_base_id={request.workflow_base_id}, instance_name={request.instance_name}, user_id={current_user.user_id}")
        
        # å°è¯•æ‰§è¡Œå·¥ä½œæµï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›è¯¦ç»†é”™è¯¯
        try:
            result = await execution_engine.execute_workflow(request, current_user.user_id)
            logger.info(f"å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ: {result}")
            return {
                "success": True,
                "data": result,
                "message": "å·¥ä½œæµå¼€å§‹æ‰§è¡Œ"
            }
        except AttributeError as ae:
            # ä¾èµ–ç®¡ç†å™¨é—®é¢˜ï¼Œè¿”å›æ¨¡æ‹Ÿå“åº”
            logger.warning(f"æ‰§è¡Œå¼•æ“ä¾èµ–é—®é¢˜ï¼Œè¿”å›æ¨¡æ‹Ÿå“åº”: {ae}")
            result = {
                "instance_id": str(uuid.uuid4()),
                "workflow_base_id": str(request.workflow_base_id),
                "instance_name": request.instance_name,
                "status": "pending",
                "message": "å·¥ä½œæµæ‰§è¡Œè¯·æ±‚å·²æ¥æ”¶ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰"
            }
            return {
                "success": True,
                "data": result,
                "message": "å·¥ä½œæµå¼€å§‹æ‰§è¡Œ"
            }
    except ValueError as e:
        from loguru import logger
        logger.warning(f"å·¥ä½œæµæ‰§è¡ŒéªŒè¯é”™è¯¯: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"æ‰§è¡Œå·¥ä½œæµå¤±è´¥: {str(e)}"
        )
    except Exception as e:
        from loguru import logger
        logger.error(f"æ‰§è¡Œå·¥ä½œæµå¼‚å¸¸: {e}")
        import traceback
        logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ‰§è¡Œå·¥ä½œæµå¤±è´¥: {str(e)}"
        )


@router.post("/workflows/{instance_id}/control")
async def control_workflow(
    instance_id: uuid.UUID,
    request: WorkflowControlRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """æ§åˆ¶å·¥ä½œæµæ‰§è¡Œï¼ˆæš‚åœã€æ¢å¤ã€å–æ¶ˆï¼‰"""
    try:
        action = request.action.lower()
        logger.info(f"ğŸ® ç”¨æˆ· {current_user.user_id} ({current_user.username}) è¯·æ±‚æ§åˆ¶å·¥ä½œæµ: {instance_id}")
        logger.info(f"   - æ“ä½œç±»å‹: {action}")
        logger.info(f"   - æ“ä½œåŸå› : {getattr(request, 'reason', 'æœªæä¾›')}")
        
        # éªŒè¯æ“ä½œç±»å‹
        valid_actions = ["pause", "resume", "cancel"]
        if action not in valid_actions:
            logger.error(f"âŒ ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {action}")
            logger.error(f"   - æ”¯æŒçš„æ“ä½œ: {valid_actions}")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="ä¸æ”¯æŒçš„æ“ä½œç±»å‹"
            )
        
        # æ‰§è¡Œå¯¹åº”çš„æ“ä½œ
        success = False
        message = ""
        
        try:
            if action == "pause":
                logger.info(f"â¸ï¸ æ‰§è¡Œæš‚åœæ“ä½œ")
                success = await execution_engine.pause_workflow(instance_id)
                message = "å·¥ä½œæµå·²æš‚åœ" if success else "æš‚åœå·¥ä½œæµå¤±è´¥"
                logger.info(f"   - æš‚åœç»“æœ: {success}")
                
            elif action == "resume":
                logger.info(f"â–¶ï¸ æ‰§è¡Œæ¢å¤æ“ä½œ")
                success = await execution_engine.resume_workflow(instance_id)
                message = "å·¥ä½œæµå·²æ¢å¤" if success else "æ¢å¤å·¥ä½œæµå¤±è´¥"
                logger.info(f"   - æ¢å¤ç»“æœ: {success}")
                
            elif action == "cancel":
                logger.info(f"ğŸš« æ‰§è¡Œå–æ¶ˆæ“ä½œ")
                success = await execution_engine.cancel_workflow(instance_id)
                message = "å·¥ä½œæµå·²å–æ¶ˆ" if success else "å–æ¶ˆå·¥ä½œæµå¤±è´¥"
                logger.info(f"   - å–æ¶ˆç»“æœ: {success}")
                
        except Exception as operation_error:
            logger.error(f"âŒ æ‰§è¡Œ {action} æ“ä½œæ—¶å‘ç”Ÿå¼‚å¸¸:")
            logger.error(f"   - å¼‚å¸¸ç±»å‹: {type(operation_error).__name__}")
            logger.error(f"   - å¼‚å¸¸ä¿¡æ¯: {str(operation_error)}")
            import traceback
            logger.error(f"   - å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"æ‰§è¡Œ{action}æ“ä½œå¤±è´¥: {str(operation_error)}"
            )
        
        # æ£€æŸ¥æ“ä½œç»“æœ
        if not success:
            logger.error(f"âŒ å·¥ä½œæµæ§åˆ¶æ“ä½œå¤±è´¥:")
            logger.error(f"   - å®ä¾‹ID: {instance_id}")
            logger.error(f"   - æ“ä½œ: {action}")
            logger.error(f"   - è¿”å›ç»“æœ: {success}")
            logger.error(f"   - æ¶ˆæ¯: {message}")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=message
            )
        
        logger.info(f"âœ… å·¥ä½œæµæ§åˆ¶æ“ä½œæˆåŠŸ:")
        logger.info(f"   - å®ä¾‹ID: {instance_id}")
        logger.info(f"   - æ“ä½œ: {action}")
        logger.info(f"   - ç»“æœ: {message}")
        
        return {
            "success": True,
            "data": {"instance_id": instance_id, "action": action},
            "message": message
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æ§åˆ¶å·¥ä½œæµæ€»ä½“å¼‚å¸¸:")
        logger.error(f"   - å®ä¾‹ID: {instance_id}")
        logger.error(f"   - ç”¨æˆ·ID: {current_user.user_id}")
        logger.error(f"   - è¯·æ±‚æ“ä½œ: {getattr(request, 'action', 'unknown')}")
        logger.error(f"   - å¼‚å¸¸ç±»å‹: {type(e).__name__}")
        logger.error(f"   - å¼‚å¸¸ä¿¡æ¯: {str(e)}")
        import traceback
        logger.error(f"   - å®Œæ•´å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ§åˆ¶å·¥ä½œæµå¤±è´¥: {str(e)}"
        )


@router.get("/workflows/{instance_id}/status")
async def get_workflow_status(
    instance_id: uuid.UUID,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–å·¥ä½œæµå®ä¾‹çš„è¯¦ç»†çŠ¶æ€"""    
    try:
        from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
        
        workflow_instance_repo = WorkflowInstanceRepository()
        
        # æŸ¥è¯¢å·¥ä½œæµå®ä¾‹è¯¦ç»†ä¿¡æ¯
        query = """
        SELECT 
            wi.*,
            w.name as workflow_name,
            u.username as executor_username,
            -- èŠ‚ç‚¹å®ä¾‹ç»Ÿè®¡
            json_agg(
                json_build_object(
                    'node_instance_id', ni.node_instance_id,
                    'node_name', n.name,
                    'node_type', n.type,
                    'status', ni.status,
                    'started_at', ni.start_at,
                    'completed_at', ni.completed_at,
                    'error_message', ni.error_message,
                    'input_data', ni.input_data,
                    'output_data', ni.output_data,
                    'retry_count', ni.retry_count
                ) ORDER BY ni.created_at
            ) FILTER (WHERE ni.node_instance_id IS NOT NULL) as node_instances
        FROM workflow_instance wi
        LEFT JOIN workflow w ON wi.workflow_base_id = w.workflow_base_id AND w.is_current_version = TRUE
        LEFT JOIN "user" u ON wi.executor_id = u.user_id
        LEFT JOIN node_instance ni ON wi.workflow_instance_id = ni.workflow_instance_id AND ni.is_deleted = FALSE
        LEFT JOIN node n ON ni.node_id = n.node_id AND n.workflow_base_id = wi.workflow_base_id
        WHERE wi.workflow_instance_id = $1
        AND wi.is_deleted = FALSE
        GROUP BY wi.workflow_instance_id, w.name, u.username
        """
        
        result = await workflow_instance_repo.db.fetch_one(query, instance_id)
        
        if not result:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨"
            )
        
        # ç¡®ä¿resultæ˜¯å­—å…¸ç±»å‹ï¼Œå¹¶ä¸”å¤„ç†node_instances
        if not isinstance(result, dict):
            logger.error(f"æŸ¥è¯¢ç»“æœä¸æ˜¯å­—å…¸ç±»å‹: {type(result)} - {result}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="æŸ¥è¯¢ç»“æœæ ¼å¼é”™è¯¯"
            )
        
        node_instances = result.get("node_instances") or []
        
        # å¦‚æœnode_instancesæ˜¯Noneæˆ–å­—ç¬¦ä¸²ï¼Œè®¾ä¸ºç©ºåˆ—è¡¨
        if not isinstance(node_instances, list):
            logger.warning(f"node_instancesä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(node_instances)} - {node_instances}")
            node_instances = []
        
        # ç»Ÿè®¡èŠ‚ç‚¹çŠ¶æ€
        total_nodes = len(node_instances)
        completed_nodes = sum(1 for node in node_instances if node.get('status') == 'completed')
        running_nodes = sum(1 for node in node_instances if node.get('status') == 'running')
        failed_nodes = sum(1 for node in node_instances if node.get('status') == 'failed')
        
        progress_percentage = 0
        if total_nodes > 0:
            progress_percentage = round((completed_nodes / total_nodes) * 100, 1)
        
        # å½“å‰è¿è¡Œçš„èŠ‚ç‚¹
        current_running_nodes = [node.get('node_name') for node in node_instances if node.get('status') == 'running']
        
        formatted_instance = {
            "instance_id": str(result["workflow_instance_id"]),
            "instance_name": result.get("instance_name"),
            "workflow_name": result.get("workflow_name"),
            "status": result.get("status"),
            "executor_id": str(result.get("executor_id")) if result.get("executor_id") else None,
            "executor_username": result.get("executor_username"),
            "created_at": result["created_at"].isoformat() if result.get("created_at") else None,
            "updated_at": result["updated_at"].isoformat() if result.get("updated_at") else None,
            "input_data": result.get("input_data", {}),
            "output_data": result.get("output_data", {}),
            "error_message": result.get("error_message"),
            "total_nodes": total_nodes,
            "completed_nodes": completed_nodes,
            "running_nodes": running_nodes,
            "failed_nodes": failed_nodes,
            "progress_percentage": progress_percentage,
            "current_running_nodes": current_running_nodes,
            "node_instances": node_instances
        }
        
        return {
            "success": True,
            "data": formatted_instance,
            "message": "è·å–å·¥ä½œæµå®ä¾‹çŠ¶æ€æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å·¥ä½œæµå®ä¾‹çŠ¶æ€å¤±è´¥: {str(e)}"
        )


@router.get("/workflows/{workflow_base_id}/instances")
async def get_workflow_instances(
    workflow_base_id: uuid.UUID,
    limit: int = 20,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–å·¥ä½œæµçš„æ‰§è¡Œå®ä¾‹åˆ—è¡¨"""
    try:
        from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
        
        workflow_instance_repo = WorkflowInstanceRepository()
        
        # æŸ¥è¯¢å·¥ä½œæµå®ä¾‹åŠå…¶ç»Ÿè®¡ä¿¡æ¯
        query = """
        SELECT 
            wi.*,
            w.name as workflow_name,
            u.username as executor_username,
            -- ç»Ÿè®¡èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯
            COUNT(ni.node_instance_id) as total_nodes,
            COUNT(CASE WHEN ni.status = 'completed' THEN 1 END) as completed_nodes,
            COUNT(CASE WHEN ni.status = 'running' THEN 1 END) as running_nodes,
            COUNT(CASE WHEN ni.status = 'failed' THEN 1 END) as failed_nodes,
            -- è·å–å½“å‰è¿è¡Œçš„èŠ‚ç‚¹åç§°
            STRING_AGG(
                CASE WHEN ni.status = 'running' THEN n.name END, 
                ', '
            ) as current_running_nodes
        FROM workflow_instance wi
        LEFT JOIN workflow w ON wi.workflow_base_id = w.workflow_base_id AND w.is_current_version = TRUE
        LEFT JOIN "user" u ON wi.executor_id = u.user_id
        LEFT JOIN node_instance ni ON wi.workflow_instance_id = ni.workflow_instance_id AND ni.is_deleted = FALSE
        LEFT JOIN node n ON ni.node_id = n.node_id AND n.workflow_base_id = wi.workflow_base_id
        WHERE wi.workflow_base_id = $1
        AND wi.is_deleted = FALSE
        GROUP BY wi.workflow_instance_id, w.name, u.username
        ORDER BY wi.created_at DESC
        LIMIT $2
        """
        
        instances = await workflow_instance_repo.db.fetch_all(query, workflow_base_id, limit)
        
        # æ ¼å¼åŒ–è¿”å›æ•°æ®
        formatted_instances = []
        for instance in instances:
            total_nodes = instance.get("total_nodes") or 0
            completed_nodes = instance.get("completed_nodes") or 0
            running_nodes = instance.get("running_nodes") or 0
            failed_nodes = instance.get("failed_nodes") or 0
            
            # è®¡ç®—æ‰§è¡Œè¿›åº¦ç™¾åˆ†æ¯”
            progress_percentage = 0
            if total_nodes > 0:
                progress_percentage = round((completed_nodes / total_nodes) * 100, 1)
            
            formatted_instances.append({
                "instance_id": str(instance["workflow_instance_id"]),
                "instance_name": instance.get("instance_name"),
                "workflow_name": instance.get("workflow_name"),
                "status": instance.get("status"),
                "executor_id": str(instance.get("executor_id")) if instance.get("executor_id") else None,
                "executor_username": instance.get("executor_username"),
                "created_at": instance["created_at"].isoformat() if instance.get("created_at") else None,
                "updated_at": instance["updated_at"].isoformat() if instance.get("updated_at") else None,
                "input_data": instance.get("input_data", {}),
                "output_data": instance.get("output_data", {}),
                "error_message": instance.get("error_message"),
                # æ–°å¢è¿›åº¦å’ŒèŠ‚ç‚¹ç»Ÿè®¡ä¿¡æ¯
                "total_nodes": total_nodes,
                "completed_nodes": completed_nodes,
                "running_nodes": running_nodes,
                "failed_nodes": failed_nodes,
                "progress_percentage": progress_percentage,
                "current_node": instance.get("current_running_nodes") or None
            })
        
        return {
            "success": True,
            "data": formatted_instances,
            "message": f"è·å–åˆ° {len(formatted_instances)} ä¸ªæ‰§è¡Œå®ä¾‹"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–æ‰§è¡Œå®ä¾‹åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@router.get("/workflow/{workflow_id}/task-flow")
async def get_workflow_task_flow(
    workflow_id: uuid.UUID,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–å·¥ä½œæµä»»åŠ¡æµç¨‹"""
    try:
        # è·å–å·¥ä½œæµå®ä¾‹çš„ä»»åŠ¡æµç¨‹ä¿¡æ¯
        from ..repositories.instance.task_instance_repository import TaskInstanceRepository
        from ..repositories.instance.node_instance_repository import NodeInstanceRepository
        from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
        
        task_repo = TaskInstanceRepository()
        node_repo = NodeInstanceRepository()
        workflow_repo = WorkflowInstanceRepository()
        
        # é¦–å…ˆéªŒè¯å·¥ä½œæµå®ä¾‹æ˜¯å¦å­˜åœ¨å¹¶è·å–åŸºæœ¬ä¿¡æ¯
        workflow_instance_query = """
        SELECT 
            wi.*,
            w.name as workflow_name,
            u.username as executor_username
        FROM workflow_instance wi
        LEFT JOIN workflow w ON wi.workflow_base_id = w.workflow_base_id AND w.is_current_version = TRUE
        LEFT JOIN "user" u ON wi.executor_id = u.user_id
        WHERE wi.workflow_instance_id = $1 AND wi.is_deleted = FALSE
        """
        
        workflow_instance = await workflow_repo.db.fetch_one(workflow_instance_query, workflow_id)
        if not workflow_instance:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨"
            )
        
        # è·å–å·¥ä½œæµå®ä¾‹çš„æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹ï¼ˆæŒ‰ä¾èµ–å…³ç³»æ’åºï¼‰
        nodes_query = """
        SELECT 
            ni.*,
            n.name as node_name,
            n.type as node_type,
            -- è®¡ç®—èŠ‚ç‚¹æ‰§è¡Œæ—¶é—´
            CASE 
                WHEN ni.start_at IS NOT NULL AND ni.completed_at IS NOT NULL 
                THEN EXTRACT(EPOCH FROM (ni.completed_at - ni.start_at))::INTEGER
                WHEN ni.start_at IS NOT NULL 
                THEN EXTRACT(EPOCH FROM (NOW() - ni.start_at))::INTEGER
                ELSE NULL
            END as execution_duration_seconds
        FROM node_instance ni
        JOIN node n ON ni.node_id = n.node_id
        WHERE ni.workflow_instance_id = $1
        AND ni.is_deleted = FALSE
        ORDER BY 
            CASE 
                WHEN ni.start_at IS NOT NULL THEN ni.start_at 
                ELSE ni.created_at 
            END ASC
        """
        
        nodes = await node_repo.db.fetch_all(nodes_query, workflow_id)
        
        # è·å–æ‰€æœ‰ä»»åŠ¡å®ä¾‹ï¼ˆåŒ…å«æ›´è¯¦ç»†çš„çŠ¶æ€ä¿¡æ¯ï¼‰
        tasks_query = """
        SELECT 
            ti.*,
            p.name as processor_name,
            p.type as processor_type,
            u.username as assigned_username,
            a.agent_name as assigned_agent_name,
            -- è®¡ç®—ä»»åŠ¡æ‰§è¡Œæ—¶é—´
            CASE 
                WHEN ti.started_at IS NOT NULL AND ti.completed_at IS NOT NULL 
                THEN EXTRACT(EPOCH FROM (ti.completed_at - ti.started_at))::INTEGER
                WHEN ti.started_at IS NOT NULL 
                THEN EXTRACT(EPOCH FROM (NOW() - ti.started_at))::INTEGER
                ELSE NULL
            END as actual_duration_seconds,
            -- ä»»åŠ¡æ˜¯å¦è¶…æ—¶
            CASE 
                WHEN ti.estimated_duration IS NOT NULL 
                     AND ti.started_at IS NOT NULL 
                     AND ti.completed_at IS NULL
                     AND EXTRACT(EPOCH FROM (NOW() - ti.started_at)) > ti.estimated_duration * 60
                THEN TRUE
                ELSE FALSE
            END as is_overdue
        FROM task_instance ti
        LEFT JOIN processor p ON ti.processor_id = p.processor_id
        LEFT JOIN "user" u ON ti.assigned_user_id = u.user_id
        LEFT JOIN agent a ON ti.assigned_agent_id = a.agent_id
        WHERE ti.workflow_instance_id = $1
        AND ti.is_deleted = FALSE
        ORDER BY ti.created_at
        """
        
        tasks = await task_repo.db.fetch_all(tasks_query, workflow_id)
        
        # è·å–å·¥ä½œæµè¾¹ç¼˜å…³ç³»ï¼ˆç”¨äºå‰ç«¯æµç¨‹å›¾æ˜¾ç¤ºï¼‰
        edges_query = """
        SELECT 
            e.from_node_id,
            e.to_node_id,
            e.condition_expression,
            n1.name as from_node_name,
            n2.name as to_node_name
        FROM edge e
        JOIN node n1 ON e.from_node_id = n1.node_base_id
        JOIN node n2 ON e.to_node_id = n2.node_base_id
        WHERE e.workflow_base_id = $1
        AND e.is_deleted = FALSE
        ORDER BY e.created_at
        """
        
        edges = await node_repo.db.fetch_all(edges_query, workflow_instance['workflow_base_id'])
        
        # æ„å»ºä»»åŠ¡æµç¨‹æ•°æ®
        task_flow = {
            "workflow_id": str(workflow_id),
            "workflow_name": workflow_instance['workflow_name'],
            "workflow_instance_status": workflow_instance['status'],
            "executor_username": workflow_instance['executor_username'],
            "created_at": workflow_instance['created_at'].isoformat() if workflow_instance['created_at'] else None,
            "started_at": workflow_instance['started_at'].isoformat() if workflow_instance['started_at'] else None,
            "completed_at": workflow_instance['completed_at'].isoformat() if workflow_instance['completed_at'] else None,
            "current_user_role": "viewer",  # é»˜è®¤ä¸ºviewerï¼Œåç»­å¯æ ¹æ®æƒé™è®¾ç½®
            "nodes": [],
            "tasks": [],
            "edges": []
        }
        
        # åˆ¤æ–­ç”¨æˆ·è§’è‰²
        if str(workflow_instance['executor_id']) == str(current_user.user_id):
            task_flow["current_user_role"] = "creator"
        else:
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†é…ç»™å½“å‰ç”¨æˆ·çš„ä»»åŠ¡
            user_tasks = [task for task in tasks if task.get('assigned_user_id') == current_user.user_id]
            if user_tasks:
                task_flow["current_user_role"] = "assignee"
                task_flow["assigned_tasks"] = []
        
        # æ ¼å¼åŒ–èŠ‚ç‚¹æ•°æ®ï¼ˆåŒ…å«å®æ—¶çŠ¶æ€å’Œæ‰§è¡Œä¿¡æ¯ï¼‰
        for node in nodes:
            node_data = {
                "node_instance_id": str(node['node_instance_id']),
                "node_name": node['node_name'],
                "node_type": node['node_type'],
                "status": node['status'],  # è¿™æ˜¯ä»æ•°æ®åº“å®æ—¶è¯»å–çš„çŠ¶æ€
                "input_data": node['input_data'],
                "output_data": node['output_data'],
                "start_at": node['start_at'].isoformat() if node['start_at'] else None,
                "completed_at": node['completed_at'].isoformat() if node['completed_at'] else None,
                "execution_duration_seconds": node['execution_duration_seconds'],
                "error_message": node['error_message'],
                "retry_count": node.get('retry_count', 0),
                # èŠ‚ç‚¹å…³è”çš„ä»»åŠ¡æ•°é‡
                "task_count": len([task for task in tasks if str(task['node_instance_id']) == str(node['node_instance_id'])])
            }
            task_flow["nodes"].append(node_data)
        
        # æ ¼å¼åŒ–ä»»åŠ¡æ•°æ®ï¼ˆåŒ…å«å®æ—¶çŠ¶æ€å’Œåˆ†é…ä¿¡æ¯ï¼‰
        for task in tasks:
            assignee_info = None
            if task['assigned_username']:
                assignee_info = {
                    "id": str(task['assigned_user_id']),
                    "name": task['assigned_username'],
                    "type": "user"
                }
            elif task['assigned_agent_name']:
                assignee_info = {
                    "id": str(task['assigned_agent_id']),
                    "name": task['assigned_agent_name'],
                    "type": "agent"
                }
            
            task_data = {
                "task_instance_id": str(task['task_instance_id']),
                "node_instance_id": str(task['node_instance_id']),
                "task_title": task['task_title'],
                "task_type": task['task_type'],
                "status": task['status'],  # è¿™æ˜¯ä»æ•°æ®åº“å®æ—¶è¯»å–çš„çŠ¶æ€
                "processor_name": task['processor_name'],
                "processor_type": task['processor_type'],
                "assignee": assignee_info,
                "priority": task['priority'],
                "estimated_duration": task['estimated_duration'],
                "actual_duration_seconds": task['actual_duration_seconds'],
                "is_overdue": task['is_overdue'],
                "created_at": task['created_at'].isoformat() if task['created_at'] else None,
                "started_at": task['started_at'].isoformat() if task['started_at'] else None,
                "completed_at": task['completed_at'].isoformat() if task['completed_at'] else None,
                "input_data": task['input_data'],
                "output_data": task['output_data'],
                "result_summary": task.get('result_summary'),
                "error_message": task.get('error_message')
            }
            
            task_flow["tasks"].append(task_data)
            
            # å¦‚æœæ˜¯åˆ†é…ç»™å½“å‰ç”¨æˆ·çš„ä»»åŠ¡ï¼Œæ·»åŠ åˆ°assigned_tasks
            if (task_flow["current_user_role"] == "assignee" and 
                task.get('assigned_user_id') == current_user.user_id):
                task_flow["assigned_tasks"].append(task_data)
        
        # æ ¼å¼åŒ–è¾¹ç¼˜æ•°æ®ï¼ˆç”¨äºæµç¨‹å›¾æ˜¾ç¤ºï¼‰
        for edge in edges:
            edge_data = {
                "id": f"{edge['from_node_id']}-{edge['to_node_id']}",
                "source": str(edge['from_node_id']),
                "target": str(edge['to_node_id']),
                "label": edge['condition_expression'],
                "from_node_name": edge['from_node_name'],
                "to_node_name": edge['to_node_name']
            }
            task_flow["edges"].append(edge_data)
        
        # æ·»åŠ å®æ—¶ç»Ÿè®¡ä¿¡æ¯
        node_status_count = {}
        task_status_count = {}
        
        for node in task_flow["nodes"]:
            status = node["status"]
            node_status_count[status] = node_status_count.get(status, 0) + 1
        
        for task in task_flow["tasks"]:
            status = task["status"]
            task_status_count[status] = task_status_count.get(status, 0) + 1
        
        # è®¡ç®—æ€»ä½“è¿›åº¦
        total_nodes = len(task_flow["nodes"])
        completed_nodes = node_status_count.get("completed", 0)
        progress_percentage = round((completed_nodes / total_nodes) * 100, 1) if total_nodes > 0 else 0
        
        task_flow["statistics"] = {
            "total_nodes": total_nodes,
            "total_tasks": len(task_flow["tasks"]),
            "node_status_count": node_status_count,
            "task_status_count": task_status_count,
            "progress_percentage": progress_percentage,
            "is_completed": workflow_instance['status'] == 'completed',
            "is_running": workflow_instance['status'] == 'running',
            "is_failed": workflow_instance['status'] == 'failed'
        }
        
        # æ·»åŠ åˆ›å»ºè€…ä¿¡æ¯
        task_flow["creator"] = {
            "id": str(workflow_instance['executor_id']),
            "name": workflow_instance['executor_username']
        }
        
        return {
            "success": True,
            "data": task_flow,
            "message": f"è·å–å®æ—¶ä»»åŠ¡æµç¨‹æˆåŠŸï¼ŒåŒ…å« {len(task_flow['nodes'])} ä¸ªèŠ‚ç‚¹å’Œ {len(task_flow['tasks'])} ä¸ªä»»åŠ¡ï¼ˆå·¥ä½œæµçŠ¶æ€: {workflow_instance['status']}ï¼‰"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å·¥ä½œæµä»»åŠ¡æµç¨‹å¤±è´¥: {str(e)}"
        )




# ==================== Debugç«¯ç‚¹ ====================

@router.get("/debug/tasks")
async def debug_get_all_tasks(
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """Debug: è·å–æ‰€æœ‰ä»»åŠ¡çŠ¶æ€ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
    try:
        from ..repositories.instance.task_instance_repository import TaskInstanceRepository
        
        task_repo = TaskInstanceRepository()
        
        # è·å–æ‰€æœ‰ä»»åŠ¡å®ä¾‹ï¼ŒåŒ…å«è¯¦ç»†ä¿¡æ¯
        query = """
        SELECT 
            ti.*,
            wi.instance_name as workflow_instance_name,
            w.name as workflow_name,
            p.name as processor_name,
            p.type as processor_type,
            u.username as assigned_username,
            a.agent_name as assigned_agent_name
        FROM task_instance ti
        LEFT JOIN workflow_instance wi ON ti.workflow_instance_id = wi.workflow_instance_id
        LEFT JOIN workflow w ON wi.workflow_base_id = w.workflow_base_id AND w.is_current_version = TRUE
        LEFT JOIN processor p ON ti.processor_id = p.processor_id
        LEFT JOIN "user" u ON ti.assigned_user_id = u.user_id
        LEFT JOIN agent a ON ti.assigned_agent_id = a.agent_id
        WHERE ti.is_deleted = FALSE
        ORDER BY ti.created_at DESC
        LIMIT 50
        """
        
        tasks = await task_repo.db.fetch_all(query)
        
        debug_data = {
            "total_tasks": len(tasks),
            "current_user_id": str(current_user.user_id),
            "current_username": current_user.username,
            "tasks": []
        }
        
        # ç»Ÿè®¡å„ç§çŠ¶æ€çš„ä»»åŠ¡æ•°é‡
        status_counts = {}
        user_task_counts = {}
        
        for task in tasks:
            task_data = {
                "task_id": str(task['task_instance_id']),
                "task_title": task['task_title'],
                "task_type": task['task_type'],
                "status": task['status'],
                "workflow_name": task['workflow_name'],
                "processor_name": task['processor_name'],
                "processor_type": task['processor_type'],
                "assigned_user_id": str(task['assigned_user_id']) if task['assigned_user_id'] else None,
                "assigned_username": task['assigned_username'],
                "assigned_agent_name": task['assigned_agent_name'],
                "priority": task['priority'],
                "created_at": task['created_at'].isoformat() if task['created_at'] else None,
                "is_current_user_task": str(task['assigned_user_id']) == str(current_user.user_id) if task['assigned_user_id'] else False
            }
            debug_data["tasks"].append(task_data)
            
            # ç»Ÿè®¡çŠ¶æ€
            status = task['status']
            status_counts[status] = status_counts.get(status, 0) + 1
            
            # ç»Ÿè®¡ç”¨æˆ·ä»»åŠ¡
            if task['assigned_user_id']:
                user_id = str(task['assigned_user_id'])
                username = task['assigned_username'] or 'Unknown'
                user_task_counts[f"{username} ({user_id})"] = user_task_counts.get(f"{username} ({user_id})", 0) + 1
        
        debug_data["status_counts"] = status_counts
        debug_data["user_task_counts"] = user_task_counts
        debug_data["current_user_tasks"] = len([t for t in debug_data["tasks"] if t["is_current_user_task"]])
        
        return {
            "success": True,
            "data": debug_data,
            "message": f"è·å–è°ƒè¯•ä¿¡æ¯æˆåŠŸï¼Œæ€»å…± {len(tasks)} ä¸ªä»»åŠ¡"
        }
        
    except Exception as e:
        logger.error(f"è·å–è°ƒè¯•ä»»åŠ¡ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–è°ƒè¯•ä¿¡æ¯å¤±è´¥: {str(e)}"
        )


# ==================== äººå·¥ä»»åŠ¡ç«¯ç‚¹ ====================

@router.get("/tasks/my")
async def get_my_tasks(
    task_status: Optional[TaskInstanceStatus] = None,
    limit: int = 50,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–æˆ‘çš„ä»»åŠ¡åˆ—è¡¨"""
    try:
        tasks = await human_task_service.get_user_tasks(
            current_user.user_id, task_status, limit
        )
        
        return {
            "success": True,
            "data": tasks,
            "message": f"è·å–åˆ° {len(tasks)} ä¸ªä»»åŠ¡"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@router.get("/tasks/{task_id}")
async def get_task_details(
    task_id: uuid.UUID,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–ä»»åŠ¡è¯¦æƒ…ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    try:
        from ..repositories.instance.task_instance_repository import TaskInstanceRepository
        from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
        from ..repositories.instance.node_instance_repository import NodeInstanceRepository
        
        task_repo = TaskInstanceRepository()
        workflow_repo = WorkflowInstanceRepository()
        node_repo = NodeInstanceRepository()
        
        # è·å–ä»»åŠ¡è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…å«å®Œæ•´çš„ä¸Šä¸‹æ–‡
        task_query = """
        SELECT 
            ti.*,
            p.name as processor_name, 
            p.type as processor_type,
            u.username as assigned_user_name,
            u.email as assigned_user_email,
            a.agent_name as assigned_agent_name,
            wi.instance_name as workflow_instance_name,
            wi.input_data as workflow_input_data,
            wi.context_data as workflow_context_data,
            w.name as workflow_name,
            n.name as node_name,
            n.type as node_type,
            n.task_description as node_task_description,
            ni.input_data as node_input_data,
            ni.output_data as node_output_data
        FROM task_instance ti
        LEFT JOIN processor p ON p.processor_id = ti.processor_id
        LEFT JOIN "user" u ON u.user_id = ti.assigned_user_id
        LEFT JOIN agent a ON a.agent_id = ti.assigned_agent_id
        LEFT JOIN workflow_instance wi ON wi.workflow_instance_id = ti.workflow_instance_id
        LEFT JOIN workflow w ON w.workflow_id = wi.workflow_id
        LEFT JOIN node_instance ni ON ni.node_instance_id = ti.node_instance_id
        LEFT JOIN node n ON n.node_id = ni.node_id
        WHERE ti.task_instance_id = $1 AND ti.is_deleted = FALSE
        """
        
        task = await task_repo.db.fetch_one(task_query, task_id)
        
        if not task:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ä»»åŠ¡ä¸å­˜åœ¨"
            )
        
        # æƒé™æ£€æŸ¥ï¼šåªæœ‰åˆ†é…ç»™ç”¨æˆ·çš„ä»»åŠ¡æˆ–ç®¡ç†å‘˜æ‰èƒ½æŸ¥çœ‹
        if (str(task.get('assigned_user_id')) != str(current_user.user_id) and 
            current_user.role not in ['admin', 'manager']):
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡"
            )
        
        # è§£æJSONå­—æ®µ
        input_data = json.loads(task.get('input_data', '{}')) if task.get('input_data') else {}
        output_data = json.loads(task.get('output_data', '{}')) if task.get('output_data') else {}
        context_data = json.loads(task.get('context_data', '{}')) if task.get('context_data') else {}
        workflow_input_data = json.loads(task.get('workflow_input_data', '{}')) if task.get('workflow_input_data') else {}
        workflow_context_data = json.loads(task.get('workflow_context_data', '{}')) if task.get('workflow_context_data') else {}
        node_input_data = json.loads(task.get('node_input_data', '{}')) if task.get('node_input_data') else {}
        node_output_data = json.loads(task.get('node_output_data', '{}')) if task.get('node_output_data') else {}
        
        # æ„å»ºå¢å¼ºçš„ä»»åŠ¡è¯¦æƒ…
        enhanced_task = {
            # åŸºæœ¬ä»»åŠ¡ä¿¡æ¯
            "task_instance_id": str(task['task_instance_id']),
            "task_title": task.get('task_title', ''),
            "task_description": task.get('task_description', ''),
            "task_type": task.get('task_type', ''),
            "instructions": task.get('instructions', ''),
            "priority": task.get('priority', 1),
            "status": task.get('status', ''),
            "estimated_duration": task.get('estimated_duration'),
            "actual_duration": task.get('actual_duration'),
            "result_summary": task.get('result_summary'),
            "error_message": task.get('error_message'),
            
            # æ—¶é—´ä¿¡æ¯
            "created_at": task['created_at'].isoformat() if task.get('created_at') else None,
            "assigned_at": task['assigned_at'].isoformat() if task.get('assigned_at') else None,
            "started_at": task['started_at'].isoformat() if task.get('started_at') else None,
            "completed_at": task['completed_at'].isoformat() if task.get('completed_at') else None,
            "updated_at": task['updated_at'].isoformat() if task.get('updated_at') else None,
            
            # åˆ†é…ä¿¡æ¯
            "assigned_user": {
                "user_id": str(task['assigned_user_id']) if task.get('assigned_user_id') else None,
                "username": task.get('assigned_user_name'),
                "email": task.get('assigned_user_email')
            } if task.get('assigned_user_id') else None,
            
            "assigned_agent": {
                "agent_id": str(task['assigned_agent_id']) if task.get('assigned_agent_id') else None,
                "agent_name": task.get('assigned_agent_name')
            } if task.get('assigned_agent_id') else None,
            
            # å¤„ç†å™¨ä¿¡æ¯
            "processor": {
                "processor_id": str(task['processor_id']) if task.get('processor_id') else None,
                "name": task.get('processor_name'),
                "type": task.get('processor_type')
            },
            
            # å·¥ä½œæµä¸Šä¸‹æ–‡
            "workflow_context": {
                "workflow_id": str(task['workflow_instance_id']) if task.get('workflow_instance_id') else None,
                "workflow_name": task.get('workflow_name'),
                "instance_name": task.get('workflow_instance_name'),
                "workflow_input_data": workflow_input_data,
                "workflow_context_data": workflow_context_data
            },
            
            # èŠ‚ç‚¹ä¸Šä¸‹æ–‡
            "node_context": {
                "node_instance_id": str(task['node_instance_id']) if task.get('node_instance_id') else None,
                "node_name": task.get('node_name'),
                "node_type": task.get('node_type'),
                "node_task_description": task.get('node_task_description'),
                "node_input_data": node_input_data,
                "node_output_data": node_output_data
            },
            
            # ä»»åŠ¡æ•°æ®
            "input_data": input_data,
            "output_data": output_data,
            "context_data": context_data,
            
            # ç”¨æˆ·æƒé™
            "user_permissions": {
                "can_start": task.get('status') == 'assigned' and str(task.get('assigned_user_id')) == str(current_user.user_id),
                "can_submit": task.get('status') == 'in_progress' and str(task.get('assigned_user_id')) == str(current_user.user_id),
                "can_view_only": str(task.get('assigned_user_id')) != str(current_user.user_id),
                "is_owner": str(task.get('assigned_user_id')) == str(current_user.user_id)
            }
        }
        
        return {
            "success": True,
            "data": enhanced_task,
            "message": "è·å–ä»»åŠ¡è¯¦æƒ…æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {str(e)}"
        )


@router.post("/tasks/{task_id}/start")
async def start_task(
    task_id: uuid.UUID,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """å¼€å§‹æ‰§è¡Œä»»åŠ¡"""
    try:
        result = await human_task_service.start_task(task_id, current_user.user_id)
        
        return {
            "success": True,
            "data": result,
            "message": "ä»»åŠ¡å·²å¼€å§‹æ‰§è¡Œ"
        }
        
    except PermissionError:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒæ‰§è¡Œæ­¤ä»»åŠ¡"
        )
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¼€å§‹æ‰§è¡Œä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.post("/tasks/{task_id}/submit")
async def submit_task_result(
    task_id: uuid.UUID,
    raw_request: Request,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """æäº¤ä»»åŠ¡ç»“æœ"""
    try:
        # å…ˆè¯»å–åŸå§‹è¯·æ±‚ä½“è¿›è¡Œè°ƒè¯•
        body = await raw_request.body()
        logger.info(f"ğŸ“ æ”¶åˆ°ä»»åŠ¡æäº¤çš„åŸå§‹è¯·æ±‚:")
        logger.info(f"  ä»»åŠ¡ID: {task_id}")
        logger.info(f"  ç”¨æˆ·ID: {current_user.user_id}")
        logger.info(f"  åŸå§‹è¯·æ±‚ä½“ ({len(body)} å­—èŠ‚): {body.decode('utf-8', errors='ignore')}")
        
        # å°è¯•è§£æJSON
        import json
        try:
            raw_data = json.loads(body.decode('utf-8'))
            logger.info(f"  è§£æçš„JSONæ•°æ®: {raw_data}")
            logger.info(f"  æ•°æ®ç±»å‹åˆ†æ:")
            for key, value in raw_data.items():
                logger.info(f"    {key}: {type(value).__name__} = {repr(value)}")
        except Exception as json_error:
            logger.error(f"  JSONè§£æå¤±è´¥: {json_error}")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"æ— æ•ˆçš„JSONæ ¼å¼: {str(json_error)}"
            )
        
        # é¢„å¤„ç†ï¼šç¡®ä¿result_dataæ˜¯å­—å…¸ç±»å‹
        if 'result_data' in raw_data:
            result_data_value = raw_data['result_data']
            logger.info(f"  åŸå§‹result_data: {type(result_data_value).__name__} = {repr(result_data_value)}")
            
            # å¦‚æœresult_dataæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
            if isinstance(result_data_value, str):
                try:
                    parsed_json = json.loads(result_data_value)
                    # æ£€æŸ¥è§£æç»“æœæ˜¯å¦ä¸ºå­—å…¸
                    if isinstance(parsed_json, dict):
                        raw_data['result_data'] = parsed_json
                        logger.info(f"  å­—ç¬¦ä¸²è§£æåresult_data: {raw_data['result_data']}")
                    else:
                        # å¦‚æœè§£æå‡ºæ¥ä¸æ˜¯å­—å…¸ï¼ŒåŒ…è£…ä¸ºå­—å…¸
                        raw_data['result_data'] = {"value": parsed_json}
                        logger.info(f"  è§£æç»“æœåŒ…è£…åresult_data: {raw_data['result_data']}")
                except:
                    # å¦‚æœä¸æ˜¯JSONå­—ç¬¦ä¸²ï¼ŒåŒ…è£…ä¸ºå­—å…¸
                    raw_data['result_data'] = {"answer": result_data_value}
                    logger.info(f"  å­—ç¬¦ä¸²åŒ…è£…åresult_data: {raw_data['result_data']}")
            elif result_data_value is None:
                raw_data['result_data'] = {}
                logger.info(f"  Noneè½¬æ¢åresult_data: {raw_data['result_data']}")
            elif not isinstance(result_data_value, dict):
                # å…¶ä»–ç±»å‹ä¹ŸåŒ…è£…ä¸ºå­—å…¸
                raw_data['result_data'] = {"value": result_data_value}
                logger.info(f"  å…¶ä»–ç±»å‹åŒ…è£…åresult_data: {raw_data['result_data']}")
        
        # æ‰‹åŠ¨éªŒè¯è¯·æ±‚æ•°æ®
        try:
            request = TaskSubmissionRequest(**raw_data)
            logger.info(f"  âœ… PydanticéªŒè¯æˆåŠŸ:")
            logger.info(f"    result_data: {request.result_data}")
            logger.info(f"    result_summary: {request.result_summary}")
        except ValidationError as ve:
            logger.error(f"  âŒ PydanticéªŒè¯å¤±è´¥:")
            for error in ve.errors():
                logger.error(f"    - {error['loc']}: {error['msg']} (type: {error['type']})")
            logger.error(f"  å¤„ç†åçš„æ•°æ®: {raw_data}")
            raise HTTPException(
                status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
                detail=f"è¯·æ±‚æ•°æ®éªŒè¯å¤±è´¥: {ve.errors()}"
            )
        
        # ç¡®ä¿ result_data ä¸ä¸º None
        result_data = request.result_data if request.result_data is not None else {}
        logger.info(f"  ğŸ”„ å‡†å¤‡æäº¤ä»»åŠ¡ç»“æœ: result_data={result_data}")
        
        result = await human_task_service.submit_task_result(
            task_id, current_user.user_id, 
            result_data, request.result_summary
        )
        
        logger.info(f"  âœ… ä»»åŠ¡æäº¤æˆåŠŸ: {result}")
        
        return {
            "success": True,
            "data": result,
            "message": "ä»»åŠ¡ç»“æœå·²æäº¤"
        }
        
    except PermissionError:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒæäº¤æ­¤ä»»åŠ¡"
        )
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æäº¤ä»»åŠ¡ç»“æœå¤±è´¥: {str(e)}"
        )


@router.post("/tasks/{task_id}/pause")
async def pause_task(
    task_id: uuid.UUID,
    request: TaskActionRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """æš‚åœä»»åŠ¡"""
    try:
        result = await human_task_service.pause_task(
            task_id, current_user.user_id, request.reason
        )
        
        return {
            "success": True,
            "data": result,
            "message": "ä»»åŠ¡å·²æš‚åœ"
        }
        
    except PermissionError:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒæš‚åœæ­¤ä»»åŠ¡"
        )
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æš‚åœä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.post("/tasks/{task_id}/help")
async def request_help(
    task_id: uuid.UUID,
    request: HelpRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è¯·æ±‚å¸®åŠ©"""
    try:
        result = await human_task_service.request_help(
            task_id, current_user.user_id, request.help_message
        )
        
        return {
            "success": True,
            "data": result,
            "message": "å¸®åŠ©è¯·æ±‚å·²æäº¤"
        }
        
    except PermissionError:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒä¸ºæ­¤ä»»åŠ¡è¯·æ±‚å¸®åŠ©"
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è¯·æ±‚å¸®åŠ©å¤±è´¥: {str(e)}"
        )


@router.post("/tasks/{task_id}/reject")
async def reject_task(
    task_id: uuid.UUID,
    request: TaskActionRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """æ‹’ç»ä»»åŠ¡"""
    try:
        if not request.reason:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="æ‹’ç»ä»»åŠ¡æ—¶å¿…é¡»æä¾›æ‹’ç»åŸå› "
            )
        
        result = await human_task_service.reject_task(
            task_id, current_user.user_id, request.reason
        )
        
        return {
            "success": True,
            "data": result,
            "message": "ä»»åŠ¡å·²æ‹’ç»"
        }
        
    except PermissionError:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒæ‹’ç»æ­¤ä»»åŠ¡"
        )
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ‹’ç»ä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.post("/tasks/{task_id}/cancel")
async def cancel_task(
    task_id: uuid.UUID,
    request: TaskActionRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """å–æ¶ˆä»»åŠ¡"""
    try:
        result = await human_task_service.cancel_task(
            task_id, current_user.user_id, request.reason or "ç”¨æˆ·å–æ¶ˆ"
        )
        
        return {
            "success": True,
            "data": result,
            "message": "ä»»åŠ¡å·²å–æ¶ˆ"
        }
        
    except PermissionError:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒå–æ¶ˆæ­¤ä»»åŠ¡"
        )
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.get("/tasks/history")
async def get_task_history(
    days: int = 30,
    limit: int = 100,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–ä»»åŠ¡å†å²"""
    try:
        tasks = await human_task_service.get_task_history(
            current_user.user_id, days, limit
        )
        
        return {
            "success": True,
            "data": tasks,
            "message": f"è·å–åˆ° {days} å¤©å†…çš„ {len(tasks)} ä¸ªå†å²ä»»åŠ¡"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ä»»åŠ¡å†å²å¤±è´¥: {str(e)}"
        )


@router.get("/tasks/statistics")
async def get_task_statistics(
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–ä»»åŠ¡ç»Ÿè®¡"""
    try:
        stats = await human_task_service.get_task_statistics(current_user.user_id)
        
        return {
            "success": True,
            "data": stats,
            "message": "è·å–ä»»åŠ¡ç»Ÿè®¡æˆåŠŸ"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {str(e)}"
        )


# ==================== Agentä»»åŠ¡ç«¯ç‚¹ ====================

@router.get("/agent-tasks/pending")
async def get_pending_agent_tasks(
    agent_id: Optional[uuid.UUID] = None,
    limit: int = 50,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–å¾…å¤„ç†çš„Agentä»»åŠ¡"""
    try:
        tasks = await agent_task_service.get_pending_agent_tasks(agent_id, limit)
        
        return {
            "success": True,
            "data": tasks,
            "message": f"è·å–åˆ° {len(tasks)} ä¸ªå¾…å¤„ç†Agentä»»åŠ¡"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å¾…å¤„ç†Agentä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.post("/agent-tasks/{task_id}/process")
async def process_agent_task(
    task_id: uuid.UUID,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """æ‰‹åŠ¨è§¦å‘Agentä»»åŠ¡å¤„ç†"""
    try:
        result = await agent_task_service.process_agent_task(task_id)
        
        return {
            "success": True,
            "data": result,
            "message": "Agentä»»åŠ¡å¤„ç†å®Œæˆ"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¤„ç†Agentä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.post("/agent-tasks/{task_id}/retry")
async def retry_agent_task(
    task_id: uuid.UUID,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """é‡è¯•å¤±è´¥çš„Agentä»»åŠ¡"""
    try:
        result = await agent_task_service.retry_failed_task(task_id)
        
        return {
            "success": True,
            "data": result,
            "message": "Agentä»»åŠ¡å·²é‡æ–°åŠ å…¥å¤„ç†é˜Ÿåˆ—"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"é‡è¯•Agentä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.post("/agent-tasks/{task_id}/cancel")
async def cancel_agent_task(
    task_id: uuid.UUID,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """å–æ¶ˆAgentä»»åŠ¡"""
    try:
        result = await agent_task_service.cancel_agent_task(task_id)
        
        return {
            "success": True,
            "data": result,
            "message": "Agentä»»åŠ¡å·²å–æ¶ˆ"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å–æ¶ˆAgentä»»åŠ¡å¤±è´¥: {str(e)}"
        )


@router.get("/agent-tasks/statistics")
async def get_agent_task_statistics(
    agent_id: Optional[uuid.UUID] = None,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–Agentä»»åŠ¡ç»Ÿè®¡"""
    try:
        stats = await agent_task_service.get_agent_task_statistics(agent_id)
        
        return {
            "success": True,
            "data": stats,
            "message": "è·å–Agentä»»åŠ¡ç»Ÿè®¡æˆåŠŸ"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–Agentä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {str(e)}"
        )


# ==================== å·¥ä½œæµå®ä¾‹ç®¡ç†ç«¯ç‚¹ ====================

@router.post("/workflows/instances/{instance_id}/cancel")
async def cancel_workflow_instance(
    instance_id: uuid.UUID,
    request: TaskActionRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """å–æ¶ˆå·¥ä½œæµå®ä¾‹"""
    try:
        logger.info(f"ğŸš« ç”¨æˆ· {current_user.user_id} è¯·æ±‚å–æ¶ˆå·¥ä½œæµå®ä¾‹: {instance_id}")
        logger.info(f"  å–æ¶ˆåŸå› : {request.reason}")
        
        # è°ƒç”¨æœåŠ¡å±‚å¤„ç†å·¥ä½œæµå–æ¶ˆ
        result = await human_task_service.cancel_workflow_instance(
            instance_id, current_user.user_id, request.reason or "ç”¨æˆ·å–æ¶ˆ"
        )
        
        return {
            "success": True,
            "data": result,
            "message": "å·¥ä½œæµå®ä¾‹å·²å–æ¶ˆ"
        }
        
    except PermissionError:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒå–æ¶ˆæ­¤å·¥ä½œæµå®ä¾‹"
        )
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.error(f"å–æ¶ˆå·¥ä½œæµå®ä¾‹å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å–æ¶ˆå·¥ä½œæµå®ä¾‹å¤±è´¥: {str(e)}"
        )


@router.delete("/workflows/{instance_id}")
async def delete_workflow_instance(
    instance_id: uuid.UUID,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """åˆ é™¤å·¥ä½œæµå®ä¾‹"""
    try:
        logger.info(f"ğŸ—‘ï¸ ç”¨æˆ· {current_user.user_id} ({current_user.username}) è¯·æ±‚åˆ é™¤å·¥ä½œæµå®ä¾‹: {instance_id}")
        
        from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
        workflow_instance_repo = WorkflowInstanceRepository()
        
        # æ£€æŸ¥å®ä¾‹æ˜¯å¦å­˜åœ¨
        logger.info(f"ğŸ” æ­¥éª¤1: æ£€æŸ¥å·¥ä½œæµå®ä¾‹æ˜¯å¦å­˜åœ¨")
        instance = await workflow_instance_repo.get_instance_by_id(instance_id)
        if not instance:
            logger.warning(f"âš ï¸ å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨: {instance_id}")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨"
            )
        
        logger.info(f"ğŸ“‹ æ‰¾åˆ°å·¥ä½œæµå®ä¾‹è¯¦ç»†ä¿¡æ¯:")
        logger.info(f"   - å®ä¾‹åç§°: {instance.get('instance_name', 'æœªå‘½å')}")
        logger.info(f"   - å½“å‰çŠ¶æ€: {instance.get('status')}")
        logger.info(f"   - æ‰§è¡Œè€…ID: {instance.get('executor_id')}")
        logger.info(f"   - åˆ›å»ºæ—¶é—´: {instance.get('created_at')}")
        logger.info(f"   - æ›´æ–°æ—¶é—´: {instance.get('updated_at')}")
        logger.info(f"   - æ˜¯å¦å·²åˆ é™¤: {instance.get('is_deleted', False)}")
        
        # æ£€æŸ¥æƒé™ï¼ˆåªæœ‰æ‰§è¡Œè€…å¯ä»¥åˆ é™¤ï¼‰
        logger.info(f"ğŸ” æ­¥éª¤2: æ£€æŸ¥åˆ é™¤æƒé™")
        current_user_id_str = str(current_user.user_id)
        executor_id_str = str(instance.get('executor_id'))
        logger.info(f"   - å½“å‰ç”¨æˆ·ID: {current_user_id_str}")
        logger.info(f"   - æ‰§è¡Œè€…ID: {executor_id_str}")
        
        if executor_id_str != current_user_id_str:
            logger.warning(f"ğŸš« æƒé™æ£€æŸ¥å¤±è´¥:")
            logger.warning(f"   - ç”¨æˆ· {current_user_id_str} æ— æƒåˆ é™¤å®ä¾‹ {instance_id}")
            logger.warning(f"   - åªæœ‰æ‰§è¡Œè€… {executor_id_str} å¯ä»¥åˆ é™¤æ­¤å®ä¾‹")
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒåˆ é™¤æ­¤å·¥ä½œæµå®ä¾‹"
            )
        logger.info(f"âœ… æƒé™æ£€æŸ¥é€šè¿‡")
        
        # æ£€æŸ¥å®ä¾‹çŠ¶æ€ï¼ˆä¸å…è®¸åˆ é™¤æ­£åœ¨è¿è¡Œçš„å®ä¾‹ï¼‰
        logger.info(f"ğŸ” æ­¥éª¤3: æ£€æŸ¥å®ä¾‹çŠ¶æ€")
        current_status = instance.get('status')
        logger.info(f"   - å½“å‰çŠ¶æ€: {current_status}")
        
        if current_status == 'running':
            logger.warning(f"âš ï¸ çŠ¶æ€æ£€æŸ¥å¤±è´¥: ä¸èƒ½åˆ é™¤æ­£åœ¨è¿è¡Œçš„å®ä¾‹")
            logger.warning(f"   - å®ä¾‹ {instance_id} çŠ¶æ€ä¸º 'running'")
            logger.warning(f"   - è¯·å…ˆå–æ¶ˆå®ä¾‹åå†åˆ é™¤")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="æ— æ³•åˆ é™¤æ­£åœ¨è¿è¡Œçš„å·¥ä½œæµå®ä¾‹ï¼Œè¯·å…ˆå–æ¶ˆå®ä¾‹"
            )
        logger.info(f"âœ… çŠ¶æ€æ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥åˆ é™¤")
        
        # æ‰§è¡Œè½¯åˆ é™¤
        logger.info(f"ğŸ” æ­¥éª¤4: æ‰§è¡Œè½¯åˆ é™¤æ“ä½œ")
        logger.info(f"   - è°ƒç”¨ workflow_instance_repo.delete_instance({instance_id}, soft_delete=True)")
        
        try:
            success = await workflow_instance_repo.delete_instance(instance_id, soft_delete=True)
            logger.info(f"   - åˆ é™¤æ“ä½œè¿”å›ç»“æœ: {success}")
            
            if success:
                logger.info(f"âœ… å·¥ä½œæµå®ä¾‹åˆ é™¤æˆåŠŸ: {instance_id}")
                
                # éªŒè¯åˆ é™¤ç»“æœ
                logger.info(f"ğŸ” æ­¥éª¤5: éªŒè¯åˆ é™¤ç»“æœ")
                verification_instance = await workflow_instance_repo.get_instance_by_id(instance_id)
                if verification_instance:
                    logger.info(f"   - éªŒè¯: å®ä¾‹ä»å­˜åœ¨ (è½¯åˆ é™¤)")
                    logger.info(f"   - is_deleted æ ‡å¿—: {verification_instance.get('is_deleted', 'unknown')}")
                else:
                    logger.info(f"   - éªŒè¯: å®ä¾‹å·²ä¸å¯è®¿é—® (åˆ é™¤æˆåŠŸ)")
                
                return {
                    "success": True,
                    "data": {"instance_id": str(instance_id)},
                    "message": "å·¥ä½œæµå®ä¾‹å·²åˆ é™¤"
                }
            else:
                logger.error(f"âŒ åˆ é™¤å·¥ä½œæµå®ä¾‹å¤±è´¥:")
                logger.error(f"   - å®ä¾‹ID: {instance_id}")
                logger.error(f"   - æ•°æ®åº“æ“ä½œè¿”å›: {success}")
                logger.error(f"   - å¯èƒ½çš„åŸå› : æ•°æ®åº“çº¦æŸã€æƒé™é—®é¢˜æˆ–å®ä¾‹ä¸å­˜åœ¨")
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail="åˆ é™¤å·¥ä½œæµå®ä¾‹å¤±è´¥"
                )
        except Exception as delete_error:
            logger.error(f"âŒ æ‰§è¡Œåˆ é™¤æ“ä½œæ—¶å‘ç”Ÿå¼‚å¸¸:")
            logger.error(f"   - å¼‚å¸¸ç±»å‹: {type(delete_error).__name__}")
            logger.error(f"   - å¼‚å¸¸ä¿¡æ¯: {str(delete_error)}")
            import traceback
            logger.error(f"   - å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"åˆ é™¤æ“ä½œå¼‚å¸¸: {str(delete_error)}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ åˆ é™¤å·¥ä½œæµå®ä¾‹æ€»ä½“å¼‚å¸¸:")
        logger.error(f"   - å®ä¾‹ID: {instance_id}")
        logger.error(f"   - ç”¨æˆ·ID: {current_user.user_id}")
        logger.error(f"   - å¼‚å¸¸ç±»å‹: {type(e).__name__}")
        logger.error(f"   - å¼‚å¸¸ä¿¡æ¯: {str(e)}")
        import traceback
        logger.error(f"   - å®Œæ•´å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ é™¤å·¥ä½œæµå®ä¾‹å¤±è´¥: {str(e)}"
        )


@router.get("/workflows/instances/{instance_id}/context")
async def get_workflow_context(
    instance_id: uuid.UUID,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–å·¥ä½œæµå®ä¾‹çš„å®Œæ•´ä¸Šä¸‹æ–‡å†…å®¹"""
    try:
        logger.info(f"ğŸ“Š ç”¨æˆ· {current_user.user_id} è¯·æ±‚è·å–å·¥ä½œæµä¸Šä¸‹æ–‡: {instance_id}")
        
        # éªŒè¯å·¥ä½œæµå®ä¾‹æ˜¯å¦å­˜åœ¨å’Œæƒé™
        workflow_query = '''
        SELECT workflow_instance_id, executor_id, status, instance_name
        FROM workflow_instance 
        WHERE workflow_instance_id = $1 AND is_deleted = FALSE
        '''
        workflow = await human_task_service.task_repo.db.fetch_one(workflow_query, instance_id)
        
        if not workflow:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨"
            )
        
        # æ£€æŸ¥è®¿é—®æƒé™ï¼ˆæ‰§è¡Œè€…æˆ–ç®¡ç†å‘˜å¯ä»¥æŸ¥çœ‹ï¼‰
        if workflow['executor_id'] != current_user.user_id:
            # TODO: è¿™é‡Œå¯ä»¥æ·»åŠ ç®¡ç†å‘˜æƒé™æ£€æŸ¥
            logger.warning(f"âš ï¸ ç”¨æˆ· {current_user.user_id} å°è¯•è®¿é—®ä¸å±äºè‡ªå·±çš„å·¥ä½œæµ: {instance_id}")
            # æš‚æ—¶å…è®¸æ‰€æœ‰ç”¨æˆ·æŸ¥çœ‹ï¼ˆç”Ÿäº§ç¯å¢ƒéœ€è¦ä¸¥æ ¼æƒé™æ§åˆ¶ï¼‰
        
        # è·å–å®Œæ•´çš„å·¥ä½œæµä¸Šä¸‹æ–‡
        context = await human_task_service._collect_workflow_context(instance_id)
        
        # æŸ¥æ‰¾ç»“æŸèŠ‚ç‚¹çš„è¾“å‡ºæ•°æ®
        end_node_output = None
        end_nodes_query = '''
        SELECT ni.output_data, n.name as node_name
        FROM node_instance ni
        JOIN node n ON ni.node_id = n.node_id
        WHERE ni.workflow_instance_id = $1 
        AND n.node_type = 'end'
        AND ni.status = 'completed'
        ORDER BY ni.updated_at DESC
        LIMIT 1
        '''
        end_node = await human_task_service.task_repo.db.fetch_one(end_nodes_query, instance_id)
        
        if end_node and end_node['output_data']:
            end_node_output = {
                'end_node_name': end_node['node_name'],
                'full_context': end_node['output_data']
            }
        
        return {
            "success": True,
            "data": {
                "workflow_instance_id": str(instance_id),
                "workflow_status": workflow['status'],
                "workflow_name": workflow['instance_name'],
                "context_summary": context,
                "end_node_output": end_node_output,
                "has_complete_context": end_node_output is not None
            },
            "message": "å·¥ä½œæµä¸Šä¸‹æ–‡è·å–æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–å·¥ä½œæµä¸Šä¸‹æ–‡å¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å·¥ä½œæµä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}"
        )


# ==================== ç®¡ç†å‘˜ä»»åŠ¡ç®¡ç†ç«¯ç‚¹ ====================

@router.post("/admin/tasks/{task_id}/assign")
async def assign_task_to_user(
    task_id: uuid.UUID,
    request: TaskAssignmentRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """ç®¡ç†å‘˜åˆ†é…ä»»åŠ¡ç»™ç”¨æˆ·"""
    try:
        # éªŒè¯ç®¡ç†å‘˜æƒé™
        if current_user.role not in ['admin', 'manager']:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒé™æ‰§è¡Œæ­¤æ“ä½œ"
            )
        
        result = await human_task_service.assign_task_to_user(
            task_id, request.user_id, current_user.user_id
        )
        
        return {
            "success": True,
            "data": result,
            "message": "ä»»åŠ¡åˆ†é…æˆåŠŸ"
        }
        
    except PermissionError:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒåˆ†é…ä»»åŠ¡"
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ†é…ä»»åŠ¡å¤±è´¥: {str(e)}"
        )


# ==================== ç³»ç»Ÿç›‘æ§ç«¯ç‚¹ ====================

@router.get("/system/status")
async def get_system_status(
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–æ‰§è¡Œç³»ç»ŸçŠ¶æ€"""
    try:
        # éªŒè¯ç®¡ç†å‘˜æƒé™
        if current_user.role not in ['admin', 'manager']:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="æ— æƒé™è®¿é—®ç³»ç»ŸçŠ¶æ€"
            )
        
        system_status = {
            "execution_engine": {
                "is_running": execution_engine.is_running,
                "running_instances": len(execution_engine.running_instances),
                "queue_size": execution_engine.execution_queue.qsize()
            },
            "agent_service": {
                "is_running": agent_task_service.is_running,
                "queue_size": agent_task_service.processing_queue.qsize(),
                "max_concurrent": agent_task_service.max_concurrent_tasks
            }
        }
        
        return {
            "success": True,
            "data": system_status,
            "message": "è·å–ç³»ç»ŸçŠ¶æ€æˆåŠŸ"
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {str(e)}"
        )


@router.get("/online-resources")
async def get_online_resources(
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–åœ¨çº¿èµ„æºï¼ˆç”¨æˆ·å’ŒAgentï¼‰"""
    try:
        from ..repositories.user.user_repository import UserRepository
        from ..repositories.processor.processor_repository import ProcessorRepository
        
        user_repo = UserRepository()
        processor_repo = ProcessorRepository()
        
        # è·å–æ‰€æœ‰æ´»è·ƒç”¨æˆ·
        users = await user_repo.list_all({"status": True, "is_deleted": False})
        
        # è·å–æ‰€æœ‰Agentå¤„ç†å™¨
        agents = await processor_repo.list_all({"type": "agent", "is_deleted": False})
        
        # æ ¼å¼åŒ–ç”¨æˆ·æ•°æ®
        online_users = []
        for user in users:
            # å®‰å…¨å¤„ç†profileå­—æ®µ
            profile = user.get("profile", {})
            if isinstance(profile, str):
                try:
                    import json
                    profile = json.loads(profile)
                except:
                    profile = {}
            
            online_users.append({
                "user_id": str(user["user_id"]),
                "username": user["username"],
                "email": user["email"],
                "full_name": profile.get("full_name", "") if isinstance(profile, dict) else "",
                "description": user.get("description", ""),
                "status": "online",
                "capabilities": profile.get("capabilities", []) if isinstance(profile, dict) else [],
                "role": user.get("role", "user"),
                "created_at": user["created_at"].isoformat() if user.get("created_at") else None,
                "last_login": user["updated_at"].isoformat() if user.get("updated_at") else None
            })
        
        # æ ¼å¼åŒ–Agentæ•°æ®
        online_agents = []
        for agent in agents:
            online_agents.append({
                "agent_id": str(agent["processor_id"]),
                "name": agent["name"],
                "description": agent.get("description", ""),
                "status": "online",
                "capabilities": agent.get("capabilities", []),
                "tools": agent.get("tools", []),
                "config": agent.get("config", {}),
                "created_at": agent["created_at"].isoformat() if agent.get("created_at") else None,
                "last_used": agent["updated_at"].isoformat() if agent.get("updated_at") else None
            })
        
        return {
            "success": True,
            "data": {
                "users": online_users,
                "agents": online_agents,
                "statistics": {
                    "total_users": len(online_users),
                    "total_agents": len(online_agents),
                    "online_users": len(online_users),
                    "online_agents": len(online_agents)
                }
            },
            "message": "è·å–åœ¨çº¿èµ„æºæˆåŠŸ"
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–åœ¨çº¿èµ„æºå¤±è´¥: {str(e)}"
        )


@router.get("/workflows/{instance_id}/nodes-detail")
async def get_workflow_nodes_detail(
    instance_id: uuid.UUID,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–å·¥ä½œæµå®ä¾‹çš„è¯¦ç»†èŠ‚ç‚¹è¾“å‡ºä¿¡æ¯"""
    try:
        from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
        from ..repositories.instance.node_instance_repository import NodeInstanceRepository
        from ..repositories.instance.task_instance_repository import TaskInstanceRepository
        
        workflow_repo = WorkflowInstanceRepository()
        node_repo = NodeInstanceRepository()
        task_repo = TaskInstanceRepository()
        
        # 1. éªŒè¯å·¥ä½œæµå®ä¾‹æ˜¯å¦å­˜åœ¨
        workflow_instance = await workflow_repo.get_instance_by_id(instance_id)
        if not workflow_instance:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨"
            )
        
        # 2. è·å–è¯¦ç»†çš„èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯ï¼ˆåŒ…æ‹¬å¤„ç†å™¨ä¿¡æ¯ï¼‰
        nodes_query = """
        SELECT 
            ni.node_instance_id,
            ni.node_id,
            n.node_base_id,
            ni.workflow_instance_id,
            ni.status as node_status,
            ni.input_data as node_input,
            ni.output_data as node_output,
            ni.error_message as node_error,
            ni.retry_count,
            ni.created_at as node_created_at,
            ni.start_at as node_started_at,
            ni.completed_at as node_completed_at,
            -- èŠ‚ç‚¹å®šä¹‰ä¿¡æ¯
            n.name as node_name,
            n.type as node_type,
            -- å¤„ç†å™¨ä¿¡æ¯ï¼ˆé€šè¿‡node_processorå…³è”è¡¨ï¼‰
            p.name as processor_name,
            p.type as processor_type,
            -- æ‰§è¡Œæ—¶é•¿è®¡ç®—
            CASE 
                WHEN ni.start_at IS NOT NULL AND ni.completed_at IS NOT NULL 
                THEN EXTRACT(EPOCH FROM (ni.completed_at - ni.start_at))::INTEGER
                WHEN ni.start_at IS NOT NULL 
                THEN EXTRACT(EPOCH FROM (NOW() - ni.start_at))::INTEGER
                ELSE NULL
            END as execution_duration_seconds
        FROM node_instance ni
        LEFT JOIN node n ON ni.node_id = n.node_id
        LEFT JOIN node_processor np ON n.node_id = np.node_id
        LEFT JOIN processor p ON np.processor_id = p.processor_id
        WHERE ni.workflow_instance_id = $1
        AND ni.is_deleted = FALSE
        ORDER BY ni.created_at ASC
        """
        
        nodes = await node_repo.db.fetch_all(nodes_query, instance_id)
        
        # 3. è·å–æ¯ä¸ªèŠ‚ç‚¹çš„ä»»åŠ¡å®ä¾‹ä¿¡æ¯
        tasks_query = """
        SELECT 
            ti.task_instance_id,
            ti.node_instance_id,
            ti.task_title,
            ti.task_description,
            ti.status as task_status,
            ti.input_data as task_input,
            ti.output_data as task_output,
            ti.result_summary as task_result,
            ti.error_message as task_error,
            ti.task_type,
            ti.priority,
            ti.estimated_duration,
            ti.actual_duration,
            ti.created_at as task_created_at,
            ti.started_at as task_started_at,
            ti.completed_at as task_completed_at,
            -- å¤„ç†å™¨ä¿¡æ¯
            p.name as processor_name,
            p.type as processor_type,
            -- åˆ†é…ä¿¡æ¯
            u.username as assigned_user_name,
            a.agent_name as assigned_agent_name
        FROM task_instance ti
        LEFT JOIN processor p ON ti.processor_id = p.processor_id
        LEFT JOIN "user" u ON ti.assigned_user_id = u.user_id
        LEFT JOIN agent a ON ti.assigned_agent_id = a.agent_id
        WHERE ti.workflow_instance_id = $1
        AND ti.is_deleted = FALSE
        ORDER BY ti.created_at ASC
        """
        
        tasks = await task_repo.db.fetch_all(tasks_query, instance_id)
        
        # 4. ç»„ç»‡èŠ‚ç‚¹å’Œä»»åŠ¡æ•°æ®
        formatted_nodes = []
        tasks_by_node = {}
        
        # æŒ‰èŠ‚ç‚¹å®ä¾‹IDåˆ†ç»„ä»»åŠ¡
        for task in tasks:
            node_id = str(task['node_instance_id']) if task['node_instance_id'] else None
            if node_id:
                if node_id not in tasks_by_node:
                    tasks_by_node[node_id] = []
                
                task_data = {
                    "task_instance_id": str(task['task_instance_id']),
                    "task_title": task['task_title'],
                    "task_description": task['task_description'],
                    "status": task['task_status'],
                    "task_type": task['task_type'],
                    "priority": task['priority'],
                    "input_data": task['task_input'] or {},
                    "output_data": task['task_output'] or {},
                    "result_summary": task['task_result'],
                    "error_message": task['task_error'],
                    "estimated_duration": task['estimated_duration'],
                    "actual_duration": task['actual_duration'],
                    "processor": {
                        "name": task['processor_name'],
                        "type": task['processor_type']
                    },
                    "assignment": {
                        "assigned_user": task['assigned_user_name'],
                        "assigned_agent": task['assigned_agent_name']
                    },
                    "timestamps": {
                        "created_at": task['task_created_at'].isoformat() if task.get('task_created_at') else None,
                        "started_at": task['task_started_at'].isoformat() if task.get('task_started_at') else None,
                        "completed_at": task['task_completed_at'].isoformat() if task.get('task_completed_at') else None
                    }
                }
                tasks_by_node[node_id].append(task_data)
        
        # å¤„ç†èŠ‚ç‚¹æ•°æ®
        for node in nodes:
            node_id = str(node['node_instance_id'])
            node_tasks = tasks_by_node.get(node_id, [])
            
            # è®¡ç®—èŠ‚ç‚¹çº§åˆ«çš„ç»Ÿè®¡ä¿¡æ¯
            total_tasks = len(node_tasks)
            completed_tasks = len([t for t in node_tasks if t['status'] == 'completed'])
            failed_tasks = len([t for t in node_tasks if t['status'] == 'failed'])
            running_tasks = len([t for t in node_tasks if t['status'] in ['in_progress', 'assigned']])
            
            # æ±‡æ€»èŠ‚ç‚¹è¾“å‡ºæ•°æ®ï¼šä»æ‰€æœ‰å·²å®Œæˆä»»åŠ¡çš„è¾“å‡ºä¸­åˆå¹¶
            node_output_data = {}
            node_input_data = node['node_input'] or {}
            
            # æ”¶é›†æ‰€æœ‰å·²å®Œæˆä»»åŠ¡çš„è¾“å‡ºæ•°æ®
            for task in node_tasks:
                if task['status'] == 'completed' and task['output_data']:
                    # åˆå¹¶ä»»åŠ¡è¾“å‡ºåˆ°èŠ‚ç‚¹è¾“å‡º
                    if isinstance(task['output_data'], dict):
                        node_output_data.update(task['output_data'])
                    else:
                        # å¦‚æœä»»åŠ¡è¾“å‡ºä¸æ˜¯å­—å…¸ï¼Œä»¥ä»»åŠ¡IDä¸ºé”®å­˜å‚¨
                        task_key = f"task_{task['task_instance_id']}"
                        node_output_data[task_key] = task['output_data']
            
            # å¦‚æœæ²¡æœ‰ä»»åŠ¡è¾“å‡ºä½†èŠ‚ç‚¹æœ‰è¾“å‡ºï¼Œä½¿ç”¨èŠ‚ç‚¹çº§åˆ«çš„è¾“å‡º
            if not node_output_data and (node['node_output'] or {}):
                node_output_data = node['node_output'] or {}
            
            node_data = {
                "node_instance_id": str(node['node_instance_id']),
                "node_id": str(node['node_id']),
                "node_base_id": str(node['node_base_id']),
                "node_name": node['node_name'],
                "node_type": node['node_type'],
                "status": node['node_status'],
                "retry_count": node['retry_count'] or 0,
                "input_data": node_input_data,
                "output_data": node_output_data,
                "error_message": node['node_error'],
                "config": node.get('node_config', {}),  # ä½¿ç”¨getæ–¹æ³•é˜²æ­¢KeyError
                "execution_duration_seconds": node['execution_duration_seconds'],
                "processor_name": node['processor_name'],
                "processor_type": node['processor_type'],
                "task_count": total_tasks,
                "timestamps": {
                    "created_at": node['node_created_at'].isoformat() if node.get('node_created_at') else None,
                    "started_at": node['node_started_at'].isoformat() if node.get('node_started_at') else None,
                    "completed_at": node['node_completed_at'].isoformat() if node.get('node_completed_at') else None
                },
                "task_statistics": {
                    "total_tasks": total_tasks,
                    "completed_tasks": completed_tasks,
                    "failed_tasks": failed_tasks,
                    "running_tasks": running_tasks,
                    "success_rate": (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
                },
                "tasks": node_tasks
            }
            formatted_nodes.append(node_data)
        
        # 5. è·å–èŠ‚ç‚¹è¿æ¥å…³ç³»ï¼ˆä»å·¥ä½œæµå®šä¹‰ä¸­ï¼‰
        edges_query = """
        SELECT 
            nc.from_node_id as source_node_id,
            nc.to_node_id as target_node_id,
            nc.connection_type,
            nc.condition_config,
            -- è·å–æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹çš„å®ä¾‹ID
            ni_source.node_instance_id as source_instance_id,
            ni_target.node_instance_id as target_instance_id,
            -- è·å–èŠ‚ç‚¹åç§°ç”¨äºè°ƒè¯•
            n_source.name as source_node_name,
            n_target.name as target_node_name
        FROM node_connection nc
        LEFT JOIN node n_source ON nc.from_node_id = n_source.node_id
        LEFT JOIN node n_target ON nc.to_node_id = n_target.node_id
        LEFT JOIN node_instance ni_source ON n_source.node_id = ni_source.node_id 
            AND ni_source.workflow_instance_id = $1
        LEFT JOIN node_instance ni_target ON n_target.node_id = ni_target.node_id 
            AND ni_target.workflow_instance_id = $1
        WHERE nc.workflow_id = (
            SELECT workflow_id FROM workflow_instance WHERE instance_id = $1
        )
        """
        
        edges_data = await node_repo.db.fetch_all(edges_query, instance_id)
        
        # æ ¼å¼åŒ–è¿æ¥è¾¹æ•°æ®
        formatted_edges = []
        for edge in edges_data:
            if edge['source_instance_id'] and edge['target_instance_id']:
                # å¤„ç†æ¡ä»¶é…ç½®
                condition_config = edge['condition_config'] or {}
                condition_label = None
                if edge['connection_type'] == 'conditional' and condition_config:
                    condition_label = condition_config.get('condition', '')
                
                edge_data = {
                    "id": f"edge_{edge['source_instance_id']}_{edge['target_instance_id']}",
                    "source": str(edge['source_instance_id']),
                    "target": str(edge['target_instance_id']),
                    "connection_type": edge['connection_type'],
                    "condition_config": condition_config,
                    "condition_label": condition_label,
                    "source_node_name": edge['source_node_name'],
                    "target_node_name": edge['target_node_name']
                }
                formatted_edges.append(edge_data)
        
        # 6. è®¡ç®—å·¥ä½œæµçº§åˆ«ç»Ÿè®¡
        total_nodes = len(formatted_nodes)
        completed_nodes = len([n for n in formatted_nodes if n['status'] == 'completed'])
        failed_nodes = len([n for n in formatted_nodes if n['status'] == 'failed'])
        running_nodes = len([n for n in formatted_nodes if n['status'] == 'running'])
        
        all_tasks = sum([len(n['tasks']) for n in formatted_nodes])
        all_completed_tasks = sum([n['task_statistics']['completed_tasks'] for n in formatted_nodes])
        all_failed_tasks = sum([n['task_statistics']['failed_tasks'] for n in formatted_nodes])
        
        workflow_statistics = {
            "workflow_instance_id": str(instance_id),
            "workflow_name": workflow_instance.get('workflow_name'),
            "instance_name": workflow_instance.get('instance_name'),
            "status": workflow_instance.get('status'),
            "node_statistics": {
                "total_nodes": total_nodes,
                "completed_nodes": completed_nodes,
                "failed_nodes": failed_nodes,
                "running_nodes": running_nodes,
                "success_rate": (completed_nodes / total_nodes * 100) if total_nodes > 0 else 0
            },
            "task_statistics": {
                "total_tasks": all_tasks,
                "completed_tasks": all_completed_tasks,
                "failed_tasks": all_failed_tasks,
                "running_tasks": all_tasks - all_completed_tasks - all_failed_tasks,
                "success_rate": (all_completed_tasks / all_tasks * 100) if all_tasks > 0 else 0
            },
            "timestamps": {
                "started_at": workflow_instance.get('started_at'),
                "completed_at": workflow_instance.get('completed_at'),
                "created_at": workflow_instance.get('created_at')
            }
        }
        
        return {
            "success": True,
            "data": {
                "workflow_statistics": workflow_statistics,
                "nodes": formatted_nodes,
                "edges": formatted_edges
            },
            "message": "è·å–å·¥ä½œæµèŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–å·¥ä½œæµèŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
        import traceback
        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å·¥ä½œæµèŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯å¤±è´¥: {str(e)}"
        )