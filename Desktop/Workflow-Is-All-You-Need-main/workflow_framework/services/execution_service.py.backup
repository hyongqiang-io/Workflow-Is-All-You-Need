"""
å·¥ä½œæµæ‰§è¡Œå¼•æ“æœåŠ¡
Workflow Execution Engine Service
"""

import uuid
import asyncio
from typing import Optional, Dict, Any, List
from datetime import datetime
from loguru import logger

from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
from ..repositories.instance.task_instance_repository import TaskInstanceRepository
from ..repositories.workflow.workflow_repository import WorkflowRepository
from ..repositories.node.node_repository import NodeRepository
from ..repositories.processor.processor_repository import ProcessorRepository
from ..repositories.user.user_repository import UserRepository
from ..repositories.agent.agent_repository import AgentRepository
from ..models.instance import (
    WorkflowInstanceCreate, WorkflowInstanceUpdate, WorkflowInstanceStatus,
    TaskInstanceCreate, TaskInstanceUpdate, TaskInstanceStatus, TaskInstanceType,
    WorkflowExecuteRequest
)
from ..models.node import NodeType
from ..utils.helpers import now_utc
from .agent_task_service import agent_task_service
from .workflow_context_manager import WorkflowContextManager
from .node_dependency_manager import NodeDependencyManager


class ExecutionEngine:
    """å·¥ä½œæµæ‰§è¡Œå¼•æ“"""
    
    def __init__(self):
        self.workflow_instance_repo = WorkflowInstanceRepository()
        self.task_instance_repo = TaskInstanceRepository()
        self.workflow_repo = WorkflowRepository()
        self.node_repo = NodeRepository()
        self.processor_repo = ProcessorRepository()
        self.user_repo = UserRepository()
        self.agent_repo = AgentRepository()
        
        # æ‰§è¡Œé˜Ÿåˆ—å’ŒçŠ¶æ€è·Ÿè¸ª
        self.execution_queue = asyncio.Queue()
        self.running_instances = {}
        self.is_running = False
        
        # ä»»åŠ¡å®Œæˆå›è°ƒæ˜ å°„
        self.task_callbacks = {}
        
        # æ–°å¢ï¼šä¸Šä¸‹æ–‡ç®¡ç†å’Œä¾èµ–ç®¡ç†
        self.context_manager = WorkflowContextManager()
        self.dependency_manager = None  # å°†åœ¨start_engineä¸­åˆå§‹åŒ–
    
    async def start_engine(self):
        """å¯åŠ¨æ‰§è¡Œå¼•æ“"""
        if self.is_running:
            logger.warning("æ‰§è¡Œå¼•æ“å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.is_running = True
        logger.info("å·¥ä½œæµæ‰§è¡Œå¼•æ“å¯åŠ¨")
        
        # åˆå§‹åŒ–ä¾èµ–ç®¡ç†å™¨
        self.dependency_manager = NodeDependencyManager("node_instance")
        
        # æ³¨å†Œä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„å›è°ƒ
        self.context_manager.register_completion_callback(self._on_nodes_ready_to_execute)
        
        # æ³¨å†Œä¸ºAgentTaskServiceçš„å›è°ƒç›‘å¬å™¨
        agent_task_service.register_completion_callback(self)
        logger.info("å·²æ³¨å†Œå›è°ƒç›‘å¬å™¨")
        
        # å¯åŠ¨ä»»åŠ¡å¤„ç†åç¨‹
        asyncio.create_task(self._process_execution_queue())
        asyncio.create_task(self._monitor_running_instances())
    
    async def stop_engine(self):
        """åœæ­¢æ‰§è¡Œå¼•æ“"""
        self.is_running = False
        logger.info("å·¥ä½œæµæ‰§è¡Œå¼•æ“åœæ­¢")
    
    async def execute_workflow(self, request: WorkflowExecuteRequest, 
                             executor_id: uuid.UUID) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥ä½œæµ"""
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {request.workflow_base_id}, æ‰§è¡Œè€…: {executor_id}")
            # 1. éªŒè¯å·¥ä½œæµæ˜¯å¦å­˜åœ¨ä¸”å¯æ‰§è¡Œ
            logger.info(f"æ­¥éª¤1: æŸ¥è¯¢å·¥ä½œæµ {request.workflow_base_id}")
            workflow = await self.workflow_repo.get_workflow_by_base_id(request.workflow_base_id)
            if not workflow:
                logger.error(f"å·¥ä½œæµä¸å­˜åœ¨: {request.workflow_base_id}")
                raise ValueError("å·¥ä½œæµä¸å­˜åœ¨")
            logger.info(f"âœ… å·¥ä½œæµæŸ¥è¯¢æˆåŠŸ: {workflow.get('name', 'Unknown')} (ID: {workflow['workflow_id']})")
            
            # 2. åˆ›å»ºå·¥ä½œæµå®ä¾‹
            logger.info(f"æ­¥éª¤2: åˆ›å»ºå·¥ä½œæµå®ä¾‹ '{request.instance_name}'")
            instance_data = WorkflowInstanceCreate(
                workflow_base_id=request.workflow_base_id,
                executor_id=executor_id,
                instance_name=request.instance_name,
                input_data=request.input_data,
                context_data=request.context_data
            )
            
            instance = await self.workflow_instance_repo.create_instance(instance_data)
            if not instance:
                logger.error("åˆ›å»ºå·¥ä½œæµå®ä¾‹å¤±è´¥")
                raise RuntimeError("åˆ›å»ºå·¥ä½œæµå®ä¾‹å¤±è´¥")
            
            instance_id = instance['workflow_instance_id']
            logger.info(f"âœ… å·¥ä½œæµå®ä¾‹åˆ›å»ºæˆåŠŸ: {request.instance_name} (ID: {instance_id})")
            
            # 3. è·å–å·¥ä½œæµçš„æ‰€æœ‰èŠ‚ç‚¹
            logger.info(f"æ­¥éª¤3: æŸ¥è¯¢å·¥ä½œæµ {request.workflow_base_id} çš„æ‰€æœ‰èŠ‚ç‚¹")
            nodes = await self.node_repo.get_workflow_nodes(request.workflow_base_id)
            
            if not nodes:
                logger.error(f"å·¥ä½œæµæ²¡æœ‰èŠ‚ç‚¹: {request.workflow_base_id}")
                raise ValueError("å·¥ä½œæµæ²¡æœ‰èŠ‚ç‚¹")
            
            logger.info(f"âœ… æ‰¾åˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹:")
            for i, node in enumerate(nodes, 1):
                logger.info(f"   èŠ‚ç‚¹{i}: {node['name']} (ç±»å‹: {node['type']}, ID: {node['node_id']})")
            
            # 4. è·å–èŠ‚ç‚¹è¿æ¥å…³ç³»
            logger.info(f"æ­¥éª¤4: æŸ¥è¯¢å·¥ä½œæµèŠ‚ç‚¹è¿æ¥å…³ç³»")
            connections = []
            try:
                if hasattr(self.node_repo, 'get_workflow_connections'):
                    connections = await self.node_repo.get_workflow_connections(request.workflow_base_id)
                    logger.info(f"âœ… æ‰¾åˆ° {len(connections)} ä¸ªè¿æ¥:")
                    for i, conn in enumerate(connections, 1):
                        logger.info(f"   è¿æ¥{i}: {conn.get('from_node_name', 'Unknown')} -> {conn.get('to_node_name', 'Unknown')}")
                else:
                    logger.warning("èŠ‚ç‚¹ä»“åº“ä¸æ”¯æŒè·å–è¿æ¥å…³ç³»")
            except Exception as e:
                logger.warning(f"è·å–å·¥ä½œæµè¿æ¥å¤±è´¥: {e}")
                connections = []
            
            # 5. åˆå§‹åŒ–å·¥ä½œæµä¸Šä¸‹æ–‡
            logger.info(f"æ­¥éª¤5: åˆå§‹åŒ–å·¥ä½œæµä¸Šä¸‹æ–‡")
            try:
                await self.context_manager.initialize_workflow_context(instance_id)
                logger.info(f"âœ… å·¥ä½œæµä¸Šä¸‹æ–‡åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"å·¥ä½œæµä¸Šä¸‹æ–‡åˆå§‹åŒ–å¤±è´¥: {e}")
                raise
            
            # 6. åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å’Œæ³¨å†Œä¾èµ–å…³ç³»ï¼ˆä¸åˆ›å»ºä»»åŠ¡å®ä¾‹ï¼‰
            logger.info(f"æ­¥éª¤6: åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å’Œä¾èµ–å…³ç³»")
            try:
                await self._create_node_instances_with_dependencies(instance_id, request.workflow_base_id, nodes)
                logger.info(f"âœ… èŠ‚ç‚¹å®ä¾‹å’Œä¾èµ–å…³ç³»åˆ›å»ºå®Œæˆ")
            except Exception as e:
                logger.error(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å’Œä¾èµ–å…³ç³»å¤±è´¥: {e}")
                raise
            
            # 7. å¯åŠ¨æ‰§è¡Œï¼ˆåªå¯åŠ¨STARTèŠ‚ç‚¹ï¼‰
            logger.info(f"æ­¥éª¤7: å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ")
            try:
                await self._start_workflow_execution_with_dependencies(instance_id, request.workflow_base_id)
                logger.info(f"âœ… å·¥ä½œæµæ‰§è¡Œå¯åŠ¨å®Œæˆ")
                
                # è¾“å‡ºæ‰§è¡Œå¯åŠ¨çš„å®Œæ•´çŠ¶æ€
                print(f"\nğŸš€ ã€å·¥ä½œæµå¯åŠ¨æˆåŠŸã€‘")
                print(f"å·¥ä½œæµ: {workflow.get('name', 'Unknown')}")
                print(f"å®ä¾‹åç§°: {request.instance_name}")
                print(f"å®ä¾‹ID: {instance_id}")
                print(f"æ‰§è¡Œè€…: {executor_id}")
                print(f"èŠ‚ç‚¹æ•°é‡: {len(nodes)}")
                print(f"çŠ¶æ€: RUNNING")
                print(f"å¯åŠ¨æ—¶é—´: {now_utc().strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"è¯·å…³æ³¨åç»­çš„ä»»åŠ¡åˆ†é…æ—¥å¿—...")
                print("=" * 60)
                
                # ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œæ‘˜è¦ï¼ˆå»¶è¿Ÿä¸€ç‚¹ï¼Œè®©ä»»åŠ¡åˆ›å»ºå®Œæˆï¼‰
                try:
                    import asyncio
                    await asyncio.sleep(1)  # ç­‰å¾…1ç§’è®©ä»»åŠ¡åˆ›å»ºå®Œæˆ
                    await self._log_workflow_execution_summary(instance_id)
                except Exception as e:
                    logger.warning(f"ç”Ÿæˆæ‰§è¡Œæ‘˜è¦å¤±è´¥: {e}")
                
            except Exception as e:
                logger.error(f"å¯åŠ¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
                raise
            
            return {
                'instance_id': instance_id,
                'status': WorkflowInstanceStatus.RUNNING.value,
                'message': 'å·¥ä½œæµå¼€å§‹æ‰§è¡Œ'
            }
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œå·¥ä½œæµå¤±è´¥: {e}")
            raise
    
    async def _create_node_instances(self, workflow_instance_id: uuid.UUID, nodes: List[Dict[str, Any]]):
        """åˆ›å»ºèŠ‚ç‚¹å®ä¾‹"""
        try:
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceCreate, NodeInstanceStatus
            
            node_instance_repo = NodeInstanceRepository()
            
            for node in nodes:
                # 1. å…ˆåˆ›å»ºèŠ‚ç‚¹å®ä¾‹
                node_instance_data = NodeInstanceCreate(
                    workflow_instance_id=workflow_instance_id,
                    node_id=node['node_id'],
                    node_base_id=node['node_base_id'],  # æ·»åŠ ç¼ºå¤±çš„node_base_id
                    node_instance_name=f"{node['name']}_instance",
                    task_description=node.get('task_description', ''),
                    status=NodeInstanceStatus.PENDING,
                    input_data={},
                    output_data={},
                    error_message=None,
                    retry_count=0
                )
                
                node_instance = await node_instance_repo.create_node_instance(node_instance_data)
                if not node_instance:
                    logger.error(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¤±è´¥: {node['name']}")
                    continue
                
                node_instance_id = node_instance['node_instance_id']
                logger.info(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹: {node['name']} (ID: {node_instance_id})")
                
                # 2. ä¸ºå¤„ç†å™¨èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹
                if node['type'] == NodeType.PROCESSOR.value:
                    # è·å–èŠ‚ç‚¹çš„å¤„ç†å™¨
                    processors = await self._get_node_processors(
                        node['node_base_id'], node['workflow_base_id']
                    )
                    
                    for processor in processors:
                        # æ ¹æ®å¤„ç†å™¨ç±»å‹ç¡®å®šä»»åŠ¡ç±»å‹å’Œåˆ†é…
                        processor_type = processor.get('processor_type', processor.get('type', 'HUMAN'))
                        task_type = self._determine_task_type(processor_type)
                        assigned_user_id = processor.get('user_id')
                        assigned_agent_id = processor.get('agent_id')
                        
                        # åˆ›å»ºä»»åŠ¡å®ä¾‹
                        task_title = f"{node['name']} - {processor.get('processor_name', processor.get('name', 'Unknown'))}"
                        task_description = node.get('task_description') or node.get('description') or f"æ‰§è¡ŒèŠ‚ç‚¹ {node['name']} çš„ä»»åŠ¡"
                        instructions = node.get('instructions') or processor.get('instructions') or f"è¯·å¤„ç†èŠ‚ç‚¹ {node['name']} çš„ç›¸å…³ä»»åŠ¡"
                        
                        task_data = TaskInstanceCreate(
                            node_instance_id=node_instance_id,  # ä½¿ç”¨çœŸå®çš„èŠ‚ç‚¹å®ä¾‹ID
                            workflow_instance_id=workflow_instance_id,
                            processor_id=processor['processor_id'],
                            task_type=task_type,
                            task_title=task_title,
                            task_description=task_description,
                            input_data={},
                            instructions=instructions,
                            priority=1,
                            assigned_user_id=assigned_user_id,
                            assigned_agent_id=assigned_agent_id,
                            estimated_duration=30
                        )
                        
                        task = await self.task_instance_repo.create_task(task_data)
                        if task:
                            logger.info(f"åˆ›å»ºä»»åŠ¡å®ä¾‹: {task['task_title']} (ID: {task['task_instance_id']})")
                        
        except Exception as e:
            logger.error(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¤±è´¥: {e}")
            raise
    
    async def _get_node_processors(self, node_base_id: uuid.UUID, workflow_base_id: uuid.UUID):
        """è·å–èŠ‚ç‚¹çš„å¤„ç†å™¨åˆ—è¡¨"""
        try:
            query = """
                SELECT np.*, p.name as processor_name, p.type as processor_type,
                       u.username, a.agent_name, p.user_id, p.agent_id
                FROM node_processor np
                JOIN processor p ON p.processor_id = np.processor_id AND p.is_deleted = FALSE
                LEFT JOIN "user" u ON u.user_id = p.user_id AND u.is_deleted = FALSE
                LEFT JOIN agent a ON a.agent_id = p.agent_id AND a.is_deleted = FALSE
                JOIN node n ON n.node_id = np.node_id AND n.is_current_version = TRUE
                WHERE n.node_base_id = $1 AND n.workflow_base_id = $2
                ORDER BY np.created_at ASC
            """
            results = await self.processor_repo.db.fetch_all(query, node_base_id, workflow_base_id)
            return results
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹å¤„ç†å™¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    async def _get_next_nodes(self, node_base_id: uuid.UUID, workflow_base_id: uuid.UUID):
        """è·å–èŠ‚ç‚¹çš„ä¸‹æ¸¸èŠ‚ç‚¹"""
        try:
            query = """
                SELECT tn.node_base_id as to_node_base_id
                FROM node_connection nc
                JOIN node fn ON fn.node_id = nc.from_node_id AND fn.is_current_version = TRUE
                JOIN node tn ON tn.node_id = nc.to_node_id AND tn.is_current_version = TRUE
                JOIN workflow w ON w.workflow_id = nc.workflow_id AND w.is_current_version = TRUE
                WHERE fn.node_base_id = $1 AND w.workflow_base_id = $2
                ORDER BY nc.created_at ASC
            """
            results = await self.node_repo.db.fetch_all(query, node_base_id, workflow_base_id)
            return [result['to_node_base_id'] for result in results]
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            return []
    
    def _determine_task_type(self, processor_type: str) -> TaskInstanceType:
        """æ ¹æ®å¤„ç†å™¨ç±»å‹ç¡®å®šä»»åŠ¡ç±»å‹"""
        if processor_type == "HUMAN":
            return TaskInstanceType.HUMAN
        elif processor_type == "AGENT":
            return TaskInstanceType.AGENT
        elif processor_type == "MIX":
            return TaskInstanceType.MIXED
        else:
            return TaskInstanceType.HUMAN  # é»˜è®¤ä¸ºäººå·¥ä»»åŠ¡
    
    def _determine_task_priority(self, task_type: TaskInstanceType, node_data: Dict[str, Any]) -> int:
        """æ ¹æ®ä»»åŠ¡ç±»å‹å’ŒèŠ‚ç‚¹é…ç½®ç¡®å®šä»»åŠ¡ä¼˜å…ˆçº§"""
        try:
            # ä»èŠ‚ç‚¹æ•°æ®ä¸­è·å–ä¼˜å…ˆçº§é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
            node_priority = node_data.get('priority', None)
            if node_priority is not None:
                return max(1, min(5, int(node_priority)))  # é™åˆ¶åœ¨1-5ä¹‹é—´
            
            # æ ¹æ®ä»»åŠ¡ç±»å‹è®¾ç½®é»˜è®¤ä¼˜å…ˆçº§
            if task_type == TaskInstanceType.HUMAN:
                return 2  # äººå·¥ä»»åŠ¡ä¼˜å…ˆçº§ç¨é«˜
            elif task_type == TaskInstanceType.AGENT:
                return 1  # Agentä»»åŠ¡ä¼˜å…ˆçº§æ­£å¸¸
            elif task_type == TaskInstanceType.MIXED:
                return 3  # æ··åˆä»»åŠ¡ä¼˜å…ˆçº§æœ€é«˜
            else:
                return 1  # é»˜è®¤ä¼˜å…ˆçº§
                
        except Exception as e:
            logger.warning(f"ç¡®å®šä»»åŠ¡ä¼˜å…ˆçº§å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            return 1
    
    def _determine_task_duration(self, task_type: TaskInstanceType, node_data: Dict[str, Any]) -> int:
        """æ ¹æ®ä»»åŠ¡ç±»å‹å’ŒèŠ‚ç‚¹é…ç½®ç¡®å®šé¢„ä¼°æ‰§è¡Œæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"""
        try:
            # ä»èŠ‚ç‚¹æ•°æ®ä¸­è·å–é¢„ä¼°æ—¶é—´é…ç½®
            node_duration = node_data.get('estimated_duration', None)
            if node_duration is not None:
                return max(5, min(480, int(node_duration)))  # é™åˆ¶åœ¨5åˆ†é’Ÿåˆ°8å°æ—¶ä¹‹é—´
            
            # æ ¹æ®ä»»åŠ¡ç±»å‹è®¾ç½®é»˜è®¤é¢„ä¼°æ—¶é—´
            if task_type == TaskInstanceType.HUMAN:
                return 60  # äººå·¥ä»»åŠ¡é»˜è®¤1å°æ—¶
            elif task_type == TaskInstanceType.AGENT:
                return 15  # Agentä»»åŠ¡é»˜è®¤15åˆ†é’Ÿ
            elif task_type == TaskInstanceType.MIXED:
                return 45  # æ··åˆä»»åŠ¡é»˜è®¤45åˆ†é’Ÿ
            else:
                return 30  # é»˜è®¤30åˆ†é’Ÿ
                
        except Exception as e:
            logger.warning(f"ç¡®å®šä»»åŠ¡é¢„ä¼°æ—¶é—´å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            return 30
    
    async def _start_workflow_execution(self, instance_id: uuid.UUID, workflow_base_id: uuid.UUID):
        """å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ"""
        try:
            # æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.RUNNING)
            await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            # æŸ¥æ‰¾å¼€å§‹èŠ‚ç‚¹
            nodes = await self.node_repo.get_workflow_nodes(workflow_base_id)
            start_nodes = [node for node in nodes if node['type'] == NodeType.START.value]
            
            if not start_nodes:
                raise ValueError("å·¥ä½œæµæ²¡æœ‰å¼€å§‹èŠ‚ç‚¹")
            
            # å°†å·¥ä½œæµå®ä¾‹åŠ å…¥æ‰§è¡Œé˜Ÿåˆ—
            execution_item = {
                'instance_id': instance_id,
                'workflow_base_id': workflow_base_id,
                'current_nodes': [node['node_base_id'] for node in start_nodes],
                'context_data': {}
            }
            
            await self.execution_queue.put(execution_item)
            self.running_instances[instance_id] = execution_item
            
            logger.info(f"å·¥ä½œæµå®ä¾‹ {instance_id} å¼€å§‹æ‰§è¡Œ")
            
        except Exception as e:
            logger.error(f"å¯åŠ¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    async def _process_execution_queue(self):
        """å¤„ç†æ‰§è¡Œé˜Ÿåˆ—"""
        while self.is_running:
            try:
                # ä»é˜Ÿåˆ—è·å–æ‰§è¡Œé¡¹ç›®
                execution_item = await asyncio.wait_for(
                    self.execution_queue.get(), timeout=1.0
                )
                
                # å¤„ç†æ‰§è¡Œé¡¹ç›®
                await self._process_workflow_step(execution_item)
                
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"å¤„ç†æ‰§è¡Œé˜Ÿåˆ—å¤±è´¥: {e}")
                await asyncio.sleep(1)
    
    async def _process_workflow_step(self, execution_item: Dict[str, Any]):
        """å¤„ç†å·¥ä½œæµæ­¥éª¤"""
        try:
            instance_id = execution_item['instance_id']
            workflow_base_id = execution_item['workflow_base_id']
            current_nodes = execution_item['current_nodes']
            
            logger.info(f"å¤„ç†å·¥ä½œæµå®ä¾‹ {instance_id} çš„èŠ‚ç‚¹: {current_nodes}")
            
            # å¤„ç†å½“å‰èŠ‚ç‚¹
            next_nodes = []
            for node_id in current_nodes:
                node_result = await self._process_node(instance_id, workflow_base_id, node_id)
                if node_result.get('next_nodes'):
                    next_nodes.extend(node_result['next_nodes'])
            
            # å¦‚æœæœ‰ä¸‹ä¸€æ­¥èŠ‚ç‚¹ï¼Œç»§ç»­æ‰§è¡Œ
            if next_nodes:
                execution_item['current_nodes'] = next_nodes
                await self.execution_queue.put(execution_item)
            else:
                # å·¥ä½œæµå®Œæˆ
                await self._complete_workflow(instance_id)
                
        except Exception as e:
            logger.error(f"å¤„ç†å·¥ä½œæµæ­¥éª¤å¤±è´¥: {e}")
            await self._fail_workflow(execution_item['instance_id'], str(e))
    
    async def _process_node(self, instance_id: uuid.UUID, workflow_base_id: uuid.UUID, 
                          node_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªèŠ‚ç‚¹"""
        try:
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            node = await self.node_repo.get_node_by_base_id(node_id, workflow_base_id)
            if not node:
                raise ValueError(f"èŠ‚ç‚¹ {node_id} ä¸å­˜åœ¨")
            
            node_type = node['type']
            logger.info(f"å¤„ç†èŠ‚ç‚¹: {node['name']} (ç±»å‹: {node_type})")
            
            if node_type == NodeType.START.value:
                # å¼€å§‹èŠ‚ç‚¹ç›´æ¥å®Œæˆ
                return await self._handle_start_node(instance_id, workflow_base_id, node_id)
            elif node_type == NodeType.END.value:
                # ç»“æŸèŠ‚ç‚¹
                return await self._handle_end_node(instance_id, workflow_base_id, node_id)
            elif node_type == NodeType.PROCESSOR.value:
                # å¤„ç†å™¨èŠ‚ç‚¹
                return await self._handle_processor_node(instance_id, workflow_base_id, node_id)
            else:
                logger.warning(f"æœªçŸ¥èŠ‚ç‚¹ç±»å‹: {node_type}")
                return {'next_nodes': []}
                
        except Exception as e:
            logger.error(f"å¤„ç†èŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _handle_start_node(self, instance_id: uuid.UUID, workflow_base_id: uuid.UUID, 
                                node_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†å¼€å§‹èŠ‚ç‚¹"""
        try:
            # è·å–ä¸‹æ¸¸èŠ‚ç‚¹
            next_nodes = await self._get_next_nodes(node_id, workflow_base_id)
            
            logger.info(f"å¼€å§‹èŠ‚ç‚¹å¤„ç†å®Œæˆï¼Œä¸‹ä¸€æ­¥èŠ‚ç‚¹: {next_nodes}")
            return {'next_nodes': next_nodes}
            
        except Exception as e:
            logger.error(f"å¤„ç†å¼€å§‹èŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _handle_end_node(self, instance_id: uuid.UUID, workflow_base_id: uuid.UUID, 
                              node_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†ç»“æŸèŠ‚ç‚¹"""
        try:
            logger.info(f"åˆ°è¾¾ç»“æŸèŠ‚ç‚¹ï¼Œå·¥ä½œæµå®ä¾‹ {instance_id} å³å°†å®Œæˆ")
            return {'next_nodes': []}  # æ²¡æœ‰ä¸‹ä¸€æ­¥èŠ‚ç‚¹
            
        except Exception as e:
            logger.error(f"å¤„ç†ç»“æŸèŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _handle_processor_node(self, instance_id: uuid.UUID, workflow_base_id: uuid.UUID, 
                                   node_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†å¤„ç†å™¨èŠ‚ç‚¹"""
        try:
            # è·å–èŠ‚ç‚¹çš„ä»»åŠ¡å®ä¾‹
            tasks = await self.task_instance_repo.get_tasks_by_workflow_instance(instance_id)
            node_tasks = [task for task in tasks if task.get('node_base_id') == node_id]
            
            if not node_tasks:
                logger.warning(f"èŠ‚ç‚¹ {node_id} æ²¡æœ‰ä»»åŠ¡å®ä¾‹")
                return {'next_nodes': []}
            
            # å¯åŠ¨ä»»åŠ¡æ‰§è¡Œ
            for task in node_tasks:
                await self._execute_task(task)
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥å¼‚æ­¥ç­‰å¾…ï¼‰
            await asyncio.sleep(1)  # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œæ—¶é—´
            
            # è·å–ä¸‹æ¸¸èŠ‚ç‚¹
            next_nodes = await self._get_next_nodes(node_id, workflow_base_id)
            
            logger.info(f"å¤„ç†å™¨èŠ‚ç‚¹å¤„ç†å®Œæˆï¼Œä¸‹ä¸€æ­¥èŠ‚ç‚¹: {next_nodes}")
            return {'next_nodes': next_nodes}
            
        except Exception as e:
            logger.error(f"å¤„ç†å¤„ç†å™¨èŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _execute_task(self, task: Dict[str, Any]):
        """æ‰§è¡Œå•ä¸ªä»»åŠ¡"""
        try:
            task_id = task['task_instance_id']
            task_type = task['task_type']
            
            logger.info(f"æ‰§è¡Œä»»åŠ¡: {task['task_title']} (ç±»å‹: {task_type})")
            
            if task_type == TaskInstanceType.HUMAN.value:
                # äººå·¥ä»»åŠ¡ï¼šæ›´æ–°çŠ¶æ€ä¸ºå·²åˆ†é…ï¼Œç­‰å¾…äººå·¥å¤„ç†
                logger.info(f"ğŸ‘¤ å¤„ç†äººå·¥ä»»åŠ¡: {task['task_title']}")
                logger.info(f"   - ä»»åŠ¡ID: {task_id}")
                logger.info(f"   - åˆ†é…ç›®æ ‡ç”¨æˆ·: {task.get('assigned_user_id')}")
                
                # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æœ‰åˆ†é…çš„ç”¨æˆ·
                assigned_user_id = task.get('assigned_user_id')
                if not assigned_user_id:
                    logger.warning(f"âš ï¸  äººå·¥ä»»åŠ¡æ²¡æœ‰åˆ†é…ç”¨æˆ·ï¼Œä»»åŠ¡å°†ä¿æŒPENDINGçŠ¶æ€")
                    logger.warning(f"   - ä»»åŠ¡ID: {task_id}")
                    logger.warning(f"   - ä»»åŠ¡æ ‡é¢˜: {task['task_title']}")
                    logger.warning(f"   - å»ºè®®: è¯·ä¸ºè¯¥ä»»åŠ¡çš„å¤„ç†å™¨é…ç½®ç”¨æˆ·")
                    return
                
                # ä»»åŠ¡åˆ›å»ºæ—¶å·²ç»è®¾ç½®äº†æ­£ç¡®çš„çŠ¶æ€ï¼Œè¿™é‡Œä¸éœ€è¦å†æ›´æ–°
                # ï¼ˆä»»åŠ¡åˆ›å»ºæ—¶å¦‚æœæœ‰assigned_user_idï¼ŒçŠ¶æ€å°±æ˜¯ASSIGNEDï¼‰
                logger.info(f"   âœ… ä»»åŠ¡å·²å¤„äºæ­£ç¡®çŠ¶æ€ï¼Œæ— éœ€æ›´æ–°")
                
                # è·å–ä»»åŠ¡è¯¦ç»†ä¿¡æ¯ç”¨äºé€šçŸ¥
                task_title = task.get('task_title', 'æœªå‘½åä»»åŠ¡')
                workflow_name = task.get('workflow_name', 'æœªå‘½åå·¥ä½œæµ')
                priority = task.get('priority', 1)
                estimated_duration = task.get('estimated_duration', 30)
                
                logger.info(f"ğŸ“‹ äººå·¥ä»»åŠ¡åˆ†é…è¯¦æƒ…:")
                logger.info(f"   - ä»»åŠ¡æ ‡é¢˜: {task_title}")
                logger.info(f"   - å·¥ä½œæµ: {workflow_name}")
                logger.info(f"   - åˆ†é…ç»™ç”¨æˆ·: {assigned_user_id}")
                logger.info(f"   - ä¼˜å…ˆçº§: {priority}")
                logger.info(f"   - é¢„ä¼°æ—¶é•¿: {estimated_duration}åˆ†é’Ÿ")
                logger.info(f"   - ä»»åŠ¡æè¿°: {task.get('task_description', 'æ— æè¿°')[:100]}...")
                
                # å®æ—¶é€šçŸ¥ç”¨æˆ·æœ‰æ–°ä»»åŠ¡ - é‡è¦æ”¹è¿›ï¼
                try:
                    await self._notify_user_new_task(assigned_user_id, task_id, task_title)
                    logger.info(f"   ğŸ“¬ ç”¨æˆ·é€šçŸ¥å·²å‘é€")
                except Exception as e:
                    logger.error(f"   âŒ å‘é€ç”¨æˆ·é€šçŸ¥å¤±è´¥: {e}")
                
                # è®°å½•ä»»åŠ¡åˆ†é…äº‹ä»¶ï¼ˆç”¨äºåç»­åˆ†æå’Œç›‘æ§ï¼‰
                await self._log_task_assignment_event(task_id, assigned_user_id, task_title)
                
                # è®°å½•åˆ°æ§åˆ¶å°ç”¨äºè°ƒè¯•
                print(f"\nğŸ¯ ã€ä»»åŠ¡æ¨é€ã€‘ æ–°çš„äººå·¥ä»»åŠ¡å·²åˆ†é…:")
                print(f"   ç”¨æˆ·ID: {assigned_user_id}")
                print(f"   ä»»åŠ¡ID: {task_id}")
                print(f"   ä»»åŠ¡æ ‡é¢˜: {task_title}")
                print(f"   å·¥ä½œæµ: {workflow_name}")
                print(f"   ä¼˜å…ˆçº§: {priority}")
                print(f"   æ—¶é—´: {now_utc().strftime('%Y-%m-%d %H:%M:%S')}")
                print("=" * 60)
                
            elif task_type == TaskInstanceType.AGENT.value:
                # Agentä»»åŠ¡ï¼šè°ƒç”¨AIå¤„ç†
                await self._process_agent_task(task)
                
            elif task_type == TaskInstanceType.MIXED.value:
                # æ··åˆä»»åŠ¡ï¼šåŒæ—¶æäº¤ç»™äººå·¥å’ŒAgentå¤„ç†
                await self._process_mixed_task(task)
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _process_agent_task(self, task: Dict[str, Any]):
        """å¤„ç†Agentä»»åŠ¡ - é›†æˆAgentTaskService"""
        try:
            task_id = task['task_instance_id']
            logger.info(f"é›†æˆAgentä»»åŠ¡æœåŠ¡å¤„ç†ä»»åŠ¡: {task['task_title']}")
            
            # æ³¨å†Œä»»åŠ¡å®Œæˆå›è°ƒ
            callback_future = asyncio.Future()
            self.task_callbacks[task_id] = callback_future
            
            # æäº¤ä»»åŠ¡åˆ°AgentTaskServiceè¿›è¡Œå¤„ç†
            result = await agent_task_service.submit_task_to_agent(task_id, priority=1)
            
            if result['status'] == 'queued':
                logger.info(f"Agentä»»åŠ¡ {task_id} å·²æäº¤åˆ°æœåŠ¡é˜Ÿåˆ—")
                
                # ç­‰å¾…ä»»åŠ¡å¤„ç†å®Œæˆï¼ˆé€šè¿‡å›è°ƒæœºåˆ¶ï¼‰
                try:
                    await asyncio.wait_for(callback_future, timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                    logger.info(f"Agentä»»åŠ¡ {task_id} é€šè¿‡å›è°ƒæœºåˆ¶å®Œæˆ")
                except asyncio.TimeoutError:
                    logger.error(f"Agentä»»åŠ¡ {task_id} å¤„ç†è¶…æ—¶")
                    raise TimeoutError("Agentä»»åŠ¡å¤„ç†è¶…æ—¶")
                finally:
                    # æ¸…ç†å›è°ƒ
                    self.task_callbacks.pop(task_id, None)
                
            else:
                logger.warning(f"Agentä»»åŠ¡æäº¤å¤±è´¥: {result}")
                # æ¸…ç†å›è°ƒ
                self.task_callbacks.pop(task_id, None)
                raise RuntimeError(f"Agentä»»åŠ¡æäº¤å¤±è´¥: {result}")
            
        except Exception as e:
            logger.error(f"å¤„ç†Agentä»»åŠ¡å¤±è´¥: {e}")
            # æ¸…ç†å›è°ƒ
            self.task_callbacks.pop(task.get('task_instance_id'), None)
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            fail_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.FAILED,
                error_message=str(e)
            )
            await self.task_instance_repo.update_task(task['task_instance_id'], fail_update)
            raise
    
    async def on_task_completed(self, task_id: uuid.UUID, result: Dict[str, Any]):
        """ä»»åŠ¡å®Œæˆå›è°ƒå¤„ç†"""
        try:
            logger.info(f"æ”¶åˆ°ä»»åŠ¡å®Œæˆå›è°ƒ: {task_id}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…çš„å›è°ƒ
            if task_id in self.task_callbacks:
                callback_future = self.task_callbacks[task_id]
                if not callback_future.done():
                    callback_future.set_result(result)
                    logger.info(f"ä»»åŠ¡ {task_id} å›è°ƒå·²è§¦å‘")
            else:
                logger.warning(f"æœªæ‰¾åˆ°ä»»åŠ¡ {task_id} çš„å›è°ƒæ³¨å†Œ")
                
        except Exception as e:
            logger.error(f"å¤„ç†ä»»åŠ¡å®Œæˆå›è°ƒå¤±è´¥: {e}")
    
    async def on_task_failed(self, task_id: uuid.UUID, error_message: str):
        """ä»»åŠ¡å¤±è´¥å›è°ƒå¤„ç†"""
        try:
            logger.info(f"æ”¶åˆ°ä»»åŠ¡å¤±è´¥å›è°ƒ: {task_id} - {error_message}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…çš„å›è°ƒ
            if task_id in self.task_callbacks:
                callback_future = self.task_callbacks[task_id]
                if not callback_future.done():
                    callback_future.set_exception(RuntimeError(error_message))
                    logger.info(f"ä»»åŠ¡ {task_id} å¤±è´¥å›è°ƒå·²è§¦å‘")
            else:
                logger.warning(f"æœªæ‰¾åˆ°ä»»åŠ¡ {task_id} çš„å¤±è´¥å›è°ƒæ³¨å†Œ")
                
        except Exception as e:
            logger.error(f"å¤„ç†ä»»åŠ¡å¤±è´¥å›è°ƒå¤±è´¥: {e}")
    
    async def _process_mixed_task(self, task: Dict[str, Any]):
        """å¤„ç†æ··åˆä»»åŠ¡ - äººæœºåä½œ"""
        try:
            task_id = task['task_instance_id']
            logger.info(f"å¤„ç†æ··åˆä»»åŠ¡: {task['task_title']}")
            
            # 1. é¦–å…ˆåˆ†é…ç»™äººå·¥ç”¨æˆ·å¤„ç†
            human_update = TaskInstanceUpdate(status=TaskInstanceStatus.ASSIGNED)
            await self.task_instance_repo.update_task(task_id, human_update)
            logger.info(f"æ··åˆä»»åŠ¡ {task_id} å·²åˆ†é…ç»™äººå·¥ç”¨æˆ·")
            
            # 2. åŒæ—¶æäº¤ç»™AgentæœåŠ¡è·å–AIå»ºè®®ï¼ˆä¸é˜»å¡ï¼‰
            try:
                # åˆ›å»ºAIå»ºè®®ä»»åŠ¡çš„å‰¯æœ¬æ•°æ®
                ai_suggestion_task = task.copy()
                ai_suggestion_task['task_title'] = f"[AIå»ºè®®] {task['task_title']}"
                ai_suggestion_task['task_description'] = f"ä¸ºäººå·¥ä»»åŠ¡æä¾›AIå»ºè®®: {task['task_description']}"
                
                # å¼‚æ­¥æäº¤åˆ°AgentæœåŠ¡è·å–å»ºè®®
                asyncio.create_task(self._provide_ai_assistance(task_id, ai_suggestion_task))
                logger.info(f"ä¸ºæ··åˆä»»åŠ¡ {task_id} å¯åŠ¨AIååŠ©")
                
            except Exception as e:
                logger.warning(f"å¯åŠ¨AIååŠ©å¤±è´¥ï¼Œç»§ç»­äººå·¥å¤„ç†: {e}")
            
            # 3. æ··åˆä»»åŠ¡ä¸»è¦ç­‰å¾…äººå·¥å®Œæˆï¼ŒAIå»ºè®®ä½œä¸ºè¾…åŠ©
            logger.info(f"æ··åˆä»»åŠ¡ {task_id} è¿›å…¥äººæœºåä½œæ¨¡å¼")
            
        except Exception as e:
            logger.error(f"å¤„ç†æ··åˆä»»åŠ¡å¤±è´¥: {e}")
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            fail_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.FAILED,
                error_message=str(e)
            )
            await self.task_instance_repo.update_task(task['task_instance_id'], fail_update)
            raise
    
    async def _provide_ai_assistance(self, original_task_id: uuid.UUID, ai_task: Dict[str, Any]):
        """ä¸ºäººå·¥ä»»åŠ¡æä¾›AIååŠ©å»ºè®®"""
        try:
            logger.info(f"ä¸ºä»»åŠ¡ {original_task_id} ç”ŸæˆAIå»ºè®®")
            
            # è°ƒç”¨AgentTaskServiceç”ŸæˆAIå»ºè®®
            ai_result = await agent_task_service.process_agent_task(original_task_id)
            
            # å°†AIå»ºè®®å­˜å‚¨åˆ°åŸä»»åŠ¡çš„ä¸Šä¸‹æ–‡ä¸­
            if ai_result['status'] == TaskInstanceStatus.COMPLETED.value:
                ai_suggestions = {
                    'ai_analysis': ai_result['result'],
                    'suggestions_generated_at': now_utc().isoformat(),
                    'confidence_score': ai_result['result'].get('confidence_score', 0.8),
                    'ai_recommendations': ai_result['result'].get('recommendations', [])
                }
                
                # æ›´æ–°åŸä»»åŠ¡ï¼Œæ·»åŠ AIå»ºè®®åˆ°ä¸Šä¸‹æ–‡
                update_data = TaskInstanceUpdate(
                    context_data={'ai_assistance': ai_suggestions}
                )
                await self.task_instance_repo.update_task(original_task_id, update_data)
                
                logger.info(f"AIå»ºè®®å·²æ·»åŠ åˆ°ä»»åŠ¡ {original_task_id} çš„ä¸Šä¸‹æ–‡ä¸­")
            
        except Exception as e:
            logger.warning(f"ç”ŸæˆAIååŠ©å»ºè®®å¤±è´¥: {e}")
            # AIååŠ©å¤±è´¥ä¸å½±å“ä¸»ä»»åŠ¡
    
    async def _complete_workflow(self, instance_id: uuid.UUID):
        """å®Œæˆå·¥ä½œæµ"""
        try:
            # æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºå·²å®Œæˆ
            update_data = WorkflowInstanceUpdate(
                status=WorkflowInstanceStatus.COMPLETED,
                output_data={'message': 'å·¥ä½œæµæ‰§è¡Œå®Œæˆ'}
            )
            await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            # ä»è¿è¡Œå®ä¾‹ä¸­ç§»é™¤
            self.running_instances.pop(instance_id, None)
            
            logger.info(f"å·¥ä½œæµå®ä¾‹ {instance_id} æ‰§è¡Œå®Œæˆ")
            
        except Exception as e:
            logger.error(f"å®Œæˆå·¥ä½œæµå¤±è´¥: {e}")
            raise
    
    async def _fail_workflow(self, instance_id: uuid.UUID, error_message: str):
        """å·¥ä½œæµæ‰§è¡Œå¤±è´¥"""
        try:
            # æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºå¤±è´¥
            update_data = WorkflowInstanceUpdate(
                status=WorkflowInstanceStatus.FAILED,
                error_message=error_message
            )
            await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            # ä»è¿è¡Œå®ä¾‹ä¸­ç§»é™¤
            self.running_instances.pop(instance_id, None)
            
            logger.error(f"å·¥ä½œæµå®ä¾‹ {instance_id} æ‰§è¡Œå¤±è´¥: {error_message}")
            
        except Exception as e:
            logger.error(f"æ ‡è®°å·¥ä½œæµå¤±è´¥çŠ¶æ€å¤±è´¥: {e}")
    
    async def _monitor_running_instances(self):
        """ç›‘æ§è¿è¡Œä¸­çš„å®ä¾‹"""
        while self.is_running:
            try:
                # æ£€æŸ¥è¶…æ—¶çš„å®ä¾‹
                for instance_id, execution_item in list(self.running_instances.items()):
                    # è¿™é‡Œå¯ä»¥æ·»åŠ è¶…æ—¶æ£€æŸ¥é€»è¾‘
                    pass
                
                await asyncio.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"ç›‘æ§è¿è¡Œå®ä¾‹å¤±è´¥: {e}")
                await asyncio.sleep(10)
    
    async def pause_workflow(self, instance_id: uuid.UUID) -> bool:
        """æš‚åœå·¥ä½œæµ"""
        try:
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.PAUSED)
            result = await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            if result:
                logger.info(f"å·¥ä½œæµå®ä¾‹ {instance_id} å·²æš‚åœ")
                return True
            return False
            
        except Exception as e:
            logger.error(f"æš‚åœå·¥ä½œæµå¤±è´¥: {e}")
            return False
    
    async def resume_workflow(self, instance_id: uuid.UUID) -> bool:
        """æ¢å¤å·¥ä½œæµ"""
        try:
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.RUNNING)
            result = await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            if result:
                logger.info(f"å·¥ä½œæµå®ä¾‹ {instance_id} å·²æ¢å¤")
                return True
            return False
            
        except Exception as e:
            logger.error(f"æ¢å¤å·¥ä½œæµå¤±è´¥: {e}")
            return False
    
    async def cancel_workflow(self, instance_id: uuid.UUID) -> bool:
        """å–æ¶ˆå·¥ä½œæµ"""
        try:
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.CANCELLED)
            result = await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            if result:
                # ä»è¿è¡Œå®ä¾‹ä¸­ç§»é™¤
                self.running_instances.pop(instance_id, None)
                logger.info(f"å·¥ä½œæµå®ä¾‹ {instance_id} å·²å–æ¶ˆ")
                return True
            return False
            
        except Exception as e:
            logger.error(f"å–æ¶ˆå·¥ä½œæµå¤±è´¥: {e}")
            return False
    
    async def get_workflow_status(self, instance_id: uuid.UUID) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        try:
            instance = await self.workflow_instance_repo.get_instance_by_id(instance_id)
            if not instance:
                return None
            
            # è·å–æ‰§è¡Œç»Ÿè®¡
            stats = await self.workflow_instance_repo.get_execution_statistics(instance_id)
            
            return {
                'instance': instance,
                'statistics': stats,
                'is_running': instance_id in self.running_instances
            }
            
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµçŠ¶æ€å¤±è´¥: {e}")
            return None
    
    # =============================================================================
    # æ–°å¢ï¼šä¾èµ–ç­‰å¾…å’Œä¸Šä¸‹æ–‡ç®¡ç†æ–¹æ³•
    # =============================================================================
    
    async def _create_node_instances_with_dependencies(self, 
                                                     workflow_instance_id: uuid.UUID,
                                                     workflow_base_id: uuid.UUID,
                                                     nodes: List[Dict[str, Any]]):
        """åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¹¶æ³¨å†Œä¾èµ–å…³ç³»"""
        try:
            logger.info(f"å¼€å§‹åˆ›å»ºèŠ‚ç‚¹å®ä¾‹: å·¥ä½œæµå®ä¾‹ ID={workflow_instance_id}, èŠ‚ç‚¹æ•°é‡={len(nodes)}")
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceCreate, NodeInstanceStatus
            
            node_instance_repo = NodeInstanceRepository()
            created_nodes = []
            
            # 1. å…ˆåˆ›å»ºæ‰€æœ‰èŠ‚ç‚¹å®ä¾‹
            logger.info(f"é˜¶æ®µ1: åˆ›å»º {len(nodes)} ä¸ªèŠ‚ç‚¹å®ä¾‹")
            for i, node in enumerate(nodes, 1):
                logger.info(f"  æ­£åœ¨åˆ›å»ºèŠ‚ç‚¹å®ä¾‹ {i}/{len(nodes)}: {node['name']} (ç±»å‹: {node['type']})")
                
                # è®¾ç½®åˆå§‹çŠ¶æ€ï¼šSTARTèŠ‚ç‚¹ä¸ºREADYï¼Œå…¶ä»–ä¸ºWAITING
                initial_status = NodeInstanceStatus.READY if node['type'] == NodeType.START.value else NodeInstanceStatus.WAITING
                logger.info(f"    åˆå§‹çŠ¶æ€: {initial_status.value}")
                
                node_instance_data = NodeInstanceCreate(
                    workflow_instance_id=workflow_instance_id,
                    node_id=node['node_id'],
                    node_base_id=node['node_base_id'],
                    node_instance_name=f"{node['name']}_instance",
                    task_description=node.get('task_description') or '',
                    status=initial_status,
                    input_data={},
                    output_data={},
                    error_message=None,
                    retry_count=0
                )
                
                node_instance = await node_instance_repo.create_node_instance(node_instance_data)
                if node_instance:
                    created_nodes.append({
                        'node_instance_id': node_instance['node_instance_id'],
                        'node_base_id': node['node_base_id'],
                        'node_type': node['type'],
                        'node_data': node
                    })
                    logger.info(f"  âœ… èŠ‚ç‚¹å®ä¾‹åˆ›å»ºæˆåŠŸ: {node['name']} (ID: {node_instance['node_instance_id']})")
                else:
                    logger.error(f"  âŒ èŠ‚ç‚¹å®ä¾‹åˆ›å»ºå¤±è´¥: {node['name']}")
            
            # 2. ä¸ºæ¯ä¸ªèŠ‚ç‚¹æ³¨å†Œä¾èµ–å…³ç³»
            logger.info(f"é˜¶æ®µ2: æ³¨å†Œ {len(created_nodes)} ä¸ªèŠ‚ç‚¹çš„ä¾èµ–å…³ç³»")
            for i, created_node in enumerate(created_nodes, 1):
                logger.info(f"  æ­£åœ¨æ³¨å†ŒèŠ‚ç‚¹ {i}/{len(created_nodes)} çš„ä¾èµ–: {created_node['node_data']['name']}")
                try:
                    upstream_nodes = await self.dependency_manager.get_immediate_upstream_nodes(
                        workflow_base_id, created_node['node_base_id']
                    )
                    upstream_node_ids = [n['upstream_node_id'] for n in upstream_nodes]
                    
                    await self.context_manager.register_node_dependencies(
                        created_node['node_instance_id'],
                        created_node['node_base_id'],
                        workflow_instance_id,
                        upstream_node_ids
                    )
                    
                    logger.info(f"  âœ… èŠ‚ç‚¹ä¾èµ–æ³¨å†ŒæˆåŠŸ: {len(upstream_node_ids)} ä¸ªä¸Šæ¸¸èŠ‚ç‚¹")
                except Exception as e:
                    logger.error(f"  âŒ èŠ‚ç‚¹ä¾èµ–æ³¨å†Œå¤±è´¥: {e}")
            
            # 3. ä¸å†ä¸ºæ‰€æœ‰å¤„ç†å™¨èŠ‚ç‚¹ç«‹å³åˆ›å»ºä»»åŠ¡ - æ”¹ä¸ºå»¶è¿Ÿåˆ›å»ºæœºåˆ¶
            logger.info(f"é˜¶æ®µ3: å¯ç”¨å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶ï¼Œåªä¸ºSTARTèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡")
            try:
                # åªä¸ºSTARTèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡ï¼ˆå¦‚æœSTARTèŠ‚ç‚¹æ˜¯PROCESSORç±»å‹ï¼‰
                start_nodes = [n for n in created_nodes if n['node_data']['type'] == NodeType.START.value]
                if start_nodes:
                    await self._create_tasks_for_nodes(start_nodes, workflow_instance_id)
                    logger.info(f"âœ… STARTèŠ‚ç‚¹ä»»åŠ¡åˆ›å»ºå®Œæˆ")
                
                # æ£€æŸ¥æ‰€æœ‰å°±ç»ªèŠ‚ç‚¹ï¼Œä¸ºæ»¡è¶³æ¡ä»¶çš„èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
                await self._check_downstream_nodes_for_task_creation(workflow_instance_id)
                logger.info(f"âœ… å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶å¯åŠ¨å®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶å¯åŠ¨å¤±è´¥: {e}")
            
            logger.info(f"âœ… èŠ‚ç‚¹å®ä¾‹å’Œä¾èµ–å…³ç³»åˆ›å»ºå®Œæˆ: {len(created_nodes)} ä¸ªèŠ‚ç‚¹")
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºå¸¦ä¾èµ–çš„èŠ‚ç‚¹å®ä¾‹å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def _create_tasks_for_nodes(self, created_nodes: List[Dict], workflow_instance_id: uuid.UUID):
        """ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹"""
        logger.info(f"ğŸ”§ å¼€å§‹ä¸º {len(created_nodes)} ä¸ªèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹")
        
        task_creation_count = 0
        for i, created_node in enumerate(created_nodes, 1):
            logger.info(f"ğŸ“‹ å¤„ç†èŠ‚ç‚¹ {i}/{len(created_nodes)}: {created_node.get('node_data', {}).get('name', 'æœªçŸ¥èŠ‚ç‚¹')}")
            logger.info(f"   èŠ‚ç‚¹ç±»å‹: {created_node['node_type']}")
            logger.info(f"   èŠ‚ç‚¹å®ä¾‹ID: {created_node['node_instance_id']}")
            
            if created_node['node_type'] == NodeType.PROCESSOR.value:
                node_data = created_node['node_data']
                
                logger.info(f"   ğŸ” æŸ¥è¯¢èŠ‚ç‚¹å¤„ç†å™¨...")
                # è·å–èŠ‚ç‚¹çš„å¤„ç†å™¨
                processors = await self._get_node_processors(
                    created_node['node_base_id'], 
                    node_data['workflow_base_id']
                )
                
                if not processors:
                    logger.warning(f"   âš ï¸  èŠ‚ç‚¹ {node_data['name']} æ²¡æœ‰é…ç½®å¤„ç†å™¨ï¼Œè·³è¿‡ä»»åŠ¡åˆ›å»º")
                    continue
                
                logger.info(f"   âœ… æ‰¾åˆ° {len(processors)} ä¸ªå¤„ç†å™¨")
                
                for j, processor in enumerate(processors, 1):
                    logger.info(f"   ğŸ¯ å¤„ç†å¤„ç†å™¨ {j}/{len(processors)}: {processor.get('processor_name', processor.get('name', 'Unknown'))}")
                    
                    processor_type = processor.get('processor_type', processor.get('type', 'HUMAN'))
                    task_type = self._determine_task_type(processor_type)
                    
                    logger.info(f"      å¤„ç†å™¨ç±»å‹: {processor_type}")
                    logger.info(f"      ä»»åŠ¡ç±»å‹: {task_type.value}")
                    
                    # æ ¹æ®ä»»åŠ¡ç±»å‹å’ŒèŠ‚ç‚¹é…ç½®ç¡®å®šä¼˜å…ˆçº§å’Œè¶…æ—¶è®¾ç½®
                    priority = self._determine_task_priority(task_type, node_data)
                    estimated_duration = self._determine_task_duration(task_type, node_data)
                    
                    logger.info(f"      è®¡ç®—å¾—å‡ºä¼˜å…ˆçº§: {priority}")
                    logger.info(f"      é¢„ä¼°æŒç»­æ—¶é—´: {estimated_duration}åˆ†é’Ÿ")
                    
                    # ç¡®å®šä»»åŠ¡åˆ†é…
                    assigned_user_id = processor.get('user_id')
                    assigned_agent_id = processor.get('agent_id')
                    
                    if assigned_user_id:
                        logger.info(f"      ğŸ‘¤ ä»»åŠ¡å°†åˆ†é…ç»™ç”¨æˆ·: {assigned_user_id}")
                    elif assigned_agent_id:
                        logger.info(f"      ğŸ¤– ä»»åŠ¡å°†åˆ†é…ç»™ä»£ç†: {assigned_agent_id}")
                    else:
                        logger.info(f"      â³ ä»»åŠ¡æš‚æœªåˆ†é…ï¼Œå°†ä¿æŒPENDINGçŠ¶æ€")
                    
                    # åˆ›å»ºä»»åŠ¡å®ä¾‹ï¼Œä½†æš‚æ—¶ä¸åˆ†é…ä¸Šä¸‹æ–‡æ•°æ®
                    task_title = f"{node_data['name']} - {processor.get('processor_name', processor.get('name', 'Unknown'))}"
                    
                    # ç¡®ä¿task_descriptionæœ‰å€¼
                    task_description = node_data.get('task_description') or node_data.get('description') or f"æ‰§è¡ŒèŠ‚ç‚¹ {node_data['name']} çš„ä»»åŠ¡"
                    
                    # ç¡®ä¿instructionsæœ‰å€¼  
                    instructions = node_data.get('instructions') or processor.get('instructions') or f"è¯·å¤„ç†èŠ‚ç‚¹ {node_data['name']} çš„ç›¸å…³ä»»åŠ¡"
                    
                    logger.info(f"      ğŸ“ ä»»åŠ¡æè¿°: {task_description[:50]}{'...' if len(task_description) > 50 else ''}")
                    logger.info(f"      ğŸ“‹ æ‰§è¡ŒæŒ‡ä»¤: {instructions[:50]}{'...' if len(instructions) > 50 else ''}")
                    
                    task_data = TaskInstanceCreate(
                        node_instance_id=created_node['node_instance_id'],
                        workflow_instance_id=workflow_instance_id,
                        processor_id=processor['processor_id'],
                        task_type=task_type,
                        task_title=task_title,
                        task_description=task_description,
                        input_data={},  # å°†åœ¨æ‰§è¡Œæ—¶å¡«å……ä¸Šä¸‹æ–‡æ•°æ®
                        instructions=instructions,
                        priority=priority,
                        assigned_user_id=assigned_user_id,
                        assigned_agent_id=assigned_agent_id,
                        estimated_duration=estimated_duration
                    )
                    
                    logger.info(f"      ğŸ“ æ­£åœ¨åˆ›å»ºä»»åŠ¡å®ä¾‹...")
                    try:
                        task = await self.task_instance_repo.create_task(task_data)
                        if task:
                            task_creation_count += 1
                            logger.info(f"      âœ… ä»»åŠ¡å®ä¾‹åˆ›å»ºæˆåŠŸ!")
                            logger.info(f"         ä»»åŠ¡ID: {task['task_instance_id']}")
                            logger.info(f"         ä»»åŠ¡æ ‡é¢˜: {task['task_title']}")
                        else:
                            logger.error(f"      âŒ ä»»åŠ¡å®ä¾‹åˆ›å»ºå¤±è´¥: è¿”å›ç©ºç»“æœ")
                    except Exception as e:
                        logger.error(f"      âŒ ä»»åŠ¡å®ä¾‹åˆ›å»ºå¼‚å¸¸: {e}")
                        import traceback
                        logger.error(f"      å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            else:
                logger.info(f"   â­ï¸  èŠ‚ç‚¹ç±»å‹ä¸æ˜¯PROCESSORï¼Œè·³è¿‡ä»»åŠ¡åˆ›å»º")
        
        logger.info(f"ğŸ‰ ä»»åŠ¡åˆ›å»ºå®Œæˆ! æ€»å…±åˆ›å»ºäº† {task_creation_count} ä¸ªä»»åŠ¡å®ä¾‹")
    
    async def _start_workflow_execution_with_dependencies(self, 
                                                        workflow_instance_id: uuid.UUID,
                                                        workflow_base_id: uuid.UUID):
        """å¯åŠ¨å·¥ä½œæµæ‰§è¡Œï¼ˆåªå¯åŠ¨STARTèŠ‚ç‚¹ï¼‰"""
        try:
            logger.info(f"å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ: {workflow_instance_id}")
            logger.info(f"è°ƒç”¨_get_start_nodesï¼Œå·¥ä½œæµå®ä¾‹ID: {workflow_instance_id}")
            
            # é¦–å…ˆæ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.RUNNING)
            await self.workflow_instance_repo.update_instance(workflow_instance_id, update_data)
            
            # è·å–STARTèŠ‚ç‚¹
            logger.info(f"æ­¥éª¤A: æŸ¥æ‰¾STARTèŠ‚ç‚¹")
            start_nodes = await self._get_start_nodes(workflow_instance_id)
            logger.info(f"âœ… STARTèŠ‚ç‚¹æŸ¥è¯¢ç»“æœ: æ‰¾åˆ° {len(start_nodes)} ä¸ªSTARTèŠ‚ç‚¹")
            
            if not start_nodes:
                logger.error(f"âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•STARTèŠ‚ç‚¹æˆ–å‡†å¤‡æ‰§è¡Œçš„èŠ‚ç‚¹")
                raise ValueError("æ²¡æœ‰æ‰¾åˆ°STARTèŠ‚ç‚¹æˆ–å‡†å¤‡æ‰§è¡Œçš„èŠ‚ç‚¹")
            
            # æ˜¾ç¤ºæ‰¾åˆ°çš„STARTèŠ‚ç‚¹è¯¦æƒ…
            for i, start_node in enumerate(start_nodes, 1):
                logger.info(f"  STARTèŠ‚ç‚¹{i}: {start_node.get('node_name', '\u672a\u77e5')} (ID: {start_node['node_instance_id']})")
            
            # æ‰§è¡ŒSTARTèŠ‚ç‚¹
            logger.info(f"æ­¥éª¤B: å¼€å§‹æ‰§è¡Œ {len(start_nodes)} ä¸ªSTARTèŠ‚ç‚¹")
            for i, start_node in enumerate(start_nodes, 1):
                node_name = start_node.get('node_name', '\u672a\u77e5')
                logger.info(f"  æ­£åœ¨æ‰§è¡ŒSTARTèŠ‚ç‚¹ {i}/{len(start_nodes)}: {node_name} (ID: {start_node['node_instance_id']})")
                try:
                    await self._execute_start_node_directly(workflow_instance_id, start_node)
                    logger.info(f"  âœ… STARTèŠ‚ç‚¹æ‰§è¡ŒæˆåŠŸ: {node_name}")
                except Exception as e:
                    logger.error(f"  âŒ STARTèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {node_name} - {e}")
                    raise
            
            logger.info(f"âœ… å·¥ä½œæµ {workflow_instance_id} æ‰€æœ‰STARTèŠ‚ç‚¹æ‰§è¡Œå®Œæˆï¼Œå·¥ä½œæµå·²å¼€å§‹è¿è¡Œ")
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆè¯¦æƒ…: {traceback.format_exc()}")
            raise
    
    async def _get_start_nodes(self, workflow_instance_id: uuid.UUID) -> List[Dict]:
        """è·å–STARTèŠ‚ç‚¹"""
        try:
            logger.info(f"ğŸ” å¼€å§‹æŸ¥è¯¢STARTèŠ‚ç‚¹: workflow_instance_id={workflow_instance_id}")
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_instance_repo = NodeInstanceRepository()
            
            query = """
            SELECT ni.*, n.type as node_type, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1
            AND LOWER(n.type) = 'start'
            AND ni.status IN ('pending', 'PENDING')
            AND ni.is_deleted = FALSE
            AND n.is_deleted = FALSE
            ORDER BY ni.created_at ASC
            """
            
            # ä½¿ç”¨æ•°æ®åº“ç®¡ç†å™¨ç›´æ¥æ‰§è¡ŒæŸ¥è¯¢
            start_nodes = await node_instance_repo.db.fetch_all(query, workflow_instance_id)
            logger.info(f"æ‰¾åˆ° {len(start_nodes)} ä¸ªSTARTèŠ‚ç‚¹å®ä¾‹ï¼Œå·¥ä½œæµå®ä¾‹ID: {workflow_instance_id}")
            
            # æ€»æ˜¯æŸ¥æ‰¾æ‰€æœ‰èŠ‚ç‚¹ä»¥è¿›è¡Œè°ƒè¯•
            logger.info("è°ƒè¯•: æŸ¥æ‰¾æ‰€æœ‰èŠ‚ç‚¹ç±»å‹")
            debug_query = """
            SELECT ni.*, n.type as node_type, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1
            AND ni.is_deleted = FALSE
            AND n.is_deleted = FALSE
            ORDER BY n.type, ni.created_at ASC
            """
            all_nodes = await node_instance_repo.db.fetch_all(debug_query, workflow_instance_id)
            logger.info(f"å·¥ä½œæµå®ä¾‹ {workflow_instance_id} çš„æ‰€æœ‰èŠ‚ç‚¹ ({len(all_nodes)} ä¸ª):")
            for node in all_nodes:
                logger.info(f"  - èŠ‚ç‚¹: {node.get('node_name', 'Unknown')} (ç±»å‹: '{node.get('node_type', 'Unknown')}', çŠ¶æ€: {node.get('status', 'Unknown')})")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°STARTèŠ‚ç‚¹ï¼Œä½†æœ‰èŠ‚ç‚¹å­˜åœ¨ï¼Œå°è¯•ç›´æ¥æŸ¥æ‰¾startç±»å‹
            if not start_nodes and all_nodes:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°STARTèŠ‚ç‚¹ä½†æ‰¾åˆ°äº†å…¶ä»–èŠ‚ç‚¹ï¼Œå°è¯•ä¸åŒçš„æŸ¥è¯¢æ–¹å¼")
                alt_query = """
                SELECT ni.*, n.type as node_type, n.name as node_name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.workflow_instance_id = $1
                AND n.type IN ('start', 'START')
                AND ni.status IN ('pending', 'PENDING')
                AND ni.is_deleted = FALSE
                AND n.is_deleted = FALSE
                ORDER BY ni.created_at ASC
                """
                alt_start_nodes = await node_instance_repo.db.fetch_all(alt_query, workflow_instance_id)
                logger.info(f"å¤‡ç”¨æŸ¥è¯¢æ‰¾åˆ° {len(alt_start_nodes)} ä¸ªSTARTèŠ‚ç‚¹")
                if alt_start_nodes:
                    start_nodes = alt_start_nodes
            
            return start_nodes
            
        except Exception as e:
            logger.error(f"è·å–STARTèŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            return []
    
    async def _execute_start_node_directly(self, workflow_instance_id: uuid.UUID, start_node: Dict[str, Any]):
        """ç›´æ¥æ‰§è¡ŒSTARTèŠ‚ç‚¹"""
        try:
            node_instance_id = start_node['node_instance_id']
            node_name = start_node.get('node_name', 'æœªçŸ¥')
            logger.info(f"â–¶ï¸ å¼€å§‹ç›´æ¥æ‰§è¡ŒSTARTèŠ‚ç‚¹: {node_name} (ID: {node_instance_id})")
            
            # æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
            logger.info(f"  æ­¥éª¤1: æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€ä¸º RUNNING")
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceUpdate, NodeInstanceStatus
            
            node_instance_repo = NodeInstanceRepository()
            
            # æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
            update_data = NodeInstanceUpdate(
                status=NodeInstanceStatus.RUNNING
            )
            await node_instance_repo.update_node_instance(node_instance_id, update_data)
            logger.info(f"  âœ… èŠ‚ç‚¹çŠ¶æ€æ›´æ–°ä¸º RUNNING æˆåŠŸ")
            
            # STARTèŠ‚ç‚¹æ²¡æœ‰å®é™…ä»»åŠ¡ï¼Œç›´æ¥å®Œæˆ
            logger.info(f"  æ­¥éª¤2: STARTèŠ‚ç‚¹æ— å®é™…ä»»åŠ¡ï¼Œç›´æ¥æ ‡è®°ä¸º COMPLETED")
            completed_data = NodeInstanceUpdate(
                status=NodeInstanceStatus.COMPLETED,
                output_data={
                    'message': 'STARTèŠ‚ç‚¹è‡ªåŠ¨å®Œæˆ',
                    'completed_at': datetime.utcnow().isoformat()
                }
            )
            await node_instance_repo.update_node_instance(node_instance_id, completed_data)
            logger.info(f"  âœ… èŠ‚ç‚¹çŠ¶æ€æ›´æ–°ä¸º COMPLETED æˆåŠŸ")
            
            # è·å–ä¸‹æ¸¸èŠ‚ç‚¹å¹¶å¯åŠ¨æ‰§è¡Œ
            logger.info(f"  æ­¥éª¤3: è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹æ‰§è¡Œ")
            await self._trigger_downstream_nodes(workflow_instance_id, start_node)
            logger.info(f"  âœ… ä¸‹æ¸¸èŠ‚ç‚¹è§¦å‘å®Œæˆ")
            
            logger.info(f"  âœ… STARTèŠ‚ç‚¹æ‰§è¡Œå®Œæˆ: {node_name} (ID: {node_instance_id})")
            
        except Exception as e:
            node_name = start_node.get('node_name', 'æœªçŸ¥')
            logger.error(f"âŒ æ‰§è¡ŒSTARTèŠ‚ç‚¹å¤±è´¥ {node_name}: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆè¯¦æƒ…: {traceback.format_exc()}")
            raise
    
    async def _trigger_downstream_nodes(self, workflow_instance_id: uuid.UUID, completed_node: Dict[str, Any]):
        """è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹æ‰§è¡Œ"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹çš„é€»è¾‘
            # æš‚æ—¶ç®€åŒ–å¤„ç†ï¼Œåªæ˜¯æ ‡è®°å·¥ä½œæµå¼€å§‹æ‰§è¡Œ
            logger.info(f"STARTèŠ‚ç‚¹å®Œæˆï¼Œå·¥ä½œæµ {workflow_instance_id} å¼€å§‹æ­£å¸¸æ‰§è¡Œæµç¨‹")
            
        except Exception as e:
            logger.error(f"è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _execute_node_when_ready(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """å½“èŠ‚ç‚¹å‡†å¤‡å¥½æ—¶æ‰§è¡ŒèŠ‚ç‚¹"""
        try:
            # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å‡†å¤‡å¥½æ‰§è¡Œ
            if not self.context_manager.is_node_ready_to_execute(node_instance_id):
                logger.warning(f"èŠ‚ç‚¹ {node_instance_id} å°šæœªå‡†å¤‡å¥½æ‰§è¡Œ")
                return
            
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            dep_info = self.context_manager.get_node_dependency_info(node_instance_id)
            if not dep_info:
                logger.error(f"æ— æ³•è·å–èŠ‚ç‚¹ {node_instance_id} çš„ä¾èµ–ä¿¡æ¯")
                return
            
            node_base_id = dep_info['node_base_id']
            
            # æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
            await self.context_manager.mark_node_executing(
                workflow_instance_id, node_base_id, node_instance_id
            )
            
            # è·å–èŠ‚ç‚¹çš„ä¸Šæ¸¸ä¸Šä¸‹æ–‡
            upstream_context = await self.context_manager.get_node_upstream_context(
                workflow_instance_id, node_instance_id
            )
            
            # æ›´æ–°èŠ‚ç‚¹çš„ä»»åŠ¡å®ä¾‹ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡æ•°æ®
            await self._update_node_tasks_with_context(node_instance_id, upstream_context)
            
            # æ‰§è¡ŒèŠ‚ç‚¹çš„ä»»åŠ¡
            await self._execute_node_tasks(workflow_instance_id, node_instance_id, node_base_id)
            
        except Exception as e:
            logger.error(f"æ‰§è¡ŒèŠ‚ç‚¹ {node_instance_id} å¤±è´¥: {e}")
            # æ ‡è®°èŠ‚ç‚¹å¤±è´¥
            dep_info = self.context_manager.get_node_dependency_info(node_instance_id)
            if dep_info:
                await self.context_manager.mark_node_failed(
                    workflow_instance_id, 
                    dep_info['node_base_id'], 
                    node_instance_id,
                    {'error': str(e)}
                )
    
    async def _update_node_tasks_with_context(self, node_instance_id: uuid.UUID, upstream_context: Dict[str, Any]):
        """æ›´æ–°èŠ‚ç‚¹ä»»åŠ¡çš„ä¸Šä¸‹æ–‡æ•°æ®"""
        try:
            # è·å–èŠ‚ç‚¹çš„æ‰€æœ‰ä»»åŠ¡
            tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
            
            for task in tasks:
                # æ„å»ºå®Œæ•´çš„ä»»åŠ¡ä¸Šä¸‹æ–‡
                task_context = {
                    'immediate_upstream': upstream_context.get('immediate_upstream_results', {}),
                    'workflow_global': upstream_context.get('workflow_global', {}),
                    'node_info': {
                        'node_instance_id': str(node_instance_id),
                        'upstream_node_count': upstream_context.get('upstream_node_count', 0)
                    }
                }
                
                # æ›´æ–°ä»»åŠ¡çš„è¾“å…¥æ•°æ®
                update_data = TaskInstanceUpdate(
                    input_data=task_context,
                    status=TaskInstanceStatus.ASSIGNED if task.get('assigned_user_id') or task.get('assigned_agent_id') else TaskInstanceStatus.PENDING
                )
                
                await self.task_instance_repo.update_task(task['task_instance_id'], update_data)
                logger.debug(f"æ›´æ–°ä»»åŠ¡ {task['task_instance_id']} çš„ä¸Šä¸‹æ–‡æ•°æ®")
                
        except Exception as e:
            logger.error(f"æ›´æ–°èŠ‚ç‚¹ä»»åŠ¡ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            raise
    
    async def _execute_node_tasks(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID, node_base_id: uuid.UUID):
        """æ‰§è¡ŒèŠ‚ç‚¹çš„ä»»åŠ¡"""
        try:
            # è·å–èŠ‚ç‚¹çš„æ‰€æœ‰ä»»åŠ¡
            tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
            
            if not tasks:
                # å¦‚æœæ²¡æœ‰ä»»åŠ¡ï¼ˆå¦‚STARTæˆ–ENDèŠ‚ç‚¹ï¼‰ï¼Œç›´æ¥æ ‡è®°å®Œæˆ
                await self._complete_node_without_tasks(workflow_instance_id, node_base_id, node_instance_id)
                return
            
            # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            for task in tasks:
                if task['task_type'] == TaskInstanceType.AGENT.value:
                    # Agentä»»åŠ¡ï¼šæäº¤ç»™AgentTaskServiceå¤„ç†
                    await self._execute_agent_task(task)
                elif task['task_type'] == TaskInstanceType.HUMAN.value:
                    # Humanä»»åŠ¡ï¼šç­‰å¾…ç”¨æˆ·å¤„ç†ï¼ˆå·²ç»åœ¨assignedçŠ¶æ€ï¼‰
                    logger.info(f"Humanä»»åŠ¡ {task['task_instance_id']} å·²åˆ†é…ï¼Œç­‰å¾…ç”¨æˆ·å¤„ç†")
                elif task['task_type'] == TaskInstanceType.MIXED.value:
                    # Mixedä»»åŠ¡ï¼šå…ˆåˆ†é…ç»™ç”¨æˆ·ï¼ŒåŒæ—¶æä¾›AIè¾…åŠ©
                    await self._execute_mixed_task(task)
            
            # æ³¨å†Œä»»åŠ¡å®Œæˆç›‘å¬
            await self._register_node_completion_monitor(workflow_instance_id, node_instance_id, node_base_id)
            
        except Exception as e:
            logger.error(f"æ‰§è¡ŒèŠ‚ç‚¹ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _complete_node_without_tasks(self, workflow_instance_id: uuid.UUID, node_base_id: uuid.UUID, node_instance_id: uuid.UUID):
        """å®Œæˆæ²¡æœ‰ä»»åŠ¡çš„èŠ‚ç‚¹ï¼ˆå¦‚STARTã€ENDèŠ‚ç‚¹ï¼‰"""
        try:
            # æ ‡è®°èŠ‚ç‚¹å®Œæˆ
            output_data = {
                'completed_at': datetime.utcnow().isoformat(),
                'node_type': 'system',
                'message': 'ç³»ç»ŸèŠ‚ç‚¹è‡ªåŠ¨å®Œæˆ'
            }
            
            await self.context_manager.mark_node_completed(
                workflow_instance_id, node_base_id, node_instance_id, output_data
            )
            
            logger.info(f"ç³»ç»ŸèŠ‚ç‚¹ {node_base_id} è‡ªåŠ¨å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å®Œæˆç³»ç»ŸèŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _execute_agent_task(self, task: Dict[str, Any]):
        """æ‰§è¡ŒAgentä»»åŠ¡"""
        try:
            # è°ƒç”¨AgentTaskServiceå¤„ç†ä»»åŠ¡
            task_id = task['task_instance_id']
            await agent_task_service.process_agent_task(task_id)
            
        except Exception as e:
            logger.error(f"æ‰§è¡ŒAgentä»»åŠ¡ {task['task_instance_id']} å¤±è´¥: {e}")
            raise
    
    async def _execute_mixed_task(self, task: Dict[str, Any]):
        """æ‰§è¡ŒMixedä»»åŠ¡ï¼ˆäººæœºåä½œï¼‰"""
        try:
            # Mixedä»»åŠ¡åˆ†é…ç»™ç”¨æˆ·ï¼ŒåŒæ—¶å¯åŠ¨AIè¾…åŠ©
            task_id = task['task_instance_id']
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºASSIGNEDï¼ˆåˆ†é…ç»™ç”¨æˆ·ï¼‰
            update_data = TaskInstanceUpdate(status=TaskInstanceStatus.ASSIGNED)
            await self.task_instance_repo.update_task(task_id, update_data)
            
            # å¯åŠ¨AIè¾…åŠ©ï¼ˆå¯é€‰ï¼‰
            asyncio.create_task(self._provide_ai_assistance(task))
            
            logger.info(f"Mixedä»»åŠ¡ {task_id} å·²åˆ†é…ç»™ç”¨æˆ·ï¼ŒAIè¾…åŠ©å·²å¯åŠ¨")
            
        except Exception as e:
            logger.error(f"æ‰§è¡ŒMixedä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _provide_ai_assistance(self, task: Dict[str, Any]):
        """ä¸ºMixedä»»åŠ¡æä¾›AIè¾…åŠ©"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°AIè¾…åŠ©é€»è¾‘
            # ä¾‹å¦‚ï¼šåˆ†æä»»åŠ¡å†…å®¹ï¼Œæä¾›å»ºè®®ç­‰
            logger.info(f"ä¸ºä»»åŠ¡ {task['task_instance_id']} æä¾›AIè¾…åŠ©")
            
        except Exception as e:
            logger.error(f"æä¾›AIè¾…åŠ©å¤±è´¥: {e}")
    
    async def _register_node_completion_monitor(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID, node_base_id: uuid.UUID):
        """æ³¨å†ŒèŠ‚ç‚¹å®Œæˆç›‘å¬å™¨"""
        try:
            # å¯åŠ¨èŠ‚ç‚¹å®Œæˆç›‘å¬åç¨‹
            asyncio.create_task(self._monitor_node_completion(workflow_instance_id, node_instance_id, node_base_id))
            
        except Exception as e:
            logger.error(f"æ³¨å†ŒèŠ‚ç‚¹å®Œæˆç›‘å¬å¤±è´¥: {e}")
    
    async def _monitor_node_completion(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID, node_base_id: uuid.UUID):
        """ç›‘å¬èŠ‚ç‚¹å®Œæˆ"""
        try:
            while True:
                # æ£€æŸ¥èŠ‚ç‚¹çš„æ‰€æœ‰ä»»åŠ¡æ˜¯å¦å®Œæˆ
                tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
                
                if not tasks:
                    break
                
                completed_tasks = [t for t in tasks if t['status'] == 'COMPLETED']
                failed_tasks = [t for t in tasks if t['status'] == 'FAILED']
                
                if len(completed_tasks) == len(tasks):
                    # æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œæ ‡è®°èŠ‚ç‚¹å®Œæˆ
                    output_data = await self._aggregate_node_output(completed_tasks)
                    await self.context_manager.mark_node_completed(
                        workflow_instance_id, node_base_id, node_instance_id, output_data
                    )
                    break
                elif len(failed_tasks) > 0:
                    # æœ‰ä»»åŠ¡å¤±è´¥ï¼Œæ ‡è®°èŠ‚ç‚¹å¤±è´¥
                    error_info = {'failed_tasks': [t['task_instance_id'] for t in failed_tasks]}
                    await self.context_manager.mark_node_failed(
                        workflow_instance_id, node_base_id, node_instance_id, error_info
                    )
                    break
                
                # ç­‰å¾…5ç§’åå†æ¬¡æ£€æŸ¥
                await asyncio.sleep(5)
                
        except Exception as e:
            logger.error(f"ç›‘å¬èŠ‚ç‚¹å®Œæˆå¤±è´¥: {e}")
    
    async def _aggregate_node_output(self, completed_tasks: List[Dict]) -> Dict[str, Any]:
        """èšåˆèŠ‚ç‚¹çš„è¾“å‡ºæ•°æ®"""
        try:
            aggregated = {
                'task_count': len(completed_tasks),
                'completed_at': datetime.utcnow().isoformat(),
                'task_results': []
            }
            
            combined_output = {}
            
            for task in completed_tasks:
                task_result = {
                    'task_id': task['task_instance_id'],
                    'task_title': task.get('task_title', ''),
                    'output_data': task.get('output_data', {}),
                    'result_summary': task.get('result_summary', '')
                }
                aggregated['task_results'].append(task_result)
                
                # åˆå¹¶ä»»åŠ¡è¾“å‡ºæ•°æ®
                if task.get('output_data'):
                    combined_output.update(task['output_data'])
            
            aggregated['combined_output'] = combined_output
            
            return aggregated
            
        except Exception as e:
            logger.error(f"èšåˆèŠ‚ç‚¹è¾“å‡ºå¤±è´¥: {e}")
            return {'error': str(e)}
    
    async def _on_nodes_ready_to_execute(self, workflow_instance_id: uuid.UUID, ready_node_instance_ids: List[uuid.UUID]):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å›è°ƒï¼šæœ‰èŠ‚ç‚¹å‡†å¤‡æ‰§è¡Œ"""
        try:
            logger.info(f"å·¥ä½œæµ {workflow_instance_id} ä¸­æœ‰ {len(ready_node_instance_ids)} ä¸ªèŠ‚ç‚¹å‡†å¤‡æ‰§è¡Œ")
            
            # æ‰§è¡Œå‡†å¤‡å¥½çš„èŠ‚ç‚¹
            for node_instance_id in ready_node_instance_ids:
                await self._execute_node_when_ready(workflow_instance_id, node_instance_id)
                
        except Exception as e:
            logger.error(f"æ‰§è¡Œå‡†å¤‡å¥½çš„èŠ‚ç‚¹å¤±è´¥: {e}")
    
    async def _log_task_assignment_event(self, task_id: uuid.UUID, assigned_user_id: Optional[uuid.UUID], task_title: str):
        """è®°å½•ä»»åŠ¡åˆ†é…äº‹ä»¶"""
        try:
            event_data = {
                'event_type': 'task_assigned',
                'task_id': str(task_id),
                'assigned_user_id': str(assigned_user_id) if assigned_user_id else None,
                'task_title': task_title,
                'timestamp': now_utc().isoformat(),
                'status': 'success'
            }
            
            # è¿™é‡Œå¯ä»¥è®°å½•åˆ°äº‹ä»¶æ—¥å¿—è¡¨æˆ–å‘é€åˆ°æ¶ˆæ¯é˜Ÿåˆ—
            logger.info(f"ğŸ“ ä»»åŠ¡åˆ†é…äº‹ä»¶è®°å½•: {event_data}")
            
            # è®°å½•åˆ°ä¸“é—¨çš„äº‹ä»¶æ—¥å¿—æ–‡ä»¶
            try:
                event_log_entry = f"{event_data['timestamp']}|{event_data['event_type']}|{event_data['task_id']}|{event_data['assigned_user_id']}|{task_title[:50]}"
                with open("task_events.log", "a", encoding="utf-8") as f:
                    f.write(event_log_entry + "\n")
                logger.debug(f"   äº‹ä»¶å·²è®°å½•åˆ°æ–‡ä»¶")
            except Exception as e:
                logger.warning(f"   äº‹ä»¶æ–‡ä»¶è®°å½•å¤±è´¥: {e}")
            
            # TODO: å¯ä»¥åœ¨è¿™é‡Œé›†æˆæ¶ˆæ¯é˜Ÿåˆ—ç³»ç»Ÿï¼Œå¦‚Redisã€RabbitMQç­‰
            # await self.message_queue.publish('task_assignments', event_data)
            
        except Exception as e:
            logger.error(f"è®°å½•ä»»åŠ¡åˆ†é…äº‹ä»¶å¤±è´¥: {e}")
    
    async def _log_workflow_execution_summary(self, workflow_instance_id: uuid.UUID):
        """è®°å½•å·¥ä½œæµæ‰§è¡Œæ‘˜è¦"""
        try:
            logger.info(f"ğŸ“Š ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œæ‘˜è¦: {workflow_instance_id}")
            
            # è·å–å·¥ä½œæµå®ä¾‹ä¿¡æ¯
            instance = await self.workflow_instance_repo.get_instance_by_id(workflow_instance_id)
            if not instance:
                logger.warning(f"   å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨: {workflow_instance_id}")
                return
            
            # è·å–æ‰€æœ‰ä»»åŠ¡
            tasks = await self.task_instance_repo.get_tasks_by_workflow_instance(workflow_instance_id)
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_tasks = len(tasks)
            human_tasks = len([t for t in tasks if t['task_type'] == TaskInstanceType.HUMAN.value])
            agent_tasks = len([t for t in tasks if t['task_type'] == TaskInstanceType.AGENT.value])
            assigned_tasks = len([t for t in tasks if t['status'] in ['ASSIGNED', 'IN_PROGRESS', 'COMPLETED']])
            pending_tasks = len([t for t in tasks if t['status'] == 'PENDING'])
            
            # è¾“å‡ºæ‘˜è¦
            print(f"\nğŸ“Š ã€å·¥ä½œæµæ‰§è¡Œæ‘˜è¦ã€‘")
            print(f"å·¥ä½œæµå®ä¾‹: {instance.get('workflow_instance_name', 'Unknown')}")
            print(f"å®ä¾‹ID: {workflow_instance_id}")
            print(f"çŠ¶æ€: {instance.get('status', 'Unknown')}")
            print(f"æ€»ä»»åŠ¡æ•°: {total_tasks}")
            print(f"  - äººå·¥ä»»åŠ¡: {human_tasks}")
            print(f"  - Agentä»»åŠ¡: {agent_tasks}")
            print(f"  - å·²åˆ†é…: {assigned_tasks}")
            print(f"  - ç­‰å¾…ä¸­: {pending_tasks}")
            print(f"åˆ›å»ºæ—¶é—´: {instance.get('created_at', 'Unknown')}")
            print("=" * 50)
            
            # åˆ—å‡ºæ‰€æœ‰å·²åˆ†é…çš„äººå·¥ä»»åŠ¡
            human_assigned_tasks = [t for t in tasks if t['task_type'] == TaskInstanceType.HUMAN.value and t.get('assigned_user_id')]
            if human_assigned_tasks:
                print(f"ğŸ“‹ å·²åˆ†é…çš„äººå·¥ä»»åŠ¡:")
                for i, task in enumerate(human_assigned_tasks, 1):
                    print(f"  {i}. {task['task_title']}")
                    print(f"     ç”¨æˆ·: {task.get('assigned_user_id')}")
                    print(f"     çŠ¶æ€: {task['status']}")
                    print(f"     ä¼˜å…ˆçº§: {task.get('priority', 1)}")
                print("=" * 50)
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œæ‘˜è¦å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
    
    async def _notify_user_new_task(self, user_id: uuid.UUID, task_id: uuid.UUID, task_title: str):
        """é€šçŸ¥ç”¨æˆ·æœ‰æ–°ä»»åŠ¡åˆ†é…"""
        try:
            logger.info(f"ğŸ”” å¼€å§‹å‘é€ä»»åŠ¡é€šçŸ¥ç»™ç”¨æˆ·: {user_id}")
            
            # è·å–ç”¨æˆ·ä¿¡æ¯ç”¨äºé€šçŸ¥
            user_info = await self.user_repo.get_by_id(user_id)
            username = user_info.get('username', 'Unknown') if user_info else 'Unknown'
            
            notification_data = {
                'user_id': str(user_id),
                'username': username,
                'task_id': str(task_id),
                'task_title': task_title,
                'notification_type': 'new_task_assigned',
                'timestamp': now_utc().isoformat(),
                'message': f'æ‚¨æœ‰æ–°çš„ä»»åŠ¡: {task_title}',
                'action_url': f'/tasks/{task_id}'
            }
            
            logger.info(f"ğŸ“¨ é€šçŸ¥æ•°æ®å‡†å¤‡å®Œæˆ:")
            logger.info(f"   - ç”¨æˆ·: {username} ({user_id})")
            logger.info(f"   - ä»»åŠ¡: {task_title}")
            logger.info(f"   - æ—¶é—´: {notification_data['timestamp']}")
            
            # æ–¹å¼1: æ§åˆ¶å°é€šçŸ¥ï¼ˆç”¨äºå¼€å‘è°ƒè¯•ï¼‰
            print(f"\nğŸ”” ã€ç”¨æˆ·é€šçŸ¥ã€‘")
            print(f"ç”¨æˆ·: {username} ({user_id})")
            print(f"æ¶ˆæ¯: æ‚¨æœ‰æ–°çš„ä»»åŠ¡åˆ†é…")
            print(f"ä»»åŠ¡: {task_title}")
            print(f"ä»»åŠ¡ID: {task_id}")
            print(f"æ—¶é—´: {notification_data['timestamp']}")
            print(f"æ“ä½œ: è¯·ç™»å½•ç³»ç»ŸæŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…")
            print("=" * 50)
            
            # æ–¹å¼2: è®°å½•åˆ°æ•°æ®åº“ï¼ˆç”¨æˆ·é€šçŸ¥å†å²ï¼‰
            try:
                await self._store_user_notification(notification_data)
                logger.info(f"   âœ… é€šçŸ¥å·²å­˜å‚¨åˆ°æ•°æ®åº“")
            except Exception as e:
                logger.warning(f"   âš ï¸  å­˜å‚¨é€šçŸ¥å¤±è´¥: {e}")
            
            # æ–¹å¼3: æ–‡ä»¶æ—¥å¿—è®°å½•ï¼ˆå¯ç”¨äºå…¶ä»–ç³»ç»Ÿè¯»å–ï¼‰
            try:
                notification_log_entry = f"{now_utc().isoformat()}|TASK_ASSIGNED|{user_id}|{username}|{task_id}|{task_title}"
                with open("user_notifications.log", "a", encoding="utf-8") as f:
                    f.write(notification_log_entry + "\n")
                logger.info(f"   âœ… é€šçŸ¥å·²è®°å½•åˆ°æ–‡ä»¶")
            except Exception as e:
                logger.warning(f"   âš ï¸  æ–‡ä»¶è®°å½•å¤±è´¥: {e}")
            
            # TODO: æ–¹å¼4: å®æ—¶æ¨é€ï¼ˆæœªæ¥å®ç°ï¼‰
            # å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€å®ç°ï¼š
            # 1. WebSocket æ¨é€: await self.websocket_manager.send_to_user(user_id, notification_data)
            # 2. Server-Sent Events (SSE): await self.sse_manager.send_event(user_id, notification_data)
            # 3. æ¶ˆæ¯é˜Ÿåˆ—: await self.message_queue.publish(f"user.{user_id}.notifications", notification_data)
            # 4. é‚®ä»¶é€šçŸ¥: await self.email_service.send_task_notification(user_info.get('email'), notification_data)
            
            logger.info(f"   ğŸ‰ ç”¨æˆ·é€šçŸ¥å¤„ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å‘é€ç”¨æˆ·é€šçŸ¥å¤±è´¥: {e}")
            import traceback
            logger.error(f"   å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
    
    async def _store_user_notification(self, notification_data: dict):
        """å­˜å‚¨ç”¨æˆ·é€šçŸ¥åˆ°æ•°æ®åº“ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰"""
        try:
            # è¿™é‡Œå¯ä»¥å­˜å‚¨åˆ°ä¸“é—¨çš„é€šçŸ¥è¡¨ä¸­
            # å¦‚æœæ²¡æœ‰é€šçŸ¥è¡¨ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªç®€å•çš„è®°å½•è¡¨
            logger.debug(f"å­˜å‚¨é€šçŸ¥æ•°æ®: {notification_data}")
            # æš‚æ—¶è·³è¿‡æ•°æ®åº“å­˜å‚¨ï¼Œé¿å…è¡¨ç»“æ„ä¾èµ–
        except Exception as e:
            logger.warning(f"å­˜å‚¨ç”¨æˆ·é€šçŸ¥å¤±è´¥: {e}")
    
    # ================================================================================
    # å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶ - æ ¸å¿ƒæ–¹æ³•
    # ================================================================================
    
    async def _check_node_prerequisites(self, workflow_instance_id: uuid.UUID, 
                                      node_instance_id: uuid.UUID) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹çš„å‰ç½®æ¡ä»¶æ˜¯å¦æ»¡è¶³"""
        try:
            logger.info(f"ğŸ” æ£€æŸ¥èŠ‚ç‚¹å‰ç½®æ¡ä»¶: {node_instance_id}")
            
            # ä»æ•°æ®åº“æŸ¥è¯¢èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_repo = NodeInstanceRepository()
            node_instance = await node_repo.get_node_instance_by_id(node_instance_id)
            
            if not node_instance:
                logger.error(f"âŒ èŠ‚ç‚¹å®ä¾‹ä¸å­˜åœ¨: {node_instance_id}")
                return False
            
            node_id = node_instance['node_id']
            logger.info(f"  èŠ‚ç‚¹ID: {node_id}")
            
            # æŸ¥è¯¢è¯¥èŠ‚ç‚¹çš„å‰ç½®èŠ‚ç‚¹
            prerequisite_query = '''
            SELECT source_n.node_id as prerequisite_node_id, source_n.name as prerequisite_name,
                   source_ni.node_instance_id as prerequisite_instance_id, source_ni.status as prerequisite_status
            FROM node_connection c
            JOIN node source_n ON c.source_node_id = source_n.node_id  
            JOIN node target_n ON c.target_node_id = target_n.node_id
            JOIN node_instance source_ni ON source_n.node_id = source_ni.node_id
            WHERE target_n.node_id = $1 
              AND source_ni.workflow_instance_id = $2
              AND c.is_deleted = FALSE
              AND source_ni.is_deleted = FALSE
            '''
            
            prerequisites = await self.workflow_instance_repo.db.fetch_all(
                prerequisite_query, node_id, workflow_instance_id
            )
            
            logger.info(f"  æ‰¾åˆ° {len(prerequisites)} ä¸ªå‰ç½®èŠ‚ç‚¹")
            
            # å¦‚æœæ²¡æœ‰å‰ç½®èŠ‚ç‚¹ï¼ˆå¦‚STARTèŠ‚ç‚¹ï¼‰ï¼Œç›´æ¥è¿”å›True
            if not prerequisites:
                logger.info(f"  âœ… æ— å‰ç½®èŠ‚ç‚¹ï¼Œæ»¡è¶³æ¡ä»¶")
                return True
            
            # æ£€æŸ¥æ‰€æœ‰å‰ç½®èŠ‚ç‚¹æ˜¯å¦éƒ½å·²å®Œæˆ
            all_completed = True
            for prerequisite in prerequisites:
                status = prerequisite['prerequisite_status']
                name = prerequisite['prerequisite_name']
                logger.info(f"    å‰ç½®èŠ‚ç‚¹ {name}: {status}")
                
                if status != 'completed':
                    all_completed = False
                    logger.info(f"    âŒ å‰ç½®èŠ‚ç‚¹ {name} æœªå®Œæˆ: {status}")
            
            if all_completed:
                logger.info(f"  âœ… æ‰€æœ‰å‰ç½®èŠ‚ç‚¹å·²å®Œæˆï¼Œæ»¡è¶³ä»»åŠ¡åˆ›å»ºæ¡ä»¶")
            else:
                logger.info(f"  â³ å‰ç½®èŠ‚ç‚¹æœªå…¨éƒ¨å®Œæˆï¼Œç­‰å¾…ä¸­")
            
            return all_completed
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥èŠ‚ç‚¹å‰ç½®æ¡ä»¶å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return False
    
    async def _create_tasks_when_ready(self, workflow_instance_id: uuid.UUID, 
                                     node_instance_id: uuid.UUID) -> bool:
        """å½“èŠ‚ç‚¹æ»¡è¶³å‰ç½®æ¡ä»¶æ—¶åˆ›å»ºä»»åŠ¡"""
        try:
            logger.info(f"ğŸ¯ å°è¯•ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡: {node_instance_id}")
            
            # æ£€æŸ¥å‰ç½®æ¡ä»¶
            prerequisites_met = await self._check_node_prerequisites(workflow_instance_id, node_instance_id)
            if not prerequisites_met:
                logger.info(f"  â³ å‰ç½®æ¡ä»¶æœªæ»¡è¶³ï¼Œæš‚ä¸åˆ›å»ºä»»åŠ¡")
                return False
            
            # è·å–èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_repo = NodeInstanceRepository()
            node_instance = await node_repo.get_node_instance_by_id(node_instance_id)
            
            if not node_instance:
                logger.error(f"âŒ èŠ‚ç‚¹å®ä¾‹ä¸å­˜åœ¨: {node_instance_id}")
                return False
            
            # è·å–èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
            node = await self.node_repo.get_node_by_id(node_instance['node_id'])
            if not node:
                logger.error(f"âŒ èŠ‚ç‚¹ä¸å­˜åœ¨: {node_instance['node_id']}")
                return False
            
            # åªä¸ºPROCESSORèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
            if node['type'] != NodeType.PROCESSOR.value:
                logger.info(f"  â­ï¸ èŠ‚ç‚¹ç±»å‹ä¸æ˜¯PROCESSOR ({node['type']})ï¼Œè‡ªåŠ¨å®Œæˆ")
                
                # å¯¹äºéPROCESSORèŠ‚ç‚¹ï¼ˆå¦‚ENDèŠ‚ç‚¹ï¼‰ï¼Œç›´æ¥æ ‡è®°ä¸ºå®Œæˆ
                if node['type'] == NodeType.END.value:
                    await self._execute_end_node(workflow_instance_id, node_instance_id)
                else:
                    # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå®Œæˆ
                    from ..models.instance import NodeInstanceUpdate, NodeInstanceStatus
                    update_data = NodeInstanceUpdate(status=NodeInstanceStatus.COMPLETED)
                    await node_repo.update_node_instance(node_instance_id, update_data)
                    
                # ç»§ç»­æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹
                await self._check_downstream_nodes_for_task_creation(workflow_instance_id)
                return True
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»åˆ›å»ºè¿‡ä»»åŠ¡
            existing_tasks_query = '''
            SELECT task_instance_id FROM task_instance 
            WHERE node_instance_id = $1 AND is_deleted = FALSE
            '''
            existing_tasks = await self.task_instance_repo.db.fetch_all(existing_tasks_query, node_instance_id)
            
            if existing_tasks:
                logger.info(f"  âœ… ä»»åŠ¡å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤åˆ›å»º")
                return True
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå‡†å¤‡ä¸­
            from ..models.instance import NodeInstanceUpdate, NodeInstanceStatus
            update_data = NodeInstanceUpdate(status=NodeInstanceStatus.READY)
            await node_repo.update_node_instance(node_instance_id, update_data)
            
            # ä¸ºè¯¥èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
            created_node = {
                'node_instance_id': node_instance_id,
                'node_base_id': node['node_base_id'],
                'node_type': node['type'],
                'node_data': node
            }
            
            await self._create_tasks_for_nodes([created_node], workflow_instance_id)
            
            logger.info(f"  âœ… èŠ‚ç‚¹ä»»åŠ¡åˆ›å»ºå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºèŠ‚ç‚¹ä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return False
    
    async def _check_downstream_nodes_for_task_creation(self, workflow_instance_id: uuid.UUID):
        """æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹æ˜¯å¦å¯ä»¥åˆ›å»ºä»»åŠ¡"""
        try:
            logger.info(f"ğŸ”„ æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹ä»»åŠ¡åˆ›å»ºæœºä¼š")
            
            # æŸ¥è¯¢å·¥ä½œæµä¸­æ‰€æœ‰ç­‰å¾…çŠ¶æ€çš„èŠ‚ç‚¹
            waiting_nodes_query = '''
            SELECT ni.node_instance_id, ni.node_id, n.name, n.type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 
              AND ni.status IN ('pending', 'waiting')
              AND ni.is_deleted = FALSE
            '''
            
            waiting_nodes = await self.workflow_instance_repo.db.fetch_all(
                waiting_nodes_query, workflow_instance_id
            )
            
            logger.info(f"  æ‰¾åˆ° {len(waiting_nodes)} ä¸ªç­‰å¾…ä¸­çš„èŠ‚ç‚¹")
            
            # ä¸ºæ¯ä¸ªç­‰å¾…èŠ‚ç‚¹æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆ›å»ºä»»åŠ¡
            for node in waiting_nodes:
                node_instance_id = node['node_instance_id']
                node_name = node['name']
                
                logger.info(f"  æ£€æŸ¥èŠ‚ç‚¹: {node_name} ({node_instance_id})")
                
                # å°è¯•åˆ›å»ºä»»åŠ¡
                created = await self._create_tasks_when_ready(workflow_instance_id, node_instance_id)
                if created:
                    logger.info(f"    âœ… èŠ‚ç‚¹ {node_name} ä»»åŠ¡åˆ›å»ºæˆåŠŸ")
                else:
                    logger.info(f"    â³ èŠ‚ç‚¹ {node_name} æ¡ä»¶æœªæ»¡è¶³")
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _execute_end_node(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """æ‰§è¡Œç»“æŸèŠ‚ç‚¹"""
        try:
            logger.info(f"ğŸ æ‰§è¡Œç»“æŸèŠ‚ç‚¹: {node_instance_id}")
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceUpdate, NodeInstanceStatus
            
            node_repo = NodeInstanceRepository()
            update_data = NodeInstanceUpdate(status=NodeInstanceStatus.RUNNING)
            await node_repo.update_node_instance(node_instance_id, update_data)
            
            # æ”¶é›†å®Œæ•´çš„å·¥ä½œæµä¸Šä¸‹æ–‡
            context_data = await self._collect_workflow_context(workflow_instance_id)
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå®Œæˆï¼Œå¹¶ä¿å­˜ä¸Šä¸‹æ–‡æ•°æ®
            final_update = NodeInstanceUpdate(
                status=NodeInstanceStatus.COMPLETED,
                output_data=context_data
            )
            await node_repo.update_node_instance(node_instance_id, final_update)
            
            logger.info(f"âœ… ç»“æŸèŠ‚ç‚¹æ‰§è¡Œå®Œæˆ")
            
            # æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å¯ä»¥å®Œæˆ
            await self._check_workflow_completion(workflow_instance_id)
            
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œç»“æŸèŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _collect_workflow_context(self, workflow_instance_id: uuid.UUID) -> Dict[str, Any]:
        """æ”¶é›†å·¥ä½œæµçš„å®Œæ•´ä¸Šä¸‹æ–‡"""
        try:
            logger.info(f"ğŸ“‹ æ”¶é›†å·¥ä½œæµä¸Šä¸‹æ–‡: {workflow_instance_id}")
            
            # è·å–æ‰€æœ‰å·²å®Œæˆçš„èŠ‚ç‚¹å®ä¾‹åŠå…¶è¾“å‡º
            context_query = '''
            SELECT ni.node_instance_id, ni.output_data, n.name as node_name, n.type as node_type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 
              AND ni.status = 'completed'
              AND ni.is_deleted = FALSE
            ORDER BY ni.created_at
            '''
            
            completed_nodes = await self.workflow_instance_repo.db.fetch_all(
                context_query, workflow_instance_id
            )
            
            # è·å–æ‰€æœ‰å·²å®Œæˆçš„ä»»åŠ¡å®ä¾‹åŠå…¶è¾“å‡º  
            task_context_query = '''
            SELECT ti.task_instance_id, ti.output_data, ti.task_title, ti.result_summary,
                   ni.node_name, n.type as node_type
            FROM task_instance ti
            JOIN node_instance ni ON ti.node_instance_id = ni.node_instance_id
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 
              AND ti.status = 'completed'
              AND ti.is_deleted = FALSE
            ORDER BY ti.completed_at
            '''
            
            completed_tasks = await self.task_instance_repo.db.fetch_all(
                task_context_query, workflow_instance_id
            )
            
            # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
            context_data = {
                'workflow_instance_id': str(workflow_instance_id),
                'completed_at': now_utc().isoformat(),
                'nodes_context': {},
                'tasks_context': {},
                'execution_summary': {
                    'total_nodes': len(completed_nodes),
                    'total_tasks': len(completed_tasks)
                }
            }
            
            # æ·»åŠ èŠ‚ç‚¹ä¸Šä¸‹æ–‡
            for node in completed_nodes:
                node_id = str(node['node_instance_id'])
                context_data['nodes_context'][node_id] = {
                    'node_name': node['node_name'],
                    'node_type': node['node_type'],
                    'output_data': node['output_data'] or {}
                }
            
            # æ·»åŠ ä»»åŠ¡ä¸Šä¸‹æ–‡
            for task in completed_tasks:
                task_id = str(task['task_instance_id'])
                context_data['tasks_context'][task_id] = {
                    'task_title': task['task_title'],
                    'node_name': task['node_name'],
                    'node_type': task['node_type'],
                    'output_data': task['output_data'] or {},
                    'result_summary': task['result_summary']
                }
            
            logger.info(f"âœ… ä¸Šä¸‹æ–‡æ”¶é›†å®Œæˆ: {len(completed_nodes)} ä¸ªèŠ‚ç‚¹, {len(completed_tasks)} ä¸ªä»»åŠ¡")
            return context_data
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†å·¥ä½œæµä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {}
    
    async def _check_workflow_completion(self, workflow_instance_id: uuid.UUID):
        """æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å¯ä»¥å®Œæˆ"""
        try:
            logger.info(f"ğŸ æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€: {workflow_instance_id}")
            
            # æŸ¥è¯¢æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹çš„çŠ¶æ€
            nodes_status_query = '''
            SELECT ni.node_instance_id, ni.status, n.name, n.type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 AND ni.is_deleted = FALSE
            '''
            
            all_nodes = await self.workflow_instance_repo.db.fetch_all(
                nodes_status_query, workflow_instance_id
            )
            
            logger.info(f"  å·¥ä½œæµæ€»èŠ‚ç‚¹æ•°: {len(all_nodes)}")
            
            # æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹æ˜¯å¦éƒ½å·²å®Œæˆ
            completed_nodes = [n for n in all_nodes if n['status'] == 'completed']
            failed_nodes = [n for n in all_nodes if n['status'] == 'failed']
            
            logger.info(f"  å·²å®ŒæˆèŠ‚ç‚¹: {len(completed_nodes)}")
            logger.info(f"  å¤±è´¥èŠ‚ç‚¹: {len(failed_nodes)}")
            
            # å¦‚æœæœ‰å¤±è´¥èŠ‚ç‚¹ï¼Œæ ‡è®°å·¥ä½œæµä¸ºå¤±è´¥
            if failed_nodes:
                from ..models.instance import WorkflowInstanceUpdate, WorkflowInstanceStatus
                update_data = WorkflowInstanceUpdate(
                    status=WorkflowInstanceStatus.FAILED,
                    error_message=f"å·¥ä½œæµåŒ…å« {len(failed_nodes)} ä¸ªå¤±è´¥èŠ‚ç‚¹"
                )
                await self.workflow_instance_repo.update_instance(workflow_instance_id, update_data)
                logger.info(f"âŒ å·¥ä½œæµæ ‡è®°ä¸ºå¤±è´¥")
                return
            
            # å¦‚æœæ‰€æœ‰èŠ‚ç‚¹éƒ½å·²å®Œæˆï¼Œæ ‡è®°å·¥ä½œæµä¸ºå®Œæˆ
            if len(completed_nodes) == len(all_nodes):
                from ..models.instance import WorkflowInstanceUpdate, WorkflowInstanceStatus
                update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.COMPLETED)
                await self.workflow_instance_repo.update_instance(workflow_instance_id, update_data)
                logger.info(f"âœ… å·¥ä½œæµæ ‡è®°ä¸ºå®Œæˆ")
            else:
                logger.info(f"â³ å·¥ä½œæµä»åœ¨è¿›è¡Œä¸­: {len(completed_nodes)}/{len(all_nodes)} èŠ‚ç‚¹å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")


# å…¨å±€æ‰§è¡Œå¼•æ“å®ä¾‹
execution_engine = ExecutionEngine()