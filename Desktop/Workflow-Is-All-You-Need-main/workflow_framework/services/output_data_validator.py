"""
å·¥ä½œæµè¾“å‡ºæ•°æ®éªŒè¯å™¨
Output Data Validator for Workflow Results
"""

import uuid
import json
from typing import Dict, Any, List, Optional, Tuple, Union
from datetime import datetime
from loguru import logger
from pydantic import ValidationError

from ..models.instance import (
    WorkflowOutputSummary, ExecutionResult, ExecutionStatistics,
    QualityMetrics, DataLineage, ExecutionIssues,
    WorkflowInstanceStatus
)


class ValidationResult:
    """éªŒè¯ç»“æœç±»"""
    
    def __init__(self):
        self.is_valid = True
        self.errors = []
        self.warnings = []
        self.suggestions = []
    
    def add_error(self, field: str, message: str):
        self.is_valid = False
        self.errors.append({"field": field, "message": message})
    
    def add_warning(self, field: str, message: str):
        self.warnings.append({"field": field, "message": message})
    
    def add_suggestion(self, field: str, message: str):
        self.suggestions.append({"field": field, "message": message})
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "is_valid": self.is_valid,
            "errors": self.errors,
            "warnings": self.warnings,
            "suggestions": self.suggestions,
            "validation_time": datetime.utcnow().isoformat()
        }


class OutputDataValidator:
    """å·¥ä½œæµè¾“å‡ºæ•°æ®éªŒè¯å™¨"""
    
    def __init__(self):
        # æ•°æ®ç±»å‹éªŒè¯è§„åˆ™
        self.field_types = {
            'execution_result': {
                'result_type': str,
                'processed_count': int,
                'success_count': int,
                'error_count': int,
                'data_output': dict
            },
            'execution_stats': {
                'total_nodes': int,
                'completed_nodes': int,
                'failed_nodes': int,
                'total_tasks': int,
                'completed_tasks': int,
                'failed_tasks': int,
                'human_tasks': int,
                'agent_tasks': int,
                'mixed_tasks': int
            },
            'quality_metrics': {
                'data_completeness': float,
                'accuracy_score': float,
                'validation_errors': list,
                'quality_gates_passed': bool,
                'overall_quality_score': float
            }
        }
        
        # æ•°å€¼èŒƒå›´éªŒè¯è§„åˆ™
        self.value_ranges = {
            'data_completeness': (0.0, 1.0),
            'accuracy_score': (0.0, 1.0),
            'overall_quality_score': (0.0, 1.0),
            'processed_count': (0, None),
            'success_count': (0, None),
            'error_count': (0, None),
            'total_nodes': (0, None),
            'completed_nodes': (0, None),
            'failed_nodes': (0, None)
        }
        
        # å¿…éœ€å­—æ®µå®šä¹‰
        self.required_fields = {
            'execution_result': ['result_type', 'processed_count', 'success_count', 'error_count'],
            'execution_stats': ['total_nodes', 'completed_nodes', 'failed_nodes', 'total_tasks'],
            'quality_metrics': ['quality_gates_passed']
        }
    
    async def validate_workflow_output_summary(self, output_summary: Union[WorkflowOutputSummary, Dict[str, Any]]) -> ValidationResult:
        """éªŒè¯å·¥ä½œæµè¾“å‡ºæ‘˜è¦"""
        result = ValidationResult()
        
        try:
            logger.info("ğŸ” å¼€å§‹éªŒè¯å·¥ä½œæµè¾“å‡ºæ‘˜è¦")
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼è¿›è¡ŒéªŒè¯
            if isinstance(output_summary, WorkflowOutputSummary):
                summary_dict = output_summary.dict()
            else:
                summary_dict = output_summary
            
            # 1. éªŒè¯åŸºæœ¬ç»“æ„
            await self._validate_basic_structure(summary_dict, result)
            
            # 2. éªŒè¯æ‰§è¡Œç»“æœ
            if 'execution_result' in summary_dict and summary_dict['execution_result']:
                await self._validate_execution_result(summary_dict['execution_result'], result)
            
            # 3. éªŒè¯æ‰§è¡Œç»Ÿè®¡
            if 'execution_stats' in summary_dict and summary_dict['execution_stats']:
                await self._validate_execution_statistics(summary_dict['execution_stats'], result)
            
            # 4. éªŒè¯è´¨é‡æŒ‡æ ‡
            if 'quality_metrics' in summary_dict and summary_dict['quality_metrics']:
                await self._validate_quality_metrics(summary_dict['quality_metrics'], result)
            
            # 5. éªŒè¯æ•°æ®è¡€ç¼˜
            if 'data_lineage' in summary_dict and summary_dict['data_lineage']:
                await self._validate_data_lineage(summary_dict['data_lineage'], result)
            
            # 6. éªŒè¯æ‰§è¡Œé—®é¢˜
            if 'issues' in summary_dict and summary_dict['issues']:
                await self._validate_execution_issues(summary_dict['issues'], result)
            
            # 7. éªŒè¯é€»è¾‘ä¸€è‡´æ€§
            await self._validate_logical_consistency(summary_dict, result)
            
            # 8. ç”Ÿæˆä¼˜åŒ–å»ºè®®
            await self._generate_optimization_suggestions(summary_dict, result)
            
            if result.is_valid:
                logger.info("âœ… å·¥ä½œæµè¾“å‡ºæ‘˜è¦éªŒè¯é€šè¿‡")
            else:
                logger.warning(f"âš ï¸ å·¥ä½œæµè¾“å‡ºæ‘˜è¦éªŒè¯å¤±è´¥ï¼Œå‘ç° {len(result.errors)} ä¸ªé”™è¯¯")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ éªŒè¯å·¥ä½œæµè¾“å‡ºæ‘˜è¦å¼‚å¸¸: {e}")
            result.add_error("validation", f"éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
            return result
    
    async def _validate_basic_structure(self, summary_dict: Dict[str, Any], result: ValidationResult):
        """éªŒè¯åŸºæœ¬ç»“æ„"""
        try:
            # æ£€æŸ¥é¡¶çº§å­—æ®µ
            expected_fields = ['execution_result', 'execution_stats', 'quality_metrics', 'data_lineage', 'issues']
            present_fields = [field for field in expected_fields if field in summary_dict and summary_dict[field] is not None]
            
            if len(present_fields) == 0:
                result.add_error("structure", "è¾“å‡ºæ‘˜è¦ä¸ºç©ºæˆ–ç¼ºå°‘æ‰€æœ‰å…³é”®å­—æ®µ")
            elif len(present_fields) < 3:
                result.add_warning("structure", f"è¾“å‡ºæ‘˜è¦å­—æ®µä¸å®Œæ•´ï¼Œä»…åŒ…å«: {present_fields}")
            
            # æ£€æŸ¥ç”Ÿæˆæ—¶é—´
            if 'generated_at' not in summary_dict:
                result.add_warning("structure", "ç¼ºå°‘ç”Ÿæˆæ—¶é—´å­—æ®µ")
            else:
                try:
                    datetime.fromisoformat(summary_dict['generated_at'].replace('Z', '+00:00'))
                except (ValueError, AttributeError):
                    result.add_error("generated_at", "ç”Ÿæˆæ—¶é—´æ ¼å¼æ— æ•ˆ")
            
        except Exception as e:
            result.add_error("structure", f"åŸºæœ¬ç»“æ„éªŒè¯å¼‚å¸¸: {str(e)}")
    
    async def _validate_execution_result(self, execution_result: Dict[str, Any], result: ValidationResult):
        """éªŒè¯æ‰§è¡Œç»“æœ"""
        try:
            # éªŒè¯å¿…éœ€å­—æ®µ
            for field in self.required_fields['execution_result']:
                if field not in execution_result:
                    result.add_error(f"execution_result.{field}", f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
            
            # éªŒè¯ç»“æœç±»å‹
            if 'result_type' in execution_result:
                valid_types = ['success', 'partial_success', 'failure']
                if execution_result['result_type'] not in valid_types:
                    result.add_error("execution_result.result_type", f"æ— æ•ˆçš„ç»“æœç±»å‹ï¼Œåº”ä¸º: {valid_types}")
            
            # éªŒè¯æ•°å€¼å­—æ®µ
            numeric_fields = ['processed_count', 'success_count', 'error_count']
            for field in numeric_fields:
                if field in execution_result:
                    value = execution_result[field]
                    if not isinstance(value, int) or value < 0:
                        result.add_error(f"execution_result.{field}", f"{field} åº”ä¸ºéè´Ÿæ•´æ•°")
            
            # éªŒè¯é€»è¾‘å…³ç³»
            if all(field in execution_result for field in ['processed_count', 'success_count', 'error_count']):
                processed = execution_result['processed_count']
                success = execution_result['success_count']
                error = execution_result['error_count']
                
                if success + error != processed:
                    result.add_error("execution_result.logic", 
                                   f"æ•°æ®ä¸ä¸€è‡´: success_count({success}) + error_count({error}) != processed_count({processed})")
                
                # æ£€æŸ¥æˆåŠŸç‡
                if processed > 0:
                    success_rate = success / processed
                    if success_rate < 0.5:
                        result.add_warning("execution_result.performance", f"æˆåŠŸç‡è¾ƒä½: {success_rate:.2%}")
                    elif success_rate > 0.95:
                        result.add_suggestion("execution_result.performance", f"æˆåŠŸç‡ä¼˜ç§€: {success_rate:.2%}")
            
        except Exception as e:
            result.add_error("execution_result", f"æ‰§è¡Œç»“æœéªŒè¯å¼‚å¸¸: {str(e)}")
    
    async def _validate_execution_statistics(self, execution_stats: Dict[str, Any], result: ValidationResult):
        """éªŒè¯æ‰§è¡Œç»Ÿè®¡"""
        try:
            # éªŒè¯å¿…éœ€å­—æ®µ
            for field in self.required_fields['execution_stats']:
                if field not in execution_stats:
                    result.add_error(f"execution_stats.{field}", f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
            
            # éªŒè¯æ•°å€¼å­—æ®µç±»å‹å’ŒèŒƒå›´
            numeric_fields = ['total_nodes', 'completed_nodes', 'failed_nodes', 'pending_nodes',
                            'total_tasks', 'completed_tasks', 'failed_tasks', 'pending_tasks',
                            'human_tasks', 'agent_tasks', 'mixed_tasks']
            
            for field in numeric_fields:
                if field in execution_stats:
                    value = execution_stats[field]
                    if not isinstance(value, int) or value < 0:
                        result.add_error(f"execution_stats.{field}", f"{field} åº”ä¸ºéè´Ÿæ•´æ•°")
            
            # éªŒè¯èŠ‚ç‚¹ç»Ÿè®¡é€»è¾‘
            if all(field in execution_stats for field in ['total_nodes', 'completed_nodes', 'failed_nodes']):
                total = execution_stats['total_nodes']
                completed = execution_stats['completed_nodes']
                failed = execution_stats['failed_nodes']
                pending = execution_stats.get('pending_nodes', 0)
                
                if completed + failed + pending != total:
                    result.add_warning("execution_stats.nodes", 
                                     f"èŠ‚ç‚¹ç»Ÿè®¡å¯èƒ½ä¸ä¸€è‡´: completed({completed}) + failed({failed}) + pending({pending}) != total({total})")
            
            # éªŒè¯ä»»åŠ¡ç»Ÿè®¡é€»è¾‘
            if all(field in execution_stats for field in ['total_tasks', 'human_tasks', 'agent_tasks', 'mixed_tasks']):
                total_tasks = execution_stats['total_tasks']
                type_sum = execution_stats['human_tasks'] + execution_stats['agent_tasks'] + execution_stats['mixed_tasks']
                
                if type_sum != total_tasks:
                    result.add_warning("execution_stats.tasks", 
                                     f"ä»»åŠ¡ç±»å‹ç»Ÿè®¡ä¸ä¸€è‡´: human + agent + mixed = {type_sum} != total_tasks({total_tasks})")
            
            # éªŒè¯æ‰§è¡Œæ—¶é•¿
            if 'total_duration_minutes' in execution_stats:
                duration = execution_stats['total_duration_minutes']
                if isinstance(duration, (int, float)):
                    if duration > 1440:  # è¶…è¿‡24å°æ—¶
                        result.add_warning("execution_stats.duration", f"æ‰§è¡Œæ—¶é•¿è¾ƒé•¿: {duration} åˆ†é’Ÿ")
                    elif duration < 1:  # å°‘äº1åˆ†é’Ÿ
                        result.add_suggestion("execution_stats.duration", f"æ‰§è¡Œæ•ˆç‡å¾ˆé«˜: {duration} åˆ†é’Ÿ")
            
        except Exception as e:
            result.add_error("execution_stats", f"æ‰§è¡Œç»Ÿè®¡éªŒè¯å¼‚å¸¸: {str(e)}")
    
    async def _validate_quality_metrics(self, quality_metrics: Dict[str, Any], result: ValidationResult):
        """éªŒè¯è´¨é‡æŒ‡æ ‡"""
        try:
            # éªŒè¯è¯„åˆ†å­—æ®µèŒƒå›´
            score_fields = ['data_completeness', 'accuracy_score', 'overall_quality_score']
            for field in score_fields:
                if field in quality_metrics:
                    value = quality_metrics[field]
                    if value is not None:
                        if not isinstance(value, (int, float)) or not (0.0 <= value <= 1.0):
                            result.add_error(f"quality_metrics.{field}", f"{field} åº”ä¸º 0.0-1.0 ä¹‹é—´çš„æ•°å€¼")
            
            # éªŒè¯è´¨é‡é—¨ç¦
            if 'quality_gates_passed' in quality_metrics:
                if not isinstance(quality_metrics['quality_gates_passed'], bool):
                    result.add_error("quality_metrics.quality_gates_passed", "è´¨é‡é—¨ç¦çŠ¶æ€åº”ä¸ºå¸ƒå°”å€¼")
            
            # éªŒè¯éªŒè¯é”™è¯¯åˆ—è¡¨
            if 'validation_errors' in quality_metrics:
                errors = quality_metrics['validation_errors']
                if not isinstance(errors, list):
                    result.add_error("quality_metrics.validation_errors", "éªŒè¯é”™è¯¯åº”ä¸ºåˆ—è¡¨æ ¼å¼")
                elif len(errors) > 0:
                    result.add_warning("quality_metrics.validation", f"å‘ç° {len(errors)} ä¸ªéªŒè¯é”™è¯¯")
            
            # éªŒè¯è´¨é‡è¯„åˆ†ä¸€è‡´æ€§
            if all(field in quality_metrics and quality_metrics[field] is not None 
                   for field in ['data_completeness', 'accuracy_score', 'overall_quality_score']):
                completeness = quality_metrics['data_completeness']
                accuracy = quality_metrics['accuracy_score']
                overall = quality_metrics['overall_quality_score']
                
                expected_overall = (completeness + accuracy) / 2
                if abs(overall - expected_overall) > 0.1:
                    result.add_warning("quality_metrics.consistency", 
                                     f"æ•´ä½“è´¨é‡è¯„åˆ†({overall:.2f})ä¸é¢„æœŸ({expected_overall:.2f})å·®å¼‚è¾ƒå¤§")
            
            # è´¨é‡å»ºè®®
            if 'overall_quality_score' in quality_metrics and quality_metrics['overall_quality_score'] is not None:
                score = quality_metrics['overall_quality_score']
                if score < 0.6:
                    result.add_warning("quality_metrics.score", f"æ•´ä½“è´¨é‡è¯„åˆ†è¾ƒä½: {score:.2f}")
                elif score > 0.9:
                    result.add_suggestion("quality_metrics.score", f"æ•´ä½“è´¨é‡è¯„åˆ†ä¼˜ç§€: {score:.2f}")
            
        except Exception as e:
            result.add_error("quality_metrics", f"è´¨é‡æŒ‡æ ‡éªŒè¯å¼‚å¸¸: {str(e)}")
    
    async def _validate_data_lineage(self, data_lineage: Dict[str, Any], result: ValidationResult):
        """éªŒè¯æ•°æ®è¡€ç¼˜"""
        try:
            # éªŒè¯è¾“å…¥æ¥æº
            if 'input_sources' in data_lineage:
                sources = data_lineage['input_sources']
                if not isinstance(sources, list):
                    result.add_error("data_lineage.input_sources", "è¾“å…¥æ¥æºåº”ä¸ºåˆ—è¡¨æ ¼å¼")
                elif len(sources) == 0:
                    result.add_warning("data_lineage.input_sources", "æœªè®°å½•è¾“å…¥æ¥æº")
            
            # éªŒè¯è½¬æ¢æ­¥éª¤
            if 'transformation_steps' in data_lineage:
                steps = data_lineage['transformation_steps']
                if not isinstance(steps, list):
                    result.add_error("data_lineage.transformation_steps", "è½¬æ¢æ­¥éª¤åº”ä¸ºåˆ—è¡¨æ ¼å¼")
                else:
                    for i, step in enumerate(steps):
                        if not isinstance(step, dict):
                            result.add_error(f"data_lineage.transformation_steps[{i}]", "è½¬æ¢æ­¥éª¤åº”ä¸ºå­—å…¸æ ¼å¼")
                            continue
                        
                        if 'node' not in step:
                            result.add_error(f"data_lineage.transformation_steps[{i}]", "è½¬æ¢æ­¥éª¤ç¼ºå°‘èŠ‚ç‚¹åç§°")
                        
                        if 'operations' not in step or not isinstance(step['operations'], list):
                            result.add_error(f"data_lineage.transformation_steps[{i}]", "è½¬æ¢æ­¥éª¤ç¼ºå°‘æ“ä½œåˆ—è¡¨")
            
            # éªŒè¯è¾“å‡ºç›®æ ‡
            if 'output_destinations' in data_lineage:
                destinations = data_lineage['output_destinations']
                if not isinstance(destinations, list):
                    result.add_error("data_lineage.output_destinations", "è¾“å‡ºç›®æ ‡åº”ä¸ºåˆ—è¡¨æ ¼å¼")
                elif len(destinations) == 0:
                    result.add_warning("data_lineage.output_destinations", "æœªè®°å½•è¾“å‡ºç›®æ ‡")
            
        except Exception as e:
            result.add_error("data_lineage", f"æ•°æ®è¡€ç¼˜éªŒè¯å¼‚å¸¸: {str(e)}")
    
    async def _validate_execution_issues(self, issues: Dict[str, Any], result: ValidationResult):
        """éªŒè¯æ‰§è¡Œé—®é¢˜"""
        try:
            issue_types = ['errors', 'warnings', 'recoverable_failures']
            
            for issue_type in issue_types:
                if issue_type in issues:
                    issue_list = issues[issue_type]
                    if not isinstance(issue_list, list):
                        result.add_error(f"issues.{issue_type}", f"{issue_type} åº”ä¸ºåˆ—è¡¨æ ¼å¼")
                    else:
                        # æ£€æŸ¥é—®é¢˜æ•°é‡
                        if issue_type == 'errors' and len(issue_list) > 0:
                            result.add_warning(f"issues.{issue_type}", f"å‘ç° {len(issue_list)} ä¸ªé”™è¯¯")
                        elif issue_type == 'warnings' and len(issue_list) > 5:
                            result.add_warning(f"issues.{issue_type}", f"è­¦å‘Šæ•°é‡è¾ƒå¤š: {len(issue_list)} ä¸ª")
                        elif issue_type == 'recoverable_failures' and len(issue_list) > 0:
                            result.add_suggestion(f"issues.{issue_type}", f"æœ‰ {len(issue_list)} ä¸ªå¯æ¢å¤å¤±è´¥å·²å¤„ç†")
            
        except Exception as e:
            result.add_error("issues", f"æ‰§è¡Œé—®é¢˜éªŒè¯å¼‚å¸¸: {str(e)}")
    
    async def _validate_logical_consistency(self, summary_dict: Dict[str, Any], result: ValidationResult):
        """éªŒè¯é€»è¾‘ä¸€è‡´æ€§"""
        try:
            # éªŒè¯ç»“æœç±»å‹ä¸ç»Ÿè®¡æ•°æ®çš„ä¸€è‡´æ€§
            if 'execution_result' in summary_dict and 'execution_stats' in summary_dict:
                exec_result = summary_dict['execution_result']
                exec_stats = summary_dict['execution_stats']
                
                result_type = exec_result.get('result_type')
                failed_nodes = exec_stats.get('failed_nodes', 0)
                completed_nodes = exec_stats.get('completed_nodes', 0)
                total_nodes = exec_stats.get('total_nodes', 0)
                
                # æ£€æŸ¥ç»“æœç±»å‹ä¸èŠ‚ç‚¹çŠ¶æ€çš„ä¸€è‡´æ€§
                if result_type == 'success' and failed_nodes > 0:
                    result.add_warning("consistency", f"ç»“æœç±»å‹ä¸ºsuccessä½†æœ‰ {failed_nodes} ä¸ªå¤±è´¥èŠ‚ç‚¹")
                elif result_type == 'failure' and failed_nodes == 0:
                    result.add_warning("consistency", "ç»“æœç±»å‹ä¸ºfailureä½†æ²¡æœ‰å¤±è´¥èŠ‚ç‚¹")
                elif result_type == 'partial_success' and (failed_nodes == 0 or completed_nodes == 0):
                    result.add_warning("consistency", "ç»“æœç±»å‹ä¸ºpartial_successä½†èŠ‚ç‚¹çŠ¶æ€ä¸ç¬¦åˆé¢„æœŸ")
            
            # éªŒè¯è´¨é‡æŒ‡æ ‡ä¸ç»“æœçš„ä¸€è‡´æ€§
            if 'execution_result' in summary_dict and 'quality_metrics' in summary_dict:
                result_type = summary_dict['execution_result'].get('result_type')
                quality_gates = summary_dict['quality_metrics'].get('quality_gates_passed')
                
                if result_type == 'success' and quality_gates is False:
                    result.add_warning("consistency", "æ‰§è¡ŒæˆåŠŸä½†è´¨é‡é—¨ç¦æœªé€šè¿‡")
                elif result_type == 'failure' and quality_gates is True:
                    result.add_warning("consistency", "æ‰§è¡Œå¤±è´¥ä½†è´¨é‡é—¨ç¦é€šè¿‡")
            
        except Exception as e:
            result.add_error("consistency", f"é€»è¾‘ä¸€è‡´æ€§éªŒè¯å¼‚å¸¸: {str(e)}")
    
    async def _generate_optimization_suggestions(self, summary_dict: Dict[str, Any], result: ValidationResult):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        try:
            # åŸºäºæ‰§è¡Œç»Ÿè®¡çš„å»ºè®®
            if 'execution_stats' in summary_dict:
                stats = summary_dict['execution_stats']
                
                # æ‰§è¡Œæ—¶é•¿å»ºè®®
                if 'total_duration_minutes' in stats and stats['total_duration_minutes']:
                    duration = stats['total_duration_minutes']
                    total_tasks = stats.get('total_tasks', 0)
                    
                    if total_tasks > 0:
                        avg_task_time = duration / total_tasks
                        if avg_task_time > 10:
                            result.add_suggestion("optimization", f"å¹³å‡ä»»åŠ¡æ—¶é•¿è¾ƒé•¿({avg_task_time:.1f}åˆ†é’Ÿ)ï¼Œè€ƒè™‘ä¼˜åŒ–ä»»åŠ¡æ‹†åˆ†")
                
                # ä»»åŠ¡ç±»å‹åˆ†å¸ƒå»ºè®®
                human_tasks = stats.get('human_tasks', 0)
                agent_tasks = stats.get('agent_tasks', 0)
                total_tasks = stats.get('total_tasks', 0)
                
                if total_tasks > 0:
                    human_ratio = human_tasks / total_tasks
                    if human_ratio > 0.8:
                        result.add_suggestion("optimization", "äººå·¥ä»»åŠ¡æ¯”ä¾‹è¾ƒé«˜ï¼Œè€ƒè™‘å¢åŠ è‡ªåŠ¨åŒ–")
                    elif human_ratio < 0.1:
                        result.add_suggestion("optimization", "è‡ªåŠ¨åŒ–ç¨‹åº¦å¾ˆé«˜ï¼Œè¡¨ç°ä¼˜ç§€")
            
            # åŸºäºè´¨é‡æŒ‡æ ‡çš„å»ºè®®
            if 'quality_metrics' in summary_dict:
                metrics = summary_dict['quality_metrics']
                
                data_completeness = metrics.get('data_completeness')
                if data_completeness is not None and data_completeness < 0.9:
                    result.add_suggestion("optimization", f"æ•°æ®å®Œæ•´æ€§({data_completeness:.2f})æœ‰æå‡ç©ºé—´")
                
                accuracy_score = metrics.get('accuracy_score')
                if accuracy_score is not None and accuracy_score < 0.85:
                    result.add_suggestion("optimization", f"å‡†ç¡®æ€§è¯„åˆ†({accuracy_score:.2f})æœ‰æå‡ç©ºé—´")
            
        except Exception as e:
            logger.warning(f"ç”Ÿæˆä¼˜åŒ–å»ºè®®å¼‚å¸¸: {e}")
    
    async def validate_workflow_instance_output(self, workflow_instance: Dict[str, Any]) -> ValidationResult:
        """éªŒè¯å·¥ä½œæµå®ä¾‹çš„è¾“å‡ºæ•°æ®"""
        result = ValidationResult()
        
        try:
            logger.info(f"ğŸ” å¼€å§‹éªŒè¯å·¥ä½œæµå®ä¾‹è¾“å‡º: {workflow_instance.get('instance_id')}")
            
            # 1. éªŒè¯åŸºç¡€è¾“å‡ºæ•°æ®
            if 'output_data' in workflow_instance and workflow_instance['output_data']:
                await self._validate_basic_output_data(workflow_instance['output_data'], result)
            
            # 2. éªŒè¯ç»“æ„åŒ–è¾“å‡ºå­—æ®µ
            structured_fields = ['execution_summary', 'quality_metrics', 'data_lineage', 'output_summary']
            for field in structured_fields:
                if field in workflow_instance and workflow_instance[field]:
                    await self._validate_structured_field(field, workflow_instance[field], result)
            
            # 3. éªŒè¯çŠ¶æ€ä¸€è‡´æ€§
            await self._validate_instance_status_consistency(workflow_instance, result)
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ éªŒè¯å·¥ä½œæµå®ä¾‹è¾“å‡ºå¼‚å¸¸: {e}")
            result.add_error("validation", f"éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
            return result
    
    async def _validate_basic_output_data(self, output_data: Dict[str, Any], result: ValidationResult):
        """éªŒè¯åŸºç¡€è¾“å‡ºæ•°æ®"""
        try:
            # æ£€æŸ¥åŸºç¡€å­—æ®µ
            if 'message' not in output_data:
                result.add_warning("output_data", "ç¼ºå°‘æ¶ˆæ¯å­—æ®µ")
            
            if 'completion_time' in output_data:
                try:
                    datetime.fromisoformat(output_data['completion_time'].replace('Z', '+00:00'))
                except (ValueError, AttributeError):
                    result.add_error("output_data.completion_time", "å®Œæˆæ—¶é—´æ ¼å¼æ— æ•ˆ")
            
            if 'result_type' in output_data:
                valid_types = ['success', 'partial_success', 'failure']
                if output_data['result_type'] not in valid_types:
                    result.add_error("output_data.result_type", f"æ— æ•ˆçš„ç»“æœç±»å‹ï¼Œåº”ä¸º: {valid_types}")
            
        except Exception as e:
            result.add_error("output_data", f"åŸºç¡€è¾“å‡ºæ•°æ®éªŒè¯å¼‚å¸¸: {str(e)}")
    
    async def _validate_structured_field(self, field_name: str, field_data: Dict[str, Any], result: ValidationResult):
        """éªŒè¯ç»“æ„åŒ–å­—æ®µ"""
        try:
            if field_name == 'execution_summary':
                if 'execution_result' in field_data:
                    await self._validate_execution_result(field_data['execution_result'], result)
                if 'execution_stats' in field_data:
                    await self._validate_execution_statistics(field_data['execution_stats'], result)
            
            elif field_name == 'quality_metrics':
                await self._validate_quality_metrics(field_data, result)
            
            elif field_name == 'data_lineage':
                await self._validate_data_lineage(field_data, result)
            
            elif field_name == 'output_summary':
                await self.validate_workflow_output_summary(field_data)
            
        except Exception as e:
            result.add_error(field_name, f"ç»“æ„åŒ–å­—æ®µéªŒè¯å¼‚å¸¸: {str(e)}")
    
    async def _validate_instance_status_consistency(self, workflow_instance: Dict[str, Any], result: ValidationResult):
        """éªŒè¯å®ä¾‹çŠ¶æ€ä¸€è‡´æ€§"""
        try:
            status = workflow_instance.get('status')
            
            # æ£€æŸ¥å®ŒæˆçŠ¶æ€çš„ä¸€è‡´æ€§
            if status == WorkflowInstanceStatus.COMPLETED.value:
                if not workflow_instance.get('completed_at'):
                    result.add_error("status", "çŠ¶æ€ä¸ºå·²å®Œæˆä½†ç¼ºå°‘å®Œæˆæ—¶é—´")
                
                if not workflow_instance.get('output_data'):
                    result.add_warning("status", "çŠ¶æ€ä¸ºå·²å®Œæˆä½†ç¼ºå°‘è¾“å‡ºæ•°æ®")
            
            elif status == WorkflowInstanceStatus.FAILED.value:
                if not workflow_instance.get('error_message'):
                    result.add_warning("status", "çŠ¶æ€ä¸ºå¤±è´¥ä½†ç¼ºå°‘é”™è¯¯ä¿¡æ¯")
            
            elif status == WorkflowInstanceStatus.RUNNING.value:
                if workflow_instance.get('completed_at'):
                    result.add_error("status", "çŠ¶æ€ä¸ºè¿è¡Œä¸­ä½†å­˜åœ¨å®Œæˆæ—¶é—´")
            
        except Exception as e:
            result.add_error("status", f"çŠ¶æ€ä¸€è‡´æ€§éªŒè¯å¼‚å¸¸: {str(e)}")
    
    async def get_validation_summary(self, validation_results: List[ValidationResult]) -> Dict[str, Any]:
        """è·å–éªŒè¯æ‘˜è¦"""
        try:
            total_validations = len(validation_results)
            valid_count = sum(1 for r in validation_results if r.is_valid)
            invalid_count = total_validations - valid_count
            
            total_errors = sum(len(r.errors) for r in validation_results)
            total_warnings = sum(len(r.warnings) for r in validation_results)
            total_suggestions = sum(len(r.suggestions) for r in validation_results)
            
            return {
                'total_validations': total_validations,
                'valid_count': valid_count,
                'invalid_count': invalid_count,
                'success_rate': valid_count / total_validations if total_validations > 0 else 0,
                'total_errors': total_errors,
                'total_warnings': total_warnings,
                'total_suggestions': total_suggestions,
                'validation_time': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆéªŒè¯æ‘˜è¦å¼‚å¸¸: {e}")
            return {
                'error': str(e),
                'validation_time': datetime.utcnow().isoformat()
            }