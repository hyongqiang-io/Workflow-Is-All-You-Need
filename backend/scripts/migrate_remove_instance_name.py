"""
æ•°æ®åº“è¿ç§»è„šæœ¬ï¼šåˆ é™¤workflow_instanceè¡¨ä¸­çš„instance_nameå­—æ®µ
Migration Script: Remove instance_name field from workflow_instance table
"""

import asyncio
import asyncpg
import os
import sys
from pathlib import Path
from loguru import logger

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, parent_dir)

from backend.config import get_settings


class InstanceNameFieldMigration:
    """instance_nameå­—æ®µè¿ç§»å™¨"""
    
    def __init__(self):
        self.settings = get_settings()
    
    async def connect_database(self):
        """è¿æ¥åˆ°æ•°æ®åº“"""
        try:
            self.conn = await asyncpg.connect(
                host=self.settings.database.host,
                port=self.settings.database.port,
                user=self.settings.database.username,
                password=self.settings.database.password,
                database=self.settings.database.database
            )
            logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ°æ•°æ®åº“: {self.settings.database.database}")
            return True
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    async def close_connection(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if hasattr(self, 'conn') and self.conn:
            await self.conn.close()
            logger.info("ğŸ”’ æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    async def check_table_structure(self):
        """æ£€æŸ¥å½“å‰è¡¨ç»“æ„"""
        logger.info("ğŸ” æ£€æŸ¥workflow_instanceè¡¨å½“å‰ç»“æ„...")
        
        query = """
        SELECT column_name, data_type, is_nullable, column_default
        FROM information_schema.columns 
        WHERE table_name = 'workflow_instance' 
        AND table_schema = 'public'
        AND column_name IN ('workflow_instance_name', 'instance_name')
        ORDER BY column_name
        """
        
        columns = await self.conn.fetch(query)
        
        if not columns:
            logger.error("âŒ æœªæ‰¾åˆ°workflow_instanceè¡¨æˆ–ç›¸å…³å­—æ®µ")
            return False
        
        logger.info("ğŸ“‹ å½“å‰å­—æ®µçŠ¶æ€:")
        for col in columns:
            nullable = "å¯ç©º" if col['is_nullable'] == 'YES' else "éç©º"
            default = f" é»˜è®¤å€¼:{col['column_default']}" if col['column_default'] else ""
            logger.info(f"  â€¢ {col['column_name']}: {col['data_type']} [{nullable}]{default}")
        
        return columns
    
    async def backup_and_migrate_data(self):
        """å¤‡ä»½instance_nameæ•°æ®åˆ°workflow_instance_name"""
        logger.info("ğŸ’¾ å¼€å§‹å¤‡ä»½instance_nameæ•°æ®åˆ°workflow_instance_name...")
        
        # æ£€æŸ¥æœ‰å¤šå°‘æ¡è®°å½•éœ€è¦è¿ç§»
        count_query = """
        SELECT COUNT(*) as total_count,
               COUNT(CASE WHEN workflow_instance_name IS NULL OR workflow_instance_name = '' THEN 1 END) as null_workflow_name,
               COUNT(CASE WHEN instance_name IS NOT NULL AND instance_name != '' THEN 1 END) as has_instance_name
        FROM workflow_instance
        """
        
        stats = await self.conn.fetchrow(count_query)
        logger.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        logger.info(f"  â€¢ æ€»è®°å½•æ•°: {stats['total_count']}")
        logger.info(f"  â€¢ workflow_instance_nameä¸ºç©ºçš„è®°å½•: {stats['null_workflow_name']}")
        logger.info(f"  â€¢ æœ‰instance_nameå€¼çš„è®°å½•: {stats['has_instance_name']}")
        
        if stats['null_workflow_name'] > 0:
            # å°†instance_nameçš„å€¼å¤åˆ¶åˆ°workflow_instance_name
            migration_query = """
            UPDATE workflow_instance 
            SET workflow_instance_name = instance_name,
                updated_at = NOW()
            WHERE (workflow_instance_name IS NULL OR workflow_instance_name = '') 
            AND instance_name IS NOT NULL 
            AND instance_name != ''
            """
            
            result = await self.conn.execute(migration_query)
            affected_rows = int(result.split()[-1]) if "UPDATE" in result else 0
            logger.info(f"âœ… æˆåŠŸè¿ç§» {affected_rows} æ¡è®°å½•çš„æ•°æ®")
        else:
            logger.info("â„¹ï¸ æ‰€æœ‰workflow_instance_nameå­—æ®µéƒ½å·²æœ‰å€¼ï¼Œæ— éœ€è¿ç§»æ•°æ®")
        
        return True
    
    async def verify_data_integrity(self):
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        logger.info("ğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§...")
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰workflow_instance_nameä¸ºç©ºä½†instance_nameæœ‰å€¼çš„è®°å½•
        integrity_query = """
        SELECT workflow_instance_id, workflow_instance_name, instance_name
        FROM workflow_instance
        WHERE (workflow_instance_name IS NULL OR workflow_instance_name = '')
        AND (instance_name IS NOT NULL AND instance_name != '')
        LIMIT 5
        """
        
        problem_records = await self.conn.fetch(integrity_query)
        
        if problem_records:
            logger.error(f"âŒ å‘ç° {len(problem_records)} æ¡æ•°æ®å®Œæ•´æ€§é—®é¢˜:")
            for record in problem_records:
                logger.error(f"  â€¢ ID: {record['workflow_instance_id']}, workflow_instance_name: '{record['workflow_instance_name']}', instance_name: '{record['instance_name']}'")
            return False
        
        logger.info("âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
        return True
    
    async def update_workflow_instance_name_constraint(self):
        """æ›´æ–°workflow_instance_nameå­—æ®µä¸ºéç©ºçº¦æŸ"""
        logger.info("ğŸ”§ æ›´æ–°workflow_instance_nameå­—æ®µä¸ºéç©ºçº¦æŸ...")
        
        try:
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦è¿˜æœ‰NULLå€¼
            null_check_query = "SELECT COUNT(*) FROM workflow_instance WHERE workflow_instance_name IS NULL"
            null_count = await self.conn.fetchval(null_check_query)
            
            if null_count > 0:
                logger.error(f"âŒ ä»æœ‰ {null_count} æ¡è®°å½•çš„workflow_instance_nameä¸ºç©ºï¼Œæ— æ³•è®¾ç½®éç©ºçº¦æŸ")
                return False
            
            # è®¾ç½®éç©ºçº¦æŸ
            alter_query = "ALTER TABLE workflow_instance ALTER COLUMN workflow_instance_name SET NOT NULL"
            await self.conn.execute(alter_query)
            logger.info("âœ… æˆåŠŸå°†workflow_instance_nameå­—æ®µè®¾ç½®ä¸ºéç©ºçº¦æŸ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ è®¾ç½®éç©ºçº¦æŸå¤±è´¥: {e}")
            return False
    
    async def check_field_dependencies(self):
        """æ£€æŸ¥instance_nameå­—æ®µçš„ä¾èµ–å…³ç³»"""
        logger.info("ğŸ” æ£€æŸ¥instance_nameå­—æ®µçš„ä¾èµ–å…³ç³»...")
        
        # æŸ¥æ‰¾ä¾èµ–çš„è§†å›¾
        dependency_query = """
        SELECT DISTINCT dependent_ns.nspname as dependent_schema,
               dependent_view.relname as dependent_table,
               source_ns.nspname as source_schema,
               source_table.relname as source_table
        FROM pg_depend 
        JOIN pg_rewrite ON pg_depend.objid = pg_rewrite.oid
        JOIN pg_class as dependent_view ON pg_rewrite.ev_class = dependent_view.oid
        JOIN pg_class as source_table ON pg_depend.refobjid = source_table.oid
        JOIN pg_attribute ON pg_depend.refobjid = pg_attribute.attrelid 
            AND pg_depend.refobjsubid = pg_attribute.attnum
        JOIN pg_namespace dependent_ns ON dependent_view.relnamespace = dependent_ns.oid
        JOIN pg_namespace source_ns ON source_table.relnamespace = source_ns.oid
        WHERE source_table.relname = 'workflow_instance'
        AND pg_attribute.attname = 'instance_name'
        AND dependent_view.relkind = 'v'
        """
        
        dependencies = await self.conn.fetch(dependency_query)
        
        if dependencies:
            logger.info("ğŸ“‹ å‘ç°ä»¥ä¸‹è§†å›¾ä¾èµ–instance_nameå­—æ®µ:")
            for dep in dependencies:
                logger.info(f"  â€¢ {dep['dependent_schema']}.{dep['dependent_table']}")
            return dependencies
        else:
            logger.info("â„¹ï¸ æ²¡æœ‰å‘ç°è§†å›¾ä¾èµ–instance_nameå­—æ®µ")
            return []
    
    async def drop_dependent_views(self, dependencies):
        """åˆ é™¤ä¾èµ–çš„è§†å›¾"""
        if not dependencies:
            return True
        
        logger.info("ğŸ—‘ï¸ åˆ é™¤ä¾èµ–çš„è§†å›¾...")
        
        try:
            for dep in dependencies:
                view_name = f"{dep['dependent_schema']}.{dep['dependent_table']}"
                drop_view_query = f"DROP VIEW IF EXISTS {view_name} CASCADE"
                await self.conn.execute(drop_view_query)
                logger.info(f"  âœ… åˆ é™¤è§†å›¾: {view_name}")
            
            logger.info("âœ… æ‰€æœ‰ä¾èµ–è§†å›¾åˆ é™¤å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤ä¾èµ–è§†å›¾å¤±è´¥: {e}")
            return False
    
    async def recreate_views_without_instance_name(self):
        """é‡æ–°åˆ›å»ºè§†å›¾(ä¸åŒ…å«instance_nameå­—æ®µ)"""
        logger.info("ğŸ”§ é‡æ–°åˆ›å»ºè§†å›¾(å»é™¤instance_nameå­—æ®µ)...")
        
        # é‡æ–°åˆ›å»ºworkflow_instance_detail_viewè§†å›¾
        recreate_view_query = """
        CREATE OR REPLACE VIEW workflow_instance_detail_view AS
        SELECT 
            wi.workflow_instance_id,
            wi.workflow_id,
            wi.workflow_base_id,
            wi.workflow_instance_name,
            wi.status,
            wi.input_data,
            wi.context_data,
            wi.output_data,
            wi.started_at,
            wi.completed_at,
            wi.error_message,
            wi.current_node_id,
            wi.retry_count,
            wi.execution_summary,
            wi.quality_metrics,
            wi.data_lineage,
            wi.output_summary,
            wi.created_at,
            wi.updated_at,
            w.name as workflow_name,
            w.description as workflow_description,
            u.username as executor_name,
            COALESCE(node_stats.total_nodes, 0) as total_nodes,
            COALESCE(node_stats.completed_nodes, 0) as completed_nodes,
            COALESCE(node_stats.failed_nodes, 0) as failed_nodes,
            COALESCE(node_stats.running_nodes, 0) as running_nodes
        FROM workflow_instance wi
        LEFT JOIN workflow w ON wi.workflow_id = w.workflow_id
        LEFT JOIN "user" u ON wi.executor_id = u.user_id
        LEFT JOIN (
            SELECT 
                ni.workflow_instance_id,
                COUNT(*) as total_nodes,
                COUNT(CASE WHEN ni.status = 'completed' THEN 1 END) as completed_nodes,
                COUNT(CASE WHEN ni.status = 'failed' THEN 1 END) as failed_nodes,
                COUNT(CASE WHEN ni.status IN ('running', 'pending') THEN 1 END) as running_nodes
            FROM node_instance ni
            WHERE ni.is_deleted = FALSE
            GROUP BY ni.workflow_instance_id
        ) node_stats ON wi.workflow_instance_id = node_stats.workflow_instance_id
        WHERE wi.is_deleted = FALSE
        """
        
        try:
            await self.conn.execute(recreate_view_query)
            logger.info("âœ… æˆåŠŸé‡æ–°åˆ›å»ºworkflow_instance_detail_viewè§†å›¾")
            return True
            
        except Exception as e:
            logger.error(f"âŒ é‡æ–°åˆ›å»ºè§†å›¾å¤±è´¥: {e}")
            return False
    
    async def remove_instance_name_field(self):
        """åˆ é™¤instance_nameå­—æ®µ"""
        logger.info("ğŸ—‘ï¸ åˆ é™¤instance_nameå­—æ®µ...")
        
        try:
            # 1. æ£€æŸ¥å­—æ®µä¾èµ–å…³ç³»
            dependencies = await self.check_field_dependencies()
            
            # 2. åˆ é™¤ä¾èµ–çš„è§†å›¾
            if not await self.drop_dependent_views(dependencies):
                return False
            
            # 3. åˆ é™¤å­—æ®µ
            drop_query = "ALTER TABLE workflow_instance DROP COLUMN IF EXISTS instance_name"
            await self.conn.execute(drop_query)
            logger.info("âœ… æˆåŠŸåˆ é™¤instance_nameå­—æ®µ")
            
            # 4. é‡æ–°åˆ›å»ºè§†å›¾(ä¸åŒ…å«instance_nameå­—æ®µ)
            if not await self.recreate_views_without_instance_name():
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤instance_nameå­—æ®µå¤±è´¥: {e}")
            return False
    
    async def verify_final_structure(self):
        """éªŒè¯æœ€ç»ˆè¡¨ç»“æ„"""
        logger.info("ğŸ” éªŒè¯æœ€ç»ˆè¡¨ç»“æ„...")
        
        query = """
        SELECT column_name, data_type, is_nullable, column_default
        FROM information_schema.columns 
        WHERE table_name = 'workflow_instance' 
        AND table_schema = 'public'
        AND column_name IN ('workflow_instance_name', 'instance_name')
        ORDER BY column_name
        """
        
        columns = await self.conn.fetch(query)
        
        logger.info("ğŸ“‹ æœ€ç»ˆå­—æ®µç»“æ„:")
        for col in columns:
            nullable = "å¯ç©º" if col['is_nullable'] == 'YES' else "éç©º"
            default = f" é»˜è®¤å€¼:{col['column_default']}" if col['column_default'] else ""
            logger.info(f"  â€¢ {col['column_name']}: {col['data_type']} [{nullable}]{default}")
        
        # éªŒè¯åªæœ‰workflow_instance_nameå­—æ®µå­˜åœ¨ä¸”ä¸ºéç©º
        has_workflow_instance_name = any(col['column_name'] == 'workflow_instance_name' for col in columns)
        has_instance_name = any(col['column_name'] == 'instance_name' for col in columns)
        workflow_name_not_null = any(col['column_name'] == 'workflow_instance_name' and col['is_nullable'] == 'NO' for col in columns)
        
        if has_workflow_instance_name and not has_instance_name and workflow_name_not_null:
            logger.info("âœ… è¡¨ç»“æ„è¿ç§»æˆåŠŸï¼")
            logger.info("  â€¢ workflow_instance_nameå­—æ®µå­˜åœ¨ä¸”ä¸ºéç©º")
            logger.info("  â€¢ instance_nameå­—æ®µå·²è¢«åˆ é™¤")
            return True
        else:
            logger.error("âŒ è¡¨ç»“æ„è¿ç§»æœªå®Œæˆ")
            if not has_workflow_instance_name:
                logger.error("  â€¢ workflow_instance_nameå­—æ®µä¸å­˜åœ¨")
            if has_instance_name:
                logger.error("  â€¢ instance_nameå­—æ®µä»ç„¶å­˜åœ¨")
            if not workflow_name_not_null:
                logger.error("  â€¢ workflow_instance_nameå­—æ®µä»ç„¶å¯ç©º")
            return False
    
    async def run_migration(self):
        """æ‰§è¡Œå®Œæ•´çš„è¿ç§»è¿‡ç¨‹"""
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œinstance_nameå­—æ®µè¿ç§»...")
        logger.info("="*60)
        
        try:
            # 1. è¿æ¥æ•°æ®åº“
            if not await self.connect_database():
                return False
            
            # 2. æ£€æŸ¥å½“å‰è¡¨ç»“æ„
            current_structure = await self.check_table_structure()
            if not current_structure:
                return False
            
            # 3. å¤‡ä»½å’Œè¿ç§»æ•°æ®
            if not await self.backup_and_migrate_data():
                return False
            
            # 4. éªŒè¯æ•°æ®å®Œæ•´æ€§
            if not await self.verify_data_integrity():
                return False
            
            # 5. æ›´æ–°workflow_instance_nameä¸ºéç©ºçº¦æŸ
            if not await self.update_workflow_instance_name_constraint():
                return False
            
            # 6. åˆ é™¤instance_nameå­—æ®µ
            if not await self.remove_instance_name_field():
                return False
            
            # 7. éªŒè¯æœ€ç»ˆç»“æ„
            if not await self.verify_final_structure():
                return False
            
            logger.info("="*60)
            logger.info("ğŸ‰ è¿ç§»å®Œæˆï¼instance_nameå­—æ®µå·²æˆåŠŸåˆ é™¤")
            logger.info("ğŸ“ è¿ç§»æ‘˜è¦:")
            logger.info("  â€¢ æ•°æ®å·²ä»instance_nameè¿ç§»åˆ°workflow_instance_name")
            logger.info("  â€¢ workflow_instance_nameå­—æ®µå·²è®¾ç½®ä¸ºéç©ºçº¦æŸ")
            logger.info("  â€¢ instance_nameå­—æ®µå·²è¢«åˆ é™¤")
            logger.info("  â€¢ æ•°æ®åº“ç»“æ„ç°åœ¨ä¸ä»£ç ä¿æŒä¸€è‡´")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return False
        
        finally:
            await self.close_connection()


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ”„ workflow_instanceè¡¨instance_nameå­—æ®µè¿ç§»å·¥å…·")
    logger.info("ç‰ˆæœ¬: 1.0")
    logger.info("ä½œç”¨: åˆ é™¤instance_nameå­—æ®µï¼Œç»Ÿä¸€ä½¿ç”¨workflow_instance_name")
    
    migrator = InstanceNameFieldMigration()
    success = await migrator.run_migration()
    
    if success:
        logger.info("âœ… è¿ç§»æˆåŠŸå®Œæˆ")
        return 0
    else:
        logger.error("âŒ è¿ç§»å¤±è´¥")
        return 1


if __name__ == "__main__":
    import sys
    exit_code = asyncio.run(main())
    sys.exit(exit_code)