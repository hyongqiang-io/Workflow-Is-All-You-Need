"""
å·¥ä½œæµTabè¡¥å…¨API
æä¾›æ™ºèƒ½èŠ‚ç‚¹å’Œè¿æ¥å»ºè®®çš„APIç«¯ç‚¹
"""

import json
import re
import uuid
from typing import List, Dict, Any, Optional
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel, Field
from loguru import logger

from ..services.workflow_tab_prediction import tab_prediction_service
from ..services.user_interaction_tracker import interaction_tracker, InteractionEventType, SuggestionType
from ..utils.middleware import get_current_user_context, CurrentUser

router = APIRouter(prefix="/api/tab-completion", tags=["tab-completion"])


# ==================== è¯·æ±‚/å“åº”æ¨¡å‹ ====================

class NodePredictionRequest(BaseModel):
    """èŠ‚ç‚¹é¢„æµ‹è¯·æ±‚"""
    context_summary: str = Field(..., description="å·¥ä½œæµä¸Šä¸‹æ–‡æ‘˜è¦")
    max_suggestions: int = Field(3, description="æœ€å¤§å»ºè®®æ•°é‡", ge=1, le=5)
    trigger_type: str = Field("empty_space_click", description="è§¦å‘ç±»å‹")
    cursor_position: Dict[str, float] = Field(default={"x": 0, "y": 0}, description="å…‰æ ‡ä½ç½®")


class ConnectionPredictionRequest(BaseModel):
    """è¿æ¥é¢„æµ‹è¯·æ±‚"""
    context_summary: str = Field(..., description="å·¥ä½œæµä¸Šä¸‹æ–‡æ‘˜è¦")
    source_node_id: str = Field(..., description="æºèŠ‚ç‚¹ID")
    max_suggestions: int = Field(3, description="æœ€å¤§å»ºè®®æ•°é‡", ge=1, le=5)


class WorkflowCompletionRequest(BaseModel):
    """å·¥ä½œæµå®Œæ•´æ€§é¢„æµ‹è¯·æ±‚"""
    context_summary: str = Field(..., description="å½“å‰å·¥ä½œæµçŠ¶æ€")
    partial_description: str = Field(..., description="éƒ¨åˆ†ä»»åŠ¡æè¿°")


class PredictionResponse(BaseModel):
    """é¢„æµ‹å“åº”åŸºç±»"""
    success: bool = Field(..., description="æ˜¯å¦æˆåŠŸ")
    message: str = Field(..., description="å“åº”æ¶ˆæ¯")
    suggestions: List[Dict[str, Any]] = Field(..., description="å»ºè®®åˆ—è¡¨")
    context_analysis: Dict[str, Any] = Field(default={}, description="ä¸Šä¸‹æ–‡åˆ†æç»“æœ")


class InteractionTrackingRequest(BaseModel):
    """äº¤äº’è·Ÿè¸ªè¯·æ±‚"""
    workflow_id: str = Field(..., description="å·¥ä½œæµID")
    session_id: str = Field(..., description="ä¼šè¯ID")
    event_type: str = Field(..., description="äº‹ä»¶ç±»å‹")
    suggestion_type: Optional[str] = Field(None, description="å»ºè®®ç±»å‹")
    event_data: Optional[Dict[str, Any]] = Field(default={}, description="äº‹ä»¶æ•°æ®")
    context_summary: Optional[str] = Field(None, description="ä¸Šä¸‹æ–‡æ‘˜è¦")


class BatchInteractionTrackingRequest(BaseModel):
    """æ‰¹é‡äº¤äº’è·Ÿè¸ªè¯·æ±‚"""
    interactions: List[InteractionTrackingRequest] = Field(..., description="äº¤äº’äº‹ä»¶åˆ—è¡¨")


class UserSatisfactionRequest(BaseModel):
    """ç”¨æˆ·æ»¡æ„åº¦è¯·æ±‚"""
    interaction_id: str = Field(..., description="äº¤äº’è®°å½•ID")
    satisfaction: str = Field(..., description="æ»¡æ„åº¦çº§åˆ«")


# ==================== APIç«¯ç‚¹ ====================

@router.post("/predict-nodes", response_model=PredictionResponse)
async def predict_next_nodes(
    request: NodePredictionRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """é¢„æµ‹ä¸‹ä¸€ä¸ªå¯èƒ½çš„èŠ‚ç‚¹"""
    try:
        logger.info(f"ğŸ”® [API] æ”¶åˆ°èŠ‚ç‚¹é¢„æµ‹è¯·æ±‚")
        logger.info(f"ğŸ”® [API] ç”¨æˆ·: {current_user.user_id}")
        logger.info(f"ğŸ”® [API] è§¦å‘ç±»å‹: {request.trigger_type}")
        logger.info(f"ğŸ”® [API] ä¸Šä¸‹æ–‡é•¿åº¦: {len(request.context_summary)}")

        # è°ƒç”¨é¢„æµ‹æœåŠ¡
        suggestions = await tab_prediction_service.predict_next_nodes(
            context_summary=request.context_summary,
            max_suggestions=request.max_suggestions
        )

        # åˆ†æä¸Šä¸‹æ–‡
        context_analysis = _analyze_prediction_context(request.context_summary)

        logger.info(f"ğŸ”® [API] âœ… èŠ‚ç‚¹é¢„æµ‹å®Œæˆï¼Œå»ºè®®æ•°é‡: {len(suggestions)}")

        return PredictionResponse(
            success=True,
            message=f"æˆåŠŸç”Ÿæˆ {len(suggestions)} ä¸ªèŠ‚ç‚¹å»ºè®®",
            suggestions=suggestions,
            context_analysis=context_analysis
        )

    except Exception as e:
        logger.error(f"ğŸ”® [API] âŒ èŠ‚ç‚¹é¢„æµ‹å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"èŠ‚ç‚¹é¢„æµ‹å¤±è´¥: {str(e)}"
        )


@router.post("/predict-connections", response_model=PredictionResponse)
async def predict_next_connections(
    request: ConnectionPredictionRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """é¢„æµ‹ä»æŒ‡å®šèŠ‚ç‚¹å‡ºå‘çš„å¯èƒ½è¿æ¥"""
    try:
        logger.info(f"ğŸ”® [API] æ”¶åˆ°è¿æ¥é¢„æµ‹è¯·æ±‚")
        logger.info(f"ğŸ”® [API] ç”¨æˆ·: {current_user.user_id}")
        logger.info(f"ğŸ”® [API] æºèŠ‚ç‚¹: {request.source_node_id}")

        # è°ƒç”¨é¢„æµ‹æœåŠ¡
        suggestions = await tab_prediction_service.predict_next_connections(
            context_summary=request.context_summary,
            source_node_id=request.source_node_id,
            max_suggestions=request.max_suggestions
        )

        # åˆ†æä¸Šä¸‹æ–‡
        context_analysis = _analyze_prediction_context(request.context_summary)

        logger.info(f"ğŸ”® [API] âœ… è¿æ¥é¢„æµ‹å®Œæˆï¼Œå»ºè®®æ•°é‡: {len(suggestions)}")

        return PredictionResponse(
            success=True,
            message=f"æˆåŠŸç”Ÿæˆ {len(suggestions)} ä¸ªè¿æ¥å»ºè®®",
            suggestions=suggestions,
            context_analysis=context_analysis
        )

    except Exception as e:
        logger.error(f"ğŸ”® [API] âŒ è¿æ¥é¢„æµ‹å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"è¿æ¥é¢„æµ‹å¤±è´¥: {str(e)}"
        )


@router.post("/predict-completion", response_model=PredictionResponse)
async def predict_workflow_completion(
    request: WorkflowCompletionRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """é¢„æµ‹å·¥ä½œæµçš„å®Œæ•´ç»“æ„"""
    try:
        logger.info(f"ğŸ”® [API] æ”¶åˆ°å·¥ä½œæµå®Œæ•´æ€§é¢„æµ‹è¯·æ±‚")
        logger.info(f"ğŸ”® [API] ç”¨æˆ·: {current_user.user_id}")

        # è°ƒç”¨é¢„æµ‹æœåŠ¡
        suggestions = await tab_prediction_service.predict_workflow_completion(
            context_summary=request.context_summary,
            partial_description=request.partial_description
        )

        # åˆ†æä¸Šä¸‹æ–‡
        context_analysis = _analyze_prediction_context(request.context_summary)

        logger.info(f"ğŸ”® [API] âœ… å·¥ä½œæµå®Œæ•´æ€§é¢„æµ‹å®Œæˆ")

        return PredictionResponse(
            success=True,
            message="å·¥ä½œæµå®Œæ•´æ€§åˆ†æå®Œæˆ",
            suggestions=suggestions,
            context_analysis=context_analysis
        )

    except Exception as e:
        logger.error(f"ğŸ”® [API] âŒ å·¥ä½œæµå®Œæ•´æ€§é¢„æµ‹å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"å·¥ä½œæµå®Œæ•´æ€§é¢„æµ‹å¤±è´¥: {str(e)}"
        )


@router.post("/track-interaction")
async def track_user_interaction(
    request: InteractionTrackingRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·Ÿè¸ªç”¨æˆ·äº¤äº’äº‹ä»¶"""
    try:
        logger.info(f"ğŸ” [API] æ”¶åˆ°äº¤äº’è·Ÿè¸ªè¯·æ±‚")
        logger.info(f"ğŸ” [API] ç”¨æˆ·: {current_user.user_id}")
        logger.info(f"ğŸ” [API] äº‹ä»¶ç±»å‹: {request.event_type}")
        logger.info(f"ğŸ” [API] å·¥ä½œæµ: {request.workflow_id}")

        # è½¬æ¢äº‹ä»¶ç±»å‹
        try:
            event_type = InteractionEventType(request.event_type)
        except ValueError:
            logger.warning(f"ğŸ” [API] æœªçŸ¥äº‹ä»¶ç±»å‹: {request.event_type}")
            event_type = InteractionEventType.TRIGGER_ACTIVATED

        # è½¬æ¢å»ºè®®ç±»å‹
        suggestion_type = None
        if request.suggestion_type:
            try:
                suggestion_type = SuggestionType(request.suggestion_type)
            except ValueError:
                logger.warning(f"ğŸ” [API] æœªçŸ¥å»ºè®®ç±»å‹: {request.suggestion_type}")

        # è®°å½•äº¤äº’
        interaction_id = await interaction_tracker.track_interaction(
            user_id=current_user.user_id,
            workflow_id=request.workflow_id,
            event_type=event_type,
            suggestion_type=suggestion_type,
            suggestion_data=request.event_data,
            context_data={'context_summary': request.context_summary} if request.context_summary else None,
            session_id=request.session_id
        )

        logger.info(f"ğŸ” [API] âœ… äº¤äº’è·Ÿè¸ªå®Œæˆ: {interaction_id}")

        return {
            "success": True,
            "interaction_id": interaction_id,
            "message": "äº¤äº’äº‹ä»¶å·²è®°å½•"
        }

    except Exception as e:
        logger.error(f"ğŸ” [API] âŒ äº¤äº’è·Ÿè¸ªå¤±è´¥: {str(e)}")
        # äº¤äº’è·Ÿè¸ªå¤±è´¥ä¸åº”é˜»å¡ä¸»è¦åŠŸèƒ½
        return {
            "success": False,
            "message": f"äº¤äº’è·Ÿè¸ªå¤±è´¥: {str(e)}"
        }


@router.get("/user-behavior-analysis")
async def get_user_behavior_analysis(
    days_back: int = 30,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–ç”¨æˆ·è¡Œä¸ºåˆ†æ"""
    try:
        logger.info(f"ğŸ” [API] æ”¶åˆ°ç”¨æˆ·è¡Œä¸ºåˆ†æè¯·æ±‚")
        logger.info(f"ğŸ” [API] ç”¨æˆ·: {current_user.user_id}")
        logger.info(f"ğŸ” [API] åˆ†æå¤©æ•°: {days_back}")

        # è·å–ç”¨æˆ·è¡Œä¸ºæ¨¡å¼
        behavior_patterns = await interaction_tracker.get_user_behavior_patterns(
            user_id=current_user.user_id,
            days_back=days_back
        )

        logger.info(f"ğŸ” [API] âœ… ç”¨æˆ·è¡Œä¸ºåˆ†æå®Œæˆ")

        return {
            "success": True,
            "behavior_patterns": behavior_patterns,
            "message": "ç”¨æˆ·è¡Œä¸ºåˆ†æå®Œæˆ"
        }

    except Exception as e:
        logger.error(f"ğŸ” [API] âŒ ç”¨æˆ·è¡Œä¸ºåˆ†æå¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ç”¨æˆ·è¡Œä¸ºåˆ†æå¤±è´¥: {str(e)}"
        )


@router.get("/global-statistics")
async def get_global_statistics(
    days_back: int = 7,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–å…¨å±€ç»Ÿè®¡ä¿¡æ¯"""
    try:
        logger.info(f"ğŸ” [API] æ”¶åˆ°å…¨å±€ç»Ÿè®¡è¯·æ±‚")
        logger.info(f"ğŸ” [API] åˆ†æå¤©æ•°: {days_back}")

        # è·å–å…¨å±€ç»Ÿè®¡
        global_stats = await interaction_tracker.get_global_statistics(days_back=days_back)

        logger.info(f"ğŸ” [API] âœ… å…¨å±€ç»Ÿè®¡å®Œæˆ")

        return {
            "success": True,
            "global_statistics": global_stats,
            "message": "å…¨å±€ç»Ÿè®¡å®Œæˆ"
        }

    except Exception as e:
        logger.error(f"ğŸ” [API] âŒ å…¨å±€ç»Ÿè®¡å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"å…¨å±€ç»Ÿè®¡å¤±è´¥: {str(e)}"
        )


@router.post("/clear-cache")
async def clear_prediction_cache(
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """æ¸…ç©ºé¢„æµ‹ç¼“å­˜"""
    try:
        tab_prediction_service.clear_cache()
        logger.info(f"ğŸ”® [API] ç”¨æˆ· {current_user.user_id} æ¸…ç©ºäº†é¢„æµ‹ç¼“å­˜")

        return {
            "success": True,
            "message": "é¢„æµ‹ç¼“å­˜å·²æ¸…ç©º"
        }
    except Exception as e:
        logger.error(f"ğŸ”® [API] æ¸…ç©ºç¼“å­˜å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {str(e)}"
        )


# ==================== è¾…åŠ©å‡½æ•° ====================

def _analyze_prediction_context(context_summary: str) -> Dict[str, Any]:
    """åˆ†æé¢„æµ‹ä¸Šä¸‹æ–‡ï¼Œæä¾›é¢å¤–çš„åˆ†æä¿¡æ¯"""
    try:
        import json
        context_data = json.loads(context_summary)

        return {
            "workflow_completeness": _calculate_completeness(context_data),
            "suggested_priority": _determine_priority(context_data),
            "complexity_score": _calculate_complexity(context_data),
            "pattern_match": _identify_patterns(context_data)
        }
    except:
        return {
            "workflow_completeness": "unknown",
            "suggested_priority": "medium",
            "complexity_score": 0.5,
            "pattern_match": "none"
        }


def _calculate_completeness(context_data: Dict[str, Any]) -> str:
    """è®¡ç®—å·¥ä½œæµå®Œæ•´æ€§"""
    node_count = context_data.get("nodeCount", 0)
    has_start = context_data.get("hasStart", False)
    has_end = context_data.get("hasEnd", False)

    if node_count == 0:
        return "empty"
    elif not has_start:
        return "missing_start"
    elif node_count == 1 and has_start:
        return "needs_processing"
    elif not has_end:
        return "missing_end"
    else:
        return "complete"


def _determine_priority(context_data: Dict[str, Any]) -> str:
    """ç¡®å®šå»ºè®®ä¼˜å…ˆçº§"""
    completeness = _calculate_completeness(context_data)

    if completeness in ["empty", "missing_start"]:
        return "high"
    elif completeness in ["needs_processing", "missing_end"]:
        return "medium"
    else:
        return "low"


def _calculate_complexity(context_data: Dict[str, Any]) -> float:
    """è®¡ç®—å·¥ä½œæµå¤æ‚åº¦åˆ†æ•°"""
    node_count = context_data.get("nodeCount", 0)
    edge_count = context_data.get("edgeCount", 0)

    if node_count == 0:
        return 0.0

    # åŸºäºèŠ‚ç‚¹æ•°é‡å’Œè¿æ¥å¯†åº¦è®¡ç®—å¤æ‚åº¦
    connection_density = edge_count / node_count if node_count > 0 else 0
    complexity = min(1.0, (node_count * 0.1) + (connection_density * 0.3))

    return round(complexity, 2)


def _identify_patterns(context_data: Dict[str, Any]) -> str:
    """è¯†åˆ«å·¥ä½œæµæ¨¡å¼"""
    node_count = context_data.get("nodeCount", 0)
    processor_count = context_data.get("processorCount", 0)

    if node_count <= 2:
        return "simple_linear"
    elif processor_count == 1:
        return "single_step"
    elif processor_count > 3:
        return "multi_step"
    else:
        return "standard"


# ========== æ–°å¢ï¼šç»Ÿä¸€çš„å›¾æ“ä½œå»ºè®®ç³»ç»Ÿ ==========

# å›¾æ“ä½œç±»å‹
class GraphOperationType:
    ADD_NODE = "add_node"
    REMOVE_NODE = "remove_node"
    UPDATE_NODE = "update_node"
    ADD_EDGE = "add_edge"
    REMOVE_EDGE = "remove_edge"
    UPDATE_EDGE = "update_edge"

# å›¾æ“ä½œå®šä¹‰
class GraphOperation(BaseModel):
    id: str
    type: str  # GraphOperationType
    data: Dict[str, Any]
    reasoning: str

# å›¾å»ºè®®
class GraphSuggestion(BaseModel):
    id: str
    name: str
    description: str
    operations: List[GraphOperation]
    confidence: float
    reasoning: str
    preview: Optional[Dict[str, Any]] = None

# å·¥ä½œæµä¸Šä¸‹æ–‡
class WorkflowContext(BaseModel):
    workflow_id: Optional[str] = None
    workflow_name: Optional[str] = None
    workflow_description: Optional[str] = None

    current_nodes: List[Dict[str, Any]] = []
    current_edges: List[Dict[str, Any]] = []

    cursor_position: Optional[Dict[str, float]] = None
    selected_node_id: Optional[str] = None
    recent_actions: Optional[List[Dict[str, Any]]] = []

    completion_status: Dict[str, Any] = {}

# è¯·æ±‚æ¨¡å‹
class GraphSuggestionRequest(BaseModel):
    workflow_context: WorkflowContext
    trigger_type: str  # 'canvas_click', 'node_select', 'manual_request'
    max_suggestions: int = 3

# å“åº”æ¨¡å‹
class GraphSuggestionResponse(BaseModel):
    success: bool
    suggestions: List[GraphSuggestion] = []
    context_analysis: Optional[Dict[str, Any]] = None
    message: Optional[str] = None

# æ“ä½œæ‰§è¡Œè·Ÿè¸ª
class OperationExecutionTrack(BaseModel):
    suggestion_id: str
    operations: List[GraphOperation]
    success: bool
    executed_at: str

@router.post("/predict-graph-operations", response_model=GraphSuggestionResponse)
async def predict_graph_operations(
    request: GraphSuggestionRequest,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·å–å›¾æ“ä½œå»ºè®®ï¼ˆå¹½çµç¼–è¾‘æ¨¡å¼ï¼‰"""
    try:
        logger.info(f"ğŸ”® [GRAPH-API] æ”¶åˆ°å›¾æ“ä½œå»ºè®®è¯·æ±‚")
        logger.info(f"ğŸ”® [GRAPH-API] ç”¨æˆ·: {current_user.user_id}")
        logger.info(f"ğŸ”® [GRAPH-API] è§¦å‘ç±»å‹: {request.trigger_type}")
        logger.info(f"ğŸ”® [GRAPH-API] å·¥ä½œæµ: {request.workflow_context.workflow_id}")

        # åˆ†æå½“å‰å·¥ä½œæµçŠ¶æ€
        context = request.workflow_context
        analysis = analyze_workflow_context(context)

        # æ„å»ºç»™LLMçš„prompt
        prompt = build_graph_operations_prompt(context, analysis, request.trigger_type)

        # è·å–Function Calling schema
        functions = [get_graph_operations_function_schema()]

        # ä½¿ç”¨Function Callingè°ƒç”¨AIæœåŠ¡
        ai_result = await tab_prediction_service.ai_generator._call_real_api_with_functions(
            prompt,
            functions,
            function_call="generate_graph_operations"
        )

        # å¤„ç†å“åº”
        if ai_result['type'] == 'function_call':
            # è§£æFunction Callç»“æœ
            suggestions = parse_function_call_response(ai_result['function_call'], context)
        else:
            # DeepSeekä¸æ”¯æŒFunction Callingï¼Œä½¿ç”¨æ”¹è¿›çš„æ–‡æœ¬è§£æ
            logger.info("ğŸ”® [GRAPH-API] ä½¿ç”¨æ–‡æœ¬è§£ææ¨¡å¼")
            logger.debug(f"ğŸ”® [GRAPH-API] AIåŸå§‹å“åº”: {ai_result['content'][:1000]}...")
            suggestions = parse_ai_graph_suggestions_improved(ai_result['content'], context)

        logger.info(f"ğŸ”® [GRAPH-API] âœ… ç”Ÿæˆäº† {len(suggestions)} ä¸ªå›¾æ“ä½œå»ºè®®")

        return GraphSuggestionResponse(
            success=True,
            suggestions=suggestions,
            context_analysis=analysis,
            message="å›¾æ“ä½œå»ºè®®ç”ŸæˆæˆåŠŸ"
        )

    except Exception as e:
        logger.error(f"ğŸ”® [GRAPH-API] âŒ å›¾æ“ä½œå»ºè®®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å›¾æ“ä½œå»ºè®®å¤±è´¥: {str(e)}")

@router.post("/track-operation-execution")
async def track_operation_execution(
    request: OperationExecutionTrack,
    current_user: CurrentUser = Depends(get_current_user_context)
):
    """è·Ÿè¸ªå›¾æ“ä½œæ‰§è¡Œç»“æœ"""
    try:
        logger.info(f"ğŸ”® [TRACK] æ”¶åˆ°æ“ä½œæ‰§è¡Œè·Ÿè¸ª")
        logger.info(f"ğŸ”® [TRACK] å»ºè®®ID: {request.suggestion_id}")
        logger.info(f"ğŸ”® [TRACK] æ“ä½œæ•°é‡: {len(request.operations)}")
        logger.info(f"ğŸ”® [TRACK] æ‰§è¡Œç»“æœ: {request.success}")

        # è®°å½•åˆ°ç”¨æˆ·äº¤äº’è·Ÿè¸ªå™¨
        await interaction_tracker.track_interaction(
            user_id=current_user.user_id,
            workflow_id=request.suggestion_id,  # æš‚æ—¶ç”¨å»ºè®®IDä½œä¸ºå·¥ä½œæµID
            event_type=InteractionEventType.SUGGESTION_ACCEPTED if request.success else InteractionEventType.SUGGESTION_REJECTED,
            suggestion_type=SuggestionType.WORKFLOW_COMPLETION,
            suggestion_data={
                'suggestion_id': request.suggestion_id,
                'operations_count': len(request.operations),
                'success': request.success,
                'executed_at': request.executed_at
            }
        )

        return {
            "success": True,
            "message": "æ“ä½œæ‰§è¡Œè·Ÿè¸ªå®Œæˆ"
        }

    except Exception as e:
        logger.error(f"ğŸ”® [TRACK] âŒ æ“ä½œæ‰§è¡Œè·Ÿè¸ªå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "message": f"è·Ÿè¸ªå¤±è´¥: {str(e)}"
        }

def analyze_workflow_context(context: WorkflowContext) -> Dict[str, Any]:
    """åˆ†æå·¥ä½œæµä¸Šä¸‹æ–‡"""
    nodes = context.current_nodes
    edges = context.current_edges

    has_start = any(n.get('type') == 'start' for n in nodes)
    has_end = any(n.get('type') == 'end' for n in nodes)
    node_count = len(nodes)
    edge_count = len(edges)

    # è®¡ç®—å®Œæ•´åº¦
    completeness = 0
    if has_start:
        completeness += 0.3
    if has_end:
        completeness += 0.3
    if node_count > 2:
        completeness += 0.2
    if edge_count >= max(0, node_count - 1):
        completeness += 0.2

    completeness = min(completeness, 1.0)

    # è¯†åˆ«ç¼ºå¤±ç»„ä»¶
    missing_components = []
    if not has_start:
        missing_components.append("å¼€å§‹èŠ‚ç‚¹")
    if not has_end:
        missing_components.append("ç»“æŸèŠ‚ç‚¹")
    if node_count < 2:
        missing_components.append("å¤„ç†èŠ‚ç‚¹")
    if edge_count == 0 and node_count > 1:
        missing_components.append("èŠ‚ç‚¹è¿æ¥")

    # å»ºè®®ä¸‹ä¸€æ­¥
    suggested_steps = []
    if not has_start and node_count == 0:
        suggested_steps.append("åˆ›å»ºå¼€å§‹èŠ‚ç‚¹")
    elif has_start and not any(n.get('type') == 'processor' for n in nodes):
        suggested_steps.append("æ·»åŠ å¤„ç†èŠ‚ç‚¹")
    elif node_count > 1 and edge_count == 0:
        suggested_steps.append("è¿æ¥èŠ‚ç‚¹")
    elif has_start and node_count > 1 and not has_end:
        suggested_steps.append("æ·»åŠ ç»“æŸèŠ‚ç‚¹")
    else:
        suggested_steps.append("ä¼˜åŒ–å·¥ä½œæµç»“æ„")

    return {
        "workflow_completeness": completeness,
        "missing_components": missing_components,
        "suggested_next_steps": suggested_steps,
        "node_types_distribution": {
            "start": sum(1 for n in nodes if n.get('type') == 'start'),
            "processor": sum(1 for n in nodes if n.get('type') == 'processor'),
            "end": sum(1 for n in nodes if n.get('type') == 'end')
        },
        "connectivity_analysis": {
            "total_nodes": node_count,
            "total_edges": edge_count,
            "is_connected": edge_count >= node_count - 1 if node_count > 0 else True
        }
    }

def build_graph_operations_prompt(
    context: WorkflowContext,
    analysis: Dict[str, Any],
    trigger_type: str
) -> str:
    """æ„å»ºç»™LLMçš„å›¾æ“ä½œå»ºè®®prompt"""

    # åŸºç¡€ä¿¡æ¯
    workflow_info = ""
    if context.workflow_name:
        workflow_info += f"å·¥ä½œæµåç§°: {context.workflow_name}\n"
    if context.workflow_description:
        workflow_info += f"å·¥ä½œæµæè¿°: {context.workflow_description}\n"

    # å½“å‰çŠ¶æ€
    current_state = f"""å½“å‰å·¥ä½œæµçŠ¶æ€:
- èŠ‚ç‚¹æ•°é‡: {len(context.current_nodes)}
- è¿æ¥æ•°é‡: {len(context.current_edges)}
- å®Œæ•´åº¦: {analysis['workflow_completeness']:.1%}
- ç¼ºå¤±ç»„ä»¶: {', '.join(analysis['missing_components']) if analysis['missing_components'] else 'æ— '}

å½“å‰èŠ‚ç‚¹ä¿¡æ¯:
"""

    for i, node in enumerate(context.current_nodes):
        current_state += f"- èŠ‚ç‚¹{i+1}: {node.get('name', 'æœªå‘½å')} ({node.get('type', 'processor')})\n"

    # è§¦å‘ä¸Šä¸‹æ–‡
    trigger_context = f"è§¦å‘æ–¹å¼: {trigger_type}\n"
    if context.cursor_position:
        trigger_context += f"å…‰æ ‡ä½ç½®: ({context.cursor_position['x']:.0f}, {context.cursor_position['y']:.0f})\n"
    if context.selected_node_id:
        trigger_context += f"é€‰ä¸­èŠ‚ç‚¹: {context.selected_node_id}\n"

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµè®¾è®¡åŠ©æ‰‹ã€‚ç”¨æˆ·æ­£åœ¨è®¾è®¡å·¥ä½œæµï¼Œè¯·æ ¹æ®å½“å‰çŠ¶æ€ç”Ÿæˆæœ€åˆé€‚çš„å›¾æ“ä½œå»ºè®®ã€‚

{workflow_info}

{current_state}

{trigger_context}

è¯·ç”Ÿæˆä¸€ä¸ªå›¾æ“ä½œåºåˆ—å»ºè®®ï¼Œä»¥JSONæ ¼å¼è¿”å›:

{{
  "suggestions": [
    {{
      "id": "suggestion_1",
      "name": "å»ºè®®åç§°ï¼ˆå¦‚ï¼šæ·»åŠ æ•°æ®å¤„ç†æµç¨‹ï¼‰",
      "description": "è¯¦ç»†æè¿°è¿™ä¸ªå»ºè®®çš„ä½œç”¨å’Œä»·å€¼",
      "operations": [
        {{
          "id": "op_1",
          "type": "add_node",
          "data": {{
            "node": {{
              "id": "temp_node_1",
              "name": "èŠ‚ç‚¹åç§°",
              "type": "start|processor|end",
              "task_description": "èŠ‚ç‚¹åŠŸèƒ½æè¿°",
              "position": {{"x": 100, "y": 200}},
              "processor_id": null
            }}
          }},
          "reasoning": "æ·»åŠ æ­¤èŠ‚ç‚¹çš„ç†ç”±"
        }},
        {{
          "id": "op_2",
          "type": "add_edge",
          "data": {{
            "edge": {{
              "source_node_id": "temp_node_1",
              "target_node_id": "existing_node_id",
              "connection_type": "normal",
              "condition_config": null
            }}
          }},
          "reasoning": "æ·»åŠ æ­¤è¿æ¥çš„ç†ç”±"
        }}
      ],
      "confidence": 0.85,
      "reasoning": "æ•´ä½“å»ºè®®çš„æ¨ç†è¿‡ç¨‹",
      "preview": {{
        "nodes_to_add": 1,
        "edges_to_add": 1,
        "estimated_completion_improvement": 0.3
      }}
    }}
  ]
}}

è¦æ±‚:
1. æ ¹æ®å·¥ä½œæµå®Œæ•´åº¦å’Œç¼ºå¤±ç»„ä»¶ï¼Œä¼˜å…ˆå»ºè®®æœ€éœ€è¦çš„æ“ä½œ
2. æ“ä½œåºåˆ—è¦é€»è¾‘è¿è´¯ï¼Œå…ˆåˆ›å»ºèŠ‚ç‚¹å†åˆ›å»ºè¿æ¥
3. èŠ‚ç‚¹ä½ç½®è¦åˆç†ï¼Œé¿å…é‡å 
4. confidenceè¡¨ç¤ºæ•´ä½“å»ºè®®çš„ç½®ä¿¡åº¦(0-1)
5. æ¯ä¸ªæ“ä½œéƒ½è¦æœ‰æ¸…æ™°çš„reasoning
6. ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼
7. å»ºè®®è¦å®ç”¨ä¸”ç¬¦åˆå·¥ä½œæµè®¾è®¡æœ€ä½³å®è·µ

è¯·ç”Ÿæˆæœ€å¤š1ä¸ªæœ€ä½³å»ºè®®ï¼ˆå¹½çµç¼–è¾‘æ¨¡å¼ï¼‰ï¼š"""

    return prompt


def get_graph_operations_function_schema():
    """è·å–å›¾æ“ä½œçš„Function Calling schema"""
    return {
        "name": "generate_graph_operations",
        "description": "ç”Ÿæˆå·¥ä½œæµå›¾çš„æ“ä½œåºåˆ—ï¼ŒåŒ…æ‹¬æ·»åŠ èŠ‚ç‚¹ã€è¿æ¥èŠ‚ç‚¹ã€ä¿®æ”¹èŠ‚ç‚¹ç­‰æ“ä½œ",
        "parameters": {
            "type": "object",
            "properties": {
                "suggestions": {
                    "type": "array",
                    "description": "å›¾æ“ä½œå»ºè®®åˆ—è¡¨",
                    "items": {
                        "type": "object",
                        "properties": {
                            "id": {
                                "type": "string",
                                "description": "å»ºè®®çš„å”¯ä¸€ID"
                            },
                            "name": {
                                "type": "string",
                                "description": "å»ºè®®çš„åç§°"
                            },
                            "description": {
                                "type": "string",
                                "description": "å»ºè®®çš„è¯¦ç»†æè¿°"
                            },
                            "confidence": {
                                "type": "number",
                                "minimum": 0,
                                "maximum": 1,
                                "description": "å»ºè®®çš„ç½®ä¿¡åº¦(0-1)"
                            },
                            "reasoning": {
                                "type": "string",
                                "description": "å»ºè®®çš„ç†ç”±å’Œè§£é‡Š"
                            },
                            "operations": {
                                "type": "array",
                                "description": "å…·ä½“çš„å›¾æ“ä½œåˆ—è¡¨",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "id": {
                                            "type": "string",
                                            "description": "æ“ä½œçš„å”¯ä¸€ID"
                                        },
                                        "type": {
                                            "type": "string",
                                            "enum": ["add_node", "add_edge", "update_node", "delete_node", "delete_edge"],
                                            "description": "æ“ä½œç±»å‹"
                                        },
                                        "reasoning": {
                                            "type": "string",
                                            "description": "è¯¥æ“ä½œçš„ç†ç”±"
                                        },
                                        "data": {
                                            "type": "object",
                                            "description": "æ“ä½œçš„å…·ä½“æ•°æ®",
                                            "properties": {
                                                "node": {
                                                    "type": "object",
                                                    "description": "èŠ‚ç‚¹æ•°æ®",
                                                    "properties": {
                                                        "id": {"type": "string"},
                                                        "type": {"type": "string", "enum": ["start", "processor", "end"]},
                                                        "name": {"type": "string"},
                                                        "description": {"type": "string"},
                                                        "processor_type": {"type": "string", "enum": ["human", "agent"]},
                                                        "position": {
                                                            "type": "object",
                                                            "properties": {
                                                                "x": {"type": "number"},
                                                                "y": {"type": "number"}
                                                            }
                                                        }
                                                    }
                                                },
                                                "edge": {
                                                    "type": "object",
                                                    "description": "è¾¹æ•°æ®",
                                                    "properties": {
                                                        "id": {"type": "string"},
                                                        "source": {"type": "string"},
                                                        "target": {"type": "string"},
                                                        "type": {"type": "string", "enum": ["normal", "conditional"]},
                                                        "label": {"type": "string"}
                                                    }
                                                },
                                                "updates": {
                                                    "type": "object",
                                                    "description": "æ›´æ–°æ•°æ®"
                                                }
                                            }
                                        }
                                    },
                                    "required": ["id", "type", "data", "reasoning"]
                                }
                            }
                        },
                        "required": ["id", "name", "description", "operations", "confidence", "reasoning"]
                    }
                }
            },
            "required": ["suggestions"]
        }
    }


def parse_function_call_response(function_call: dict, context: WorkflowContext) -> List[GraphSuggestion]:
    """è§£æFunction Callingå“åº”ä¸ºå›¾å»ºè®®å¯¹è±¡"""
    try:
        import json
        arguments = json.loads(function_call['arguments'])
        suggestions = []

        for suggestion_data in arguments.get('suggestions', []):
            # è½¬æ¢æ“ä½œ
            operations = []
            for op_data in suggestion_data.get('operations', []):
                operation = GraphOperation(
                    id=op_data.get('id', str(uuid.uuid4())),
                    type=op_data.get('type', 'add_node'),
                    data=op_data.get('data', {}),
                    reasoning=op_data.get('reasoning', 'æ— è¯´æ˜')
                )
                operations.append(operation)

            # åˆ›å»ºå»ºè®®å¯¹è±¡
            suggestion = GraphSuggestion(
                id=suggestion_data.get('id', str(uuid.uuid4())),
                name=suggestion_data.get('name', 'æœªå‘½åå»ºè®®'),
                description=suggestion_data.get('description', ''),
                operations=operations,
                confidence=suggestion_data.get('confidence', 0.5),
                reasoning=suggestion_data.get('reasoning', ''),
                preview=None
            )
            suggestions.append(suggestion)

        logger.info(f"ğŸ¤– [FUNCTION-PARSE] âœ… è§£æäº† {len(suggestions)} ä¸ªå»ºè®®")
        return suggestions

    except Exception as e:
        logger.error(f"ğŸ¤– [FUNCTION-PARSE] âŒ Function Callå“åº”è§£æå¤±è´¥: {str(e)}")
        return []


def parse_ai_graph_suggestions_improved(ai_response: str, context: WorkflowContext) -> List[GraphSuggestion]:
    """æ”¹è¿›çš„AIå›¾å»ºè®®è§£æï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
    try:
        logger.info(f"ğŸ”® [PARSE-IMPROVED] å¼€å§‹è§£æAIå“åº”ï¼Œé•¿åº¦: {len(ai_response)}")

        # æ–¹æ³•1ï¼šå°è¯•æ ‡å‡†JSONè§£æ
        json_suggestions = _try_standard_json_parse(ai_response, context)
        if json_suggestions:
            logger.info(f"ğŸ”® [PARSE-IMPROVED] JSONè§£ææˆåŠŸï¼Œå»ºè®®æ•°: {len(json_suggestions)}")
            return json_suggestions

        # æ–¹æ³•2ï¼šå°è¯•æ™ºèƒ½æ¨¡å¼è§£æï¼ˆä»AIè‡ªç„¶è¯­è¨€ä¸­æå–ç»“æ„ï¼‰
        intelligent_suggestions = _try_intelligent_parse(ai_response, context)
        if intelligent_suggestions:
            logger.info(f"ğŸ”® [PARSE-IMPROVED] æ™ºèƒ½è§£ææˆåŠŸï¼Œå»ºè®®æ•°: {len(intelligent_suggestions)}")
            return intelligent_suggestions

        # æ–¹æ³•3ï¼šåŸºäºå…³é”®è¯çš„æœ€ç®€è§£æ
        keyword_suggestions = _try_keyword_parse(ai_response, context)
        if keyword_suggestions:
            logger.info(f"ğŸ”® [PARSE-IMPROVED] å…³é”®è¯è§£ææˆåŠŸï¼Œå»ºè®®æ•°: {len(keyword_suggestions)}")
            return keyword_suggestions

        logger.warning("ğŸ”® [PARSE-IMPROVED] æ‰€æœ‰è§£ææ–¹æ³•éƒ½å¤±è´¥äº†")
        return []

    except Exception as e:
        logger.error(f"ğŸ”® [PARSE-IMPROVED] âŒ æ”¹è¿›è§£æå¤±è´¥: {str(e)}")
        return []


def _try_standard_json_parse(ai_response: str, context: WorkflowContext) -> List[GraphSuggestion]:
    """å°è¯•æ ‡å‡†JSONè§£æ"""
    try:
        # ä½¿ç”¨åŸæœ‰çš„JSONæ¸…ç†é€»è¾‘
        json_content = _extract_and_clean_json(ai_response)
        if not json_content:
            return []

        parsed_data = json.loads(json_content)
        return _convert_parsed_data_to_suggestions(parsed_data, context)

    except Exception as e:
        logger.debug(f"ğŸ”® [JSON-PARSE] æ ‡å‡†JSONè§£æå¤±è´¥: {str(e)}")
        return []


def _try_intelligent_parse(ai_response: str, context: WorkflowContext) -> List[GraphSuggestion]:
    """æ™ºèƒ½è§£æï¼šä»AIçš„è‡ªç„¶è¯­è¨€ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯"""
    try:
        # åˆ†æAIå›å¤ä¸­çš„å…³é”®ä¿¡æ¯
        lines = ai_response.split('\n')
        suggestions = []
        current_suggestion = None
        current_operations = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # æ£€æµ‹å»ºè®®å¼€å§‹
            if 'å»ºè®®' in line or 'suggestion' in line.lower() or 'æ¨è' in line:
                if current_suggestion and current_operations:
                    # ä¿å­˜ä¸Šä¸€ä¸ªå»ºè®®
                    current_suggestion['operations'] = current_operations
                    suggestions.append(_create_suggestion_from_dict(current_suggestion, context))

                current_suggestion = {
                    'id': f'suggestion_{len(suggestions) + 1}',
                    'name': line,
                    'description': line,
                    'confidence': 0.8,
                    'reasoning': 'åŸºäºAIåˆ†æ'
                }
                current_operations = []

            # æ£€æµ‹æ“ä½œ
            elif 'æ·»åŠ ' in line or 'add' in line.lower() or 'åˆ›å»º' in line:
                operation = _parse_operation_from_text(line, 'add_node')
                if operation:
                    current_operations.append(operation)

            elif 'è¿æ¥' in line or 'connect' in line.lower() or 'é“¾æ¥' in line:
                operation = _parse_operation_from_text(line, 'add_edge')
                if operation:
                    current_operations.append(operation)

        # ä¿å­˜æœ€åä¸€ä¸ªå»ºè®®
        if current_suggestion and current_operations:
            current_suggestion['operations'] = current_operations
            suggestions.append(_create_suggestion_from_dict(current_suggestion, context))

        return suggestions

    except Exception as e:
        logger.debug(f"ğŸ”® [INTELLIGENT-PARSE] æ™ºèƒ½è§£æå¤±è´¥: {str(e)}")
        return []


def _try_keyword_parse(ai_response: str, context: WorkflowContext) -> List[GraphSuggestion]:
    """åŸºäºå…³é”®è¯çš„æœ€ç®€è§£æ"""
    try:
        # å¦‚æœå·¥ä½œæµä¸ºç©ºï¼Œç”Ÿæˆä¸€ä¸ªå¼€å§‹èŠ‚ç‚¹çš„å»ºè®®
        if not context.nodes:
            return [_create_default_start_suggestion()]

        # æ ¹æ®ç°æœ‰èŠ‚ç‚¹ç”Ÿæˆç®€å•çš„æ‰©å±•å»ºè®®
        if len(context.nodes) == 1:
            # åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹æ—¶ï¼Œå»ºè®®æ·»åŠ å¤„ç†èŠ‚ç‚¹å¹¶è¿æ¥
            existing_node = context.nodes[0]
            return [_create_processor_with_connection_suggestion(existing_node)]

        # å¦‚æœæœ‰å¤šä¸ªèŠ‚ç‚¹ä½†æ²¡æœ‰ç»“æŸèŠ‚ç‚¹ï¼Œå»ºè®®æ·»åŠ ç»“æŸèŠ‚ç‚¹
        has_end = any(node.get('type') == 'end' for node in context.nodes)
        if not has_end and len(context.nodes) >= 2:
            # æ‰¾åˆ°æœ€åä¸€ä¸ªå¤„ç†èŠ‚ç‚¹
            last_processor = None
            for node in reversed(context.nodes):
                if node.get('type') == 'processor':
                    last_processor = node
                    break

            if last_processor:
                return [_create_end_with_connection_suggestion(last_processor)]

        # é»˜è®¤ï¼šæ·»åŠ ä¸€ä¸ªæ–°çš„å¤„ç†èŠ‚ç‚¹
        return [_create_default_processor_suggestion()]

    except Exception as e:
        logger.debug(f"ğŸ”® [KEYWORD-PARSE] å…³é”®è¯è§£æå¤±è´¥: {str(e)}")
        return []


def _create_processor_with_connection_suggestion(existing_node: dict) -> GraphSuggestion:
    """åˆ›å»ºå¤„ç†èŠ‚ç‚¹å¹¶è¿æ¥åˆ°ç°æœ‰èŠ‚ç‚¹"""
    processor_id = f'processor_{uuid.uuid4().hex[:8]}'

    return GraphSuggestion(
        id='connect_processor',
        name='æ·»åŠ å¤„ç†èŠ‚ç‚¹å¹¶è¿æ¥',
        description=f'æ·»åŠ æ–°çš„å¤„ç†èŠ‚ç‚¹å¹¶è¿æ¥åˆ°"{existing_node.get("name", "ç°æœ‰èŠ‚ç‚¹")}"',
        operations=[
            # å…ˆæ·»åŠ èŠ‚ç‚¹
            GraphOperation(
                id='op_add_processor',
                type='add_node',
                data={
                    'node': {
                        'id': processor_id,
                        'type': 'processor',
                        'name': 'å¤„ç†ä»»åŠ¡',
                        'description': 'æ‰§è¡Œå…·ä½“çš„å¤„ç†ä»»åŠ¡',
                        'processor_type': 'human',
                        'position': {'x': 400, 'y': 200}
                    }
                },
                reasoning='æ·»åŠ æ–°çš„å¤„ç†èŠ‚ç‚¹'
            ),
            # å†æ·»åŠ è¿æ¥
            GraphOperation(
                id='op_add_connection',
                type='add_edge',
                data={
                    'edge': {
                        'id': f'edge_{uuid.uuid4().hex[:8]}',
                        'source_node_id': existing_node.get('node_base_id', existing_node.get('id')),
                        'target_node_id': processor_id,
                        'connection_type': 'normal',
                        'condition_config': None,
                        'label': 'è¿æ¥'
                    }
                },
                reasoning='è¿æ¥ç°æœ‰èŠ‚ç‚¹åˆ°æ–°èŠ‚ç‚¹'
            )
        ],
        confidence=0.8,
        reasoning='æ‰©å±•å·¥ä½œæµå¤„ç†èƒ½åŠ›',
        preview=None
    )


def _create_end_with_connection_suggestion(last_processor: dict) -> GraphSuggestion:
    """åˆ›å»ºç»“æŸèŠ‚ç‚¹å¹¶è¿æ¥åˆ°æœ€åçš„å¤„ç†èŠ‚ç‚¹"""
    end_id = f'end_{uuid.uuid4().hex[:8]}'

    return GraphSuggestion(
        id='connect_end',
        name='æ·»åŠ ç»“æŸèŠ‚ç‚¹',
        description=f'æ·»åŠ ç»“æŸèŠ‚ç‚¹å¹¶è¿æ¥åˆ°"{last_processor.get("name", "å¤„ç†èŠ‚ç‚¹")}"',
        operations=[
            # å…ˆæ·»åŠ ç»“æŸèŠ‚ç‚¹
            GraphOperation(
                id='op_add_end',
                type='add_node',
                data={
                    'node': {
                        'id': end_id,
                        'type': 'end',
                        'name': 'ç»“æŸ',
                        'description': 'å·¥ä½œæµç»“æŸèŠ‚ç‚¹',
                        'position': {'x': 600, 'y': 300}
                    }
                },
                reasoning='æ·»åŠ å·¥ä½œæµç»“æŸèŠ‚ç‚¹'
            ),
            # å†æ·»åŠ è¿æ¥
            GraphOperation(
                id='op_add_end_connection',
                type='add_edge',
                data={
                    'edge': {
                        'id': f'edge_{uuid.uuid4().hex[:8]}',
                        'source_node_id': last_processor.get('node_base_id', last_processor.get('id')),
                        'target_node_id': end_id,
                        'connection_type': 'normal',
                        'condition_config': None,
                        'label': 'å®Œæˆ'
                    }
                },
                reasoning='è¿æ¥å¤„ç†èŠ‚ç‚¹åˆ°ç»“æŸèŠ‚ç‚¹'
            )
        ],
        confidence=0.9,
        reasoning='å®Œå–„å·¥ä½œæµç»“æ„',
        preview=None
    )


def _parse_operation_from_text(text: str, operation_type: str) -> dict:
    """ä»æ–‡æœ¬ä¸­è§£ææ“ä½œ"""
    try:
        return {
            'id': f'op_{uuid.uuid4().hex[:8]}',
            'type': operation_type,
            'reasoning': text,
            'data': _extract_operation_data_from_text(text, operation_type)
        }
    except:
        return None


def _extract_operation_data_from_text(text: str, operation_type: str) -> dict:
    """ä»æ–‡æœ¬ä¸­æå–æ“ä½œæ•°æ®"""
    if operation_type == 'add_node':
        # ç®€å•çš„èŠ‚ç‚¹åˆ›å»º
        return {
            'node': {
                'id': f'node_{uuid.uuid4().hex[:8]}',
                'type': 'processor',
                'name': 'å¤„ç†èŠ‚ç‚¹',
                'description': text,
                'processor_type': 'human',
                'position': {'x': 200, 'y': 200}
            }
        }
    elif operation_type == 'add_edge':
        # ç®€å•çš„è¿æ¥åˆ›å»º - éœ€è¦å®é™…çš„èŠ‚ç‚¹ID
        return {
            'edge': {
                'id': f'edge_{uuid.uuid4().hex[:8]}',
                'source_node_id': 'requires_real_node_id',  # éœ€è¦åœ¨ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®èŠ‚ç‚¹ID
                'target_node_id': 'requires_real_node_id',  # éœ€è¦åœ¨ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®èŠ‚ç‚¹ID
                'connection_type': 'normal',
                'condition_config': None,
                'label': 'è¿æ¥'
            }
        }
    return {}


def _create_suggestion_from_dict(data: dict, context: WorkflowContext) -> GraphSuggestion:
    """ä»å­—å…¸åˆ›å»ºå»ºè®®å¯¹è±¡"""
    operations = []
    for op_data in data.get('operations', []):
        operations.append(GraphOperation(
            id=op_data.get('id', str(uuid.uuid4())),
            type=op_data.get('type', 'add_node'),
            data=op_data.get('data', {}),
            reasoning=op_data.get('reasoning', 'æ— è¯´æ˜')
        ))

    return GraphSuggestion(
        id=data.get('id', str(uuid.uuid4())),
        name=data.get('name', 'æœªå‘½åå»ºè®®'),
        description=data.get('description', ''),
        operations=operations,
        confidence=data.get('confidence', 0.5),
        reasoning=data.get('reasoning', ''),
        preview=None
    )


def _create_default_start_suggestion() -> GraphSuggestion:
    """åˆ›å»ºé»˜è®¤çš„å¼€å§‹èŠ‚ç‚¹å»ºè®®"""
    return GraphSuggestion(
        id='default_start',
        name='æ·»åŠ å¼€å§‹èŠ‚ç‚¹',
        description='ä¸ºç©ºç™½å·¥ä½œæµæ·»åŠ å¼€å§‹èŠ‚ç‚¹',
        operations=[
            GraphOperation(
                id='op_start',
                type='add_node',
                data={
                    'node': {
                        'id': f'start_{uuid.uuid4().hex[:8]}',
                        'type': 'start',
                        'name': 'å¼€å§‹',
                        'description': 'å·¥ä½œæµå¼€å§‹èŠ‚ç‚¹',
                        'position': {'x': 100, 'y': 100}
                    }
                },
                reasoning='ç©ºç™½å·¥ä½œæµéœ€è¦å¼€å§‹èŠ‚ç‚¹'
            )
        ],
        confidence=0.9,
        reasoning='ç©ºç™½å·¥ä½œæµçš„åŸºç¡€ç»“æ„éœ€æ±‚',
        preview=None
    )


def _create_default_processor_suggestion() -> GraphSuggestion:
    """åˆ›å»ºé»˜è®¤çš„å¤„ç†èŠ‚ç‚¹å»ºè®®"""
    return GraphSuggestion(
        id='default_processor',
        name='æ·»åŠ å¤„ç†èŠ‚ç‚¹',
        description='æ·»åŠ ä¸€ä¸ªå¤„ç†èŠ‚ç‚¹æ¥æ‰§è¡Œå…·ä½“ä»»åŠ¡',
        operations=[
            GraphOperation(
                id='op_processor',
                type='add_node',
                data={
                    'node': {
                        'id': f'processor_{uuid.uuid4().hex[:8]}',
                        'type': 'processor',
                        'name': 'å¤„ç†ä»»åŠ¡',
                        'description': 'æ‰§è¡Œå…·ä½“çš„å¤„ç†ä»»åŠ¡',
                        'processor_type': 'human',
                        'position': {'x': 300, 'y': 200}
                    }
                },
                reasoning='å·¥ä½œæµéœ€è¦å¤„ç†èŠ‚ç‚¹æ¥æ‰§è¡Œä»»åŠ¡'
            )
        ],
        confidence=0.8,
        reasoning='å·¥ä½œæµé€šå¸¸éœ€è¦å¤„ç†èŠ‚ç‚¹',
        preview=None
    )


def _create_default_end_suggestion() -> GraphSuggestion:
    """åˆ›å»ºé»˜è®¤çš„ç»“æŸèŠ‚ç‚¹å»ºè®®"""
    return GraphSuggestion(
        id='default_end',
        name='æ·»åŠ ç»“æŸèŠ‚ç‚¹',
        description='æ·»åŠ ç»“æŸèŠ‚ç‚¹å®Œæˆå·¥ä½œæµ',
        operations=[
            GraphOperation(
                id='op_end',
                type='add_node',
                data={
                    'node': {
                        'id': f'end_{uuid.uuid4().hex[:8]}',
                        'type': 'end',
                        'name': 'ç»“æŸ',
                        'description': 'å·¥ä½œæµç»“æŸèŠ‚ç‚¹',
                        'position': {'x': 500, 'y': 300}
                    }
                },
                reasoning='å·¥ä½œæµéœ€è¦æ˜ç¡®çš„ç»“æŸèŠ‚ç‚¹'
            )
        ],
        confidence=0.7,
        reasoning='å®Œå–„å·¥ä½œæµç»“æ„',
        preview=None
    )


def _convert_parsed_data_to_suggestions(parsed_data: dict, context: WorkflowContext) -> List[GraphSuggestion]:
    """è½¬æ¢è§£æçš„æ•°æ®ä¸ºå»ºè®®å¯¹è±¡"""
    suggestions = []
    for suggestion_data in parsed_data.get('suggestions', []):
        operations = []
        for op_data in suggestion_data.get('operations', []):
            operation = GraphOperation(
                id=op_data.get('id', str(uuid.uuid4())),
                type=op_data.get('type', 'add_node'),
                data=op_data.get('data', {}),
                reasoning=op_data.get('reasoning', 'æ— è¯´æ˜')
            )
            operations.append(operation)

        suggestion = GraphSuggestion(
            id=suggestion_data.get('id', str(uuid.uuid4())),
            name=suggestion_data.get('name', 'æœªå‘½åå»ºè®®'),
            description=suggestion_data.get('description', ''),
            operations=operations,
            confidence=suggestion_data.get('confidence', 0.5),
            reasoning=suggestion_data.get('reasoning', ''),
            preview=suggestion_data.get('preview')
        )
        suggestions.append(suggestion)
    return suggestions


def _extract_and_clean_json(text: str) -> str:
    """ä»AIå“åº”ä¸­æå–å¹¶æ¸…ç†JSONå†…å®¹"""
    try:
        # å°è¯•æ‰¾åˆ°JSONå—çš„å¼€å§‹å’Œç»“æŸ
        json_start = text.find('{')
        json_end = text.rfind('}') + 1

        if json_start == -1 or json_end == 0:
            return ""

        json_content = text[json_start:json_end]

        # æ¸…ç†å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
        # 1. ç§»é™¤æ³¨é‡Šè¡Œ
        lines = json_content.split('\n')
        cleaned_lines = []
        for line in lines:
            # è·³è¿‡æ³¨é‡Šè¡Œ
            stripped_line = line.strip()
            if not stripped_line.startswith('//') and not stripped_line.startswith('#'):
                cleaned_lines.append(line)

        json_content = '\n'.join(cleaned_lines)

        # 2. ä¿®å¤å¸¸è§çš„JSONè¯­æ³•é—®é¢˜
        # ç§»é™¤å°¾éšé€—å·
        json_content = re.sub(r',(\s*[}\]])', r'\1', json_content)

        # 3. å°è¯•è§£æä»¥éªŒè¯JSONæœ‰æ•ˆæ€§
        json.loads(json_content)
        return json_content

    except json.JSONDecodeError as e:
        logger.warning(f"JSONæ¸…ç†åä»ç„¶æ— æ•ˆ: {e}")
        # å°è¯•æ›´æ¿€è¿›çš„æ¸…ç†
        try:
            # å¦‚æœæ ‡å‡†æ¸…ç†å¤±è´¥ï¼Œå°è¯•æå–æœ€å¤–å±‚çš„{}å†…å®¹
            brace_count = 0
            start_pos = -1
            end_pos = -1

            for i, char in enumerate(text):
                if char == '{':
                    if start_pos == -1:
                        start_pos = i
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0 and start_pos != -1:
                        end_pos = i + 1
                        break

            if start_pos != -1 and end_pos != -1:
                fallback_json = text[start_pos:end_pos]
                # å†æ¬¡æ¸…ç†
                fallback_json = re.sub(r',(\s*[}\]])', r'\1', fallback_json)
                json.loads(fallback_json)  # éªŒè¯
                return fallback_json

        except Exception:
            pass

        return ""
    except Exception as e:
        logger.warning(f"JSONæå–å¤±è´¥: {e}")
        return ""


def parse_ai_graph_suggestions(ai_response: str, context: WorkflowContext) -> List[GraphSuggestion]:
    """è§£æAIå“åº”ä¸ºå›¾å»ºè®®å¯¹è±¡"""
    try:
        # æ¸…ç†å’Œæå–JSONå†…å®¹
        json_content = _extract_and_clean_json(ai_response)

        if not json_content:
            logger.warning("AIå“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼")
            return []

        parsed_data = json.loads(json_content)

        suggestions = []
        for suggestion_data in parsed_data.get('suggestions', []):
            # è½¬æ¢æ“ä½œ
            operations = []
            for op_data in suggestion_data.get('operations', []):
                operation = GraphOperation(
                    id=op_data.get('id', str(uuid.uuid4())),
                    type=op_data.get('type', 'add_node'),
                    data=op_data.get('data', {}),
                    reasoning=op_data.get('reasoning', 'æ— è¯´æ˜')
                )
                operations.append(operation)

            # åˆ›å»ºå»ºè®®å¯¹è±¡
            suggestion = GraphSuggestion(
                id=suggestion_data.get('id', str(uuid.uuid4())),
                name=suggestion_data.get('name', 'æœªå‘½åå»ºè®®'),
                description=suggestion_data.get('description', ''),
                operations=operations,
                confidence=suggestion_data.get('confidence', 0.5),
                reasoning=suggestion_data.get('reasoning', ''),
                preview=suggestion_data.get('preview')
            )

            suggestions.append(suggestion)

        return suggestions

    except Exception as e:
        logger.error(f"è§£æAIå›¾å»ºè®®å“åº”å¤±è´¥: {str(e)}")
        logger.debug(f"AIå“åº”å†…å®¹: {ai_response}")
        return []