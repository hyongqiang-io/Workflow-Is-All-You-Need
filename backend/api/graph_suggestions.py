"""
ç»Ÿä¸€çš„å›¾æ“ä½œå»ºè®®APIç«¯ç‚¹
æ›¿æ¢åˆ†ç¦»çš„èŠ‚ç‚¹/è¾¹å»ºè®®ç³»ç»Ÿï¼Œä½¿ç”¨æ“ä½œåºåˆ—æ–¹å¼
"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
from datetime import datetime
import uuid
import json
from loguru import logger

from ..services.ai_workflow_generator import AIWorkflowGenerator
from ..models.user import User
from ..utils.auth import get_current_user

router = APIRouter(prefix="/tab-completion", tags=["å›¾æ“ä½œå»ºè®®"])

# å›¾æ“ä½œç±»å‹
class GraphOperationType(str):
    ADD_NODE = "add_node"
    REMOVE_NODE = "remove_node"
    UPDATE_NODE = "update_node"
    ADD_EDGE = "add_edge"
    REMOVE_EDGE = "remove_edge"
    UPDATE_EDGE = "update_edge"

# å›¾æ“ä½œå®šä¹‰
class GraphOperation(BaseModel):
    id: str
    type: str  # GraphOperationType
    data: Dict[str, Any]
    reasoning: str

# å›¾å»ºè®®
class GraphSuggestion(BaseModel):
    id: str
    name: str
    description: str
    operations: List[GraphOperation]
    confidence: float
    reasoning: str
    preview: Optional[Dict[str, Any]] = None

# å·¥ä½œæµä¸Šä¸‹æ–‡
class WorkflowContext(BaseModel):
    workflow_id: Optional[str] = None
    workflow_name: Optional[str] = None
    workflow_description: Optional[str] = None

    current_nodes: List[Dict[str, Any]] = []
    current_edges: List[Dict[str, Any]] = []

    cursor_position: Optional[Dict[str, float]] = None
    selected_node_id: Optional[str] = None
    recent_actions: Optional[List[Dict[str, Any]]] = []

    completion_status: Dict[str, Any] = {}

# è¯·æ±‚æ¨¡å‹
class GraphSuggestionRequest(BaseModel):
    workflow_context: WorkflowContext
    trigger_type: str  # 'canvas_click', 'node_select', 'manual_request'
    max_suggestions: int = 3

# å“åº”æ¨¡å‹
class GraphSuggestionResponse(BaseModel):
    success: bool
    suggestions: List[GraphSuggestion] = []
    context_analysis: Optional[Dict[str, Any]] = None
    message: Optional[str] = None

# æ“ä½œæ‰§è¡Œè·Ÿè¸ª
class OperationExecutionTrack(BaseModel):
    suggestion_id: str
    operations: List[GraphOperation]
    success: bool
    executed_at: str

@router.post("/predict-graph-operations", response_model=GraphSuggestionResponse)
async def predict_graph_operations(
    request: GraphSuggestionRequest,
    current_user: User = Depends(get_current_user)
):
    """è·å–å›¾æ“ä½œå»ºè®®ï¼ˆå¹½çµç¼–è¾‘æ¨¡å¼ï¼‰"""
    try:
        logger.info(f"ğŸ”® [GRAPH-API] æ”¶åˆ°å›¾æ“ä½œå»ºè®®è¯·æ±‚")
        logger.info(f"ğŸ”® [GRAPH-API] ç”¨æˆ·: {current_user.user_id}")
        logger.info(f"ğŸ”® [GRAPH-API] è§¦å‘ç±»å‹: {request.trigger_type}")
        logger.info(f"ğŸ”® [GRAPH-API] å·¥ä½œæµ: {request.workflow_context.workflow_id}")

        # åˆ†æå½“å‰å·¥ä½œæµçŠ¶æ€
        context = request.workflow_context
        analysis = analyze_workflow_context(context)

        # æ„å»ºç»™LLMçš„prompt
        prompt = build_graph_operations_prompt(context, analysis, request.trigger_type)

        # è°ƒç”¨AIæœåŠ¡ç”Ÿæˆå›¾æ“ä½œå»ºè®®
        ai_generator = AIWorkflowGenerator()
        ai_response = await ai_generator._call_real_api(
            prompt=prompt,
            temperature=0.7,
            max_tokens=4000
        )

        if not ai_response:
            return GraphSuggestionResponse(
                success=False,
                message="AIæœåŠ¡å“åº”ä¸ºç©º"
            )

        # è§£æAIå“åº”
        suggestions = parse_ai_graph_suggestions(ai_response, context)

        logger.info(f"ğŸ”® [GRAPH-API] âœ… ç”Ÿæˆäº† {len(suggestions)} ä¸ªå›¾æ“ä½œå»ºè®®")

        return GraphSuggestionResponse(
            success=True,
            suggestions=suggestions,
            context_analysis=analysis,
            message="å›¾æ“ä½œå»ºè®®ç”ŸæˆæˆåŠŸ"
        )

    except Exception as e:
        logger.error(f"ğŸ”® [GRAPH-API] âŒ å›¾æ“ä½œå»ºè®®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å›¾æ“ä½œå»ºè®®å¤±è´¥: {str(e)}")

@router.post("/track-operation-execution")
async def track_operation_execution(
    request: OperationExecutionTrack,
    current_user: User = Depends(get_current_user)
):
    """è·Ÿè¸ªå›¾æ“ä½œæ‰§è¡Œç»“æœ"""
    try:
        logger.info(f"ğŸ”® [TRACK] æ”¶åˆ°æ“ä½œæ‰§è¡Œè·Ÿè¸ª")
        logger.info(f"ğŸ”® [TRACK] å»ºè®®ID: {request.suggestion_id}")
        logger.info(f"ğŸ”® [TRACK] æ“ä½œæ•°é‡: {len(request.operations)}")
        logger.info(f"ğŸ”® [TRACK] æ‰§è¡Œç»“æœ: {request.success}")

        # TODO: è¿™é‡Œå¯ä»¥å°†æ‰§è¡Œç»“æœä¿å­˜åˆ°æ•°æ®åº“è¿›è¡Œåˆ†æ
        # ç”¨äºæ”¹è¿›AIå»ºè®®çš„è´¨é‡

        return {
            "success": True,
            "message": "æ“ä½œæ‰§è¡Œè·Ÿè¸ªå®Œæˆ"
        }

    except Exception as e:
        logger.error(f"ğŸ”® [TRACK] âŒ æ“ä½œæ‰§è¡Œè·Ÿè¸ªå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "message": f"è·Ÿè¸ªå¤±è´¥: {str(e)}"
        }

def analyze_workflow_context(context: WorkflowContext) -> Dict[str, Any]:
    """åˆ†æå·¥ä½œæµä¸Šä¸‹æ–‡"""
    nodes = context.current_nodes
    edges = context.current_edges

    has_start = any(n.get('type') == 'start' for n in nodes)
    has_end = any(n.get('type') == 'end' for n in nodes)
    node_count = len(nodes)
    edge_count = len(edges)

    # è®¡ç®—å®Œæ•´åº¦
    completeness = 0
    if has_start:
        completeness += 0.3
    if has_end:
        completeness += 0.3
    if node_count > 2:
        completeness += 0.2
    if edge_count >= max(0, node_count - 1):
        completeness += 0.2

    completeness = min(completeness, 1.0)

    # è¯†åˆ«ç¼ºå¤±ç»„ä»¶
    missing_components = []
    if not has_start:
        missing_components.append("å¼€å§‹èŠ‚ç‚¹")
    if not has_end:
        missing_components.append("ç»“æŸèŠ‚ç‚¹")
    if node_count < 2:
        missing_components.append("å¤„ç†èŠ‚ç‚¹")
    if edge_count == 0 and node_count > 1:
        missing_components.append("èŠ‚ç‚¹è¿æ¥")

    # å»ºè®®ä¸‹ä¸€æ­¥
    suggested_steps = []
    if not has_start and node_count == 0:
        suggested_steps.append("åˆ›å»ºå¼€å§‹èŠ‚ç‚¹")
    elif has_start and not any(n.get('type') == 'processor' for n in nodes):
        suggested_steps.append("æ·»åŠ å¤„ç†èŠ‚ç‚¹")
    elif node_count > 1 and edge_count == 0:
        suggested_steps.append("è¿æ¥èŠ‚ç‚¹")
    elif has_start and node_count > 1 and not has_end:
        suggested_steps.append("æ·»åŠ ç»“æŸèŠ‚ç‚¹")
    else:
        suggested_steps.append("ä¼˜åŒ–å·¥ä½œæµç»“æ„")

    return {
        "workflow_completeness": completeness,
        "missing_components": missing_components,
        "suggested_next_steps": suggested_steps,
        "node_types_distribution": {
            "start": sum(1 for n in nodes if n.get('type') == 'start'),
            "processor": sum(1 for n in nodes if n.get('type') == 'processor'),
            "end": sum(1 for n in nodes if n.get('type') == 'end')
        },
        "connectivity_analysis": {
            "total_nodes": node_count,
            "total_edges": edge_count,
            "is_connected": edge_count >= node_count - 1 if node_count > 0 else True
        }
    }

def build_graph_operations_prompt(
    context: WorkflowContext,
    analysis: Dict[str, Any],
    trigger_type: str
) -> str:
    """æ„å»ºç»™LLMçš„å›¾æ“ä½œå»ºè®®prompt"""

    # åŸºç¡€ä¿¡æ¯
    workflow_info = ""
    if context.workflow_name:
        workflow_info += f"å·¥ä½œæµåç§°: {context.workflow_name}\n"
    if context.workflow_description:
        workflow_info += f"å·¥ä½œæµæè¿°: {context.workflow_description}\n"

    # å½“å‰çŠ¶æ€
    current_state = f"""å½“å‰å·¥ä½œæµçŠ¶æ€:
- èŠ‚ç‚¹æ•°é‡: {len(context.current_nodes)}
- è¿æ¥æ•°é‡: {len(context.current_edges)}
- å®Œæ•´åº¦: {analysis['workflow_completeness']:.1%}
- ç¼ºå¤±ç»„ä»¶: {', '.join(analysis['missing_components']) if analysis['missing_components'] else 'æ— '}

å½“å‰èŠ‚ç‚¹ä¿¡æ¯:
"""

    for i, node in enumerate(context.current_nodes):
        node_id = node.get('id', 'unknown_id')
        node_name = node.get('name') or node.get('data', {}).get('label', 'æœªå‘½å')
        node_type = node.get('type') or node.get('data', {}).get('type', 'processor')
        current_state += f"- èŠ‚ç‚¹{i+1}: {node_name} ({node_type}) [ID: {node_id}]\n"

    # è§¦å‘ä¸Šä¸‹æ–‡
    trigger_context = f"è§¦å‘æ–¹å¼: {trigger_type}\n"
    if context.cursor_position:
        trigger_context += f"å…‰æ ‡ä½ç½®: ({context.cursor_position['x']:.0f}, {context.cursor_position['y']:.0f})\n"
    if context.selected_node_id:
        trigger_context += f"é€‰ä¸­èŠ‚ç‚¹: {context.selected_node_id}\n"

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµè®¾è®¡åŠ©æ‰‹ã€‚ç”¨æˆ·æ­£åœ¨è®¾è®¡å·¥ä½œæµï¼Œè¯·æ ¹æ®å½“å‰çŠ¶æ€ç”Ÿæˆæœ€åˆé€‚çš„å›¾æ“ä½œå»ºè®®ã€‚

{workflow_info}

{current_state}

{trigger_context}

è¯·ç”Ÿæˆä¸€ä¸ªå›¾æ“ä½œåºåˆ—å»ºè®®ï¼Œä»¥JSONæ ¼å¼è¿”å›:

{{
  "suggestions": [
    {{
      "id": "suggestion_1",
      "name": "å»ºè®®åç§°ï¼ˆå¦‚ï¼šæ·»åŠ æ•°æ®å¤„ç†æµç¨‹ï¼‰",
      "description": "è¯¦ç»†æè¿°è¿™ä¸ªå»ºè®®çš„ä½œç”¨å’Œä»·å€¼",
      "operations": [
        {{
          "id": "op_1",
          "type": "add_node",
          "data": {{
            "node": {{
              "id": "temp_node_1",
              "name": "èŠ‚ç‚¹åç§°",
              "type": "start|processor|end",
              "task_description": "èŠ‚ç‚¹åŠŸèƒ½æè¿°",
              "position": {{"x": 100, "y": 200}},
              "processor_id": "ç›¸å…³å¤„ç†å™¨IDï¼ˆå¯é€‰ï¼‰"
            }}
          }},
          "reasoning": "æ·»åŠ æ­¤èŠ‚ç‚¹çš„ç†ç”±"
        }},
        {{
          "id": "op_2",
          "type": "add_edge",
          "data": {{
            "edge": {{
              "source_node_id": "temp_node_1",
              "target_node_id": "å®é™…çš„èŠ‚ç‚¹UUIDï¼ˆä»ä¸Šé¢çš„èŠ‚ç‚¹åˆ—è¡¨ä¸­è·å–ï¼‰",
              "connection_type": "normal|conditional|parallel",
              "condition_config": null
            }}
          }},
          "reasoning": "æ·»åŠ æ­¤è¿æ¥çš„ç†ç”±"
        }}
      ],
      "confidence": 0.85,
      "reasoning": "æ•´ä½“å»ºè®®çš„æ¨ç†è¿‡ç¨‹",
      "preview": {{
        "nodes_to_add": 1,
        "edges_to_add": 1,
        "estimated_completion_improvement": 0.3
      }}
    }}
  ]
}}

è¦æ±‚:
1. æ ¹æ®å·¥ä½œæµå®Œæ•´åº¦å’Œç¼ºå¤±ç»„ä»¶ï¼Œä¼˜å…ˆå»ºè®®æœ€éœ€è¦çš„æ“ä½œ
2. æ“ä½œåºåˆ—è¦é€»è¾‘è¿è´¯ï¼Œå…ˆåˆ›å»ºèŠ‚ç‚¹å†åˆ›å»ºè¿æ¥
3. èŠ‚ç‚¹ä½ç½®è¦åˆç†ï¼Œé¿å…é‡å 
4. confidenceè¡¨ç¤ºæ•´ä½“å»ºè®®çš„ç½®ä¿¡åº¦(0-1)
5. æ¯ä¸ªæ“ä½œéƒ½è¦æœ‰æ¸…æ™°çš„reasoning
6. ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼
7. å»ºè®®è¦å®ç”¨ä¸”ç¬¦åˆå·¥ä½œæµè®¾è®¡æœ€ä½³å®è·µ
8. **é‡è¦**ï¼šåœ¨åˆ›å»ºè¿æ¥æ—¶ï¼Œå¿…é¡»ä½¿ç”¨ä¸Šé¢èŠ‚ç‚¹åˆ—è¡¨ä¸­çš„å®é™…UUIDï¼ˆ[ID: xxx]æ ¼å¼ä¸­çš„IDï¼‰ï¼Œä¸è¦ä½¿ç”¨æè¿°æ€§åç§°

è¯·ç”Ÿæˆæœ€å¤š1ä¸ªæœ€ä½³å»ºè®®ï¼ˆå¹½çµç¼–è¾‘æ¨¡å¼ï¼‰ï¼š"""

    return prompt

def parse_ai_graph_suggestions(ai_response: str, context: WorkflowContext) -> List[GraphSuggestion]:
    """è§£æAIå“åº”ä¸ºå›¾å»ºè®®å¯¹è±¡"""
    try:
        # æå–JSONå†…å®¹
        json_start = ai_response.find('{')
        json_end = ai_response.rfind('}') + 1

        if json_start == -1 or json_end == 0:
            logger.warning("ğŸ”® [PARSE] AIå“åº”ä¸­æœªæ‰¾åˆ°JSONæ ¼å¼ï¼Œè·³è¿‡å¤„ç†")
            logger.debug(f"AIå“åº”å†…å®¹: {ai_response[:200]}...")
            return []

        json_content = ai_response[json_start:json_end]
        parsed_data = json.loads(json_content)

        # éªŒè¯æ ¹çº§ç»“æ„
        if not isinstance(parsed_data, dict) or 'suggestions' not in parsed_data:
            logger.warning("ğŸ”® [PARSE] AIå“åº”ç¼ºå°‘'suggestions'å­—æ®µï¼Œè·³è¿‡å¤„ç†")
            logger.debug(f"è§£æçš„æ•°æ®ç»“æ„: {parsed_data}")
            return []

        suggestions_data = parsed_data.get('suggestions', [])
        if not isinstance(suggestions_data, list) or len(suggestions_data) == 0:
            logger.warning("ğŸ”® [PARSE] AIå“åº”çš„'suggestions'å­—æ®µä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡å¤„ç†")
            return []

        suggestions = []
        for i, suggestion_data in enumerate(suggestions_data):
            # ä¸¥æ ¼éªŒè¯æ¯ä¸ªå»ºè®®çš„å¿…éœ€å­—æ®µ
            if not isinstance(suggestion_data, dict):
                logger.warning(f"ğŸ”® [PARSE] å»ºè®®{i+1}ä¸æ˜¯æœ‰æ•ˆçš„å¯¹è±¡æ ¼å¼ï¼Œè·³è¿‡")
                continue

            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_fields = ['name', 'operations']
            missing_fields = [field for field in required_fields if not suggestion_data.get(field)]
            if missing_fields:
                logger.warning(f"ğŸ”® [PARSE] å»ºè®®{i+1}ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}ï¼Œè·³è¿‡")
                continue

            # éªŒè¯æ“ä½œåˆ—è¡¨
            operations_data = suggestion_data.get('operations', [])
            if not isinstance(operations_data, list) or len(operations_data) == 0:
                logger.warning(f"ğŸ”® [PARSE] å»ºè®®{i+1}çš„æ“ä½œåˆ—è¡¨ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡")
                continue

            # è§£æå’ŒéªŒè¯æ¯ä¸ªæ“ä½œ
            operations = []
            for j, op_data in enumerate(operations_data):
                if not isinstance(op_data, dict):
                    logger.warning(f"ğŸ”® [PARSE] å»ºè®®{i+1}çš„æ“ä½œ{j+1}ä¸æ˜¯æœ‰æ•ˆå¯¹è±¡ï¼Œè·³è¿‡")
                    continue

                # éªŒè¯æ“ä½œçš„å¿…éœ€å­—æ®µ
                op_required_fields = ['type', 'data']
                op_missing_fields = [field for field in op_required_fields if not op_data.get(field)]
                if op_missing_fields:
                    logger.warning(f"ğŸ”® [PARSE] å»ºè®®{i+1}çš„æ“ä½œ{j+1}ç¼ºå°‘å¿…éœ€å­—æ®µ: {op_missing_fields}ï¼Œè·³è¿‡")
                    continue

                # éªŒè¯æ“ä½œç±»å‹
                op_type = op_data.get('type')
                if op_type not in [GraphOperationType.ADD_NODE, GraphOperationType.ADD_EDGE,
                                 GraphOperationType.REMOVE_NODE, GraphOperationType.REMOVE_EDGE,
                                 GraphOperationType.UPDATE_NODE, GraphOperationType.UPDATE_EDGE]:
                    logger.warning(f"ğŸ”® [PARSE] å»ºè®®{i+1}çš„æ“ä½œ{j+1}ç±»å‹æ— æ•ˆ: {op_type}ï¼Œè·³è¿‡")
                    continue

                # éªŒè¯æ“ä½œæ•°æ®çš„å®Œæ•´æ€§
                op_data_content = op_data.get('data', {})
                if not isinstance(op_data_content, dict):
                    logger.warning(f"ğŸ”® [PARSE] å»ºè®®{i+1}çš„æ“ä½œ{j+1}æ•°æ®æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡")
                    continue

                # æ ¹æ®æ“ä½œç±»å‹éªŒè¯å…·ä½“æ•°æ®
                if op_type == GraphOperationType.ADD_NODE:
                    if 'node' not in op_data_content or not isinstance(op_data_content['node'], dict):
                        logger.warning(f"ğŸ”® [PARSE] å»ºè®®{i+1}çš„æ·»åŠ èŠ‚ç‚¹æ“ä½œ{j+1}ç¼ºå°‘nodeæ•°æ®ï¼Œè·³è¿‡")
                        continue
                    node_data = op_data_content['node']
                    if not node_data.get('name') or not node_data.get('type'):
                        logger.warning(f"ğŸ”® [PARSE] å»ºè®®{i+1}çš„æ·»åŠ èŠ‚ç‚¹æ“ä½œ{j+1}ç¼ºå°‘èŠ‚ç‚¹åç§°æˆ–ç±»å‹ï¼Œè·³è¿‡")
                        continue

                elif op_type == GraphOperationType.ADD_EDGE:
                    if 'edge' not in op_data_content or not isinstance(op_data_content['edge'], dict):
                        logger.warning(f"ğŸ”® [PARSE] å»ºè®®{i+1}çš„æ·»åŠ è¿æ¥æ“ä½œ{j+1}ç¼ºå°‘edgeæ•°æ®ï¼Œè·³è¿‡")
                        continue
                    edge_data = op_data_content['edge']
                    if not edge_data.get('source_node_id') or not edge_data.get('target_node_id'):
                        logger.warning(f"ğŸ”® [PARSE] å»ºè®®{i+1}çš„æ·»åŠ è¿æ¥æ“ä½œ{j+1}ç¼ºå°‘æºæˆ–ç›®æ ‡èŠ‚ç‚¹IDï¼Œè·³è¿‡")
                        continue

                # é€šè¿‡æ‰€æœ‰éªŒè¯ï¼Œåˆ›å»ºæ“ä½œå¯¹è±¡
                operation = GraphOperation(
                    id=op_data.get('id', str(uuid.uuid4())),
                    type=op_type,
                    data=op_data_content,
                    reasoning=op_data.get('reasoning', 'æ— è¯´æ˜')
                )
                operations.append(operation)
                logger.info(f"ğŸ”® [PARSE] âœ… éªŒè¯é€šè¿‡: å»ºè®®{i+1}çš„æ“ä½œ{j+1} - {op_type}")

            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„æ“ä½œï¼Œè·³è¿‡è¿™ä¸ªå»ºè®®
            if len(operations) == 0:
                logger.warning(f"ğŸ”® [PARSE] å»ºè®®{i+1}æ²¡æœ‰æœ‰æ•ˆæ“ä½œï¼Œè·³è¿‡æ•´ä¸ªå»ºè®®")
                continue

            # åˆ›å»ºå»ºè®®å¯¹è±¡
            suggestion = GraphSuggestion(
                id=suggestion_data.get('id', str(uuid.uuid4())),
                name=suggestion_data.get('name', 'æœªå‘½åå»ºè®®'),
                description=suggestion_data.get('description', ''),
                operations=operations,
                confidence=min(max(suggestion_data.get('confidence', 0.5), 0.0), 1.0),  # é™åˆ¶åœ¨0-1èŒƒå›´
                reasoning=suggestion_data.get('reasoning', ''),
                preview=suggestion_data.get('preview')
            )

            suggestions.append(suggestion)
            logger.info(f"ğŸ”® [PARSE] âœ… æˆåŠŸè§£æå»ºè®®: {suggestion.name} (åŒ…å«{len(operations)}ä¸ªæ“ä½œ)")

        if len(suggestions) == 0:
            logger.warning("ğŸ”® [PARSE] æ‰€æœ‰å»ºè®®éƒ½æœªé€šè¿‡éªŒè¯ï¼Œè¿”å›ç©ºåˆ—è¡¨")
        else:
            logger.info(f"ğŸ”® [PARSE] âœ… è§£æå®Œæˆï¼Œå…±{len(suggestions)}ä¸ªæœ‰æ•ˆå»ºè®®")

        return suggestions

    except json.JSONDecodeError as e:
        logger.error(f"ğŸ”® [PARSE] âŒ JSONè§£æå¤±è´¥: {str(e)}")
        logger.debug(f"AIå“åº”å†…å®¹: {ai_response}")
        return []
    except Exception as e:
        logger.error(f"ğŸ”® [PARSE] âŒ è§£æAIå›¾å»ºè®®å“åº”å¤±è´¥: {str(e)}")
        logger.debug(f"AIå“åº”å†…å®¹: {ai_response}")
        return []