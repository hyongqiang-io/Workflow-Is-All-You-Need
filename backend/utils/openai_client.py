"""
OpenAIå®¢æˆ·ç«¯é›†æˆ
OpenAI Client Integration
"""

import json
import asyncio
from typing import Dict, Any, Optional, List
from loguru import logger
from .helpers import safe_json_dumps

# å°è¯•å¯¼å…¥OpenAIï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ¨¡æ‹Ÿç‰ˆæœ¬

from openai import AsyncOpenAI
OPENAI_AVAILABLE = True
logger.info("OpenAIåº“å¯¼å…¥æˆåŠŸ")


class OpenAIClient:
    """OpenAIå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None,
                 model: Optional[str] = None, prompt: Optional[str] = None,
                 temperature: float = 0.7, top_p: float = 0.9):
        self.api_key = api_key or "sk-lkyoyvnbsssstobvfhezidgmiegpwzbykyfkxwebqcmgctyz"  # åº”è¯¥ä»ç¯å¢ƒå˜é‡è·å–
        self.base_url = base_url or "https://api.siliconflow.cn/v1"
        self.model = model or "Pro/deepseek-ai/DeepSeek-V3"
        self.prompt = prompt
        self.temperature = temperature
        self.top_p = top_p
        self.timeout = 30
        
        # åˆå§‹åŒ–AsyncOpenAIå®¢æˆ·ç«¯
        self.aclient = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)
    
    async def process_task(self, task_data: Dict[str, Any],
                          model: Optional[str] = None) -> Dict[str, Any]:
        """å¤„ç†ä»»åŠ¡è¯·æ±‚ï¼Œæ”¯æŒå¤šæ¨¡æ€å†…å®¹"""
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°
            model_name = model or task_data.get('model', self.model)

            logger.info(f"ğŸš€ [OPENAI-CLIENT] å¼€å§‹å¤„ç†OpenAIä»»åŠ¡")
            logger.info(f"   - ä½¿ç”¨æ¨¡å‹: {model_name}")
            logger.info(f"   - Base URL: {self.base_url}")
            logger.info(f"   - API Keyå­˜åœ¨: {'æ˜¯' if self.api_key else 'å¦'}")

            # æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ¨¡æ€å†…å®¹
            has_multimodal = task_data.get('has_multimodal_content', False)
            images = task_data.get('images', [])

            if has_multimodal and images:
                logger.info(f"ğŸ“· [OPENAI-CLIENT] æ£€æµ‹åˆ°å¤šæ¨¡æ€å†…å®¹ï¼Œå›¾ç‰‡æ•°é‡: {len(images)}")

            # ä»task_dataä¸­æå–messages
            messages = task_data.get('messages', [])
            if not messages:
                raise ValueError("task_dataä¸­ç¼ºå°‘messageså­—æ®µ")

            # å¦‚æœæœ‰å¤šæ¨¡æ€å†…å®¹ï¼Œè½¬æ¢æ¶ˆæ¯æ ¼å¼
            if has_multimodal and images:
                messages = self._convert_to_multimodal_messages(messages, images)
                logger.info(f"ğŸ“· [OPENAI-CLIENT] å·²è½¬æ¢ä¸ºå¤šæ¨¡æ€æ¶ˆæ¯æ ¼å¼")

            # è°ƒç”¨çœŸå®çš„OpenAI API
            result = await self._call_openai_api_with_messages(messages, model_name, task_data)

            return {
                'success': True,
                'model': model_name,
                'result': result,
                'usage': result.get('usage', {}),
                'has_multimodal_content': has_multimodal
            }

        except Exception as e:
            logger.error(f"OpenAIå¤„ç†ä»»åŠ¡å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'model': model or self.model
            }

    async def chat_completion_with_functions(
        self,
        messages: List[Dict[str, str]],
        functions: List[Dict[str, Any]],
        function_call: Optional[Dict[str, str]] = None,
        model: Optional[str] = None,
        temperature: Optional[float] = None
    ) -> Dict[str, Any]:
        """ä½¿ç”¨Function Callingè°ƒç”¨OpenAI API"""
        try:
            # è½¬æ¢functionsä¸ºtoolsæ ¼å¼
            tools = []
            for func in functions:
                tools.append({
                    "type": "function",
                    "function": func
                })

            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                "model": model or self.model,
                "messages": messages,
                "temperature": temperature or self.temperature,
                "tools": tools
            }

            # å¦‚æœæŒ‡å®šäº†function_callï¼Œè½¬æ¢ä¸ºtool_choice
            if function_call:
                if function_call.get("name"):
                    request_params["tool_choice"] = {
                        "type": "function",
                        "function": {"name": function_call["name"]}
                    }

            logger.info(f"ğŸ› ï¸ [FUNCTION-CALL] è°ƒç”¨æ¨¡å‹: {request_params['model']}")
            logger.info(f"ğŸ› ï¸ [FUNCTION-CALL] å‡½æ•°æ•°é‡: {len(functions)}")

            # è°ƒç”¨OpenAI API
            response = await self.aclient.chat.completions.create(**request_params)

            # å¤„ç†å“åº”
            message = response.choices[0].message

            if message.tool_calls:
                tool_call = message.tool_calls[0]
                return {
                    "function_call": {
                        "name": tool_call.function.name,
                        "arguments": tool_call.function.arguments
                    },
                    "content": message.content,
                    "usage": response.usage.model_dump() if response.usage else {}
                }
            else:
                return {
                    "content": message.content,
                    "usage": response.usage.model_dump() if response.usage else {}
                }

        except Exception as e:
            logger.error(f"ğŸ› ï¸ [FUNCTION-CALL] APIè°ƒç”¨å¤±è´¥: {e}")
            raise

    def _convert_to_multimodal_messages(self, messages: List[Dict], images: List[Dict]) -> List[Dict]:
        """
        å°†æ™®é€šæ¶ˆæ¯è½¬æ¢ä¸ºå¤šæ¨¡æ€æ¶ˆæ¯æ ¼å¼

        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨
            images: å›¾ç‰‡æ•°æ®åˆ—è¡¨

        Returns:
            æ”¯æŒå¤šæ¨¡æ€çš„æ¶ˆæ¯åˆ—è¡¨
        """
        try:
            logger.debug(f"ğŸ”„ [MULTIMODAL] å¼€å§‹è½¬æ¢æ¶ˆæ¯æ ¼å¼")

            multimodal_messages = []

            for message in messages:
                role = message.get('role', 'user')
                content = message.get('content', '')

                if role == 'user' and images:
                    # ä¸ºç”¨æˆ·æ¶ˆæ¯æ·»åŠ å›¾ç‰‡å†…å®¹
                    content_parts = []

                    # æ·»åŠ æ–‡æœ¬å†…å®¹
                    if content:
                        content_parts.append({
                            "type": "text",
                            "text": content
                        })

                    # æ·»åŠ å›¾ç‰‡å†…å®¹
                    for image in images:
                        image_content = {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{image['content_type']};base64,{image['base64_data']}",
                                "detail": "high"  # é«˜åˆ†è¾¨ç‡åˆ†æ
                            }
                        }
                        content_parts.append(image_content)
                        logger.debug(f"ğŸ“· [MULTIMODAL] æ·»åŠ å›¾ç‰‡: {image['name']}")

                    multimodal_messages.append({
                        "role": role,
                        "content": content_parts
                    })

                    # å›¾ç‰‡åªåœ¨ç¬¬ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯ä¸­æ·»åŠ 
                    images = []  # æ¸…ç©ºï¼Œé¿å…é‡å¤æ·»åŠ 

                else:
                    # éç”¨æˆ·æ¶ˆæ¯æˆ–æ— å›¾ç‰‡ï¼Œä¿æŒåŸæ ¼å¼
                    multimodal_messages.append(message)

            logger.debug(f"âœ… [MULTIMODAL] æ¶ˆæ¯è½¬æ¢å®Œæˆï¼Œæ¶ˆæ¯æ•°é‡: {len(multimodal_messages)}")
            return multimodal_messages

        except Exception as e:
            logger.error(f"âŒ [MULTIMODAL] æ¶ˆæ¯è½¬æ¢å¤±è´¥: {e}")
            # è½¬æ¢å¤±è´¥æ—¶è¿”å›åŸå§‹æ¶ˆæ¯
            return messages
    
    async def _call_openai_api_with_messages(self, messages: List[Dict[str, str]], 
                                           model: str, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨messagesæ ¼å¼è°ƒç”¨OpenAI APIï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰"""
        try:
            logger.info(f"[OPENAI-API] å‡†å¤‡è°ƒç”¨API")
            logger.info(f"   - æ¨¡å‹: {model}")
            logger.info(f"   - æ¶ˆæ¯æ•°é‡: {len(messages)}")
            logger.info(f"   - æ¸©åº¦: {task_data.get('temperature', self.temperature)}")
            logger.info(f"   - æœ€å¤§tokens: {task_data.get('max_tokens', 2000)}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·
            tools = task_data.get('tools', [])
            tool_choice = task_data.get('tool_choice')
            
            logger.info(f"   - å·¥å…·æ•°é‡: {len(tools)}")
            logger.info(f"   - å·¥å…·é€‰æ‹©: {tool_choice}")
            
            if tools:
                logger.info(f"[TOOL-DEBUG] å·¥å…·åˆ—è¡¨:")
                for i, tool in enumerate(tools[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªå·¥å…·
                    logger.info(f"   å·¥å…· {i+1}: {tool.get('function', {}).get('name', 'unknown')}")
                    logger.info(f"     æè¿°: {tool.get('function', {}).get('description', 'no description')[:100]}...")
            
            # æ„å»ºAPIè¯·æ±‚å‚æ•°
            api_params = {
                'model': model,
                'messages': messages,
                'temperature': task_data.get('temperature', self.temperature),
                'max_tokens': task_data.get('max_tokens', 2000),
                'top_p': self.top_p,
            }
            
            # å¦‚æœæœ‰å·¥å…·ï¼Œæ·»åŠ å·¥å…·å‚æ•°
            if tools:
                api_params['tools'] = tools
                if tool_choice:
                    api_params['tool_choice'] = tool_choice
                logger.info(f"[TOOL-DEBUG] å·²æ·»åŠ å·¥å…·å‚æ•°åˆ°APIè¯·æ±‚")
            
            # è°ƒç”¨OpenAI API
            logger.info(f"[OPENAI-API] å¼€å§‹è°ƒç”¨ {model}")
            response = await asyncio.wait_for(
                self.aclient.chat.completions.create(**api_params),
                timeout=120.0  # å¢åŠ åˆ°120ç§’è¶…æ—¶
            )
            
            logger.info(f"[OPENAI-API] APIè°ƒç”¨æˆåŠŸ")
            
            # æå–å“åº”å†…å®¹
            message = response.choices[0].message
            content = message.content
            tool_calls = getattr(message, 'tool_calls', []) or []  # ç¡®ä¿ä¸æ˜¯None
            
            usage = {
                'prompt_tokens': response.usage.prompt_tokens,
                'completion_tokens': response.usage.completion_tokens,
                'total_tokens': response.usage.total_tokens
            }
            
            logger.info(f"[OPENAI-API] å“åº”è§£æå®Œæˆ")
            logger.info(f"   - å†…å®¹é•¿åº¦: {len(content) if content else 0}")
            logger.info(f"   - å·¥å…·è°ƒç”¨æ•°é‡: {len(tool_calls) if tool_calls else 0}")
            logger.info(f"   - Tokenä½¿ç”¨: {usage}")
            
            if tool_calls:
                logger.info(f"[TOOL-DEBUG] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨:")
                for i, tool_call in enumerate(tool_calls):
                    func_name = tool_call.function.name if hasattr(tool_call, 'function') else 'unknown'
                    logger.info(f"   å·¥å…·è°ƒç”¨ {i+1}: {func_name}")
                    logger.info(f"     ID: {tool_call.id}")
                    if hasattr(tool_call, 'function'):
                        logger.info(f"     å‚æ•°: {tool_call.function.arguments[:200]}...")
                
                # å°†å·¥å…·è°ƒç”¨è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
                serializable_tool_calls = []
                for tool_call in tool_calls:
                    serializable_tool_calls.append({
                        'id': tool_call.id,
                        'type': getattr(tool_call, 'type', 'function'),
                        'function': {
                            'name': tool_call.function.name,
                            'arguments': tool_call.function.arguments
                        }
                    })
            
            # è¿”å›ç¬¦åˆOpenAIå“åº”æ ¼å¼çš„ç»“æœ
            result = {
                'content': content,
                'usage': usage,
                'message': {
                    'content': content,
                    'role': 'assistant'
                }
            }
            
            # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ·»åŠ åˆ°å“åº”ä¸­
            if tool_calls:
                result['message']['tool_calls'] = serializable_tool_calls
                logger.info(f"[TOOL-DEBUG] å·¥å…·è°ƒç”¨å·²æ·»åŠ åˆ°å“åº”ä¸­")
            
            return result
                
        except Exception as e:
            logger.error(f"è°ƒç”¨OpenAI APIå¤±è´¥: {e}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            # é™çº§åˆ°æ¨¡æ‹Ÿå¤„ç†
            return await self._simulate_openai_request(messages, model)
    
    async def _call_openai_api(self, prompt: str, model: str) -> Dict[str, Any]:
        """è°ƒç”¨çœŸå®çš„OpenAI API"""
        try:
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = []
            if self.prompt is not None:
                messages.append({
                    "content": self.prompt,
                    "role": "system"
                })

            messages.append({"role": "user", "content": prompt})

            # è°ƒç”¨OpenAI API
            response = await asyncio.wait_for(
                self.aclient.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=self.temperature,
                    top_p=self.top_p,
                ),
                timeout=10.0  # 10ç§’è¶…æ—¶
            )

            # æå–å“åº”å†…å®¹
            content = response.choices[0].message.content
            usage = {
                'prompt_tokens': response.usage.prompt_tokens,
                'completion_tokens': response.usage.completion_tokens,
                'total_tokens': response.usage.total_tokens
            }
            
            # å°è¯•è§£æJSONå“åº”
            try:
                parsed_result = json.loads(content)
                parsed_result['usage'] = usage
                return parsed_result
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œè¿”å›çº¯æ–‡æœ¬ç»“æœ
                return {
                    'analysis': content,
                    'result': {'content': content},
                    'recommendations': [],
                    'confidence': 0.8,
                    'usage': usage
                }
                
        except Exception as e:
            logger.error(f"è°ƒç”¨OpenAI APIå¤±è´¥: {e}")
            # é™çº§åˆ°æ¨¡æ‹Ÿå¤„ç†
            return await self._simulate_openai_request(prompt, model)
    
    async def _simulate_openai_request(self, messages_or_prompt, model: str) -> Dict[str, Any]:
        """æ¨¡æ‹ŸOpenAI APIå“åº”ï¼ˆç”¨äºæµ‹è¯•å’Œé™çº§ï¼‰"""
        try:
            # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
            await asyncio.sleep(0.5)
            
            # æå–ç”¨æˆ·æ¶ˆæ¯å†…å®¹
            if isinstance(messages_or_prompt, list):
                user_content = ""
                for msg in messages_or_prompt:
                    if msg.get('role') == 'user':
                        user_content = msg.get('content', '')
                        break
            else:
                user_content = str(messages_or_prompt)
            
            # ç”Ÿæˆæ¨¡æ‹Ÿçš„JSONå“åº”
            mock_response = {
                "analysis_result": f"åŸºäºæä¾›çš„æ•°æ®å®Œæˆäº†æ·±åº¦åˆ†æã€‚ç”¨æˆ·å†…å®¹é•¿åº¦: {len(user_content)} å­—ç¬¦",
                "key_findings": [
                    "æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥è¿›è¡Œæœ‰æ•ˆåˆ†æ",
                    "ä¸Šæ¸¸èŠ‚ç‚¹æä¾›äº†å……åˆ†çš„ä¸Šä¸‹æ–‡ä¿¡æ¯",
                    "åˆ†æç»“æœå…·æœ‰è¾ƒé«˜çš„å¯ä¿¡åº¦"
                ],
                "recommendations": [
                    "å»ºè®®è¿›ä¸€æ­¥åˆ†ææ•°æ®è¶‹åŠ¿",
                    "å»ºè®®å…³æ³¨å…³é”®æŒ‡æ ‡å˜åŒ–",
                    "å»ºè®®å®šæœŸæ›´æ–°åˆ†ææ¨¡å‹"
                ],
                "confidence_score": 0.87,
                "summary": f"ä½¿ç”¨{model}æ¨¡å‹æˆåŠŸå®Œæˆä»»åŠ¡åˆ†æ"
            }
            
            # è¿”å›ç¬¦åˆOpenAIæ ¼å¼çš„å“åº”
            return {
                "content": safe_json_dumps(mock_response),
                "usage": {
                    "prompt_tokens": 150,
                    "completion_tokens": 200,
                    "total_tokens": 350
                }
            }
            
        except Exception as e:
            logger.error(f"æ¨¡æ‹ŸOpenAIè¯·æ±‚å¤±è´¥: {e}")
            # è¿”å›æœ€åŸºæœ¬çš„å“åº”
            return {
                "content": safe_json_dumps({
                    "analysis_result": "æ¨¡æ‹Ÿåˆ†æå®Œæˆ",
                    "key_findings": ["åŸºç¡€åˆ†æç»“æœ"],
                    "recommendations": ["å»ºè®®ä½¿ç”¨çœŸå®API"],
                    "confidence_score": 0.75,
                    "summary": "æ¨¡æ‹Ÿå¤„ç†å®Œæˆ"
                }, ensure_ascii=False),
                "usage": {"prompt_tokens": 100, "completion_tokens": 100, "total_tokens": 200}
            }

    async def generate_image(self, prompt: str, model: str = "black-forest-labs/FLUX.1-schnell",
                           size: str = "1024x1024", quality: str = "standard",
                           n: int = 1) -> Dict[str, Any]:
        """
        ç”Ÿæˆå›¾åƒ

        Args:
            prompt: å›¾åƒæè¿°æç¤º
            model: å›¾åƒç”Ÿæˆæ¨¡å‹ (SiliconFlowæ”¯æŒçš„æ¨¡å‹)
            size: å›¾åƒå°ºå¯¸
            quality: å›¾åƒè´¨é‡
            n: ç”Ÿæˆå›¾åƒæ•°é‡

        Returns:
            å›¾åƒç”Ÿæˆç»“æœ
        """
        try:
            logger.info(f"ğŸ¨ [IMAGE-GEN-API] === å›¾åƒç”ŸæˆAPIè°ƒç”¨å¼€å§‹ ===")
            logger.info(f"ğŸ¨ [IMAGE-GEN-API] æ¥æ”¶åˆ°çš„å‚æ•°:")
            logger.info(f"   - prompt: {prompt}")
            logger.info(f"   - model: {model}")
            logger.info(f"   - size: {size}")
            logger.info(f"   - quality: {quality}")
            logger.info(f"   - n: {n}")
            logger.info(f"ğŸ¨ [IMAGE-GEN-API] APIé…ç½®:")
            logger.info(f"   - Base URL: {self.base_url}")
            logger.info(f"   - API Keyå­˜åœ¨: {'æ˜¯' if self.api_key else 'å¦'}")

            # è°ƒç”¨SiliconFlowçš„å›¾åƒç”ŸæˆAPI
            logger.info(f"ğŸ¨ [IMAGE-GEN-API] å¼€å§‹è°ƒç”¨SiliconFlow API...")
            response = await asyncio.wait_for(
                self.aclient.images.generate(
                    model=model,
                    prompt=prompt,
                    size=size,
                    quality=quality,
                    n=n
                ),
                timeout=60.0  # å›¾åƒç”Ÿæˆéœ€è¦æ›´é•¿æ—¶é—´
            )

            logger.info(f"ğŸ¨ [IMAGE-GEN-API] APIè°ƒç”¨æˆåŠŸï¼Œå¼€å§‹å¤„ç†å“åº”...")
            logger.info(f"ğŸ¨ [IMAGE-GEN-API] å“åº”æ•°æ®æ¡æ•°: {len(response.data)}")

            # å¤„ç†å“åº”
            images = []
            for i, image_data in enumerate(response.data):
                logger.info(f"ğŸ¨ [IMAGE-GEN-API] å¤„ç†ç¬¬ {i+1} å¼ å›¾ç‰‡...")
                if hasattr(image_data, 'url'):
                    # URL æ ¼å¼è¿”å›
                    images.append({
                        'url': image_data.url,
                        'revised_prompt': getattr(image_data, 'revised_prompt', prompt),
                        'index': i
                    })
                    logger.info(f"   - URLæ ¼å¼: {image_data.url[:100]}...")
                elif hasattr(image_data, 'b64_json'):
                    # Base64 æ ¼å¼è¿”å›
                    images.append({
                        'b64_json': image_data.b64_json,
                        'revised_prompt': getattr(image_data, 'revised_prompt', prompt),
                        'index': i
                    })
                    logger.info(f"   - Base64æ ¼å¼: {len(image_data.b64_json)} å­—ç¬¦")

            logger.info(f"âœ… [IMAGE-GEN-API] å›¾åƒç”ŸæˆæˆåŠŸï¼Œç”Ÿæˆäº† {len(images)} å¼ å›¾ç‰‡")
            logger.info(f"ğŸ¨ [IMAGE-GEN-API] æœ€ç»ˆä½¿ç”¨çš„prompt: {prompt}")

            return {
                'success': True,
                'images': images,
                'model': model,
                'prompt': prompt
            }

        except Exception as e:
            logger.error(f"âŒ [IMAGE-GEN] å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'model': model,
                'prompt': prompt
            }

    def supports_image_generation(self, agent_tags: List[str]) -> bool:
        """
        æ£€æŸ¥Agentæ˜¯å¦æ”¯æŒå›¾åƒç”Ÿæˆ

        Args:
            agent_tags: Agentçš„æ ‡ç­¾åˆ—è¡¨

        Returns:
            æ˜¯å¦æ”¯æŒå›¾åƒç”Ÿæˆ
        """
        return 'image-generation' in (agent_tags or [])
    

# å…¨å±€OpenAIå®¢æˆ·ç«¯å®ä¾‹
openai_client = OpenAIClient()