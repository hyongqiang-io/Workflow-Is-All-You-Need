"""
Workflow Template Tree - å·¥ä½œæµæ¨¡æ¿æ ‘

æ ¸å¿ƒè®¾è®¡ï¼š
1. æ¯ä¸ªèŠ‚ç‚¹éƒ½æ˜¯å·¥ä½œæµæ¨¡æ¿ï¼Œè€Œä¸æ˜¯subdivision
2. è¿æ¥ä¿¡æ¯æ˜¯çˆ¶èŠ‚ç‚¹ä¸å­å·¥ä½œæµçš„æ›¿æ¢ä¿¡æ¯
3. æ”¯æŒåŸºäºå·¥ä½œæµæ¨¡æ¿æ ‘çš„åˆå¹¶å’ŒUIæ˜¾ç¤º
4. ç›´æ¥åŸºäºsubdivisionæ•°æ®æ„å»ºï¼Œä½†ç»“æ„æ›´æ¸…æ™°
"""

import uuid
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from loguru import logger


@dataclass
class WorkflowTemplateNode:
    """å·¥ä½œæµæ¨¡æ¿èŠ‚ç‚¹ - ä»£è¡¨ä¸€ä¸ªå·¥ä½œæµæ¨¡æ¿"""
    workflow_base_id: str
    workflow_name: str
    workflow_instance_id: Optional[str] = None
    parent_node: Optional['WorkflowTemplateNode'] = None
    children: List['WorkflowTemplateNode'] = field(default_factory=list)
    node_replacements: Dict[str, Dict[str, Any]] = field(default_factory=dict)  # è®°å½•å†…éƒ¨èŠ‚ç‚¹çš„æ›¿æ¢å…³ç³»: node_id -> source_subdivision
    depth: int = 0
    status: str = "unknown"
    # æ·»åŠ å­—æ®µæ¥å­˜å‚¨æ¥æºsubdivisionä¿¡æ¯
    source_subdivision: Optional[Dict[str, Any]] = None
    
    # ğŸ”§ æ–°å¢ï¼šåˆå¹¶æ‰€éœ€çš„å®Œæ•´æ•°æ®ï¼Œé¿å…åç»­æŸ¥subdivisionè¡¨
    original_node_id: Optional[str] = None  # è¢«æ›¿æ¢çš„åŸå§‹èŠ‚ç‚¹ID
    original_task_id: Optional[str] = None  # è¢«æ›¿æ¢çš„åŸå§‹ä»»åŠ¡ID
    original_node_name: Optional[str] = None  # è¢«æ›¿æ¢çš„åŸå§‹èŠ‚ç‚¹åç§°
    original_node_position: Optional[Dict[str, int]] = None  # åŸå§‹èŠ‚ç‚¹ä½ç½® {x, y}
    merge_node_key: Optional[str] = None  # ç”¨äºåˆå¹¶æ“ä½œçš„å”¯ä¸€æ ‡è¯†
    
    def add_child_replacement(self, child_node: 'WorkflowTemplateNode', source_subdivision: Dict[str, Any]):
        """æ·»åŠ å­å·¥ä½œæµæ›¿æ¢å…³ç³» - è®°å½•å“ªä¸ªå†…éƒ¨èŠ‚ç‚¹è¢«å“ªä¸ªå­å·¥ä½œæµæ›¿æ¢"""
        child_node.parent_node = self
        child_node.depth = self.depth + 1
        
        # é¿å…é‡å¤æ·»åŠ åŒä¸€ä¸ªå­èŠ‚ç‚¹
        if child_node not in self.children:
            self.children.append(child_node)
        
        # è®°å½•æ›¿æ¢å…³ç³»ï¼šå†…éƒ¨èŠ‚ç‚¹ID -> æ›¿æ¢ä¿¡æ¯
        original_node_id = source_subdivision.get('original_task_id')  # ä¿®æ­£ï¼šä½¿ç”¨original_task_id
        original_node_name = source_subdivision.get('original_node_name', '')
        
        # å¦‚æœæ²¡æœ‰original_task_idï¼Œä½¿ç”¨original_node_nameä½œä¸ºkey
        replacement_key = str(original_node_id) if original_node_id else original_node_name
        
        if replacement_key:
            self.node_replacements[replacement_key] = {
                'child_workflow_base_id': child_node.workflow_base_id,
                'child_workflow_name': child_node.workflow_name,
                'child_workflow_instance_id': child_node.workflow_instance_id,
                'subdivision_id': source_subdivision.get('subdivision_id'),
                'original_node_name': original_node_name,
                'task_title': source_subdivision.get('task_title'),
                'created_at': source_subdivision.get('created_at')
            }
            
        logger.info(f"  ğŸ“ æ·»åŠ å­å·¥ä½œæµæ›¿æ¢: {self.workflow_name}[{original_node_name}] -> {child_node.workflow_name}")
    
    def get_replacement_for_node(self, node_id: str) -> Optional[Dict[str, Any]]:
        """è·å–æŒ‡å®šå†…éƒ¨èŠ‚ç‚¹çš„æ›¿æ¢ä¿¡æ¯"""
        return self.node_replacements.get(str(node_id))
    
    def get_all_replaced_nodes(self) -> List[str]:
        """è·å–æ‰€æœ‰è¢«æ›¿æ¢çš„å†…éƒ¨èŠ‚ç‚¹IDåˆ—è¡¨"""
        return list(self.node_replacements.keys())
    
    def get_replacement_summary(self) -> Dict[str, Any]:
        """è·å–æ›¿æ¢å…³ç³»æ‘˜è¦"""
        return {
            'total_replacements': len(self.node_replacements),
            'replaced_nodes': list(self.node_replacements.keys()),
            'child_workflows': list(set(r['child_workflow_base_id'] for r in self.node_replacements.values())),
            'replacements_by_node': self.node_replacements
        }
    
    def get_all_descendants(self) -> List['WorkflowTemplateNode']:
        """è·å–æ‰€æœ‰åä»£èŠ‚ç‚¹"""
        descendants = []
        for child in self.children:
            descendants.append(child)
            descendants.extend(child.get_all_descendants())
        return descendants
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "workflow_base_id": self.workflow_base_id,
            "workflow_name": self.workflow_name,
            "workflow_instance_id": self.workflow_instance_id,
            "depth": self.depth,
            "status": self.status,
            "children_count": len(self.children),
            "node_replacements": self.node_replacements,
            "replaced_nodes_count": len(self.node_replacements),
            "replacement_summary": self.get_replacement_summary(),
            "source_subdivision": self.source_subdivision
        }


class WorkflowTemplateTree:
    """
    å·¥ä½œæµæ¨¡æ¿æ ‘ - æ›¿ä»£SubdivisionTreeçš„æ–°ç»“æ„
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    1. ä»¥å·¥ä½œæµæ¨¡æ¿ä¸ºèŠ‚ç‚¹ï¼Œè€Œä¸æ˜¯subdivision
    2. æ ‘çš„è¾¹ä»£è¡¨å·¥ä½œæµæ›¿æ¢å…³ç³»
    3. æ”¯æŒåˆå¹¶æ“ä½œå’ŒUIæ˜¾ç¤º
    4. æ›´æ¸…æ™°çš„æ•°æ®ç»“æ„ï¼Œä¾¿äºç†è§£å’Œç»´æŠ¤
    """
    
    def __init__(self):
        self.nodes: Dict[str, WorkflowTemplateNode] = {}  # workflow_base_id -> node
        self.roots: List[WorkflowTemplateNode] = []
        self.instance_to_base: Dict[str, str] = {}  # workflow_instance_id -> workflow_base_id
    
    async def build_from_subdivisions(self, subdivisions: List[Dict[str, Any]], 
                               root_workflow_instance_id: str) -> 'WorkflowTemplateTree':
        """
        ä»subdivisionæ•°æ®æ„å»ºå·¥ä½œæµæ¨¡æ¿æ ‘
        
        Args:
            subdivisions: subdivisionæ•°æ®åˆ—è¡¨ï¼ˆè¿™äº›æ˜¯è¾¹çš„ä¿¡æ¯ï¼‰
            root_workflow_instance_id: æ ¹å·¥ä½œæµå®ä¾‹ID
            
        Returns:
            æ„å»ºå¥½çš„å·¥ä½œæµæ¨¡æ¿æ ‘
        """
        logger.info(f"ğŸŒ³ æ„å»ºå·¥ä½œæµæ¨¡æ¿æ ‘: {len(subdivisions)} ä¸ªsubdivisionè¾¹, æ ¹å®ä¾‹: {root_workflow_instance_id}")
        
        # ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºæ ¹èŠ‚ç‚¹ï¼ˆå½“å‰å·¥ä½œæµå®ä¾‹å¯¹åº”çš„å·¥ä½œæµæ¨¡æ¿ï¼‰
        root_node = await self._create_root_node(root_workflow_instance_id)
        if root_node:
            self.nodes[root_node.workflow_base_id] = root_node
            self.roots.append(root_node)
            # é‡è¦ï¼šå°†æ ¹èŠ‚ç‚¹ä¹ŸåŠ å…¥æ˜ å°„
            self.instance_to_base[root_workflow_instance_id] = root_node.workflow_base_id
            logger.info(f"  ğŸŒ³ åˆ›å»ºæ ¹èŠ‚ç‚¹: {root_node.workflow_name} ({str(root_node.workflow_base_id)[:8]})")
        
        # ç¬¬äºŒæ­¥ï¼šä¸ºæ¯ä¸ªsubdivisionè®°å½•åˆ›å»ºå·¥ä½œæµæ¨¡æ¿èŠ‚ç‚¹ï¼Œå¹¶é¢„æŸ¥è¯¢åŸå§‹èŠ‚ç‚¹ä¿¡æ¯
        template_instances = {}
        
        # ğŸ”§ æ‰¹é‡æŸ¥è¯¢åŸå§‹èŠ‚ç‚¹ä¿¡æ¯ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢
        original_nodes_info = await self._batch_get_original_nodes_info(subdivisions)
        
        for sub in subdivisions:
            subdivision_id = str(sub['subdivision_id'])
            child_workflow_base_id = str(sub['sub_workflow_base_id'])
            child_workflow_instance_id = str(sub['sub_workflow_instance_id'])
            
            # ä»é¢„æŸ¥è¯¢ç»“æœä¸­è·å–åŸå§‹èŠ‚ç‚¹ä¿¡æ¯
            original_node_info = original_nodes_info.get(subdivision_id)
            
            # ä¸ºæ¯ä¸ªsubdivisionåˆ›å»ºç‹¬ç«‹çš„å·¥ä½œæµæ¨¡æ¿èŠ‚ç‚¹
            template_instances[subdivision_id] = sub
            
            # å»ºç«‹å®ä¾‹åˆ°åŸºç¡€IDçš„æ˜ å°„
            self.instance_to_base[child_workflow_instance_id] = child_workflow_base_id
            
            # è¿˜è¦è®°å½•çˆ¶å·¥ä½œæµå®ä¾‹çš„æ˜ å°„
            parent_instance_id = str(sub.get('root_workflow_instance_id', ''))
            if parent_instance_id and parent_instance_id != root_workflow_instance_id:
                # æŸ¥æ‰¾çˆ¶å·¥ä½œæµå®ä¾‹å¯¹åº”çš„workflow_base_id
                for other_sub in subdivisions:
                    if str(other_sub.get('sub_workflow_instance_id', '')) == parent_instance_id:
                        parent_base_id = str(other_sub['sub_workflow_base_id'])
                        self.instance_to_base[parent_instance_id] = parent_base_id
                        break
        
        logger.info(f"ğŸ“Š å‘ç° {len(template_instances)} ä¸ªå·¥ä½œæµæ¨¡æ¿å®ä¾‹èŠ‚ç‚¹")
        logger.info(f"ğŸ”— å»ºç«‹ {len(self.instance_to_base)} ä¸ªå®ä¾‹->åŸºç¡€IDæ˜ å°„")
        
        # è°ƒè¯•ï¼šè¾“å‡ºæ‰€æœ‰æ˜ å°„å…³ç³»
        for instance_id, base_id in self.instance_to_base.items():
            instance_str = str(instance_id)[:8] if instance_id else "None"
            base_str = str(base_id)[:8] if base_id else "None"
            logger.info(f"    æ˜ å°„: {instance_str}... -> {base_str}...")
        
        # ç¬¬ä¸‰æ­¥ï¼šä¸ºæ¯ä¸ªsubdivisionè®°å½•åˆ›å»ºç‹¬ç«‹çš„å·¥ä½œæµæ¨¡æ¿èŠ‚ç‚¹
        for subdivision_id, sub_data in template_instances.items():
            child_workflow_base_id = str(sub_data['sub_workflow_base_id'])
            child_workflow_instance_id = str(sub_data['sub_workflow_instance_id'])
            
            # è·å–é¢„æŸ¥è¯¢çš„åŸå§‹èŠ‚ç‚¹ä¿¡æ¯
            original_node_info = original_nodes_info.get(subdivision_id, {})
            
            # ä½¿ç”¨subdivision_idä½œä¸ºèŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†ï¼Œä½†ä¿ç•™å·¥ä½œæµæ¨¡æ¿çš„ä¿¡æ¯
            node = WorkflowTemplateNode(
                workflow_base_id=child_workflow_base_id,  # ä¿ç•™æ¨¡æ¿IDç”¨äºè¯†åˆ«
                workflow_name=sub_data['sub_workflow_name'] or f"Workflow_{str(child_workflow_base_id)[:8]}",
                workflow_instance_id=child_workflow_instance_id,
                status=sub_data.get('sub_workflow_status', 'unknown'),
                source_subdivision=sub_data,  # å­˜å‚¨å®Œæ•´çš„subdivisionä¿¡æ¯
                # ğŸ”§ æ–°å¢ï¼šåˆå¹¶æ‰€éœ€çš„å®Œæ•´æ•°æ®
                original_node_id=original_node_info.get('node_id'),
                original_task_id=original_node_info.get('original_task_id'),
                original_node_name=original_node_info.get('name'),
                original_node_position={
                    'x': original_node_info.get('position_x', 0),
                    'y': original_node_info.get('position_y', 0)
                } if original_node_info.get('position_x') is not None else None,
                merge_node_key=subdivision_id  # ä½¿ç”¨subdivision_idä½œä¸ºåˆå¹¶æ ‡è¯†
            )
            
            # ä½¿ç”¨subdivision_idä½œä¸ºèŠ‚ç‚¹çš„keyï¼Œç¡®ä¿æ¯ä¸ªsubdivisionéƒ½æœ‰ç‹¬ç«‹èŠ‚ç‚¹
            self.nodes[subdivision_id] = node
            logger.info(f"  ğŸ”§ åˆ›å»ºå·¥ä½œæµæ¨¡æ¿èŠ‚ç‚¹: {node.workflow_name} [subdivision: {subdivision_id[:8]}]")
        
        # ç¬¬å››æ­¥ï¼šåŸºäºsubdivisionæ•°æ®æ„å»ºçˆ¶å­å…³ç³»ï¼ˆsubdivisionä½œä¸ºè¾¹çš„ä¿¡æ¯ï¼‰
        self._build_hierarchy_from_subdivisions(subdivisions, root_workflow_instance_id)
        
        logger.info(f"âœ… å·¥ä½œæµæ¨¡æ¿æ ‘æ„å»ºå®Œæˆ: {len(self.nodes)} ä¸ªæ¨¡æ¿èŠ‚ç‚¹, {len(self.roots)} ä¸ªæ ¹èŠ‚ç‚¹")
        logger.info(f"ğŸ“Š æœ€å¤§æ·±åº¦: {self.get_max_depth()}")
        
        # è°ƒè¯•ï¼šè¾“å‡ºæ ‘ç»“æ„
        self._debug_print_tree_structure()
        
        return self
    
    async def _create_root_node(self, root_workflow_instance_id: str) -> Optional[WorkflowTemplateNode]:
        """åˆ›å»ºæ ¹èŠ‚ç‚¹ - å½“å‰å·¥ä½œæµå®ä¾‹å¯¹åº”çš„å·¥ä½œæµæ¨¡æ¿"""
        from ..repositories.base import BaseRepository
        
        try:
            db = BaseRepository("workflow_template_tree").db
            
            # æŸ¥è¯¢å·¥ä½œæµå®ä¾‹å¯¹åº”çš„å·¥ä½œæµæ¨¡æ¿ä¿¡æ¯
            root_info = await db.fetch_one("""
                SELECT wi.workflow_base_id, w.name, wi.status, wi.workflow_instance_id
                FROM workflow_instance wi
                JOIN workflow w ON wi.workflow_base_id = w.workflow_base_id 
                WHERE wi.workflow_instance_id = %s 
                AND w.is_current_version = TRUE
            """, root_workflow_instance_id)
            
            if root_info:
                return WorkflowTemplateNode(
                    workflow_base_id=str(root_info['workflow_base_id']),
                    workflow_name=root_info['name'] or f"Root_Workflow_{str(root_info['workflow_base_id'])[:8]}",
                    workflow_instance_id=str(root_info['workflow_instance_id']),
                    status=root_info.get('status', 'unknown'),
                    depth=0  # æ ¹èŠ‚ç‚¹æ·±åº¦ä¸º0
                )
            else:
                logger.warning(f"æ‰¾ä¸åˆ°æ ¹å·¥ä½œæµå®ä¾‹ä¿¡æ¯: {root_workflow_instance_id}")
                return None
                
        except Exception as e:
            logger.error(f"åˆ›å»ºæ ¹èŠ‚ç‚¹å¤±è´¥: {e}")
            return None
    
    async def _batch_get_original_nodes_info(self, subdivisions: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
        """æ‰¹é‡æŸ¥è¯¢åŸå§‹èŠ‚ç‚¹ä¿¡æ¯ï¼Œé¿å…é‡å¤æ•°æ®åº“æŸ¥è¯¢"""
        from ..repositories.base import BaseRepository
        
        if not subdivisions:
            return {}
            
        try:
            db = BaseRepository("workflow_template_tree").db
            
            # æå–æ‰€æœ‰subdivision_id
            subdivision_ids = [str(sub['subdivision_id']) for sub in subdivisions]
            logger.info(f"ğŸ” æ‰¹é‡æŸ¥è¯¢ {len(subdivision_ids)} ä¸ªsubdivisionçš„åŸå§‹èŠ‚ç‚¹ä¿¡æ¯")
            
            # æ„å»ºæ‰¹é‡æŸ¥è¯¢SQL
            placeholders = ','.join(['%s'] * len(subdivision_ids))
            
            # æ‰¹é‡æŸ¥è¯¢subdivision -> original_task -> nodeä¿¡æ¯
            original_nodes = await db.fetch_all(f"""
                SELECT 
                    CAST(ts.subdivision_id AS CHAR) as subdivision_id,
                    ts.original_task_id,
                    ti.task_instance_id,
                    ni.node_instance_id,
                    n.node_id, 
                    n.position_x, 
                    n.position_y, 
                    n.name, 
                    n.type, 
                    n.task_description,
                    n.workflow_id, 
                    w.name as workflow_name
                FROM task_subdivision ts
                JOIN task_instance ti ON ts.original_task_id = ti.task_instance_id  
                JOIN node_instance ni ON ti.node_instance_id = ni.node_instance_id
                JOIN node n ON ni.node_id = n.node_id
                JOIN workflow w ON n.workflow_id = w.workflow_id
                WHERE ts.subdivision_id IN ({placeholders})
                AND ts.is_deleted = FALSE
            """, *subdivision_ids)
            
            # æ„å»ºsubdivision_id -> åŸå§‹èŠ‚ç‚¹ä¿¡æ¯çš„æ˜ å°„
            result = {}
            for node_info in original_nodes:
                subdivision_id = node_info['subdivision_id']
                result[subdivision_id] = {
                    'original_task_id': node_info['original_task_id'],
                    'node_id': node_info['node_id'],
                    'position_x': node_info['position_x'],
                    'position_y': node_info['position_y'],
                    'name': node_info['name'],
                    'type': node_info['type'],
                    'task_description': node_info['task_description'],
                    'workflow_id': node_info['workflow_id'],
                    'workflow_name': node_info['workflow_name']
                }
            
            logger.info(f"âœ… æ‰¹é‡æŸ¥è¯¢å®Œæˆ: æ‰¾åˆ° {len(result)} ä¸ªåŸå§‹èŠ‚ç‚¹ä¿¡æ¯")
            
            # è°ƒè¯•ï¼šæ˜¾ç¤ºç¼ºå¤±çš„subdivision
            missing_subdivisions = set(subdivision_ids) - set(result.keys())
            if missing_subdivisions:
                logger.warning(f"âš ï¸ ç¼ºå¤±åŸå§‹èŠ‚ç‚¹ä¿¡æ¯çš„subdivision: {list(missing_subdivisions)}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡æŸ¥è¯¢åŸå§‹èŠ‚ç‚¹ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def _build_hierarchy_from_subdivisions(self, subdivisions: List[Dict[str, Any]], 
                                         root_workflow_instance_id: str):
        """æ ¹æ®subdivisionæ•°æ®æ„å»ºå±‚çº§å…³ç³» - subdivisionä½œä¸ºè¾¹çš„ä¿¡æ¯"""
        logger.info(f"ğŸ”— æ„å»ºå·¥ä½œæµæ¨¡æ¿å±‚çº§å…³ç³»")
        
        # subdivisionæ•°æ®è¡¨ç¤ºï¼šparent_workflowä¸­çš„æŸä¸ªèŠ‚ç‚¹è¢«child_workflowæ›¿æ¢
        for sub in subdivisions:
            subdivision_id = str(sub['subdivision_id'])
            child_workflow_base_id = str(sub['sub_workflow_base_id'])
            parent_workflow_instance_id = str(sub.get('root_workflow_instance_id', ''))
            
            # æ„å»ºæ›¿æ¢ä¿¡æ¯ - éœ€è¦åŒ…å«è¢«æ›¿æ¢çš„èŠ‚ç‚¹ä¿¡æ¯
            source_subdivision = {
                'subdivision_id': subdivision_id,
                'original_node_id': sub.get('original_task_id'),  # æ·»åŠ è¢«æ›¿æ¢çš„èŠ‚ç‚¹ID
                'original_node_name': sub.get('original_node_name', ''),
                'task_title': sub.get('task_title', ''),
                'parent_workflow_instance_id': parent_workflow_instance_id,
                'created_at': sub.get('subdivision_created_at')
            }
            
            # æ‰¾åˆ°çˆ¶å·¥ä½œæµæ¨¡æ¿èŠ‚ç‚¹
            parent_node = None
            if parent_workflow_instance_id == root_workflow_instance_id:
                # ç›´æ¥è¿æ¥åˆ°æ ¹èŠ‚ç‚¹
                if len(self.roots) > 0:
                    parent_node = self.roots[0]
            else:
                # æŸ¥æ‰¾å¯¹åº”çš„çˆ¶å·¥ä½œæµæ¨¡æ¿èŠ‚ç‚¹ - ç°åœ¨éœ€è¦é€šè¿‡subdivision_idæŸ¥æ‰¾
                for other_subdivision_id, other_node in self.nodes.items():
                    if (other_node.workflow_instance_id == parent_workflow_instance_id):
                        parent_node = other_node
                        break
            
            # æ‰¾åˆ°å­å·¥ä½œæµæ¨¡æ¿èŠ‚ç‚¹ - ç°åœ¨ä½¿ç”¨subdivision_idä½œä¸ºkey
            child_node = self.nodes.get(subdivision_id)
            
            if parent_node and child_node and child_node.parent_node is None:
                parent_node.add_child_replacement(child_node, sub)
                logger.info(f"    ğŸ“ å»ºç«‹æ›¿æ¢å…³ç³»: {parent_node.workflow_name}[{sub.get('original_node_name', '')}] -> {child_node.workflow_name}")
            else:
                if not parent_node:
                    logger.warning(f"    âš ï¸ æ‰¾ä¸åˆ°çˆ¶å·¥ä½œæµæ¨¡æ¿: {parent_workflow_instance_id}")
                if not child_node:
                    logger.warning(f"    âš ï¸ æ‰¾ä¸åˆ°å­å·¥ä½œæµæ¨¡æ¿: subdivision {subdivision_id}")
                if child_node and child_node.parent_node:
                    logger.warning(f"    âš ï¸ å­å·¥ä½œæµå·²æœ‰çˆ¶èŠ‚ç‚¹: {child_node.workflow_name}")
        
        logger.info(f"ğŸ”— å±‚çº§å…³ç³»æ„å»ºå®Œæˆ")
    
    def _debug_print_tree_structure(self):
        """è°ƒè¯•ï¼šè¾“å‡ºæ ‘ç»“æ„"""
        logger.info(f"ğŸŒ³ [è°ƒè¯•] å·¥ä½œæµæ¨¡æ¿æ ‘ç»“æ„:")
        
        def print_node(node: WorkflowTemplateNode, prefix: str = "", is_last: bool = True):
            connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
            logger.info(f"{prefix}{connector}{node.workflow_name} (æ·±åº¦: {node.depth}, æ›¿æ¢: {len(node.node_replacements)})")
            
            # è¾“å‡ºæ›¿æ¢ä¿¡æ¯
            for node_id, replacement in node.node_replacements.items():
                logger.info(f"{prefix}    ğŸ“‹ æ›¿æ¢èŠ‚ç‚¹ {replacement['original_node_name']} -> {replacement['child_workflow_name']}")
            
            # é€’å½’è¾“å‡ºå­èŠ‚ç‚¹
            children = node.children
            for i, child in enumerate(children):
                is_child_last = (i == len(children) - 1)
                child_prefix = prefix + ("    " if is_last else "â”‚   ")
                print_node(child, child_prefix, is_child_last)
        
        for i, root in enumerate(self.roots):
            is_root_last = (i == len(self.roots) - 1)
            print_node(root, "", is_root_last)
    
    def get_merge_candidates_with_tree_data(self) -> List[Dict[str, Any]]:
        """è·å–å¯åˆå¹¶çš„å€™é€‰èŠ‚ç‚¹ - ç›´æ¥ä»æ ‘æ•°æ®ç”Ÿæˆï¼Œæ— éœ€æŸ¥è¯¢subdivisionè¡¨"""
        candidates = []
        
        # è·å–æ‰€æœ‰éæ ¹èŠ‚ç‚¹ï¼ˆè¿™äº›èŠ‚ç‚¹ä»£è¡¨å¯åˆå¹¶çš„å·¥ä½œæµï¼‰
        for node_key, node in self.nodes.items():
            if node.parent_node is not None:  # æ’é™¤æ ¹èŠ‚ç‚¹
                # ä½¿ç”¨treeä¸­å·²æœ‰çš„å®Œæ•´æ•°æ®æ„å»ºå€™é€‰é¡¹
                candidate = {
                    'merge_node_key': node.merge_node_key or node_key,  # åˆå¹¶æ ‡è¯†
                    'subdivision_id': node.merge_node_key or node_key,  # å…¼å®¹å­—æ®µ
                    'parent_subdivision_id': self._find_node_key(node.parent_node) if node.parent_node else None,
                    'workflow_instance_id': node.workflow_instance_id or "",
                    'workflow_base_id': node.workflow_base_id,
                    'node_name': node.original_node_name or node.workflow_name,
                    'depth': node.depth,
                    'can_merge': True,
                    'merge_reason': "åŸºäºå·¥ä½œæµæ¨¡æ¿æ ‘",
                    # åˆå¹¶æ‰€éœ€çš„å®Œæ•´æ•°æ®
                    'original_node_id': node.original_node_id,
                    'original_task_id': node.original_task_id,
                    'original_node_position': node.original_node_position,
                    'status': node.status,
                    'tree_node': node  # ç›´æ¥å¼•ç”¨æ ‘èŠ‚ç‚¹ï¼Œé¿å…åç»­æŸ¥è¯¢
                }
                candidates.append(candidate)
        
        # æŒ‰æ·±åº¦ä»é«˜åˆ°ä½æ’åºï¼ˆæ·±åº¦ä¼˜å…ˆï¼Œå¶å­èŠ‚ç‚¹å…ˆåˆå¹¶ï¼‰
        candidates.sort(key=lambda c: c['depth'], reverse=True)
        
        logger.info(f"ğŸ” ä»å·¥ä½œæµæ¨¡æ¿æ ‘è·å¾— {len(candidates)} ä¸ªåˆå¹¶å€™é€‰é¡¹")
        return candidates
    
    def _find_node_key(self, target_node: WorkflowTemplateNode) -> Optional[str]:
        """æ ¹æ®èŠ‚ç‚¹å¯¹è±¡æŸ¥æ‰¾å¯¹åº”çš„key"""
        for key, node in self.nodes.items():
            if node is target_node:
                return key
        return None
    
    def calculate_recursive_merge_path(self, selected_node_keys: List[str]) -> List[Dict[str, Any]]:
        """
        è®¡ç®—é€’å½’åˆå¹¶è·¯å¾„ - åŸºäºå·¥ä½œæµæ¨¡æ¿æ ‘ç»“æ„
        
        ä»é€‰ä¸­çš„å¶å­èŠ‚ç‚¹å¼€å§‹ï¼Œæ²¿ç€æ ‘çš„è·¯å¾„å‘ä¸Šé€’å½’åˆ°æ ¹èŠ‚ç‚¹
        è¿”å›éœ€è¦åˆå¹¶çš„å®Œæ•´è·¯å¾„ä¸Šçš„æ‰€æœ‰èŠ‚ç‚¹
        """
        logger.info(f"ğŸŒ³ è®¡ç®—é€’å½’åˆå¹¶è·¯å¾„: {len(selected_node_keys)} ä¸ªé€‰ä¸­èŠ‚ç‚¹")
        logger.info(f"ğŸ” [Debug] é€‰ä¸­çš„èŠ‚ç‚¹keys: {selected_node_keys}")
        
        # ğŸ”§ è°ƒè¯•ï¼šæ˜¾ç¤ºæ ‘ä¸­æ‰€æœ‰å¯ç”¨çš„keys
        available_keys = list(self.nodes.keys())
        logger.info(f"ğŸ” [Debug] æ ‘ä¸­å¯ç”¨çš„keysæ•°é‡: {len(available_keys)}")
        logger.info(f"ğŸ” [Debug] æ ‘ä¸­å‰5ä¸ªkeysç¤ºä¾‹: {available_keys[:5]}")
        
        # ğŸ”§ è°ƒè¯•ï¼šæ£€æŸ¥keyæ ¼å¼å·®å¼‚
        if selected_node_keys and available_keys:
            selected_sample = selected_node_keys[0]
            available_sample = available_keys[0]
            logger.info(f"ğŸ” [Debug] é€‰ä¸­keyç¤ºä¾‹: '{selected_sample}' (é•¿åº¦: {len(selected_sample)})")
            logger.info(f"ğŸ” [Debug] å¯ç”¨keyç¤ºä¾‹: '{available_sample}' (é•¿åº¦: {len(available_sample)})")
        
        recursive_candidates = []
        processed_keys = set()
        
        for selected_key in selected_node_keys:
            if selected_key not in self.nodes:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°é€‰ä¸­çš„èŠ‚ç‚¹: {selected_key}")
                
                # ğŸ”§ è°ƒè¯•ï¼šå°è¯•æ¨¡ç³ŠåŒ¹é…ä»¥å‘ç°é—®é¢˜
                potential_matches = []
                for available_key in available_keys:
                    if selected_key in available_key or available_key in selected_key:
                        potential_matches.append(available_key)
                
                if potential_matches:
                    logger.info(f"ğŸ” [Debug] å¯èƒ½åŒ¹é…çš„keys: {potential_matches[:3]}")
                else:
                    logger.warning(f"ğŸ” [Debug] æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯èƒ½åŒ¹é…çš„keys")
                continue
                
            logger.info(f"ğŸ” è¿½è¸ªèŠ‚ç‚¹è·¯å¾„: {selected_key}")
            
            # ä»å½“å‰èŠ‚ç‚¹å‘ä¸Šè¿½è¸ªåˆ°æ ¹èŠ‚ç‚¹
            current_node = self.nodes[selected_key]
            path_nodes = []
            
            while current_node is not None:
                current_key = self._find_node_key(current_node)
                
                if current_key and current_key not in processed_keys:
                    # åªæœ‰éæ ¹èŠ‚ç‚¹æ‰éœ€è¦åˆå¹¶ï¼ˆæ ¹èŠ‚ç‚¹ä»£è¡¨åˆå§‹å·¥ä½œæµï¼‰
                    if current_node.parent_node is not None:
                        path_nodes.append({
                            'merge_node_key': current_key,
                            'subdivision_id': current_key,  # å…¼å®¹å­—æ®µ
                            'workflow_instance_id': current_node.workflow_instance_id or "",
                            'workflow_base_id': current_node.workflow_base_id,
                            'node_name': current_node.original_node_name or current_node.workflow_name,
                            'depth': current_node.depth,
                            'can_merge': True,
                            'merge_reason': f"é€’å½’åˆå¹¶è·¯å¾„èŠ‚ç‚¹",
                            # åˆå¹¶æ‰€éœ€çš„å®Œæ•´æ•°æ®
                            'original_node_id': current_node.original_node_id,
                            'original_task_id': current_node.original_task_id,
                            'original_node_position': current_node.original_node_position,
                            'status': current_node.status,
                            'tree_node': current_node  # ç›´æ¥å¼•ç”¨æ ‘èŠ‚ç‚¹
                        })
                        processed_keys.add(current_key)
                        logger.info(f"   âœ… æ·»åŠ åˆ°é€’å½’è·¯å¾„: {current_node.workflow_name} (æ·±åº¦: {current_node.depth})")
                
                # å‘ä¸Šç§»åŠ¨åˆ°çˆ¶èŠ‚ç‚¹
                current_node = current_node.parent_node
            
            recursive_candidates.extend(path_nodes)
        
        # æŒ‰æ·±åº¦ä»é«˜åˆ°ä½æ’åºï¼ˆä»å¶å­åˆ°æ ¹ï¼‰
        recursive_candidates.sort(key=lambda c: c['depth'], reverse=True)
        
        logger.info(f"ğŸ”„ é€’å½’åˆå¹¶è·¯å¾„è®¡ç®—å®Œæˆ:")
        for candidate in recursive_candidates:
            logger.info(f"   - {candidate['node_name']} (æ·±åº¦: {candidate['depth']})")
        
        return recursive_candidates
    
    def get_all_nodes(self) -> List[WorkflowTemplateNode]:
        """è·å–æ‰€æœ‰èŠ‚ç‚¹çš„æ‰å¹³åˆ—è¡¨"""
        return list(self.nodes.values())
    
    def get_merge_candidates(self) -> List[WorkflowTemplateNode]:
        """è·å–å¯åˆå¹¶çš„å€™é€‰èŠ‚ç‚¹ - æŒ‰æ·±åº¦ä»é«˜åˆ°ä½æ’åºï¼ŒåŒ…æ‹¬æ ¹èŠ‚ç‚¹"""
        all_nodes = self.get_all_nodes()
        # ä»æœ€æ·±å±‚å¼€å§‹ï¼ŒåŒ…æ‹¬æ ¹èŠ‚ç‚¹ï¼ˆæ·±åº¦0ï¼‰
        # æ ¹èŠ‚ç‚¹æœ€ååˆå¹¶ï¼Œå› ä¸ºå®ƒéœ€è¦æ‰€æœ‰å­å·¥ä½œæµå…ˆå®Œæˆåˆå¹¶
        return sorted(all_nodes, key=lambda n: n.depth, reverse=True)
    
    def get_max_depth(self) -> int:
        """è·å–æœ€å¤§æ·±åº¦"""
        if not self.roots:
            return 0
        
        def get_subtree_max_depth(node: WorkflowTemplateNode) -> int:
            if not node.children:
                return node.depth
            return max(get_subtree_max_depth(child) for child in node.children)
        
        return max(get_subtree_max_depth(root) for root in self.roots)
    
    def to_graph_data(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå‰ç«¯å›¾å½¢æ•°æ®"""
        nodes = []
        edges = []
        
        # è®¡ç®—å¸ƒå±€ä½ç½®
        positions = self._calculate_layout_positions()
        
        # ç”ŸæˆèŠ‚ç‚¹
        for node_key, node in self.nodes.items():
            pos = positions.get(node_key, {"x": 0, "y": 0})
            
            # ä¸ºäº†å‰ç«¯å…¼å®¹æ€§ï¼Œä»ç¬¬ä¸€ä¸ªæ›¿æ¢ä¿¡æ¯ä¸­æå–å­—æ®µ
            first_replacement = None
            if node.node_replacements:
                first_replacement = list(node.node_replacements.values())[0]
            
            nodes.append({
                "id": f"template_{node_key}",  # ä½¿ç”¨node_keyï¼ˆsubdivision_idï¼‰ä½œä¸ºID
                "type": "workflowTemplate",
                "position": pos,
                "data": {
                    "label": node.workflow_name,
                    "workflow_base_id": node.workflow_base_id,
                    "workflow_instance_id": node.workflow_instance_id,
                    "status": node.status,
                    "depth": node.depth,
                    "isRoot": node.parent_node is None,
                    "isMainWorkflow": node.parent_node is None,  # å…¼å®¹å‰ç«¯å­—æ®µ
                    "children_count": len(node.children),
                    "node_replacements": node.node_replacements,
                    "replaced_nodes_count": len(node.node_replacements),
                    # å…¼å®¹åŸæœ‰subdivisionå­—æ®µ - ä½¿ç”¨ç¬¬ä¸€ä¸ªæ›¿æ¢ä¿¡æ¯
                    "subdivision_id": first_replacement.get('subdivision_id') if first_replacement else node_key,
                    "task_title": first_replacement.get('task_title') if first_replacement else None,
                    "node_name": first_replacement.get('original_node_name') if first_replacement else None
                }
            })
        
        # ç”Ÿæˆè¾¹ï¼ˆå·¥ä½œæµæ›¿æ¢å…³ç³»ï¼‰- åŸºäºçˆ¶å­å…³ç³»
        for parent_key, parent_node in self.nodes.items():
            for child in parent_node.children:
                # æ‰¾åˆ°childå¯¹åº”çš„subdivision_id
                child_key = None
                for key, node in self.nodes.items():
                    if node is child:
                        child_key = key
                        break
                
                if child_key and child.source_subdivision:
                    # ç›´æ¥ä»childçš„source_subdivisionè·å–ä¿¡æ¯
                    sub_data = child.source_subdivision
                    original_node_name = sub_data.get('original_node_name', '')
                    
                    # æ„å»ºè¾¹çš„æ ‡ç­¾ï¼šèŠ‚ç‚¹å -> å­å·¥ä½œæµå
                    if original_node_name:
                        edge_label = f"{original_node_name} â†’ {child.workflow_name}"
                    else:
                        # fallbackï¼šä½¿ç”¨task_title
                        task_title = sub_data.get('task_title', '')
                        edge_label = f"{task_title} â†’ {child.workflow_name}" if task_title else f"Node â†’ {child.workflow_name}"
                    
                    edges.append({
                        "id": f"replacement_{parent_key}_{child_key}",
                        "source": f"template_{parent_key}",
                        "target": f"template_{child_key}",
                        "type": "smoothstep",
                        "animated": child.status == "running",
                        "label": edge_label,
                        "data": {
                            "relationship": "workflow_replacement",
                            "original_node_id": child_key,
                            "source_subdivision": {
                                'subdivision_id': child_key,
                                'original_node_name': original_node_name,
                                'task_title': sub_data.get('task_title', ''),
                                'child_workflow_name': child.workflow_name
                            },
                            # å…¼å®¹åŸæœ‰subdivisionå­—æ®µ
                            "subdivision_id": child_key,
                            "subdivision_name": original_node_name,
                            "task_title": sub_data.get('task_title', '')
                        }
                    })
        
        return {
            "nodes": nodes,
            "edges": edges,
            "layout": {
                "algorithm": "workflow_template_tree",
                "max_depth": self.get_max_depth(),
                "total_templates": len(self.nodes),
                "root_count": len(self.roots)
            }
        }
    
    def _calculate_layout_positions(self, node_spacing: int = 350, level_spacing: int = 250) -> Dict[str, Dict[str, int]]:
        """è®¡ç®—æ ‘çŠ¶å¸ƒå±€ä½ç½®"""
        positions = {}
        
        # ä¸ºæ¯ä¸ªæ ¹èŠ‚ç‚¹åˆ†é…èµ·å§‹Xä½ç½®
        current_x = 0
        for root in self.roots:
            self._calculate_subtree_positions(
                root, current_x, 0, node_spacing, level_spacing, positions
            )
            current_x += 800  # æ ¹èŠ‚ç‚¹ä¹‹é—´çš„é—´è·
        
        return positions
    
    def _calculate_subtree_positions(self, node: WorkflowTemplateNode, x: int, y: int, 
                                   node_spacing: int, level_spacing: int,
                                   positions: Dict[str, Dict[str, int]]):
        """é€’å½’è®¡ç®—å­æ ‘ä½ç½®"""
        # æ‰¾åˆ°èŠ‚ç‚¹å¯¹åº”çš„key
        node_key = None
        for key, n in self.nodes.items():
            if n is node:
                node_key = key
                break
        
        if node_key:
            positions[node_key] = {"x": x, "y": y}
        
        # å­èŠ‚ç‚¹æ’å¸ƒ
        child_count = len(node.children)
        if child_count > 0:
            # è®¡ç®—å­èŠ‚ç‚¹èµ·å§‹ä½ç½®
            total_width = (child_count - 1) * node_spacing
            start_x = x - total_width // 2
            child_y = y + level_spacing
            
            for i, child in enumerate(node.children):
                child_x = start_x + i * node_spacing
                self._calculate_subtree_positions(
                    child, child_x, child_y, node_spacing, level_spacing, positions
                )
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æ ‘ç»Ÿè®¡ä¿¡æ¯ - å…¼å®¹æ—§ç‰ˆAPIæ ¼å¼"""
        all_nodes = self.get_all_nodes()
        
        # æŒ‰æ·±åº¦ç»Ÿè®¡
        by_depth = {}
        total_replacements = 0
        
        for node in all_nodes:
            depth = node.depth
            if depth not in by_depth:
                by_depth[depth] = 0
            by_depth[depth] += 1
            total_replacements += len(node.node_replacements)
        
        # å…¼å®¹æ—§ç‰ˆAPIæ ¼å¼
        return {
            # æ–°æ ¼å¼å­—æ®µ
            "total_workflow_templates": len(all_nodes),
            "root_templates": len(self.roots),
            "max_depth": self.get_max_depth(),
            "by_depth": by_depth,
            "total_replacements": total_replacements,
            # å…¼å®¹æ—§ç‰ˆAPIæ ¼å¼
            "total_subdivisions": total_replacements,  # ç”¨æ€»æ›¿æ¢æ•°æ¥ä»£è¡¨subdivisionæ•°é‡
            "root_subdivisions": len(self.roots),
            "completed_workflows": len([n for n in all_nodes if n.status == "completed"]),
            "running_workflows": len([n for n in all_nodes if n.status == "running"]),
            "failed_workflows": len([n for n in all_nodes if n.status == "failed"]),
            # å…¶ä»–å…¼å®¹å­—æ®µ
            "completed_sub_workflows": len([n for n in all_nodes if n.status == "completed"]),
            "unique_workflows": len(all_nodes)
        }