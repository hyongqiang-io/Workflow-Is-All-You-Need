"""
ä»»åŠ¡ç»†åˆ†æœåŠ¡ - é‡æ„ç‰ˆæœ¬
Task Subdivision Service - Refactored Version

æ ¸å¿ƒæ€æƒ³ï¼š
1. åˆ†ç¦»æ¨¡æ¿(Template)å’Œå®ä¾‹(Instance)
2. ç”¨æˆ·å¯ä»¥é€‰æ‹©ç°æœ‰å·¥ä½œæµæ¨¡æ¿æˆ–åˆ›å»ºæ–°æ¨¡æ¿
3. ä¸€ä¸ªæ¨¡æ¿å¯ä»¥å¤šæ¬¡æ‰§è¡Œï¼Œæ¯æ¬¡æ‰§è¡Œåˆ›å»ºä¸€ä¸ªå®ä¾‹
4. APIä¿æŒå…¼å®¹ï¼Œå†…éƒ¨é€»è¾‘ç®€åŒ–
"""

import uuid
import json
import asyncio
from datetime import datetime
from typing import Optional, Dict, Any, List
from loguru import logger

from ..models.task_subdivision import (
    TaskSubdivisionCreate, TaskSubdivisionResponse, TaskSubdivisionStatus,
    WorkflowAdoptionCreate, WorkflowAdoptionResponse,
    SubdivisionPreviewResponse, WorkflowSubdivisionsResponse
)
from ..models.workflow import WorkflowCreate
from ..repositories.task_subdivision.task_subdivision_repository import TaskSubdivisionRepository
from ..repositories.instance.task_instance_repository import TaskInstanceRepository
from ..services.workflow_service import WorkflowService
from ..services.node_service import NodeService
from ..services.execution_service import execution_engine
from ..utils.helpers import now_utc
from ..utils.exceptions import ValidationError


class TaskSubdivisionService:
    """ä»»åŠ¡ç»†åˆ†æœåŠ¡ - é‡æ„ç‰ˆæœ¬"""
    
    def __init__(self):
        self.subdivision_repo = TaskSubdivisionRepository()
        self.task_repo = TaskInstanceRepository()
        self.workflow_service = WorkflowService()
        self.node_service = NodeService()
    
    async def create_task_subdivision(self, subdivision_data: TaskSubdivisionCreate,
                                    execute_immediately: bool = False) -> TaskSubdivisionResponse:
        """
        åˆ›å»ºä»»åŠ¡ç»†åˆ† - é‡æ„ç‰ˆæœ¬
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        1. å¦‚æœç”¨æˆ·æä¾›äº†å·¥ä½œæµæ¨¡æ¿IDï¼Œä½¿ç”¨ç°æœ‰æ¨¡æ¿
        2. å¦‚æœæ²¡æœ‰ï¼Œæ ¹æ®sub_workflow_dataåˆ›å»ºæ–°æ¨¡æ¿ï¼ˆä¸€æ¬¡ï¼‰
        3. åˆ›å»ºç»†åˆ†è®°å½•ï¼Œå…³è”åˆ°æ¨¡æ¿
        4. å¦‚æœéœ€è¦æ‰§è¡Œï¼Œä»æ¨¡æ¿åˆ›å»ºå®ä¾‹æ‰§è¡Œ
        """
        try:
            logger.info(f"ğŸ”„ å¼€å§‹åˆ›å»ºä»»åŠ¡ç»†åˆ†: {subdivision_data.subdivision_name}")
            
            # 1. éªŒè¯åŸå§‹ä»»åŠ¡
            original_task = await self.task_repo.get_task_by_id(subdivision_data.original_task_id)
            if not original_task:
                raise ValidationError("åŸå§‹ä»»åŠ¡ä¸å­˜åœ¨")
            
            # æƒé™æ£€æŸ¥
            if str(original_task.get('assigned_user_id')) != str(subdivision_data.subdivider_id):
                raise ValidationError("åªèƒ½ç»†åˆ†åˆ†é…ç»™è‡ªå·±çš„ä»»åŠ¡")
            
            # 2. éªŒè¯çˆ¶çº§ç»†åˆ†ï¼ˆå¦‚æœæä¾›ï¼‰- é“¾å¼ç»†åˆ†æ”¯æŒ
            if subdivision_data.parent_subdivision_id:
                parent_subdivision = await self.subdivision_repo.get_subdivision_by_id(subdivision_data.parent_subdivision_id)
                if not parent_subdivision:
                    raise ValidationError("çˆ¶çº§ç»†åˆ†ä¸å­˜åœ¨")
                
                # æ£€æŸ¥æƒé™ï¼šåªèƒ½åœ¨è‡ªå·±åˆ›å»ºçš„ç»†åˆ†ä¸‹åˆ›å»ºå­çº§
                if str(parent_subdivision.get('subdivider_id')) != str(subdivision_data.subdivider_id):
                    raise ValidationError("åªèƒ½åœ¨è‡ªå·±åˆ›å»ºçš„ç»†åˆ†ä¸‹åˆ›å»ºå­çº§ç»†åˆ†")
                
                # é˜²æ­¢å¾ªç¯å¼•ç”¨ï¼šä¸èƒ½å°†ç»†åˆ†è®¾ä¸ºè‡ªå·±çš„çˆ¶çº§
                if str(parent_subdivision.get('subdivision_id')) == str(subdivision_data.original_task_id):
                    raise ValidationError("ä¸èƒ½åˆ›å»ºå¾ªç¯å¼•ç”¨çš„ç»†åˆ†")
                
                logger.info(f"âœ… çˆ¶çº§ç»†åˆ†éªŒè¯é€šè¿‡: {parent_subdivision.get('subdivision_name')}")
            
            # 3. å¤„ç†å·¥ä½œæµæ¨¡æ¿ - è¿™æ˜¯å…³é”®æ”¹è¿›
            template_id = await self._get_or_create_workflow_template(
                subdivision_data.sub_workflow_base_id,
                subdivision_data.sub_workflow_data,
                subdivision_data.subdivision_name,
                subdivision_data.subdivider_id,
                subdivision_data.context_to_pass
            )
            
            # 3. åˆ›å»ºç»†åˆ†è®°å½•
            subdivision_record = await self.subdivision_repo.create_subdivision(subdivision_data)
            if not subdivision_record:
                raise ValueError("åˆ›å»ºç»†åˆ†è®°å½•å¤±è´¥")
            
            subdivision_id = subdivision_record['subdivision_id']
            
            # 4. æ›´æ–°ç»†åˆ†è®°å½•çš„å·¥ä½œæµæ¨¡æ¿ID
            await self.subdivision_repo.update_subdivision_workflow_ids(
                subdivision_id, template_id
            )
            
            # 5. å¦‚æœéœ€è¦ç«‹å³æ‰§è¡Œï¼Œåˆ›å»ºå·¥ä½œæµå®ä¾‹
            instance_id = None
            if execute_immediately:
                instance_id = await self._execute_workflow_template(
                    template_id, subdivision_id, subdivision_data.subdivider_id, 
                    subdivision_data.context_to_pass
                )
                
                # æ›´æ–°ç»†åˆ†è®°å½•çš„å®ä¾‹ID
                if instance_id:
                    await self.subdivision_repo.update_subdivision_workflow_ids(
                        subdivision_id, template_id, instance_id
                    )
            
            logger.info(f"âœ… ä»»åŠ¡ç»†åˆ†åˆ›å»ºæˆåŠŸ: {subdivision_id}")
            
            # 6. è¿”å›å“åº”
            return await self._format_subdivision_response(subdivision_record, {
                'original_task_title': original_task.get('task_title'),
                'sub_workflow_base_id': template_id,
                'sub_workflow_instance_id': instance_id
            })
            
        except Exception as e:
            logger.error(f"åˆ›å»ºä»»åŠ¡ç»†åˆ†å¤±è´¥: {e}")
            raise
    
    async def _get_or_create_workflow_template(self, 
                                             provided_template_id: Optional[uuid.UUID],
                                             workflow_data: Dict[str, Any],
                                             subdivision_name: str,
                                             creator_id: uuid.UUID,
                                             context: str) -> uuid.UUID:
        """
        è·å–æˆ–åˆ›å»ºå·¥ä½œæµæ¨¡æ¿
        
        è¿™æ˜¯å…³é”®æ”¹è¿›ï¼šæ˜ç¡®åˆ†ç¦»æ¨¡æ¿è·å–å’Œåˆ›å»ºé€»è¾‘
        """
        # æƒ…å†µ1ï¼šç”¨æˆ·é€‰æ‹©äº†ç°æœ‰å·¥ä½œæµæ¨¡æ¿
        if provided_template_id:
            logger.info(f"ğŸ”„ ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„å·¥ä½œæµæ¨¡æ¿: {provided_template_id}")
            
            # éªŒè¯æ¨¡æ¿å­˜åœ¨ä¸”æœ‰æƒé™è®¿é—®
            template = await self.workflow_service.get_workflow_by_base_id(provided_template_id)
            if not template:
                raise ValidationError(f"æŒ‡å®šçš„å·¥ä½œæµæ¨¡æ¿ä¸å­˜åœ¨: {provided_template_id}")
            
            # éªŒè¯æ¨¡æ¿æ˜¯å¦æœ‰æœ‰æ•ˆå†…å®¹ï¼ˆè‡³å°‘æœ‰éstart/endèŠ‚ç‚¹ï¼‰
            node_count_result = await self.node_service.node_repository.db.fetch_one(
                "SELECT COUNT(*) as count FROM node WHERE workflow_base_id = %s AND is_deleted = FALSE AND type NOT IN ('start', 'end')",
                provided_template_id
            )
            node_count = node_count_result.get('count', 0) if node_count_result else 0
            
            if node_count == 0:
                logger.warning(f"âš ï¸ é€‰æ‹©çš„å·¥ä½œæµæ¨¡æ¿ {template.name} æ²¡æœ‰æœ‰æ•ˆèŠ‚ç‚¹")
                raise ValidationError(f"é€‰æ‹©çš„å·¥ä½œæµæ¨¡æ¿ '{template.name}' æ˜¯ç©ºæ¨¡æ¿ï¼Œè¯·é€‰æ‹©åŒ…å«æœ‰æ•ˆèŠ‚ç‚¹çš„å·¥ä½œæµæ¨¡æ¿æˆ–åˆ›å»ºæ–°æ¨¡æ¿")
            else:
                logger.info(f"âœ… æ‰¾åˆ°ç°æœ‰å·¥ä½œæµæ¨¡æ¿: {template.name} (åŒ…å« {node_count} ä¸ªæœ‰æ•ˆèŠ‚ç‚¹)")
                return provided_template_id
        
        # æƒ…å†µ2ï¼šåˆ›å»ºæ–°çš„å·¥ä½œæµæ¨¡æ¿
        logger.info(f"ğŸ”„ åˆ›å»ºæ–°çš„å·¥ä½œæµæ¨¡æ¿: {subdivision_name}")
        
        # éªŒè¯å·¥ä½œæµæ•°æ®æ˜¯å¦æœ‰æ•ˆ
        nodes_data = workflow_data.get('nodes', [])
        if not nodes_data:
            raise ValidationError("åˆ›å»ºæ–°å·¥ä½œæµæ¨¡æ¿éœ€è¦æä¾›æœ‰æ•ˆçš„èŠ‚ç‚¹æ•°æ®ï¼Œè¯·åœ¨å·¥ä½œæµè®¾è®¡å™¨ä¸­æ·»åŠ èŠ‚ç‚¹åå†æäº¤")
        
        # åˆ›å»ºå·¥ä½œæµæ¨¡æ¿
        template_create = WorkflowCreate(
            name=subdivision_name,
            description=f"ä»»åŠ¡ç»†åˆ†å·¥ä½œæµæ¨¡æ¿ - {subdivision_name}",
            creator_id=creator_id
        )
        
        template = await self.workflow_service.create_workflow(template_create)
        template_id = template.workflow_base_id
        
        # ä¸ºæ–°æ¨¡æ¿åˆ›å»ºèŠ‚ç‚¹å’Œè¿æ¥
        await self._create_template_nodes_and_connections(
            template_id, workflow_data, creator_id, context
        )
        
        logger.info(f"âœ… æ–°å·¥ä½œæµæ¨¡æ¿åˆ›å»ºæˆåŠŸ: {template_id}")
        return template_id
    
    async def _execute_workflow_template(self, 
                                       template_id: uuid.UUID,
                                       subdivision_id: uuid.UUID,
                                       executor_id: uuid.UUID,
                                       context: str) -> Optional[uuid.UUID]:
        """
        æ‰§è¡Œå·¥ä½œæµæ¨¡æ¿ï¼Œåˆ›å»ºæ–°å®ä¾‹
        
        è¿™æ˜¯å¦ä¸€ä¸ªå…³é”®æ”¹è¿›ï¼šæ¯æ¬¡æ‰§è¡Œéƒ½æ˜¯ä»æ¨¡æ¿åˆ›å»ºæ–°å®ä¾‹
        """
        try:
            logger.info(f"ğŸš€ ä»æ¨¡æ¿åˆ›å»ºå·¥ä½œæµå®ä¾‹: {template_id}")
            
            # ğŸ” [è°ƒè¯•] å‚æ•°ç±»å‹æ£€æŸ¥
            logger.info(f"ğŸ” [UUIDè°ƒè¯•] template_idç±»å‹: {type(template_id)}, å€¼: {template_id}")
            logger.info(f"ğŸ” [UUIDè°ƒè¯•] subdivision_idç±»å‹: {type(subdivision_id)}, å€¼: {subdivision_id}")
            logger.info(f"ğŸ” [UUIDè°ƒè¯•] executor_idç±»å‹: {type(executor_id)}, å€¼: {executor_id}")
            
            # æ„é€ æ‰§è¡Œè¯·æ±‚ - ç¡®ä¿UUIDè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            from ..models.instance import WorkflowExecuteRequest
            template_id_str = str(template_id)
            subdivision_id_str = str(subdivision_id)
            
            logger.info(f"ğŸ” [UUIDè°ƒè¯•] è½¬æ¢å template_id_strç±»å‹: {type(template_id_str)}, å€¼: {template_id_str}")
            logger.info(f"ğŸ” [UUIDè°ƒè¯•] è½¬æ¢å subdivision_id_strç±»å‹: {type(subdivision_id_str)}, å€¼: {subdivision_id_str}")
            
            execute_request = WorkflowExecuteRequest(
                workflow_base_id=template_id_str,  # ä¿®å¤: UUIDè½¬å­—ç¬¦ä¸²
                workflow_instance_name=f"ç»†åˆ†æ‰§è¡Œ_{subdivision_id_str}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                input_data={},
                context_data={
                    "subdivision_context": context,
                    "subdivision_id": subdivision_id_str,
                    "execution_type": "task_subdivision"
                }
            )
            
            logger.info(f"ğŸ” [UUIDè°ƒè¯•] execute_requestå¯¹è±¡åˆ›å»ºå®Œæˆ")
            
            # æ‰§è¡Œå·¥ä½œæµï¼ˆä»æ¨¡æ¿åˆ›å»ºå®ä¾‹ï¼‰
            logger.info(f"ğŸ” [UUIDè°ƒè¯•] å‡†å¤‡è°ƒç”¨ execution_engine.execute_workflow")
            logger.info(f"ğŸ” [UUIDè°ƒè¯•] executor_idç±»å‹: {type(executor_id)}, å€¼: {executor_id}")
            
            try:
                result = await execution_engine.execute_workflow(execute_request, executor_id)
                logger.info(f"ğŸ” [UUIDè°ƒè¯•] execution_engine.execute_workflow æ‰§è¡ŒæˆåŠŸ")
                logger.info(f"ğŸ” [UUIDè°ƒè¯•] è¿”å›ç»“æœç±»å‹: {type(result)}")
            except Exception as exec_error:
                logger.error(f"ğŸ” [UUIDè°ƒè¯•] execution_engine.execute_workflow æ‰§è¡Œå¤±è´¥: {exec_error}")
                logger.error(f"ğŸ” [UUIDè°ƒè¯•] å¼‚å¸¸ç±»å‹: {type(exec_error)}")
                import traceback
                logger.error(f"ğŸ” [UUIDè°ƒè¯•] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                raise
            
            # æå–å®ä¾‹ID
            logger.info(f"ğŸ” [UUIDè°ƒè¯•] å‡†å¤‡æå–å®ä¾‹IDï¼Œresult: {type(result)}")
            try:
                instance_id = self._extract_instance_id(result)
                logger.info(f"ğŸ” [UUIDè°ƒè¯•] å®ä¾‹IDæå–ç»“æœ: {type(instance_id)}, å€¼: {instance_id}")
            except Exception as extract_error:
                logger.error(f"ğŸ” [UUIDè°ƒè¯•] æå–å®ä¾‹IDå¤±è´¥: {extract_error}")
                logger.error(f"ğŸ” [UUIDè°ƒè¯•] æå–å¼‚å¸¸ç±»å‹: {type(extract_error)}")
                import traceback
                logger.error(f"ğŸ” [UUIDè°ƒè¯•] æå–å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                raise
            
            if instance_id:
                # ğŸ” [è°ƒè¯•] å›è°ƒæ³¨å†Œå‚æ•°æ£€æŸ¥
                logger.info(f"ğŸ” [UUIDè°ƒè¯•] å‡†å¤‡æ³¨å†Œå®Œæˆå›è°ƒ")
                logger.info(f"ğŸ” [UUIDè°ƒè¯•] subdivision_idç±»å‹: {type(subdivision_id)}, å€¼: {subdivision_id}")
                logger.info(f"ğŸ” [UUIDè°ƒè¯•] instance_idç±»å‹: {type(instance_id)}, å€¼: {instance_id}")
                logger.info(f"ğŸ” [UUIDè°ƒè¯•] executor_idç±»å‹: {type(executor_id)}, å€¼: {executor_id}")
                
                # æ³¨å†Œå®Œæˆå›è°ƒ
                try:
                    await self._register_completion_callback(subdivision_id, instance_id, executor_id)
                    logger.info(f"ğŸ” [UUIDè°ƒè¯•] å®Œæˆå›è°ƒæ³¨å†ŒæˆåŠŸ")
                except Exception as callback_error:
                    logger.error(f"ğŸ” [UUIDè°ƒè¯•] å®Œæˆå›è°ƒæ³¨å†Œå¤±è´¥: {callback_error}")
                    logger.error(f"ğŸ” [UUIDè°ƒè¯•] å›è°ƒå¼‚å¸¸ç±»å‹: {type(callback_error)}")
                    import traceback
                    logger.error(f"ğŸ” [UUIDè°ƒè¯•] å›è°ƒå¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                    raise
                
                logger.info(f"âœ… å·¥ä½œæµå®ä¾‹åˆ›å»ºå¹¶å¯åŠ¨æˆåŠŸ: {instance_id}")
                return instance_id
            else:
                logger.error(f"âŒ æ— æ³•ä»æ‰§è¡Œç»“æœä¸­æå–å®ä¾‹ID: {result}")
                return None
                
        except Exception as e:
            logger.error(f"æ‰§è¡Œå·¥ä½œæµæ¨¡æ¿å¤±è´¥: {e}")
            raise
    
    async def _create_template_nodes_and_connections(self, 
                                                   template_id: uuid.UUID,
                                                   workflow_data: Dict[str, Any], 
                                                   creator_id: uuid.UUID,
                                                   context: str = "") -> None:
        """ä¸ºå·¥ä½œæµæ¨¡æ¿åˆ›å»ºèŠ‚ç‚¹å’Œè¿æ¥"""
        try:
            logger.info(f"ğŸ”„ ä¸ºæ¨¡æ¿ {template_id} åˆ›å»ºèŠ‚ç‚¹å’Œè¿æ¥")
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰èŠ‚ç‚¹ï¼ˆé˜²æ­¢é‡å¤åˆ›å»ºï¼‰
            existing_nodes_query = "SELECT COUNT(*) as node_count FROM node WHERE workflow_base_id = %s"
            existing_nodes_result = await self.node_service.node_repository.db.fetch_one(
                existing_nodes_query, template_id
            )
            existing_node_count = existing_nodes_result.get('node_count', 0) if existing_nodes_result else 0
            
            if existing_node_count > 0:
                logger.warning(f"ğŸ›¡ï¸ æ¨¡æ¿ {template_id} å·²æœ‰ {existing_node_count} ä¸ªèŠ‚ç‚¹ï¼Œè·³è¿‡åˆ›å»º")
                return
            
            nodes_data = workflow_data.get('nodes', [])
            connections_data = workflow_data.get('connections', [])
            
            if not nodes_data:
                logger.warning("æ²¡æœ‰èŠ‚ç‚¹æ•°æ®ï¼Œè·³è¿‡èŠ‚ç‚¹åˆ›å»º")
                return
            
            logger.info(f"ğŸ“¦ å‡†å¤‡åˆ›å»º {len(nodes_data)} ä¸ªèŠ‚ç‚¹å’Œ {len(connections_data)} ä¸ªè¿æ¥")
            
            # åˆ›å»ºèŠ‚ç‚¹
            node_id_mapping = {}
            for node_data in nodes_data:
                try:
                    from ..models.node import NodeCreate
                    
                    # å¯¹å¼€å§‹èŠ‚ç‚¹æ³¨å…¥ä¸Šä¸‹æ–‡
                    task_description = node_data.get('task_description', '')
                    if node_data.get('type') == 'start' and context:
                        task_description = f"{task_description}\n\n--- ä»»åŠ¡ä¸Šä¸‹æ–‡ ---\n{context}"
                    
                    node_create = NodeCreate(
                        workflow_base_id=template_id,
                        name=node_data.get('name', 'æœªå‘½åèŠ‚ç‚¹'),
                        type=node_data.get('type', 'processor'),
                        task_description=task_description,
                        position_x=float(node_data.get('position_x', 0)),
                        position_y=float(node_data.get('position_y', 0)),
                        processor_id=node_data.get('processor_id')
                    )
                    
                    created_node = await self.node_service.create_node(node_create, creator_id)
                    
                    if created_node:
                        frontend_id = node_data.get('node_base_id') or node_data.get('id')
                        node_id_mapping[frontend_id] = created_node.node_base_id
                        logger.debug(f"   âœ… èŠ‚ç‚¹åˆ›å»ºæˆåŠŸ: {created_node.name}")
                        
                except Exception as e:
                    logger.error(f"åˆ›å»ºèŠ‚ç‚¹å¤±è´¥: {node_data.get('name', 'æœªçŸ¥')}, é”™è¯¯: {e}")
                    continue
            
            # åˆ›å»ºè¿æ¥
            if connections_data and len(node_id_mapping) > 1:
                for connection_data in connections_data:
                    try:
                        from ..models.node import NodeConnectionCreate
                        
                        from_node_frontend_id = connection_data.get('from_node_id') or connection_data.get('from')
                        to_node_frontend_id = connection_data.get('to_node_id') or connection_data.get('to')
                        
                        from_node_id = node_id_mapping.get(from_node_frontend_id)
                        to_node_id = node_id_mapping.get(to_node_frontend_id)
                        
                        if not from_node_id or not to_node_id:
                            logger.warning(f"è¿æ¥è·³è¿‡ï¼ŒèŠ‚ç‚¹IDæ˜ å°„å¤±è´¥: {from_node_frontend_id} -> {to_node_frontend_id}")
                            continue
                        
                        connection_create = NodeConnectionCreate(
                            from_node_base_id=from_node_id,
                            to_node_base_id=to_node_id,
                            workflow_base_id=template_id,
                            connection_type=connection_data.get('connection_type', 'normal')
                        )
                        
                        await self.node_service.create_node_connection(connection_create, creator_id)
                        
                    except Exception as e:
                        logger.error(f"åˆ›å»ºè¿æ¥å¤±è´¥: {connection_data}, é”™è¯¯: {e}")
                        continue
            
            logger.info(f"ğŸ‰ æ¨¡æ¿ {template_id} çš„èŠ‚ç‚¹å’Œè¿æ¥åˆ›å»ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæ¨¡æ¿èŠ‚ç‚¹å’Œè¿æ¥å¤±è´¥: {e}")
            raise
    
    def _extract_instance_id(self, result) -> Optional[uuid.UUID]:
        """ä»æ‰§è¡Œç»“æœä¸­æå–å®ä¾‹ID"""
        if not result:
            return None
            
        try:
            if isinstance(result, dict):
                if 'instance_id' in result:
                    instance_id = result['instance_id']
                    if isinstance(instance_id, uuid.UUID):
                        return instance_id
                    else:
                        return uuid.UUID(instance_id)
                elif 'workflow_instance_id' in result:
                    workflow_id = result['workflow_instance_id']
                    if isinstance(workflow_id, uuid.UUID):
                        return workflow_id
                    else:
                        return uuid.UUID(workflow_id)
            elif hasattr(result, 'workflow_instance_id'):
                return result.workflow_instance_id
            elif isinstance(result, str):
                return uuid.UUID(result)
        except (ValueError, TypeError):
            logger.error(f"æ— æ³•è§£æå®ä¾‹ID: {result}")
            
        return None
    
    async def _register_completion_callback(self, subdivision_id: uuid.UUID, 
                                          instance_id: uuid.UUID,
                                          executor_id: uuid.UUID):
        """æ³¨å†Œå·¥ä½œæµå®Œæˆå›è°ƒ"""
        try:
            from ..services.monitoring_service import monitoring_service
            
            async def completion_callback(instance_id: uuid.UUID, status: str, results: dict):
                await self._handle_completion(subdivision_id, instance_id, status, results, executor_id)
            
            await monitoring_service.register_workflow_completion_callback(
                instance_id, completion_callback
            )
            
        except Exception as e:
            logger.error(f"æ³¨å†Œå®Œæˆå›è°ƒå¤±è´¥: {e}")
    
    async def _handle_completion(self, subdivision_id: uuid.UUID,
                               instance_id: uuid.UUID,
                               status: str,
                               results: dict,
                               executor_id: uuid.UUID):
        """å¤„ç†å·¥ä½œæµå®Œæˆäº‹ä»¶"""
        try:
            logger.info(f"ğŸ¯ å¤„ç†ç»†åˆ†å·¥ä½œæµå®Œæˆ: {subdivision_id}")
            
            # è·å–ç»†åˆ†ä¿¡æ¯
            subdivision = await self.subdivision_repo.get_subdivision_by_id(subdivision_id)
            if not subdivision:
                return
            
            original_task_id = subdivision['original_task_id']
            
            # æ›´æ–°ç»†åˆ†çŠ¶æ€
            if status == 'completed':
                await self._update_subdivision_status(subdivision_id, 'completed', results)
                await self._save_results_to_task(original_task_id, subdivision_id, results, executor_id)
            else:
                await self._update_subdivision_status(subdivision_id, 'failed', results)
            
        except Exception as e:
            logger.error(f"å¤„ç†å®Œæˆäº‹ä»¶å¤±è´¥: {e}")
    
    async def _update_subdivision_status(self, subdivision_id: uuid.UUID, 
                                       status: str, results: dict):
        """æ›´æ–°ç»†åˆ†çŠ¶æ€"""
        try:
            status_enum = TaskSubdivisionStatus.COMPLETED if status == 'completed' else TaskSubdivisionStatus.FAILED
            await self.subdivision_repo.update_subdivision_status(subdivision_id, status_enum)
            
        except Exception as e:
            logger.error(f"æ›´æ–°ç»†åˆ†çŠ¶æ€å¤±è´¥: {e}")
    
    async def _save_results_to_task(self, task_id: uuid.UUID,
                                  subdivision_id: uuid.UUID,
                                  results: dict,
                                  executor_id: uuid.UUID):
        """ä¿å­˜ç»“æœåˆ°åŸå§‹ä»»åŠ¡å¹¶è§¦å‘å·¥ä½œæµç»§ç»­æ‰§è¡Œ"""
        try:
            from ..models.instance import TaskInstanceUpdate
            
            # ç”Ÿæˆç»“æ„åŒ–çš„ç»“æœæ•°æ®
            result_data = {
                'type': 'subdivision_result',
                'subdivision_id': str(subdivision_id),
                'final_output': results.get('final_output', ''),
                'execution_summary': {
                    'status': results.get('status', 'unknown'),
                    'total_tasks': results.get('total_tasks', 0),
                    'completed_tasks': results.get('completed_tasks', 0),
                    'failed_tasks': results.get('failed_tasks', 0)
                },
                'completion_time': now_utc().isoformat(),
                'auto_submitted': False  # è‡ªåŠ¨æäº¤subdivisionç»“æœ
            }
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ ‡è®°åŸå§‹ä»»åŠ¡ä¸ºå·²å®Œæˆå¹¶è§¦å‘å·¥ä½œæµç»§ç»­æ‰§è¡Œ
            task_update = TaskInstanceUpdate(
                # status=TaskInstanceStatus.COMPLETED,  # æ ‡è®°ä»»åŠ¡ä¸ºå·²å®Œæˆ
                output_data=json.dumps(result_data, ensure_ascii=False, indent=2),
                instructions="ç»†åˆ†å·¥ä½œæµå·²å®Œæˆï¼Œç»“æœå·²è‡ªåŠ¨æäº¤ã€‚",
                # completed_at=now_utc()  # è®¾ç½®å®Œæˆæ—¶é—´
            )
            
            await self.task_repo.update_task(task_id, task_update)
            logger.info(f"âœ… ç»†åˆ†ç»“æœå·²ä¿å­˜åˆ°ä»»åŠ¡å¹¶æ ‡è®°ä¸ºå®Œæˆ: {task_id}")
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šè·å–ä»»åŠ¡çš„èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯å¹¶è§¦å‘å·¥ä½œæµç»§ç»­æ‰§è¡Œ
            # task_info = await self.task_repo.get_task_by_id(task_id)
            # if task_info:
            #     node_instance_id = task_info['node_instance_id']
            #     workflow_instance_id = task_info['workflow_instance_id']
                
            #     # æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€ä¸ºå·²å®Œæˆ
            #     from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            #     node_repo = NodeInstanceRepository()
            #     await node_repo.update_node_status(node_instance_id, 'completed')
            #     logger.info(f"âœ… èŠ‚ç‚¹å®ä¾‹çŠ¶æ€å·²æ›´æ–°ä¸ºå®Œæˆ: {node_instance_id}")
                
            #     # ğŸ”§ å…³é”®ä¿®å¤ï¼šè§¦å‘æ‰§è¡Œå¼•æ“æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹ï¼Œè¿™æ˜¯ä¹‹å‰ç¼ºå¤±çš„æ­¥éª¤ï¼
            #     from ..services.execution_service import execution_engine
            #     await execution_engine._check_downstream_nodes_for_task_creation(workflow_instance_id)
                
            #     # æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€
            #     await execution_engine._check_workflow_completion(workflow_instance_id)
                
            #     logger.info(f"ğŸ¯ subdivisionå®Œæˆåå·²è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹æ£€æŸ¥å’Œå·¥ä½œæµç»§ç»­æ‰§è¡Œ")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœåˆ°ä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    # ============ subdivisioné€‰æ‹©ç®¡ç†æ–¹æ³• ============
    
    async def select_subdivision(self, subdivision_id: uuid.UUID, user_id: uuid.UUID) -> bool:
        """
        é€‰æ‹©ä¸€ä¸ªsubdivisionä½œä¸ºæœ€ç»ˆæ–¹æ¡ˆï¼Œå¹¶å°†åŒä»»åŠ¡çš„å…¶ä»–subdivisionè®¾ä¸ºéé€‰æ‹©çŠ¶æ€
        
        Args:
            subdivision_id: è¦é€‰æ‹©çš„subdivision ID
            user_id: æ“ä½œç”¨æˆ·ID
            
        Returns:
            bool: æ“ä½œæ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"ğŸ¯ é€‰æ‹©subdivision: {subdivision_id}")
            
            # 1. éªŒè¯subdivisionå­˜åœ¨ä¸”æœ‰æƒé™
            subdivision = await self.subdivision_repo.get_subdivision_by_id(subdivision_id)
            if not subdivision:
                raise ValidationError("ç»†åˆ†ä¸å­˜åœ¨")
                
            if str(subdivision.get('subdivider_id')) != str(user_id):
                raise ValidationError("åªèƒ½é€‰æ‹©è‡ªå·±åˆ›å»ºçš„ç»†åˆ†")
            
            original_task_id = subdivision['original_task_id']
            
            # 2. è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…å­—ç¬¦é›†å†²çª
            subdivision_id_str = str(subdivision_id)
            user_id_str = str(user_id)
            original_task_id_str = str(original_task_id)
            
            logger.info(f"   åŸå§‹ä»»åŠ¡ID: {original_task_id_str}")
            logger.info(f"   æ“ä½œç”¨æˆ·ID: {user_id_str}")
            
            # 3. å¼€å¯äº‹åŠ¡ï¼Œç¡®ä¿åŸå­æ“ä½œ
            async with self.subdivision_repo.db.transaction():
                # æ¸…é™¤åŒä»»åŠ¡çš„å…¶ä»–subdivisionçš„é€‰æ‹©çŠ¶æ€
                clear_query = """
                UPDATE task_subdivision 
                SET is_selected = FALSE, selected_at = NULL, updated_at = NOW()
                WHERE original_task_id = %s AND subdivision_id != %s
                """
                
                clear_result = await self.subdivision_repo.db.execute(
                    clear_query, 
                    original_task_id_str, subdivision_id_str
                )
                logger.info(f"   æ¸…é™¤å…¶ä»–subdivisioné€‰æ‹©çŠ¶æ€ï¼Œå½±å“ {clear_result} è¡Œ")
                
                # è®¾ç½®å½“å‰subdivisionä¸ºé€‰æ‹©çŠ¶æ€
                select_query = """
                UPDATE task_subdivision 
                SET is_selected = TRUE, selected_at = NOW(), updated_at = NOW()
                WHERE subdivision_id = %s
                """
                
                select_result = await self.subdivision_repo.db.execute(
                    select_query, 
                    subdivision_id_str
                )
                logger.info(f"   è®¾ç½®å½“å‰subdivisionä¸ºé€‰æ‹©çŠ¶æ€ï¼Œå½±å“ {select_result} è¡Œ")
                
                if select_result == 0:
                    raise ValueError("æ›´æ–°subdivisioné€‰æ‹©çŠ¶æ€å¤±è´¥")
            
            logger.info(f"âœ… subdivisioné€‰æ‹©æˆåŠŸ: {subdivision_id}")
            return True
            
        except Exception as e:
            logger.error(f"é€‰æ‹©subdivisionå¤±è´¥: {e}")
            raise
    
    async def get_selected_subdivision(self, task_id: uuid.UUID) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡çš„å·²é€‰æ‹©subdivision"""
        try:
            query = """
            SELECT 
                ts.*,
                u.username as subdivider_name,
                w.name as sub_workflow_name,
                (SELECT COUNT(*) FROM node n 
                 WHERE n.workflow_base_id = ts.sub_workflow_base_id 
                 AND n.is_deleted = FALSE) as total_sub_nodes,
                (SELECT COUNT(*) FROM node_instance ni 
                 JOIN node n ON ni.node_id = n.node_id
                 WHERE n.workflow_base_id = ts.sub_workflow_base_id 
                 AND ni.workflow_instance_id = ts.sub_workflow_instance_id
                 AND ni.status = 'completed'
                 AND ni.is_deleted = FALSE) as completed_sub_nodes
            FROM task_subdivision ts
            LEFT JOIN "user" u ON ts.subdivider_id = u.user_id
            LEFT JOIN workflow w ON ts.sub_workflow_base_id = w.workflow_base_id 
                AND w.is_current_version = TRUE
            WHERE ts.original_task_id = %s 
                AND ts.is_selected = TRUE 
                AND ts.is_deleted = FALSE
            """
            
            result = await self.subdivision_repo.db.fetch_one(query, task_id)
            return dict(result) if result else None
            
        except Exception as e:
            logger.error(f"è·å–å·²é€‰æ‹©subdivisionå¤±è´¥: {e}")
            raise
    
    async def cleanup_unselected_subdivisions(self, task_id: uuid.UUID, 
                                           keep_count: int = 3) -> int:
        """
        æ¸…ç†æœªé€‰æ‹©çš„subdivisionè®°å½•ï¼Œä¿ç•™æœ€è¿‘çš„å‡ ä¸ª
        
        Args:
            task_id: ä»»åŠ¡ID
            keep_count: ä¿ç•™çš„è®°å½•æ•°ï¼ˆé™¤äº†å·²é€‰æ‹©çš„ï¼‰
            
        Returns:
            int: æ¸…ç†çš„è®°å½•æ•°
        """
        try:
            logger.info(f"ğŸ§¹ å¼€å§‹æ¸…ç†ä»»åŠ¡ {task_id} çš„æœªé€‰æ‹©subdivision")
            
            # è·å–è¦åˆ é™¤çš„subdivision IDs
            query = """
            SELECT subdivision_id 
            FROM task_subdivision 
            WHERE original_task_id = %s 
                AND is_selected = FALSE 
                AND is_deleted = FALSE
            ORDER BY subdivision_created_at DESC
            OFFSET %s
            """
            
            to_delete_result = await self.subdivision_repo.db.fetch_all(
                query, task_id, keep_count
            )
            
            if not to_delete_result:
                logger.info("æ²¡æœ‰éœ€è¦æ¸…ç†çš„subdivision")
                return 0
            
            to_delete_ids = [row['subdivision_id'] for row in to_delete_result]
            
            # è½¯åˆ é™¤è¿™äº›è®°å½•
            deleted_count = 0
            for subdivision_id in to_delete_ids:
                success = await self.subdivision_repo.delete_subdivision(
                    subdivision_id, soft_delete=True
                )
                if success:
                    deleted_count += 1
            
            logger.info(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªæœªé€‰æ‹©çš„subdivision")
            return deleted_count
            
        except Exception as e:
            logger.error(f"æ¸…ç†æœªé€‰æ‹©subdivisionå¤±è´¥: {e}")
            raise

    # ============ ä¿æŒå…¼å®¹æ€§çš„æ–¹æ³• ============
    
    async def get_task_subdivisions(self, task_id: uuid.UUID) -> List[TaskSubdivisionResponse]:
        """è·å–ä»»åŠ¡çš„æ‰€æœ‰ç»†åˆ† - å…¼å®¹æ¥å£"""
        subdivisions = await self.subdivision_repo.get_subdivisions_by_task(task_id)
        return [await self._format_subdivision_response(subdivision) for subdivision in subdivisions]
    
    async def get_subdivision_workflow_instance(self, subdivision_id: uuid.UUID) -> Optional[Dict[str, Any]]:
        """è·å–ç»†åˆ†çš„å­å·¥ä½œæµå®ä¾‹ä¿¡æ¯ - å…¼å®¹æ¥å£"""
        subdivision = await self.subdivision_repo.get_subdivision_by_id(subdivision_id)
        if not subdivision:
            return None
            
        instance_id = subdivision.get('sub_workflow_instance_id')
        if not instance_id:
            return None
            
        from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
        workflow_instance_repo = WorkflowInstanceRepository()
        
        return await workflow_instance_repo.get_instance_by_id(uuid.UUID(instance_id))
    
    async def _format_subdivision_response(self, subdivision: Dict[str, Any], 
                                         extra_data: Optional[Dict[str, Any]] = None) -> TaskSubdivisionResponse:
        """æ ¼å¼åŒ–ç»†åˆ†å“åº” - å…¼å®¹æ¥å£"""
        extra_data = extra_data or {}
        
        sub_workflow_base_id = extra_data.get('sub_workflow_base_id') or subdivision.get('sub_workflow_base_id')
        if sub_workflow_base_id is None:
            sub_workflow_base_id = uuid.uuid4()  # é˜²æŠ¤æªæ–½
            
        return TaskSubdivisionResponse(
            subdivision_id=subdivision['subdivision_id'],
            original_task_id=subdivision['original_task_id'],
            original_task_title=extra_data.get('original_task_title'),
            subdivider_id=subdivision['subdivider_id'],
            subdivider_name=subdivision.get('subdivider_name'),
            sub_workflow_base_id=sub_workflow_base_id,
            sub_workflow_instance_id=extra_data.get('sub_workflow_instance_id') or subdivision.get('sub_workflow_instance_id'),
            subdivision_name=subdivision['subdivision_name'],
            subdivision_description=subdivision['subdivision_description'],
            status=TaskSubdivisionStatus(subdivision['status']),
            is_selected=subdivision.get('is_selected', False),
            selected_at=subdivision.get('selected_at').isoformat() if subdivision.get('selected_at') else None,
            parent_task_description=subdivision.get('parent_task_description', ''),
            context_passed=subdivision.get('context_passed', ''),
            subdivision_created_at=subdivision['subdivision_created_at'].isoformat(),
            completed_at=subdivision['completed_at'].isoformat() if subdivision.get('completed_at') else None,
            sub_workflow_name=extra_data.get('sub_workflow_name'),
            total_sub_nodes=subdivision.get('total_sub_nodes', 0),
            completed_sub_nodes=subdivision.get('completed_sub_nodes', 0)
        )
    
    def _format_subdivision_output(self, workflow_results: dict) -> str:
        """æ ¼å¼åŒ–ç»†åˆ†å·¥ä½œæµè¾“å‡ºä¸ºå¯è¯»æ–‡æœ¬"""
        try:
            if not workflow_results:
                return "å­å·¥ä½œæµå°šæœªäº§ç”Ÿä»»ä½•è¾“å‡ºç»“æœã€‚"
            
            # æå–å…³é”®ä¿¡æ¯
            status = workflow_results.get('status', 'unknown')
            final_output = workflow_results.get('final_output', '')
            total_tasks = workflow_results.get('total_tasks', 0)
            completed_tasks = workflow_results.get('completed_tasks', 0)
            failed_tasks = workflow_results.get('failed_tasks', 0)
            
            # æ„å»ºæ ¼å¼åŒ–è¾“å‡º
            formatted_lines = []
            formatted_lines.append("=== å­å·¥ä½œæµæ‰§è¡Œç»“æœ ===")
            formatted_lines.append(f"æ‰§è¡ŒçŠ¶æ€: {status}")
            
            if total_tasks > 0:
                formatted_lines.append(f"ä»»åŠ¡ç»Ÿè®¡: æ€»è®¡ {total_tasks} ä¸ªä»»åŠ¡ï¼Œå·²å®Œæˆ {completed_tasks} ä¸ªï¼Œå¤±è´¥ {failed_tasks} ä¸ª")
            
            if final_output:
                formatted_lines.append("\n=== æœ€ç»ˆè¾“å‡º ===")
                formatted_lines.append(final_output)
            
            # å¦‚æœæœ‰ä»»åŠ¡æ‰§è¡Œè¯¦æƒ…
            if workflow_results.get('task_outputs'):
                formatted_lines.append("\n=== ä»»åŠ¡æ‰§è¡Œè¯¦æƒ… ===")
                for i, task_output in enumerate(workflow_results.get('task_outputs', []), 1):
                    if isinstance(task_output, dict):
                        task_title = task_output.get('task_title', f'ä»»åŠ¡ {i}')
                        task_result = task_output.get('result_data', task_output.get('output_data', ''))
                        formatted_lines.append(f"{i}. {task_title}")
                        if task_result:
                            # é™åˆ¶æ¯ä¸ªä»»åŠ¡ç»“æœçš„é•¿åº¦
                            result_preview = str(task_result)[:300]
                            if len(str(task_result)) > 300:
                                result_preview += "..."
                            formatted_lines.append(f"   ç»“æœ: {result_preview}")
                        formatted_lines.append("")
            
            formatted_lines.append("=== ç»“æœç»“æŸ ===")
            
            return "\n".join(formatted_lines)
            
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–ç»†åˆ†è¾“å‡ºå¤±è´¥: {e}")
            return f"æ ¼å¼åŒ–è¾“å‡ºæ—¶å‡ºç°é”™è¯¯: {str(e)}"


# åˆ›å»ºé‡æ„åçš„æœåŠ¡å®ä¾‹
task_subdivision_service = TaskSubdivisionService()