"""
å·¥ä½œæµæ‰§è¡Œå¼•æ“æœåŠ¡
Workflow Execution Engine Service
"""

import uuid
import json
import asyncio
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta
import sys
from loguru import logger
logger.remove()
logger.add(sys.stderr,level="WARNING")

from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
from ..repositories.instance.task_instance_repository import TaskInstanceRepository
from ..repositories.workflow.workflow_repository import WorkflowRepository
from ..repositories.node.node_repository import NodeRepository
from ..repositories.processor.processor_repository import ProcessorRepository
from ..repositories.user.user_repository import UserRepository
from ..repositories.agent.agent_repository import AgentRepository
from ..models.instance import (
    WorkflowInstanceCreate, WorkflowInstanceUpdate, WorkflowInstanceStatus,
    TaskInstanceCreate, TaskInstanceUpdate, TaskInstanceStatus, TaskInstanceType,
    WorkflowExecuteRequest
)
from ..models.node import NodeType
from ..utils.helpers import now_utc
from .agent_task_service import agent_task_service
from .resource_cleanup_manager import ResourceCleanupManager

# ä½¿ç”¨æ–°çš„ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
from .workflow_execution_context import get_context_manager, WorkflowExecutionContext

def _json_serializer(obj):
    """è‡ªå®šä¹‰JSONåºåˆ—åŒ–å‡½æ•°ï¼Œå¤„ç†datetimeå¯¹è±¡"""
    if isinstance(obj, datetime):
        return obj.isoformat()
    raise TypeError(f"Object of type {obj.__class__.__name__} is not JSON serializable")


class ExecutionEngine:
    """å·¥ä½œæµæ‰§è¡Œå¼•æ“ - ç®€åŒ–ç‰ˆæœ¬
    
    è´Ÿè´£ï¼š
    - å·¥ä½œæµå®ä¾‹çš„å¯åŠ¨å’Œç®¡ç†
    - èŠ‚ç‚¹å®ä¾‹çš„åˆ›å»ºå’Œæ‰§è¡Œ
    - ä»»åŠ¡å®ä¾‹çš„åˆ›å»ºå’Œè°ƒåº¦
    - å·¥ä½œæµçŠ¶æ€çš„ç»Ÿä¸€ç®¡ç†
    """
    
    def __init__(self):
        # æ•°æ®è®¿é—®å±‚
        self.workflow_instance_repo = WorkflowInstanceRepository()
        self.task_instance_repo = TaskInstanceRepository()
        self.workflow_repo = WorkflowRepository()
        self.node_repo = NodeRepository()
        self.processor_repo = ProcessorRepository()
        self.user_repo = UserRepository()
        self.agent_repo = AgentRepository()
        
        # æ‰§è¡Œé˜Ÿåˆ—å’ŒçŠ¶æ€è·Ÿè¸ª
        self.execution_queue = asyncio.Queue()
        self.running_instances = {}  # è¿è¡Œä¸­çš„å®ä¾‹è·Ÿè¸ª
        self.is_running = False
        
        # ä»»åŠ¡å®Œæˆå›è°ƒæ˜ å°„
        self.task_callbacks = {}
        
        # ç³»ç»Ÿç»„ä»¶
        self.resource_cleanup_manager = ResourceCleanupManager()
        
        # ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - ä½¿ç”¨æ–°çš„ç»Ÿä¸€æ¶æ„
        self.context_manager = get_context_manager()
        
        # ç›‘å¬å™¨è·Ÿè¸ª
        self.active_monitors = set()
        
        logger.debug("ğŸš€ åˆå§‹åŒ–ExecutionEngine")
    
    async def start_engine(self):
        """å¯åŠ¨æ‰§è¡Œå¼•æ“"""
        if self.is_running:
            logger.warning("æ‰§è¡Œå¼•æ“å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.is_running = True
        logger.trace("å·¥ä½œæµæ‰§è¡Œå¼•æ“å¯åŠ¨")
        
        # å‘ä¸‹å…¼å®¹æ£€æŸ¥ - ç¡®ä¿context_managerå·²æ­£ç¡®åˆå§‹åŒ–
        if self.context_manager is None:
            logger.error("ä¸Šä¸‹æ–‡ç®¡ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–")
            raise RuntimeError("ä¸Šä¸‹æ–‡ç®¡ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–")
        
        # æ³¨å†Œä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„å›è°ƒ
        self.context_manager.register_completion_callback(self._on_nodes_ready_to_execute)
        
        # æ³¨å†Œä¸ºAgentTaskServiceçš„å›è°ƒç›‘å¬å™¨
        agent_task_service.register_completion_callback(self)
        logger.trace("å·²æ³¨å†Œå›è°ƒç›‘å¬å™¨")
        
        # å¯åŠ¨ä»»åŠ¡å¤„ç†åç¨‹
        asyncio.create_task(self._process_execution_queue())
        asyncio.create_task(self._monitor_running_instances())
    
    async def stop_engine(self):
        """åœæ­¢æ‰§è¡Œå¼•æ“"""
        self.is_running = False
        
        # åœæ­¢èµ„æºæ¸…ç†ç®¡ç†å™¨
        if self.resource_cleanup_manager:
            await self.resource_cleanup_manager.stop_manager()
        
        logger.trace("å·¥ä½œæµæ‰§è¡Œå¼•æ“åœæ­¢")
    
    async def execute_workflow(self, request: WorkflowExecuteRequest, 
                             executor_id: uuid.UUID) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥ä½œæµ"""
        try:
            logger.trace(f"å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {request.workflow_base_id}, æ‰§è¡Œè€…: {executor_id}")
            # 1. éªŒè¯å·¥ä½œæµæ˜¯å¦å­˜åœ¨ä¸”å¯æ‰§è¡Œ
            logger.trace(f"æ­¥éª¤1: æŸ¥è¯¢å·¥ä½œæµ {request.workflow_base_id}")
            workflow = await self.workflow_repo.get_workflow_by_base_id(request.workflow_base_id)
            if not workflow:
                logger.error(f"å·¥ä½œæµä¸å­˜åœ¨: {request.workflow_base_id}")
                raise ValueError("å·¥ä½œæµä¸å­˜åœ¨")
            
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å…·ä½“çš„workflow_idè€Œä¸æ˜¯base_id
            workflow_id = workflow['workflow_id']
            logger.trace(f"âœ… å·¥ä½œæµæŸ¥è¯¢æˆåŠŸ: {workflow.get('name', 'Unknown')} (ç‰ˆæœ¬ID: {workflow_id})")
            
            # 1.5. æ£€æŸ¥æ˜¯å¦å·²æœ‰æ­£åœ¨è¿è¡Œçš„å®ä¾‹
            logger.trace(f"æ­¥éª¤1.5: æ£€æŸ¥æ˜¯å¦å·²æœ‰æ­£åœ¨è¿è¡Œçš„å·¥ä½œæµå®ä¾‹")
            existing_instances = await self._check_running_instances(request.workflow_base_id, executor_id)
            if existing_instances:
                logger.trace(f"âœ… å‘ç°å·²æœ‰æ­£åœ¨è¿è¡Œçš„å®ä¾‹: {len(existing_instances)} ä¸ª")
                latest_instance = existing_instances[0]  # è·å–æœ€æ–°çš„å®ä¾‹
                logger.trace(f"è¿”å›ç°æœ‰å®ä¾‹: {latest_instance['workflow_instance_name']} (ID: {latest_instance['workflow_instance_id']})")
                return {
                    'instance_id': latest_instance['workflow_instance_id'],
                    'status': latest_instance['status'],
                    'message': 'å·¥ä½œæµå·²åœ¨è¿è¡Œä¸­ï¼Œè¿”å›ç°æœ‰å®ä¾‹'
                }
            
            # 2. åˆ›å»ºå·¥ä½œæµå®ä¾‹
            logger.trace(f"æ­¥éª¤2: åˆ›å»ºå·¥ä½œæµå®ä¾‹ '{request.workflow_instance_name}'")
            instance_data = WorkflowInstanceCreate(
                workflow_base_id=request.workflow_base_id,
                executor_id=executor_id,
                workflow_instance_name=request.workflow_instance_name,
                input_data=request.input_data,
                context_data=request.context_data
            )
            
            instance = await self.workflow_instance_repo.create_instance(instance_data)
            if not instance:
                logger.error("åˆ›å»ºå·¥ä½œæµå®ä¾‹å¤±è´¥")
                raise RuntimeError("åˆ›å»ºå·¥ä½œæµå®ä¾‹å¤±è´¥")
            
            instance_id = instance['workflow_instance_id']
            logger.trace(f"âœ… å·¥ä½œæµå®ä¾‹åˆ›å»ºæˆåŠŸ: {request.workflow_instance_name} (ID: {instance_id})")
            
            # 3. è·å–å·¥ä½œæµçš„æ‰€æœ‰èŠ‚ç‚¹ï¼ˆä½¿ç”¨å…·ä½“ç‰ˆæœ¬IDï¼‰
            logger.trace(f"æ­¥éª¤3: æŸ¥è¯¢å·¥ä½œæµç‰ˆæœ¬ {workflow_id} çš„æ‰€æœ‰èŠ‚ç‚¹")
            nodes = await self._get_workflow_nodes_by_version_id(workflow_id)
            
            if not nodes:
                logger.error(f"å·¥ä½œæµæ²¡æœ‰èŠ‚ç‚¹: {workflow_id}")
                raise ValueError("å·¥ä½œæµæ²¡æœ‰èŠ‚ç‚¹")
            
            logger.trace(f"âœ… æ‰¾åˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹:")
            for i, node in enumerate(nodes, 1):
                logger.trace(f"   èŠ‚ç‚¹{i}: {node['name']} (ç±»å‹: {node['type']}, å…·ä½“ID: {node['node_id']})")
            
            # 4. è·å–èŠ‚ç‚¹è¿æ¥å…³ç³»
            logger.trace(f"æ­¥éª¤4: æŸ¥è¯¢å·¥ä½œæµèŠ‚ç‚¹è¿æ¥å…³ç³»")
            connections = []
            try:
                if hasattr(self.node_repo, 'get_workflow_connections'):
                    connections = await self.node_repo.get_workflow_connections(request.workflow_base_id)
                    logger.trace(f"âœ… æ‰¾åˆ° {len(connections)} ä¸ªè¿æ¥:")
                    for i, conn in enumerate(connections, 1):
                        logger.trace(f"   è¿æ¥{i}: {conn.get('from_node_name', 'Unknown')} -> {conn.get('to_node_name', 'Unknown')}")
                else:
                    logger.warning("èŠ‚ç‚¹ä»“åº“ä¸æ”¯æŒè·å–è¿æ¥å…³ç³»")
            except Exception as e:
                logger.warning(f"è·å–å·¥ä½œæµè¿æ¥å¤±è´¥: {e}")
                connections = []
            
            # 5. åˆå§‹åŒ–å·¥ä½œæµä¸Šä¸‹æ–‡
            logger.trace(f"æ­¥éª¤5: åˆå§‹åŒ–å·¥ä½œæµä¸Šä¸‹æ–‡")
            try:
                await self.context_manager.initialize_workflow_context(instance_id)
                logger.trace(f"âœ… å·¥ä½œæµä¸Šä¸‹æ–‡åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"å·¥ä½œæµä¸Šä¸‹æ–‡åˆå§‹åŒ–å¤±è´¥: {e}")
                raise
            
            # 6. åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å’Œæ³¨å†Œä¾èµ–å…³ç³»ï¼ˆä¸åˆ›å»ºä»»åŠ¡å®ä¾‹ï¼‰
            logger.trace(f"æ­¥éª¤6: åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å’Œä¾èµ–å…³ç³»")
            try:
                await self._create_node_instances_with_dependencies(instance_id, workflow_id, nodes)
                logger.trace(f"âœ… èŠ‚ç‚¹å®ä¾‹å’Œä¾èµ–å…³ç³»åˆ›å»ºå®Œæˆ")
            except Exception as e:
                logger.error(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å’Œä¾èµ–å…³ç³»å¤±è´¥: {e}")
                raise
            
            # 7. å¯åŠ¨æ‰§è¡Œï¼ˆåªå¯åŠ¨STARTèŠ‚ç‚¹ï¼‰
            logger.trace(f"æ­¥éª¤7: å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ")
            try:
                await self._start_workflow_execution_with_dependencies(instance_id, workflow_id)
                logger.trace(f"âœ… å·¥ä½œæµæ‰§è¡Œå¯åŠ¨å®Œæˆ")
                
                # è¾“å‡ºæ‰§è¡Œå¯åŠ¨çš„å®Œæ•´çŠ¶æ€
                print(f"\nğŸš€ ã€å·¥ä½œæµå¯åŠ¨æˆåŠŸã€‘")
                print(f"å·¥ä½œæµ: {workflow.get('name', 'Unknown')}")
                print(f"å®ä¾‹åç§°: {request.workflow_instance_name}")
                print(f"å®ä¾‹ID: {instance_id} - æ–°æ¶æ„")
                print(f"æ‰§è¡Œè€…: {executor_id}")
                print(f"èŠ‚ç‚¹æ•°é‡: {len(nodes)}")
                print(f"çŠ¶æ€: RUNNING")
                print(f"æ¶æ„: æ–°ä¸€ä»£ä¸Šä¸‹æ–‡ç®¡ç†")
                print(f"å¯åŠ¨æ—¶é—´: {now_utc().strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"è¯·å…³æ³¨åç»­çš„ä»»åŠ¡åˆ†é…æ—¥å¿—...")
                print("=" * 60)
                
                # ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œæ‘˜è¦ï¼ˆå»¶è¿Ÿä¸€ç‚¹ï¼Œè®©ä»»åŠ¡åˆ›å»ºå®Œæˆï¼‰
                try:
                    import asyncio
                    await asyncio.sleep(1)  # ç­‰å¾…1ç§’è®©ä»»åŠ¡åˆ›å»ºå®Œæˆ
                    await self._log_workflow_execution_summary(instance_id)
                except Exception as e:
                    logger.warning(f"ç”Ÿæˆæ‰§è¡Œæ‘˜è¦å¤±è´¥: {e}")
                
            except Exception as e:
                logger.error(f"å¯åŠ¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
                raise
            
            return {
                'instance_id': instance_id,
                'status': WorkflowInstanceStatus.RUNNING.value,
                'message': 'å·¥ä½œæµå¼€å§‹æ‰§è¡Œ'
            }
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œå·¥ä½œæµå¤±è´¥: {e}")
            raise
    
    async def _get_workflow_nodes_by_version_id(self, workflow_id: uuid.UUID) -> List[Dict[str, Any]]:
        """é€šè¿‡å·¥ä½œæµç‰ˆæœ¬IDè·å–æ‰€æœ‰èŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆæœ¬ - ä½¿ç”¨å½“å‰ç‰ˆæœ¬é€»è¾‘ï¼‰"""
        try:
            # é¦–å…ˆè·å–workflow_base_idï¼Œç„¶åæŸ¥è¯¢å½“å‰ç‰ˆæœ¬çš„èŠ‚ç‚¹
            workflow_query = """
                SELECT workflow_base_id 
                FROM workflow 
                WHERE workflow_id = $1 AND is_deleted = FALSE
            """
            workflow_result = await self.node_repo.db.fetch_one(workflow_query, workflow_id)
            
            if not workflow_result:
                logger.error(f"å·¥ä½œæµç‰ˆæœ¬ä¸å­˜åœ¨: {workflow_id}")
                return []
            
            workflow_base_id = workflow_result['workflow_base_id']
            logger.trace(f"å·¥ä½œæµç‰ˆæœ¬ {workflow_id} å¯¹åº”çš„base_id: {workflow_base_id}")
            
            # æŸ¥è¯¢å½“å‰ç‰ˆæœ¬çš„æ‰€æœ‰èŠ‚ç‚¹
            query = """
                SELECT 
                    n.*,
                    np.processor_id
                FROM "node" n
                LEFT JOIN node_processor np ON np.node_id = n.node_id
                WHERE n.workflow_base_id = $1 
                AND n.is_current_version = TRUE
                AND n.is_deleted = FALSE
                ORDER BY n.created_at ASC
            """
            results = await self.node_repo.db.fetch_all(query, workflow_base_id)
            logger.trace(f"âœ… é€šè¿‡base_id {workflow_base_id} è·å–å½“å‰ç‰ˆæœ¬èŠ‚ç‚¹ {len(results)} ä¸ª")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å½“å‰ç‰ˆæœ¬èŠ‚ç‚¹ï¼Œå°è¯•ç›´æ¥ç”¨workflow_idæŸ¥è¯¢
            if not results:
                logger.warning(f"é€šè¿‡base_idæœªæ‰¾åˆ°èŠ‚ç‚¹ï¼Œå°è¯•ç›´æ¥æŸ¥è¯¢workflow_id: {workflow_id}")
                fallback_query = """
                    SELECT 
                        n.*,
                        np.processor_id
                    FROM "node" n
                    LEFT JOIN node_processor np ON np.node_id = n.node_id
                    WHERE n.workflow_id = $1 
                    AND n.is_deleted = FALSE
                    ORDER BY n.created_at ASC
                """
                results = await self.node_repo.db.fetch_all(fallback_query, workflow_id)
                logger.trace(f"âœ… é€šè¿‡workflow_id {workflow_id} fallbackæŸ¥è¯¢è·å–åˆ° {len(results)} ä¸ªèŠ‚ç‚¹")
            
            return results
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµèŠ‚ç‚¹åˆ—è¡¨å¤±è´¥: {e}")
            raise
    
    async def _check_running_instances(self, workflow_base_id: uuid.UUID, executor_id: uuid.UUID) -> List[Dict]:
        """æ£€æŸ¥æ˜¯å¦å·²æœ‰æ­£åœ¨è¿è¡Œçš„å·¥ä½œæµå®ä¾‹"""
        try:
            from ..models.instance import WorkflowInstanceStatus
            
            # æŸ¥è¯¢æ­£åœ¨è¿è¡Œçš„å·¥ä½œæµå®ä¾‹
            query = """
            SELECT wi.*
            FROM workflow_instance wi
            WHERE wi.workflow_base_id = $1
            AND wi.executor_id = $2
            AND wi.status IN ('RUNNING', 'PAUSED')
            AND wi.is_deleted = FALSE
            ORDER BY wi.created_at DESC
            """
            
            running_instances = await self.workflow_instance_repo.db.fetch_all(
                query, workflow_base_id, executor_id
            )
            
            logger.trace(f"æ‰¾åˆ° {len(running_instances)} ä¸ªæ­£åœ¨è¿è¡Œçš„å·¥ä½œæµå®ä¾‹")
            return running_instances
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥è¿è¡Œå®ä¾‹å¤±è´¥: {e}")
            return []
    
    async def _create_node_instances(self, workflow_instance_id: uuid.UUID, nodes: List[Dict[str, Any]]):
        """åˆ›å»ºèŠ‚ç‚¹å®ä¾‹"""
        try:
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceCreate, NodeInstanceStatus
            
            node_instance_repo = NodeInstanceRepository()
            
            for node in nodes:
                # 1. å…ˆåˆ›å»ºèŠ‚ç‚¹å®ä¾‹
                node_instance_data = NodeInstanceCreate(
                    workflow_instance_id=workflow_instance_id,
                    node_id=node['node_id'],
                    node_base_id=node['node_base_id'],  # æ·»åŠ ç¼ºå¤±çš„node_base_id
                    node_instance_name=f"{node['name']}_instance",
                    task_description=node.get('task_description', ''),
                    status=NodeInstanceStatus.PENDING,
                    input_data={},
                    output_data={},
                    error_message=None,
                    retry_count=0
                )
                
                node_instance = await node_instance_repo.create_node_instance(node_instance_data)
                if not node_instance:
                    logger.error(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¤±è´¥: {node['name']}")
                    continue
                
                node_instance_id = node_instance['node_instance_id']
                logger.trace(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹: {node['name']} (ID: {node_instance_id})")
                
                # 2. ä¸ºå¤„ç†å™¨èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹
                if node['type'] == NodeType.PROCESSOR.value:
                    # è·å–èŠ‚ç‚¹çš„å¤„ç†å™¨ï¼ˆä¿®å¤ï¼šä½¿ç”¨node_idï¼‰
                    processors = await self._get_node_processors(node['node_id'])
                    
                    for processor in processors:
                        # æ ¹æ®å¤„ç†å™¨ç±»å‹ç¡®å®šä»»åŠ¡ç±»å‹å’Œåˆ†é…
                        processor_type = processor.get('processor_type', processor.get('type', 'HUMAN'))
                        task_type = self._determine_task_type(processor_type)
                        assigned_user_id = processor.get('user_id')
                        assigned_agent_id = processor.get('agent_id')
                        
                        # åˆ›å»ºä»»åŠ¡å®ä¾‹
                        task_title = node['name']
                        task_description = node.get('task_description') or node.get('description') or f"æ‰§è¡ŒèŠ‚ç‚¹ {node['name']} çš„ä»»åŠ¡"
                        
                        # æ”¶é›†ä»»åŠ¡ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆä½¿ç”¨WorkflowContextManagerï¼‰
                        context_data = await self.context_manager.get_task_context_data(workflow_instance_id, node_instance_id)
                        
                        # å°†ä¸Šä¸‹æ–‡æ•°æ®è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
                        context_text = json.dumps(context_data, ensure_ascii=False, indent=2, default=_json_serializer) if context_data else ""
                        input_text = json.dumps(node.get('input_data', {}), ensure_ascii=False, indent=2, default=_json_serializer)
                        
                        task_data = TaskInstanceCreate(
                            node_instance_id=node_instance_id,  # ä½¿ç”¨çœŸå®çš„èŠ‚ç‚¹å®ä¾‹ID
                            workflow_instance_id=workflow_instance_id,
                            processor_id=processor['processor_id'],
                            task_type=task_type,
                            task_title=task_title,
                            task_description=task_description,
                            input_data=input_text,
                            context_data=context_text,
                            assigned_user_id=assigned_user_id,
                            assigned_agent_id=assigned_agent_id,
                            estimated_duration=30
                        )
                        
                        task = await self.task_instance_repo.create_task(task_data)
                        if task:
                            logger.trace(f"åˆ›å»ºä»»åŠ¡å®ä¾‹: {task['task_title']} (ID: {task['task_instance_id']})")
                        
        except Exception as e:
            logger.error(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¤±è´¥: {e}")
            raise
    
    async def _get_node_processors(self, node_id: uuid.UUID):
        """è·å–èŠ‚ç‚¹çš„å¤„ç†å™¨åˆ—è¡¨ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼šä½¿ç”¨å…·ä½“node_idï¼‰"""
        try:
            query = """
                SELECT np.*, p.name as processor_name, p.type as processor_type,
                       u.username, a.agent_name, p.user_id, p.agent_id
                FROM node_processor np
                JOIN processor p ON p.processor_id = np.processor_id AND p.is_deleted = FALSE
                LEFT JOIN "user" u ON u.user_id = p.user_id AND u.is_deleted = FALSE
                LEFT JOIN agent a ON a.agent_id = p.agent_id AND a.is_deleted = FALSE
                WHERE np.node_id = $1
                ORDER BY np.created_at ASC
            """
            results = await self.processor_repo.db.fetch_all(query, node_id)
            return results
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹å¤„ç†å™¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    async def _get_next_nodes(self, node_id: uuid.UUID):
        """è·å–èŠ‚ç‚¹çš„ä¸‹æ¸¸èŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼šä½¿ç”¨å…·ä½“node_idï¼‰"""
        try:
            query = """
                SELECT tn.node_id as to_node_id
                FROM node_connection nc
                JOIN node tn ON tn.node_id = nc.to_node_id
                WHERE nc.from_node_id = $1
                ORDER BY nc.created_at ASC
            """
            results = await self.node_repo.db.fetch_all(query, node_id)
            return [result['to_node_id'] for result in results]
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            return []
    
    def _determine_task_type(self, processor_type: str) -> TaskInstanceType:
        """æ ¹æ®å¤„ç†å™¨ç±»å‹ç¡®å®šä»»åŠ¡ç±»å‹"""
        processor_type_upper = processor_type.upper() if processor_type else ""
        
        if processor_type_upper == "HUMAN":
            return TaskInstanceType.HUMAN
        elif processor_type_upper == "AGENT":
            return TaskInstanceType.AGENT
        elif processor_type_upper == "MIX" or processor_type_upper == "MIXED":
            return TaskInstanceType.MIXED
        else:
            # è®°å½•è°ƒè¯•ä¿¡æ¯
            logger.warning(f"æœªçŸ¥çš„å¤„ç†å™¨ç±»å‹: '{processor_type}' (è½¬æ¢å: '{processor_type_upper}')ï¼Œé»˜è®¤ä¸ºäººå·¥ä»»åŠ¡")
            return TaskInstanceType.HUMAN  # é»˜è®¤ä¸ºäººå·¥ä»»åŠ¡
    
    def _determine_task_priority(self, task_type: TaskInstanceType, node_data: Dict[str, Any]) -> int:
        """ç¡®å®šä»»åŠ¡ä¼˜å…ˆçº§ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™æ–¹æ³•é¿å…è°ƒç”¨é”™è¯¯ï¼‰"""
        try:
            # ä¼˜å…ˆçº§å­—æ®µå·²åºŸå¼ƒï¼Œè¿”å›é»˜è®¤å€¼
            return 1
                
        except Exception as e:
            logger.warning(f"ç¡®å®šä»»åŠ¡ä¼˜å…ˆçº§å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            return 1
    
    def _determine_task_duration(self, task_type: TaskInstanceType, node_data: Dict[str, Any]) -> int:
        """æ ¹æ®ä»»åŠ¡ç±»å‹å’ŒèŠ‚ç‚¹é…ç½®ç¡®å®šé¢„ä¼°æ‰§è¡Œæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"""
        try:
            # ä»èŠ‚ç‚¹æ•°æ®ä¸­è·å–é¢„ä¼°æ—¶é—´é…ç½®
            node_duration = node_data.get('estimated_duration', None)
            if node_duration is not None:
                return max(5, min(480, int(node_duration)))  # é™åˆ¶åœ¨5åˆ†é’Ÿåˆ°8å°æ—¶ä¹‹é—´
            
            # æ ¹æ®ä»»åŠ¡ç±»å‹è®¾ç½®é»˜è®¤é¢„ä¼°æ—¶é—´
            if task_type == TaskInstanceType.HUMAN:
                return 60  # äººå·¥ä»»åŠ¡é»˜è®¤1å°æ—¶
            elif task_type == TaskInstanceType.AGENT:
                return 15  # Agentä»»åŠ¡é»˜è®¤15åˆ†é’Ÿ
            elif task_type == TaskInstanceType.MIXED:
                return 45  # æ··åˆä»»åŠ¡é»˜è®¤45åˆ†é’Ÿ
            else:
                return 30  # é»˜è®¤30åˆ†é’Ÿ
                
        except Exception as e:
            logger.warning(f"ç¡®å®šä»»åŠ¡é¢„ä¼°æ—¶é—´å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            return 30
    
    async def _start_workflow_execution(self, instance_id: uuid.UUID, workflow_id: uuid.UUID):
        """å¯åŠ¨å·¥ä½œæµæ‰§è¡Œï¼ˆä¿®å¤ç‰ˆæœ¬ï¼šä½¿ç”¨å…·ä½“ç‰ˆæœ¬IDï¼‰"""
        try:
            # æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.RUNNING)
            await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            # æŸ¥æ‰¾å¼€å§‹èŠ‚ç‚¹ï¼ˆä½¿ç”¨å…·ä½“ç‰ˆæœ¬IDï¼‰
            nodes = await self._get_workflow_nodes_by_version_id(workflow_id)
            start_nodes = [node for node in nodes if node['type'] == NodeType.START.value]
            
            if not start_nodes:
                raise ValueError("å·¥ä½œæµæ²¡æœ‰å¼€å§‹èŠ‚ç‚¹")
            
            # å°†å·¥ä½œæµå®ä¾‹åŠ å…¥æ‰§è¡Œé˜Ÿåˆ—ï¼ˆä½¿ç”¨å…·ä½“node_idï¼‰
            execution_item = {
                'instance_id': instance_id,
                'workflow_id': workflow_id,
                'current_nodes': [node['node_id'] for node in start_nodes],
                'context_data': {}
            }
            
            await self.execution_queue.put(execution_item)
            self.running_instances[instance_id] = execution_item
            
            logger.trace(f"å·¥ä½œæµå®ä¾‹ {instance_id} å¼€å§‹æ‰§è¡Œ")
            
        except Exception as e:
            logger.error(f"å¯åŠ¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    async def _process_execution_queue(self):
        """å¤„ç†æ‰§è¡Œé˜Ÿåˆ—"""
        while self.is_running:
            try:
                # ä»é˜Ÿåˆ—è·å–æ‰§è¡Œé¡¹ç›®
                execution_item = await asyncio.wait_for(
                    self.execution_queue.get(), timeout=1.0
                )
                
                # å¤„ç†æ‰§è¡Œé¡¹ç›®
                await self._process_workflow_step(execution_item)
                
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"å¤„ç†æ‰§è¡Œé˜Ÿåˆ—å¤±è´¥: {e}")
                await asyncio.sleep(1)
    
    async def _process_workflow_step(self, execution_item: Dict[str, Any]):
        """å¤„ç†å·¥ä½œæµæ­¥éª¤"""
        try:
            instance_id = execution_item['instance_id']
            workflow_id = execution_item['workflow_id']
            current_nodes = execution_item['current_nodes']
            
            logger.trace(f"å¤„ç†å·¥ä½œæµå®ä¾‹ {instance_id} çš„èŠ‚ç‚¹: {current_nodes}")
            
            # å¤„ç†å½“å‰èŠ‚ç‚¹
            next_nodes = []
            for node_id in current_nodes:
                node_result = await self._process_node(instance_id, workflow_id, node_id)
                if node_result.get('next_nodes'):
                    next_nodes.extend(node_result['next_nodes'])
            
            # å¦‚æœæœ‰ä¸‹ä¸€æ­¥èŠ‚ç‚¹ï¼Œç»§ç»­æ‰§è¡Œ
            if next_nodes:
                execution_item['current_nodes'] = next_nodes
                await self.execution_queue.put(execution_item)
            else:
                # å·¥ä½œæµå®Œæˆ
                await self._complete_workflow(instance_id)
                
        except Exception as e:
            logger.error(f"å¤„ç†å·¥ä½œæµæ­¥éª¤å¤±è´¥: {e}")
            await self._fail_workflow(execution_item['instance_id'], str(e))
    
    async def _process_node(self, instance_id: uuid.UUID, workflow_id: uuid.UUID, 
                          node_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªèŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼šä½¿ç”¨å…·ä½“çš„node_idï¼‰"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šç›´æ¥é€šè¿‡node_idè·å–èŠ‚ç‚¹ä¿¡æ¯
            node = await self.node_repo.get_node_by_id(node_id)
            if not node:
                raise ValueError(f"èŠ‚ç‚¹ {node_id} ä¸å­˜åœ¨")
            
            node_type = node['type']
            logger.trace(f"å¤„ç†èŠ‚ç‚¹: {node['name']} (ç±»å‹: {node_type}, ID: {node_id})")
            
            if node_type == NodeType.START.value:
                # å¼€å§‹èŠ‚ç‚¹ç›´æ¥å®Œæˆ
                return await self._handle_start_node(instance_id, workflow_id, node_id)
            elif node_type == NodeType.END.value:
                # ç»“æŸèŠ‚ç‚¹
                return await self._handle_end_node(instance_id, workflow_id, node_id)
            elif node_type == NodeType.PROCESSOR.value:
                # å¤„ç†å™¨èŠ‚ç‚¹
                return await self._handle_processor_node(instance_id, workflow_id, node_id)
            else:
                logger.warning(f"æœªçŸ¥èŠ‚ç‚¹ç±»å‹: {node_type}")
                return {'next_nodes': []}
                
        except Exception as e:
            logger.error(f"å¤„ç†èŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _handle_start_node(self, instance_id: uuid.UUID, workflow_id: uuid.UUID, 
                                node_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†å¼€å§‹èŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰"""
        try:
            # è·å–ä¸‹æ¸¸èŠ‚ç‚¹
            next_nodes = await self._get_next_nodes(node_id)
            
            logger.trace(f"å¼€å§‹èŠ‚ç‚¹å¤„ç†å®Œæˆï¼Œä¸‹ä¸€æ­¥èŠ‚ç‚¹: {next_nodes}")
            return {'next_nodes': next_nodes}
            
        except Exception as e:
            logger.error(f"å¤„ç†å¼€å§‹èŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _handle_end_node(self, instance_id: uuid.UUID, workflow_id: uuid.UUID, 
                              node_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†ç»“æŸèŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰"""
        try:
            logger.trace(f"åˆ°è¾¾ç»“æŸèŠ‚ç‚¹ï¼Œå·¥ä½œæµå®ä¾‹ {instance_id} å³å°†å®Œæˆ")
            return {'next_nodes': []}  # æ²¡æœ‰ä¸‹ä¸€æ­¥èŠ‚ç‚¹
            
        except Exception as e:
            logger.error(f"å¤„ç†ç»“æŸèŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _handle_processor_node(self, instance_id: uuid.UUID, workflow_id: uuid.UUID, 
                                   node_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†å¤„ç†å™¨èŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šé€šè¿‡node_idæŸ¥æ‰¾ä»»åŠ¡å®ä¾‹
            tasks = await self.task_instance_repo.get_tasks_by_workflow_instance(instance_id)
            node_tasks = [task for task in tasks if task.get('node_instance', {}).get('node_id') == node_id]
            
            if not node_tasks:
                logger.warning(f"èŠ‚ç‚¹ {node_id} æ²¡æœ‰ä»»åŠ¡å®ä¾‹")
                return {'next_nodes': []}
            
            # å¯åŠ¨ä»»åŠ¡æ‰§è¡Œ
            for task in node_tasks:
                await self._execute_task(task)
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥å¼‚æ­¥ç­‰å¾…ï¼‰
            await asyncio.sleep(1)  # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œæ—¶é—´
            
            # è·å–ä¸‹æ¸¸èŠ‚ç‚¹
            next_nodes = await self._get_next_nodes(node_id)
            
            logger.trace(f"å¤„ç†å™¨èŠ‚ç‚¹å¤„ç†å®Œæˆï¼Œä¸‹ä¸€æ­¥èŠ‚ç‚¹: {next_nodes}")
            return {'next_nodes': next_nodes}
            
        except Exception as e:
            logger.error(f"å¤„ç†å¤„ç†å™¨èŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _execute_task(self, task: Dict[str, Any]):
        """æ‰§è¡Œå•ä¸ªä»»åŠ¡"""
        try:
            task_id = task['task_instance_id']
            task_type = task['task_type']
            
            logger.trace(f"æ‰§è¡Œä»»åŠ¡: {task['task_title']} (ç±»å‹: {task_type})")
            
            if task_type == TaskInstanceType.HUMAN.value:
                # äººå·¥ä»»åŠ¡ï¼šæ›´æ–°çŠ¶æ€ä¸ºå·²åˆ†é…ï¼Œç­‰å¾…äººå·¥å¤„ç†
                logger.trace(f"ğŸ‘¤ å¤„ç†äººå·¥ä»»åŠ¡: {task['task_title']}")
                logger.trace(f"   - ä»»åŠ¡ID: {task_id}")
                logger.trace(f"   - åˆ†é…ç›®æ ‡ç”¨æˆ·: {task.get('assigned_user_id')}")
                
                # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æœ‰åˆ†é…çš„ç”¨æˆ·
                assigned_user_id = task.get('assigned_user_id')
                if not assigned_user_id:
                    logger.warning(f"âš ï¸  äººå·¥ä»»åŠ¡æ²¡æœ‰åˆ†é…ç”¨æˆ·ï¼Œä»»åŠ¡å°†ä¿æŒPENDINGçŠ¶æ€")
                    logger.warning(f"   - ä»»åŠ¡ID: {task_id}")
                    logger.warning(f"   - ä»»åŠ¡æ ‡é¢˜: {task['task_title']}")
                    logger.warning(f"   - å»ºè®®: è¯·ä¸ºè¯¥ä»»åŠ¡çš„å¤„ç†å™¨é…ç½®ç”¨æˆ·")
                    return
                
                # ä»»åŠ¡åˆ›å»ºæ—¶å·²ç»è®¾ç½®äº†æ­£ç¡®çš„çŠ¶æ€ï¼Œè¿™é‡Œä¸éœ€è¦å†æ›´æ–°
                # ï¼ˆä»»åŠ¡åˆ›å»ºæ—¶å¦‚æœæœ‰assigned_user_idï¼ŒçŠ¶æ€å°±æ˜¯ASSIGNEDï¼‰
                logger.trace(f"   âœ… ä»»åŠ¡å·²å¤„äºæ­£ç¡®çŠ¶æ€ï¼Œæ— éœ€æ›´æ–°")
                
                # è·å–ä»»åŠ¡è¯¦ç»†ä¿¡æ¯ç”¨äºé€šçŸ¥
                task_title = task.get('task_title', 'æœªå‘½åä»»åŠ¡')
                workflow_name = task.get('workflow_name', 'æœªå‘½åå·¥ä½œæµ')
                estimated_duration = task.get('estimated_duration', 30)
                
                logger.trace(f"ğŸ“‹ äººå·¥ä»»åŠ¡åˆ†é…è¯¦æƒ…:")
                logger.trace(f"   - ä»»åŠ¡æ ‡é¢˜: {task_title}")
                logger.trace(f"   - å·¥ä½œæµ: {workflow_name}")
                logger.trace(f"   - åˆ†é…ç»™ç”¨æˆ·: {assigned_user_id}")
                logger.trace(f"   - é¢„ä¼°æ—¶é•¿: {estimated_duration}åˆ†é’Ÿ")
                logger.trace(f"   - ä»»åŠ¡æè¿°: {task.get('task_description', 'æ— æè¿°')[:100]}...")
                
                # å®æ—¶é€šçŸ¥ç”¨æˆ·æœ‰æ–°ä»»åŠ¡ - é‡è¦æ”¹è¿›ï¼
                try:
                    await self._notify_user_new_task(assigned_user_id, task_id, task_title)
                    logger.trace(f"   ğŸ“¬ ç”¨æˆ·é€šçŸ¥å·²å‘é€")
                except Exception as e:
                    logger.error(f"   âŒ å‘é€ç”¨æˆ·é€šçŸ¥å¤±è´¥: {e}")
                
                # è®°å½•ä»»åŠ¡åˆ†é…äº‹ä»¶ï¼ˆç”¨äºåç»­åˆ†æå’Œç›‘æ§ï¼‰
                await self._log_task_assignment_event(task_id, assigned_user_id, task_title)
                
                # è®°å½•åˆ°æ§åˆ¶å°ç”¨äºè°ƒè¯•
                print(f"\nğŸ¯ ã€ä»»åŠ¡æ¨é€ã€‘ æ–°çš„äººå·¥ä»»åŠ¡å·²åˆ†é…:")
                print(f"   ç”¨æˆ·ID: {assigned_user_id}")
                print(f"   ä»»åŠ¡ID: {task_id}")
                print(f"   ä»»åŠ¡æ ‡é¢˜: {task_title}")
                print(f"   å·¥ä½œæµ: {workflow_name}")
                print(f"   æ—¶é—´: {now_utc().strftime('%Y-%m-%d %H:%M:%S')}")
                print("=" * 60)
                
            elif task_type == TaskInstanceType.AGENT.value:
                # Agentä»»åŠ¡ï¼šè°ƒç”¨AIå¤„ç†
                await self._process_agent_task(task)
                
            elif task_type == TaskInstanceType.MIXED.value:
                # æ··åˆä»»åŠ¡ï¼šåŒæ—¶æäº¤ç»™äººå·¥å’ŒAgentå¤„ç†
                await self._process_mixed_task(task)
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _process_agent_task(self, task: Dict[str, Any]):
        """å¤„ç†Agentä»»åŠ¡ - é›†æˆAgentTaskService"""
        try:
            task_id = task['task_instance_id']
            logger.trace(f"é›†æˆAgentä»»åŠ¡æœåŠ¡å¤„ç†ä»»åŠ¡: {task['task_title']}")
            
            # æ³¨å†Œä»»åŠ¡å®Œæˆå›è°ƒ
            callback_future = asyncio.Future()
            self.task_callbacks[task_id] = callback_future
            
            # æäº¤ä»»åŠ¡åˆ°AgentTaskServiceè¿›è¡Œå¤„ç†
            result = await agent_task_service.submit_task_to_agent(task_id)
            
            if result['status'] == 'queued':
                logger.trace(f"Agentä»»åŠ¡ {task_id} å·²æäº¤åˆ°æœåŠ¡é˜Ÿåˆ—")
                
                # ç­‰å¾…ä»»åŠ¡å¤„ç†å®Œæˆï¼ˆé€šè¿‡å›è°ƒæœºåˆ¶ï¼‰
                try:
                    await asyncio.wait_for(callback_future, timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                    logger.trace(f"Agentä»»åŠ¡ {task_id} é€šè¿‡å›è°ƒæœºåˆ¶å®Œæˆ")
                except asyncio.TimeoutError:
                    logger.error(f"Agentä»»åŠ¡ {task_id} å¤„ç†è¶…æ—¶")
                    raise TimeoutError("Agentä»»åŠ¡å¤„ç†è¶…æ—¶")
                finally:
                    # æ¸…ç†å›è°ƒ
                    self.task_callbacks.pop(task_id, None)
                
            else:
                logger.warning(f"Agentä»»åŠ¡æäº¤å¤±è´¥: {result}")
                # æ¸…ç†å›è°ƒ
                self.task_callbacks.pop(task_id, None)
                raise RuntimeError(f"Agentä»»åŠ¡æäº¤å¤±è´¥: {result}")
            
        except Exception as e:
            logger.error(f"å¤„ç†Agentä»»åŠ¡å¤±è´¥: {e}")
            # æ¸…ç†å›è°ƒ
            self.task_callbacks.pop(task.get('task_instance_id'), None)
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            fail_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.FAILED,
                error_message=str(e)
            )
            await self.task_instance_repo.update_task(task['task_instance_id'], fail_update)
            raise
    
    async def on_task_completed(self, task_id: uuid.UUID, result: Dict[str, Any]):
        """ä»»åŠ¡å®Œæˆå›è°ƒå¤„ç†"""
        try:
            logger.trace(f"æ”¶åˆ°ä»»åŠ¡å®Œæˆå›è°ƒ: {task_id}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…çš„å›è°ƒ
            if task_id in self.task_callbacks:
                callback_future = self.task_callbacks[task_id]
                if not callback_future.done():
                    callback_future.set_result(result)
                    logger.trace(f"ä»»åŠ¡ {task_id} å›è°ƒå·²è§¦å‘")
            else:
                # è¿™æ˜¯æ­£å¸¸æƒ…å†µï¼šä»»åŠ¡å®Œæˆæ—¶ç­‰å¾…çš„Futureå¯èƒ½å·²ç»è¢«å¤„ç†å¹¶æ¸…ç†
                logger.debug(f"ä»»åŠ¡ {task_id} å®Œæˆï¼Œä½†å›è°ƒå·²è¢«å¤„ç†ï¼ˆæ­£å¸¸æƒ…å†µï¼‰")
            
            # è·å–ä»»åŠ¡ä¿¡æ¯ä»¥ä¾¿æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
            task_info = await self.task_instance_repo.get_task_by_id(task_id)
            if task_info:
                workflow_instance_id = task_info['workflow_instance_id']
                node_instance_id = task_info['node_instance_id']
                
                logger.trace(f"ğŸ¯ Agentä»»åŠ¡å®Œæˆï¼Œæ›´æ–°èŠ‚ç‚¹çŠ¶æ€: workflow={workflow_instance_id}, node_instance={node_instance_id}")
                
                # è·å–èŠ‚ç‚¹ä¿¡æ¯
                node_query = """
                SELECT n.node_id, n.name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.node_instance_id = $1
                """
                node_info = await self.task_instance_repo.db.fetch_one(node_query, node_instance_id)
                
                if node_info:
                    # ä½¿ç”¨WorkflowContextManageræ ‡è®°èŠ‚ç‚¹å®Œæˆ
                    output_data = {
                        'task_result': result.get('result', ''),
                        'task_summary': result.get('message', ''),
                        'execution_time': result.get('duration', 0),
                        'completion_time': datetime.utcnow().isoformat()
                    }
                    
                    await self.context_manager.mark_node_completed(
                        workflow_instance_id=workflow_instance_id,
                        node_id=node_info['node_id'],
                        node_instance_id=node_instance_id,
                        output_data=output_data
                    )
                    
                    logger.trace(f"âœ… Agentä»»åŠ¡å®ŒæˆåèŠ‚ç‚¹çŠ¶æ€æ›´æ–°å®Œæˆ")
                else:
                    logger.error(f"æ— æ³•è·å–èŠ‚ç‚¹ä¿¡æ¯: node_instance_id={node_instance_id}")
            else:
                logger.error(f"æ— æ³•è·å–ä»»åŠ¡ä¿¡æ¯: task_id={task_id}")
                
        except Exception as e:
            logger.error(f"å¤„ç†ä»»åŠ¡å®Œæˆå›è°ƒå¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def on_task_failed(self, task_id: uuid.UUID, error_message: str):
        """ä»»åŠ¡å¤±è´¥å›è°ƒå¤„ç†"""
        try:
            logger.trace(f"æ”¶åˆ°ä»»åŠ¡å¤±è´¥å›è°ƒ: {task_id} - {error_message}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…çš„å›è°ƒ
            if task_id in self.task_callbacks:
                callback_future = self.task_callbacks[task_id]
                if not callback_future.done():
                    callback_future.set_exception(RuntimeError(error_message))
                    logger.trace(f"ä»»åŠ¡ {task_id} å¤±è´¥å›è°ƒå·²è§¦å‘")
            else:
                # è¿™æ˜¯æ­£å¸¸æƒ…å†µï¼šä»»åŠ¡å¤±è´¥æ—¶ç­‰å¾…çš„Futureå¯èƒ½å·²ç»è¢«å¤„ç†å¹¶æ¸…ç†
                logger.debug(f"ä»»åŠ¡ {task_id} å¤±è´¥ï¼Œä½†å›è°ƒå·²è¢«å¤„ç†ï¼ˆæ­£å¸¸æƒ…å†µï¼‰")
            
            # è·å–ä»»åŠ¡ä¿¡æ¯ä»¥ä¾¿æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå¤±è´¥
            task_info = await self.task_instance_repo.get_task_by_id(task_id)
            if task_info:
                workflow_instance_id = task_info['workflow_instance_id']
                node_instance_id = task_info['node_instance_id']
                
                logger.trace(f"âŒ Agentä»»åŠ¡å¤±è´¥ï¼Œæ ‡è®°èŠ‚ç‚¹å¤±è´¥: workflow={workflow_instance_id}, node_instance={node_instance_id}")
                
                # è·å–èŠ‚ç‚¹ä¿¡æ¯
                node_query = """
                SELECT n.node_id, n.name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.node_instance_id = $1
                """
                node_info = await self.task_instance_repo.db.fetch_one(node_query, node_instance_id)
                
                if node_info:
                    # ä½¿ç”¨WorkflowContextManageræ ‡è®°èŠ‚ç‚¹å¤±è´¥
                    await self.context_manager.mark_node_failed(
                        workflow_instance_id=workflow_instance_id,
                        node_id=node_info['node_id'],
                        node_instance_id=node_instance_id,
                        error_info={'error': error_message}
                    )
                    
                    logger.trace(f"âŒ Agentä»»åŠ¡å¤±è´¥åèŠ‚ç‚¹çŠ¶æ€æ›´æ–°å®Œæˆ")
                else:
                    logger.error(f"æ— æ³•è·å–èŠ‚ç‚¹ä¿¡æ¯: node_instance_id={node_instance_id}")
            else:
                logger.error(f"æ— æ³•è·å–ä»»åŠ¡ä¿¡æ¯: task_id={task_id}")
                
        except Exception as e:
            logger.error(f"å¤„ç†ä»»åŠ¡å¤±è´¥å›è°ƒå¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _process_mixed_task(self, task: Dict[str, Any]):
        """å¤„ç†æ··åˆä»»åŠ¡ - äººæœºåä½œ"""
        try:
            task_id = task['task_instance_id']
            logger.trace(f"å¤„ç†æ··åˆä»»åŠ¡: {task['task_title']}")
            
            # 1. é¦–å…ˆåˆ†é…ç»™äººå·¥ç”¨æˆ·å¤„ç†
            human_update = TaskInstanceUpdate(status=TaskInstanceStatus.ASSIGNED)
            await self.task_instance_repo.update_task(task_id, human_update)
            logger.trace(f"æ··åˆä»»åŠ¡ {task_id} å·²åˆ†é…ç»™äººå·¥ç”¨æˆ·")
            
            # 2. åŒæ—¶æäº¤ç»™AgentæœåŠ¡è·å–AIå»ºè®®ï¼ˆä¸é˜»å¡ï¼‰
            try:
                # åˆ›å»ºAIå»ºè®®ä»»åŠ¡çš„å‰¯æœ¬æ•°æ®
                ai_suggestion_task = task.copy()
                ai_suggestion_task['task_title'] = f"[AIå»ºè®®] {task['task_title']}"
                ai_suggestion_task['task_description'] = f"ä¸ºäººå·¥ä»»åŠ¡æä¾›AIå»ºè®®: {task['task_description']}"
                
                # å¼‚æ­¥æäº¤åˆ°AgentæœåŠ¡è·å–å»ºè®®
                asyncio.create_task(self._provide_ai_assistance(task_id, ai_suggestion_task))
                logger.trace(f"ä¸ºæ··åˆä»»åŠ¡ {task_id} å¯åŠ¨AIååŠ©")
                
            except Exception as e:
                logger.warning(f"å¯åŠ¨AIååŠ©å¤±è´¥ï¼Œç»§ç»­äººå·¥å¤„ç†: {e}")
            
            # 3. æ··åˆä»»åŠ¡ä¸»è¦ç­‰å¾…äººå·¥å®Œæˆï¼ŒAIå»ºè®®ä½œä¸ºè¾…åŠ©
            logger.trace(f"æ··åˆä»»åŠ¡ {task_id} è¿›å…¥äººæœºåä½œæ¨¡å¼")
            
        except Exception as e:
            logger.error(f"å¤„ç†æ··åˆä»»åŠ¡å¤±è´¥: {e}")
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            fail_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.FAILED,
                error_message=str(e)
            )
            await self.task_instance_repo.update_task(task['task_instance_id'], fail_update)
            raise
    
    async def _provide_ai_assistance(self, original_task_id: uuid.UUID, ai_task: Dict[str, Any]):
        """ä¸ºäººå·¥ä»»åŠ¡æä¾›AIååŠ©å»ºè®®"""
        try:
            logger.trace(f"ä¸ºä»»åŠ¡ {original_task_id} ç”ŸæˆAIå»ºè®®")
            
            # è°ƒç”¨AgentTaskServiceç”ŸæˆAIå»ºè®®
            ai_result = await agent_task_service.process_agent_task(original_task_id)
            
            # å°†AIå»ºè®®å­˜å‚¨åˆ°åŸä»»åŠ¡çš„ä¸Šä¸‹æ–‡ä¸­
            if ai_result['status'] == TaskInstanceStatus.COMPLETED.value:
                ai_suggestions = {
                    'ai_analysis': ai_result['result'],
                    'suggestions_generated_at': now_utc().isoformat(),
                    'confidence_score': ai_result['result'].get('confidence_score', 0.8),
                    'ai_recommendations': ai_result['result'].get('recommendations', [])
                }
                
                # æ›´æ–°åŸä»»åŠ¡ï¼Œæ·»åŠ AIå»ºè®®åˆ°ä¸Šä¸‹æ–‡
                update_data = TaskInstanceUpdate(
                    context_data={'ai_assistance': ai_suggestions}
                )
                await self.task_instance_repo.update_task(original_task_id, update_data)
                
                logger.trace(f"AIå»ºè®®å·²æ·»åŠ åˆ°ä»»åŠ¡ {original_task_id} çš„ä¸Šä¸‹æ–‡ä¸­")
            
        except Exception as e:
            logger.warning(f"ç”ŸæˆAIååŠ©å»ºè®®å¤±è´¥: {e}")
            # AIååŠ©å¤±è´¥ä¸å½±å“ä¸»ä»»åŠ¡
    
    async def _complete_workflow(self, instance_id: uuid.UUID):
        """å®Œæˆå·¥ä½œæµ"""
        try:
            logger.trace(f"ğŸ å¼€å§‹å®Œæˆå·¥ä½œæµ: {instance_id}")
            
            # 1. ç”Ÿæˆæ ‡å‡†åŒ–è¾“å‡ºæ‘˜è¦
            logger.trace(f"ğŸ“Š ç”Ÿæˆå·¥ä½œæµè¾“å‡ºæ‘˜è¦")
            try:
                from .output_data_processor import OutputDataProcessor
                output_processor = OutputDataProcessor()
                
                # ç”Ÿæˆè¾“å‡ºæ‘˜è¦
                output_summary = await output_processor.generate_workflow_output_summary(instance_id)
                if output_summary:
                    logger.trace(f"âœ… å·¥ä½œæµè¾“å‡ºæ‘˜è¦ç”ŸæˆæˆåŠŸ")
                    
                    # å‡†å¤‡ç»“æ„åŒ–è¾“å‡ºæ•°æ®
                    summary_dict = output_summary.dict()
                    execution_summary = {
                        "execution_result": summary_dict.get("execution_result"),
                        "execution_stats": summary_dict.get("execution_stats")
                    }
                    quality_metrics = summary_dict.get("quality_metrics")
                    data_lineage = summary_dict.get("data_lineage")
                    
                    # è®¾ç½®åŸºç¡€è¾“å‡ºæ•°æ®
                    basic_output_data = {
                        'message': 'å·¥ä½œæµæ‰§è¡Œå®Œæˆ',
                        'completion_time': datetime.utcnow().isoformat(),
                        'result_type': summary_dict.get("execution_result", {}).get("result_type", "success")
                    }
                    
                    # å¦‚æœæœ‰å…·ä½“çš„ä¸šåŠ¡è¾“å‡ºæ•°æ®ï¼Œæ·»åŠ åˆ°åŸºç¡€è¾“å‡ºä¸­
                    if summary_dict.get("execution_result", {}).get("data_output"):
                        basic_output_data['workflow_results'] = summary_dict["execution_result"]["data_output"]
                    
                    logger.trace(f"ğŸ’¾ æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€å’Œè¾“å‡ºæ•°æ®")
                    
                    # 2. æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºå·²å®Œæˆï¼ŒåŒ…å«ç»“æ„åŒ–è¾“å‡º
                    update_data = WorkflowInstanceUpdate(
                        status=WorkflowInstanceStatus.COMPLETED,
                        output_data=basic_output_data,
                        execution_summary=execution_summary,
                        quality_metrics=quality_metrics,
                        data_lineage=data_lineage,
                        output_summary=output_summary
                    )
                    
                else:
                    logger.warning(f"âš ï¸ å·¥ä½œæµè¾“å‡ºæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€è¾“å‡ºæ•°æ®")
                    # ä½¿ç”¨åŸºç¡€è¾“å‡ºæ•°æ®
                    update_data = WorkflowInstanceUpdate(
                        status=WorkflowInstanceStatus.COMPLETED,
                        output_data={
                            'message': 'å·¥ä½œæµæ‰§è¡Œå®Œæˆ',
                            'completion_time': datetime.utcnow().isoformat(),
                            'result_type': 'success'
                        }
                    )
                    
            except Exception as output_error:
                logger.error(f"âŒ ç”Ÿæˆè¾“å‡ºæ‘˜è¦å¼‚å¸¸: {output_error}")
                import traceback
                logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                
                # å³ä½¿è¾“å‡ºæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä¹Ÿè¦å®Œæˆå·¥ä½œæµ
                update_data = WorkflowInstanceUpdate(
                    status=WorkflowInstanceStatus.COMPLETED,
                    output_data={
                        'message': 'å·¥ä½œæµæ‰§è¡Œå®Œæˆ',
                        'completion_time': datetime.utcnow().isoformat(),
                        'result_type': 'success',
                        'note': 'è¾“å‡ºæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½†å·¥ä½œæµæ­£å¸¸å®Œæˆ'
                    }
                )
            
            # 3. æ›´æ–°æ•°æ®åº“
            await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            # 4. ä»è¿è¡Œå®ä¾‹ä¸­ç§»é™¤
            self.running_instances.pop(instance_id, None)
            
            logger.trace(f"âœ… å·¥ä½œæµå®ä¾‹ {instance_id} æ‰§è¡Œå®Œæˆ")
            logger.trace(f"ğŸ“‹ å·¥ä½œæµå®Œæˆç»Ÿè®¡:")
            logger.trace(f"   - å®ä¾‹ID: {instance_id}")
            logger.trace(f"   - å®Œæˆæ—¶é—´: {datetime.utcnow().isoformat()}")
            logger.trace(f"   - è¾“å‡ºæ‘˜è¦: {'å·²ç”Ÿæˆ' if 'output_summary' in locals() and output_summary else 'ç”Ÿæˆå¤±è´¥'}")
            
        except Exception as e:
            logger.error(f"âŒ å®Œæˆå·¥ä½œæµå¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def _fail_workflow(self, instance_id: uuid.UUID, error_message: str):
        """å·¥ä½œæµæ‰§è¡Œå¤±è´¥"""
        try:
            # æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºå¤±è´¥
            update_data = WorkflowInstanceUpdate(
                status=WorkflowInstanceStatus.FAILED,
                error_message=error_message
            )
            await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            # ä»è¿è¡Œå®ä¾‹ä¸­ç§»é™¤
            self.running_instances.pop(instance_id, None)
            
            logger.error(f"å·¥ä½œæµå®ä¾‹ {instance_id} æ‰§è¡Œå¤±è´¥: {error_message}")
            
        except Exception as e:
            logger.error(f"æ ‡è®°å·¥ä½œæµå¤±è´¥çŠ¶æ€å¤±è´¥: {e}")
    
    async def _monitor_running_instances(self):
        """ç›‘æ§è¿è¡Œä¸­çš„å®ä¾‹"""
        while self.is_running:
            try:
                # æ£€æŸ¥è¶…æ—¶çš„å®ä¾‹
                for instance_id, execution_item in list(self.running_instances.items()):
                    # è¿™é‡Œå¯ä»¥æ·»åŠ è¶…æ—¶æ£€æŸ¥é€»è¾‘
                    pass
                
                # æ£€æŸ¥å¹¶è§¦å‘å°±ç»ªçš„ENDèŠ‚ç‚¹
                await self._check_and_trigger_ready_end_nodes()
                
                await asyncio.sleep(15)  # æ¯15ç§’æ£€æŸ¥ä¸€æ¬¡ - ä¼˜åŒ–ä¸ºæ›´é¢‘ç¹
                
            except Exception as e:
                logger.error(f"ç›‘æ§è¿è¡Œå®ä¾‹å¤±è´¥: {e}")
                await asyncio.sleep(10)
    
    async def _check_and_trigger_ready_end_nodes(self):
        """æ£€æŸ¥å¹¶è§¦å‘å°±ç»ªçš„ENDèŠ‚ç‚¹"""
        try:
            # æŸ¥æ‰¾æ‰€æœ‰è¿è¡Œä¸­çš„å·¥ä½œæµå®ä¾‹
            running_workflows_query = """
            SELECT workflow_instance_id, workflow_instance_name
            FROM workflow_instance 
            WHERE status = 'running' AND is_deleted = 0
            """
            
            running_workflows = await self.task_instance_repo.db.fetch_all(running_workflows_query)
            
            for workflow in running_workflows:
                workflow_id = workflow['workflow_instance_id']
                
                # æŸ¥æ‰¾pendingçŠ¶æ€çš„ENDèŠ‚ç‚¹
                end_nodes_query = """
                SELECT ni.node_instance_id, ni.node_instance_name, ni.status,
                       n.type as node_type, n.name as node_name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.workflow_instance_id = %s
                AND LOWER(n.type) = 'end'
                AND ni.status IN ('pending', 'waiting')
                AND ni.is_deleted = 0
                """
                
                end_nodes = await self.task_instance_repo.db.fetch_all(end_nodes_query, workflow_id)
                
                for end_node in end_nodes:
                    node_instance_id = end_node['node_instance_id']
                    node_name = end_node.get('node_instance_name', 'æœªçŸ¥ENDèŠ‚ç‚¹')
                    
                    # ğŸ” æ£€æŸ¥ENDèŠ‚ç‚¹çš„çŠ¶æ€ï¼Œé¿å…é‡å¤è§¦å‘
                    try:
                        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å·²ç»åœ¨æ‰§è¡Œæˆ–å®Œæˆ
                        current_state = self.context_manager.node_completion_status.get(node_instance_id, 'PENDING')
                        if current_state in ['EXECUTING', 'COMPLETED']:
                            logger.trace(f"ğŸš« [ENDèŠ‚ç‚¹æ£€æŸ¥] {node_name} çŠ¶æ€ä¸º {current_state}ï¼Œè·³è¿‡è§¦å‘")
                            continue
                        
                        # æ£€æŸ¥æ•°æ®åº“çŠ¶æ€ä½œä¸ºåŒé‡ä¿é™©
                        from ..repositories.instance.node_instance_repository import NodeInstanceRepository
                        node_repo = NodeInstanceRepository()
                        db_node = await node_repo.get_instance_by_id(node_instance_id)
                        if db_node and db_node.get('status') in ['running', 'completed']:
                            logger.trace(f"ğŸš« [ENDèŠ‚ç‚¹æ£€æŸ¥-DB] {node_name} æ•°æ®åº“çŠ¶æ€ä¸º {db_node.get('status')}ï¼Œè·³è¿‡è§¦å‘")
                            continue
                        
                        # æ£€æŸ¥ENDèŠ‚ç‚¹çš„ä¾èµ–æ˜¯å¦æ»¡è¶³
                        if await self._check_node_dependencies_satisfied(workflow_id, node_instance_id):
                            logger.info(f"ğŸ å‘ç°å°±ç»ªçš„ENDèŠ‚ç‚¹: {node_name} ({node_instance_id})")
                            
                            # æ ‡è®°ä¸ºå³å°†æ‰§è¡Œï¼Œé˜²æ­¢é‡å¤è§¦å‘
                            self.context_manager.node_completion_status[node_instance_id] = 'EXECUTING'
                            
                            try:
                                # è§¦å‘ENDèŠ‚ç‚¹æ‰§è¡Œ
                                await self._execute_node_when_ready(workflow_id, node_instance_id)
                                logger.info(f"âœ… ENDèŠ‚ç‚¹ {node_name} è§¦å‘æˆåŠŸ")
                            except Exception as e:
                                logger.error(f"âŒ ENDèŠ‚ç‚¹ {node_name} è§¦å‘å¤±è´¥: {e}")
                                # æ¢å¤çŠ¶æ€
                                self.context_manager.node_completion_status[node_instance_id] = 'PENDING'
                        else:
                            logger.trace(f"â³ [ENDèŠ‚ç‚¹æ£€æŸ¥] {node_name} ä¾èµ–å°šæœªæ»¡è¶³")
                            
                    except Exception as e:
                        logger.error(f"âŒ [ENDèŠ‚ç‚¹æ£€æŸ¥] æ£€æŸ¥ENDèŠ‚ç‚¹ {node_name} å¤±è´¥: {e}")
                        # ç¡®ä¿çŠ¶æ€æ­£ç¡®
                        if node_instance_id in self.context_manager.node_completion_status:
                            current_state = self.context_manager.node_completion_status[node_instance_id]
                            if current_state == 'EXECUTING':
                                self.context_manager.node_completion_status[node_instance_id] = 'PENDING'
                            
        except Exception as e:
            logger.error(f"æ£€æŸ¥å°±ç»ªENDèŠ‚ç‚¹å¤±è´¥: {e}")
    
    async def pause_workflow(self, instance_id: uuid.UUID) -> bool:
        """æš‚åœå·¥ä½œæµ"""
        try:
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.PAUSED)
            result = await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            if result:
                logger.trace(f"å·¥ä½œæµå®ä¾‹ {instance_id} å·²æš‚åœ")
                return True
            return False
            
        except Exception as e:
            logger.error(f"æš‚åœå·¥ä½œæµå¤±è´¥: {e}")
            return False
    
    async def resume_workflow(self, instance_id: uuid.UUID) -> bool:
        """æ¢å¤å·¥ä½œæµ"""
        try:
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.RUNNING)
            result = await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            if result:
                logger.trace(f"å·¥ä½œæµå®ä¾‹ {instance_id} å·²æ¢å¤")
                return True
            return False
            
        except Exception as e:
            logger.error(f"æ¢å¤å·¥ä½œæµå¤±è´¥: {e}")
            return False
    
    async def cancel_workflow(self, instance_id: uuid.UUID) -> bool:
        """å–æ¶ˆå·¥ä½œæµ"""
        try:
            logger.trace(f"ğŸš« å¼€å§‹å–æ¶ˆå·¥ä½œæµå®ä¾‹: {instance_id}")
            
            # é¦–å…ˆæ£€æŸ¥å·¥ä½œæµå®ä¾‹æ˜¯å¦å­˜åœ¨
            instance = await self.workflow_instance_repo.get_instance_by_id(instance_id)
            if not instance:
                logger.error(f"âŒ å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨: {instance_id}")
                return False
                
            logger.trace(f"ğŸ“‹ æ‰¾åˆ°å·¥ä½œæµå®ä¾‹: {instance.get('workflow_instance_name', 'æœªå‘½å')}")
            logger.trace(f"   - å½“å‰çŠ¶æ€: {instance.get('status')}")
            logger.trace(f"   - æ‰§è¡Œè€…: {instance.get('executor_id')}")
            logger.trace(f"   - åˆ›å»ºæ—¶é—´: {instance.get('created_at')}")
            
            # 1. å–æ¶ˆæ­£åœ¨è¿è¡Œçš„å¼‚æ­¥ä»»åŠ¡
            logger.trace(f"ğŸ¯ æ­¥éª¤1: å–æ¶ˆæ­£åœ¨è¿è¡Œçš„å¼‚æ­¥ä»»åŠ¡")
            try:
                await self._cancel_running_tasks(instance_id)
                logger.trace(f"âœ… å¼‚æ­¥ä»»åŠ¡å–æ¶ˆå®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ å–æ¶ˆå¼‚æ­¥ä»»åŠ¡å¤±è´¥: {e}")
            
            # èµ„æºæ¸…ç†å’ŒçŠ¶æ€åŒæ­¥
            logger.trace(f"ğŸ¯ æ­¥éª¤2: æ¸…ç†å®ä¾‹çŠ¶æ€")
            try:
                # ä½¿ç”¨æ–°çš„ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¸…ç†çŠ¶æ€
                if hasattr(self.context_manager, 'cleanup_workflow_context'):
                    await self.context_manager.cleanup_workflow_context(instance_id)
                    logger.trace(f"âœ… å·²ä»ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­ç§»é™¤å·¥ä½œæµ: {instance_id}")
                else:
                    logger.trace(f"   - ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸æ”¯æŒcleanupæ–¹æ³•")
            except Exception as e:
                logger.error(f"âŒ æ¸…ç†å®ä¾‹çŠ¶æ€å¤±è´¥: {e}")
            
            # 3. æ›´æ–°æ•°æ®åº“çŠ¶æ€
            logger.trace(f"ğŸ¯ æ­¥éª¤3: æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸ºCANCELLED")
            try:
                update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.CANCELLED)
                logger.trace(f"   - å‡†å¤‡æ›´æ–°æ•°æ®: {update_data}")
                result = await self.workflow_instance_repo.update_instance(instance_id, update_data)
                logger.trace(f"   - æ•°æ®åº“æ›´æ–°ç»“æœ: {result}")
                
                if result:
                    logger.trace(f"âœ… æ•°æ®åº“çŠ¶æ€æ›´æ–°æˆåŠŸ")
                    
                    # ä»è¿è¡Œå®ä¾‹ä¸­ç§»é™¤
                    logger.trace(f"ğŸ¯ æ­¥éª¤4: ä»è¿è¡Œå®ä¾‹åˆ—è¡¨ä¸­ç§»é™¤")
                    if hasattr(self, 'running_instances') and instance_id in self.running_instances:
                        self.running_instances.pop(instance_id, None)
                        logger.trace(f"   - å·²ä»è¿è¡Œå®ä¾‹åˆ—è¡¨ä¸­ç§»é™¤")
                    else:
                        logger.trace(f"   - å®ä¾‹ä¸åœ¨è¿è¡Œåˆ—è¡¨ä¸­")
                    
                    # 5. é€šçŸ¥ç›¸å…³æœåŠ¡
                    logger.trace(f"ğŸ¯ æ­¥éª¤5: é€šçŸ¥ç›¸å…³æœåŠ¡")
                    try:
                        await self._notify_services_workflow_cancelled(instance_id)
                        logger.trace(f"âœ… æœåŠ¡é€šçŸ¥å®Œæˆ")
                    except Exception as e:
                        logger.error(f"âŒ é€šçŸ¥æœåŠ¡å¤±è´¥: {e}")
                    
                    logger.trace(f"âœ… å·¥ä½œæµå®ä¾‹ {instance_id} å·²æˆåŠŸå–æ¶ˆ (æ‰€æœ‰æ­¥éª¤å®Œæˆ)")
                    return True
                else:
                    logger.error(f"âŒ æ›´æ–°å·¥ä½œæµçŠ¶æ€å¤±è´¥: {instance_id}")
                    return False
            except Exception as e:
                logger.error(f"âŒ æ•°æ®åº“æ›´æ–°å¼‚å¸¸: {e}")
                import traceback
                logger.error(f"   - æ›´æ–°å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                return False
            
        except Exception as e:
            logger.error(f"âŒ å–æ¶ˆå·¥ä½œæµå¤±è´¥: {e}")
            import traceback
            logger.error(f"   - å®Œæ•´å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            return False
    
    async def get_workflow_status(self, instance_id: uuid.UUID) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        try:
            instance = await self.workflow_instance_repo.get_instance_by_id(instance_id)
            if not instance:
                return None
            
            # è·å–æ‰§è¡Œç»Ÿè®¡
            stats = await self.workflow_instance_repo.get_execution_statistics(instance_id)
            
            return {
                'instance': instance,
                'statistics': stats,
                'is_running': instance_id in self.running_instances
            }
            
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµçŠ¶æ€å¤±è´¥: {e}")
            return None
    
    # =============================================================================
    # æ–°å¢ï¼šä¾èµ–ç­‰å¾…å’Œä¸Šä¸‹æ–‡ç®¡ç†æ–¹æ³•
    # =============================================================================
    
    async def _create_node_instances_with_dependencies(self, 
                                                     workflow_instance_id: uuid.UUID,
                                                     workflow_base_id: uuid.UUID,
                                                     nodes: List[Dict[str, Any]]):
        """åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¹¶æ³¨å†Œä¾èµ–å…³ç³»"""
        try:
            logger.trace(f"å¼€å§‹åˆ›å»ºèŠ‚ç‚¹å®ä¾‹: å·¥ä½œæµå®ä¾‹ ID={workflow_instance_id}, èŠ‚ç‚¹æ•°é‡={len(nodes)}")
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceCreate, NodeInstanceStatus
            
            node_instance_repo = NodeInstanceRepository()
            created_nodes = []
            
            # 1. å…ˆåˆ›å»ºæ‰€æœ‰èŠ‚ç‚¹å®ä¾‹
            logger.trace(f"é˜¶æ®µ1: åˆ›å»º {len(nodes)} ä¸ªèŠ‚ç‚¹å®ä¾‹")
            for i, node in enumerate(nodes, 1):
                logger.trace(f"  æ­£åœ¨åˆ›å»ºèŠ‚ç‚¹å®ä¾‹ {i}/{len(nodes)}: {node['name']} (ç±»å‹: {node['type']})")
                
                # è®¾ç½®åˆå§‹çŠ¶æ€ï¼šSTARTèŠ‚ç‚¹ä¸ºPENDINGï¼Œå…¶ä»–èŠ‚ç‚¹ä¹Ÿä¸ºPENDINGï¼ˆç­‰å¾…å‰ç½®æ¡ä»¶æ»¡è¶³ï¼‰
                initial_status = NodeInstanceStatus.PENDING
                logger.trace(f"    åˆå§‹çŠ¶æ€: {initial_status.value}")
                
                node_instance_data = NodeInstanceCreate(
                    workflow_instance_id=workflow_instance_id,
                    node_id=node['node_id'],
                    node_base_id=node['node_base_id'],
                    node_instance_name=f"{node['name']}_instance",
                    task_description=node.get('task_description') or '',
                    status=initial_status,
                    input_data={},
                    output_data={},
                    error_message=None,
                    retry_count=0
                )
                
                node_instance = await node_instance_repo.create_node_instance(node_instance_data)
                if node_instance:
                    created_nodes.append({
                        'node_instance_id': node_instance['node_instance_id'],
                        'node_base_id': node['node_base_id'],
                        'node_type': node['type'],
                        'node_data': node
                    })
                    logger.trace(f"  âœ… èŠ‚ç‚¹å®ä¾‹åˆ›å»ºæˆåŠŸ: {node['name']} (ID: {node_instance['node_instance_id']})")
                else:
                    logger.error(f"  âŒ èŠ‚ç‚¹å®ä¾‹åˆ›å»ºå¤±è´¥: {node['name']}")
            
            # 2. ä¸ºæ¯ä¸ªèŠ‚ç‚¹æ³¨å†Œä¾èµ–å…³ç³»
            logger.trace(f"é˜¶æ®µ2: æ³¨å†Œ {len(created_nodes)} ä¸ªèŠ‚ç‚¹çš„ä¾èµ–å…³ç³»")
            for i, created_node in enumerate(created_nodes, 1):
                logger.trace(f"  æ­£åœ¨æ³¨å†ŒèŠ‚ç‚¹ {i}/{len(created_nodes)} çš„ä¾èµ–: {created_node['node_data']['name']}")
                try:
                    # ç›´æ¥ä»æ•°æ®åº“æŸ¥è¯¢è¿æ¥å…³ç³»ï¼Œä½¿ç”¨æ­£ç¡®çš„workflow_id
                    from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
                    workflow_instance_repo = WorkflowInstanceRepository()
                    workflow_instance = await workflow_instance_repo.get_instance_by_id(workflow_instance_id)
                    current_workflow_id = workflow_instance['workflow_id'] if workflow_instance else None
                    
                    logger.trace(f"    ğŸ” æŸ¥è¯¢èŠ‚ç‚¹ {created_node['node_data']['name']} çš„ä¾èµ–å…³ç³»:")
                    logger.trace(f"      - node_id: {created_node['node_data']['node_id']}")
                    logger.trace(f"      - workflow_id: {current_workflow_id}")
                    
                    # æŸ¥è¯¢ä¸Šæ¸¸è¿æ¥å…³ç³»
                    upstream_query = """
                    SELECT DISTINCT 
                        nc.from_node_id as upstream_node_id,
                        n.name as upstream_node_name,
                        n.type as upstream_node_type
                    FROM node_connection nc
                    JOIN node n ON nc.from_node_id = n.node_id
                    WHERE nc.to_node_id = $1 
                    AND nc.workflow_id = $2
                    ORDER BY n.name
                    """
                    
                    upstream_connections = await self.workflow_instance_repo.db.fetch_all(
                        upstream_query, 
                        created_node['node_data']['node_id'],  # ä½¿ç”¨node_idæŸ¥è¯¢
                        current_workflow_id  # ä½¿ç”¨workflow_idæŸ¥è¯¢
                    )
                    
                    logger.trace(f"    ğŸ” æŸ¥è¯¢åˆ° {len(upstream_connections)} ä¸ªä¸Šæ¸¸èŠ‚ç‚¹è¿æ¥:")
                    upstream_node_ids = []
                    for upstream in upstream_connections:
                        upstream_node_id = upstream['upstream_node_id']
                        upstream_node_ids.append(upstream_node_id)
                        logger.trace(f"      - ä¸Šæ¸¸èŠ‚ç‚¹: {upstream.get('upstream_node_name', 'Unknown')} (node_id: {upstream_node_id})")
                    
                    logger.trace(f"    ğŸ“‹ æœ€ç»ˆä¾èµ–åˆ—è¡¨ (node_id): {upstream_node_ids}")
                    
                    await self.context_manager.register_node_dependencies(
                        workflow_instance_id,
                        created_node['node_instance_id'],
                        created_node['node_data']['node_id'],  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
                        upstream_node_ids  # ä¸Šæ¸¸èŠ‚ç‚¹çš„node_idåˆ—è¡¨
                    )
                    
                    logger.trace(f"  âœ… èŠ‚ç‚¹ä¾èµ–æ³¨å†ŒæˆåŠŸ: {len(upstream_node_ids)} ä¸ªä¸Šæ¸¸èŠ‚ç‚¹ (ä½¿ç”¨node_id)")
                except Exception as e:
                    logger.error(f"  âŒ èŠ‚ç‚¹ä¾èµ–æ³¨å†Œå¤±è´¥: {e}")
                    import traceback
                    logger.error(f"    å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            
            # 3. ä¸å†ä¸ºæ‰€æœ‰å¤„ç†å™¨èŠ‚ç‚¹ç«‹å³åˆ›å»ºä»»åŠ¡ - æ”¹ä¸ºå»¶è¿Ÿåˆ›å»ºæœºåˆ¶
            logger.trace(f"é˜¶æ®µ3: å¯ç”¨å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶ï¼Œåªä¸ºSTARTèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡")
            try:
                # åªä¸ºSTARTèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡ï¼ˆå¦‚æœSTARTèŠ‚ç‚¹æ˜¯PROCESSORç±»å‹ï¼‰
                start_nodes = [n for n in created_nodes if n['node_data']['type'] == NodeType.START.value]
                if start_nodes:
                    await self._create_tasks_for_nodes(start_nodes, workflow_instance_id)
                    logger.trace(f"âœ… STARTèŠ‚ç‚¹ä»»åŠ¡åˆ›å»ºå®Œæˆ")
                
                # æ£€æŸ¥æ‰€æœ‰å°±ç»ªèŠ‚ç‚¹ï¼Œä¸ºæ»¡è¶³æ¡ä»¶çš„èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
                await self._check_downstream_nodes_for_task_creation(workflow_instance_id)
                logger.trace(f"âœ… å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶å¯åŠ¨å®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶å¯åŠ¨å¤±è´¥: {e}")
            
            logger.trace(f"âœ… èŠ‚ç‚¹å®ä¾‹å’Œä¾èµ–å…³ç³»åˆ›å»ºå®Œæˆ: {len(created_nodes)} ä¸ªèŠ‚ç‚¹")
            
            # æ‰“å°ä¾èµ–å…³ç³»æ€»ç»“
            logger.trace(f"ğŸ“Š [ä¾èµ–æ€»ç»“] æ‰“å°å·¥ä½œæµ {workflow_instance_id} çš„å®Œæ•´ä¾èµ–å…³ç³»:")
            self.context_manager.print_dependency_summary(workflow_instance_id)
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºå¸¦ä¾èµ–çš„èŠ‚ç‚¹å®ä¾‹å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def _create_tasks_for_nodes(self, created_nodes: List[Dict], workflow_instance_id: uuid.UUID):
        """ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹"""
        logger.trace(f"ğŸ”§ å¼€å§‹ä¸º {len(created_nodes)} ä¸ªèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹")
        
        task_creation_count = 0
        for i, created_node in enumerate(created_nodes, 1):
            logger.trace(f"ğŸ“‹ å¤„ç†èŠ‚ç‚¹ {i}/{len(created_nodes)}: {created_node.get('node_data', {}).get('name', 'æœªçŸ¥èŠ‚ç‚¹')}")
            logger.trace(f"   èŠ‚ç‚¹ç±»å‹: {created_node['node_type']}")
            logger.trace(f"   èŠ‚ç‚¹å®ä¾‹ID: {created_node['node_instance_id']}")
            
            if created_node['node_type'] == NodeType.PROCESSOR.value:
                node_data = created_node['node_data']
                
                logger.trace(f"   ğŸ” æŸ¥è¯¢èŠ‚ç‚¹å¤„ç†å™¨...")
                # è·å–èŠ‚ç‚¹çš„å¤„ç†å™¨ï¼ˆä¿®å¤ï¼šä½¿ç”¨node_idï¼‰
                processors = await self._get_node_processors(
                    created_node['node_data']['node_id']
                )
                
                if not processors:
                    logger.warning(f"   âš ï¸  èŠ‚ç‚¹ {node_data['name']} æ²¡æœ‰é…ç½®å¤„ç†å™¨ï¼Œè·³è¿‡ä»»åŠ¡åˆ›å»º")
                    continue
                
                logger.trace(f"   âœ… æ‰¾åˆ° {len(processors)} ä¸ªå¤„ç†å™¨")
                
                for j, processor in enumerate(processors, 1):
                    logger.trace(f"   ğŸ¯ å¤„ç†å¤„ç†å™¨ {j}/{len(processors)}: {processor.get('processor_name', processor.get('name', 'Unknown'))}")
                    
                    processor_type = processor.get('processor_type', processor.get('type', 'HUMAN'))
                    task_type = self._determine_task_type(processor_type)
                    
                    logger.trace(f"      å¤„ç†å™¨ç±»å‹: {processor_type}")
                    logger.trace(f"      ä»»åŠ¡ç±»å‹: {task_type.value}")
                    
                    # æ ¹æ®ä»»åŠ¡ç±»å‹å’ŒèŠ‚ç‚¹é…ç½®ç¡®å®šè¶…æ—¶è®¾ç½®
                    estimated_duration = self._determine_task_duration(task_type, node_data)
                    
                    logger.trace(f"      é¢„ä¼°æŒç»­æ—¶é—´: {estimated_duration}åˆ†é’Ÿ")
                    
                    # ç¡®å®šä»»åŠ¡åˆ†é…
                    assigned_user_id = processor.get('user_id')
                    assigned_agent_id = processor.get('agent_id')
                    
                    if assigned_user_id:
                        logger.trace(f"      ğŸ‘¤ ä»»åŠ¡å°†åˆ†é…ç»™ç”¨æˆ·: {assigned_user_id}")
                    elif assigned_agent_id:
                        logger.trace(f"      ğŸ¤– ä»»åŠ¡å°†åˆ†é…ç»™ä»£ç†: {assigned_agent_id}")
                    else:
                        logger.trace(f"      â³ ä»»åŠ¡æš‚æœªåˆ†é…ï¼Œå°†ä¿æŒPENDINGçŠ¶æ€")
                    
                    # åˆ›å»ºä»»åŠ¡å®ä¾‹ï¼Œä½†æš‚æ—¶ä¸åˆ†é…ä¸Šä¸‹æ–‡æ•°æ®
                    task_title = node_data['name']
                    
                    # ç¡®ä¿task_descriptionæœ‰å€¼
                    task_description = node_data.get('task_description') or node_data.get('description') or f"æ‰§è¡ŒèŠ‚ç‚¹ {node_data['name']} çš„ä»»åŠ¡"
                    
                    logger.trace(f"      ğŸ“ ä»»åŠ¡æè¿°: {task_description[:50]}{'...' if len(task_description) > 50 else ''}")
                    
                    # æ”¶é›†ä»»åŠ¡ä¸Šä¸‹æ–‡æ•°æ®
                    logger.trace(f"      ğŸ” æ”¶é›†ä»»åŠ¡ä¸Šä¸‹æ–‡æ•°æ®...")
                    context_data = await self.context_manager.get_task_context_data(workflow_instance_id, created_node['node_instance_id'])
                    
                    # å°†ä¸Šä¸‹æ–‡æ•°æ®è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
                    context_text = json.dumps(context_data, ensure_ascii=False, indent=2, default=_json_serializer) if context_data else ""
                    input_text = json.dumps(node_data.get('input_data', {}), ensure_ascii=False, indent=2, default=_json_serializer)
                    
                    task_data = TaskInstanceCreate(
                        node_instance_id=created_node['node_instance_id'],
                        workflow_instance_id=workflow_instance_id,
                        processor_id=processor['processor_id'],
                        task_type=task_type,
                        task_title=task_title,
                        task_description=task_description,
                        input_data=input_text,
                        context_data=context_text,
                        assigned_user_id=assigned_user_id,
                        assigned_agent_id=assigned_agent_id,
                        estimated_duration=estimated_duration
                    )
                    
                    logger.trace(f"      ğŸ“ æ­£åœ¨åˆ›å»ºä»»åŠ¡å®ä¾‹...")
                    try:
                        task = await self.task_instance_repo.create_task(task_data)
                        if task:
                            task_creation_count += 1
                            logger.trace(f"      âœ… ä»»åŠ¡å®ä¾‹åˆ›å»ºæˆåŠŸ!")
                            logger.trace(f"         ä»»åŠ¡ID: {task['task_instance_id']}")
                            logger.trace(f"         ä»»åŠ¡æ ‡é¢˜: {task['task_title']}")
                        else:
                            logger.error(f"      âŒ ä»»åŠ¡å®ä¾‹åˆ›å»ºå¤±è´¥: è¿”å›ç©ºç»“æœ")
                    except Exception as e:
                        logger.error(f"      âŒ ä»»åŠ¡å®ä¾‹åˆ›å»ºå¼‚å¸¸: {e}")
                        import traceback
                        logger.error(f"      å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            else:
                logger.trace(f"   â­ï¸  èŠ‚ç‚¹ç±»å‹ä¸æ˜¯PROCESSORï¼Œè·³è¿‡ä»»åŠ¡åˆ›å»º")
        
        logger.trace(f"ğŸ‰ ä»»åŠ¡åˆ›å»ºå®Œæˆ! æ€»å…±åˆ›å»ºäº† {task_creation_count} ä¸ªä»»åŠ¡å®ä¾‹")
    
    async def _start_workflow_execution_with_dependencies(self, 
                                                        workflow_instance_id: uuid.UUID,
                                                        workflow_base_id: uuid.UUID):
        """å¯åŠ¨å·¥ä½œæµæ‰§è¡Œï¼ˆåªå¯åŠ¨STARTèŠ‚ç‚¹ï¼‰"""
        try:
            logger.trace(f"å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ: {workflow_instance_id}")
            logger.trace(f"è°ƒç”¨_get_start_nodesï¼Œå·¥ä½œæµå®ä¾‹ID: {workflow_instance_id}")
            
            # é¦–å…ˆæ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.RUNNING)
            await self.workflow_instance_repo.update_instance(workflow_instance_id, update_data)
            
            # è·å–STARTèŠ‚ç‚¹
            logger.trace(f"æ­¥éª¤A: æŸ¥æ‰¾STARTèŠ‚ç‚¹")
            start_nodes = await self._get_start_nodes(workflow_instance_id)
            logger.trace(f"âœ… STARTèŠ‚ç‚¹æŸ¥è¯¢ç»“æœ: æ‰¾åˆ° {len(start_nodes)} ä¸ªSTARTèŠ‚ç‚¹")
            
            if not start_nodes:
                logger.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°pendingçŠ¶æ€çš„STARTèŠ‚ç‚¹ï¼Œå¯èƒ½å·¥ä½œæµå·²åœ¨è¿è¡Œä¸­")
                # æ£€æŸ¥æ˜¯å¦æœ‰å·²å®Œæˆçš„STARTèŠ‚ç‚¹ï¼Œå¦‚æœæœ‰åˆ™è¯´æ˜å·¥ä½œæµå·²å¯åŠ¨
                logger.trace(f"æ£€æŸ¥å·¥ä½œæµå½“å‰çŠ¶æ€å¹¶å°è¯•æ¢å¤æ‰§è¡Œ")
                await self._resume_workflow_execution(workflow_instance_id)
                return
            
            # æ˜¾ç¤ºæ‰¾åˆ°çš„STARTèŠ‚ç‚¹è¯¦æƒ…
            for i, start_node in enumerate(start_nodes, 1):
                unknown_text = "æœªçŸ¥"
                logger.trace(f"  STARTèŠ‚ç‚¹{i}: {start_node.get('node_name', unknown_text)} (ID: {start_node['node_instance_id']})")
            
            # æ‰§è¡ŒSTARTèŠ‚ç‚¹
            logger.trace(f"æ­¥éª¤B: å¼€å§‹æ‰§è¡Œ {len(start_nodes)} ä¸ªSTARTèŠ‚ç‚¹")
            for i, start_node in enumerate(start_nodes, 1):
                node_name = start_node.get('node_name', '\u672a\u77e5')
                logger.trace(f"  æ­£åœ¨æ‰§è¡ŒSTARTèŠ‚ç‚¹ {i}/{len(start_nodes)}: {node_name} (ID: {start_node['node_instance_id']})")
                try:
                    await self._execute_start_node_directly(workflow_instance_id, start_node)
                    logger.trace(f"  âœ… STARTèŠ‚ç‚¹æ‰§è¡ŒæˆåŠŸ: {node_name}")
                except Exception as e:
                    logger.error(f"  âŒ STARTèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {node_name} - {e}")
                    raise
            
            logger.trace(f"âœ… å·¥ä½œæµ {workflow_instance_id} æ‰€æœ‰STARTèŠ‚ç‚¹æ‰§è¡Œå®Œæˆï¼Œå·¥ä½œæµå·²å¼€å§‹è¿è¡Œ")
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆè¯¦æƒ…: {traceback.format_exc()}")
            raise
    
    async def _get_start_nodes(self, workflow_instance_id: uuid.UUID) -> List[Dict]:
        """è·å–STARTèŠ‚ç‚¹"""
        try:
            logger.trace(f"ğŸ” å¼€å§‹æŸ¥è¯¢STARTèŠ‚ç‚¹: workflow_instance_id={workflow_instance_id}")
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_instance_repo = NodeInstanceRepository()
            
            query = """
            SELECT ni.*, n.type as node_type, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1
            AND LOWER(n.type) = 'start'
            AND ni.status IN ('pending', 'PENDING')
            AND ni.is_deleted = FALSE
            AND n.is_deleted = FALSE
            ORDER BY ni.created_at ASC
            """
            
            # ä½¿ç”¨æ•°æ®åº“ç®¡ç†å™¨ç›´æ¥æ‰§è¡ŒæŸ¥è¯¢
            start_nodes = await node_instance_repo.db.fetch_all(query, workflow_instance_id)
            logger.trace(f"æ‰¾åˆ° {len(start_nodes)} ä¸ªSTARTèŠ‚ç‚¹å®ä¾‹ï¼Œå·¥ä½œæµå®ä¾‹ID: {workflow_instance_id}")
            
            # æ€»æ˜¯æŸ¥æ‰¾æ‰€æœ‰èŠ‚ç‚¹ä»¥è¿›è¡Œè°ƒè¯•
            logger.trace("è°ƒè¯•: æŸ¥æ‰¾æ‰€æœ‰èŠ‚ç‚¹ç±»å‹")
            debug_query = """
            SELECT ni.*, n.type as node_type, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1
            AND ni.is_deleted = FALSE
            AND n.is_deleted = FALSE
            ORDER BY n.type, ni.created_at ASC
            """
            all_nodes = await node_instance_repo.db.fetch_all(debug_query, workflow_instance_id)
            logger.trace(f"å·¥ä½œæµå®ä¾‹ {workflow_instance_id} çš„æ‰€æœ‰èŠ‚ç‚¹ ({len(all_nodes)} ä¸ª):")
            for node in all_nodes:
                logger.trace(f"  - èŠ‚ç‚¹: {node.get('node_name', 'Unknown')} (ç±»å‹: '{node.get('node_type', 'Unknown')}', çŠ¶æ€: {node.get('status', 'Unknown')})")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°pendingçŠ¶æ€çš„STARTèŠ‚ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å·²å®Œæˆçš„STARTèŠ‚ç‚¹
            if not start_nodes and all_nodes:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°pendingçŠ¶æ€çš„STARTèŠ‚ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å·²å®Œæˆçš„STARTèŠ‚ç‚¹")
                completed_start_query = """
                SELECT ni.*, n.type as node_type, n.name as node_name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.workflow_instance_id = $1
                AND LOWER(n.type) = 'start'
                AND ni.status IN ('completed', 'COMPLETED')
                AND ni.is_deleted = FALSE
                AND n.is_deleted = FALSE
                ORDER BY ni.created_at ASC
                """
                completed_start_nodes = await node_instance_repo.db.fetch_all(completed_start_query, workflow_instance_id)
                logger.trace(f"æ‰¾åˆ° {len(completed_start_nodes)} ä¸ªå·²å®Œæˆçš„STARTèŠ‚ç‚¹")
                
                if completed_start_nodes:
                    logger.trace("STARTèŠ‚ç‚¹å·²ç»æ‰§è¡Œå®Œæˆï¼Œå·¥ä½œæµå·²åœ¨è¿è¡Œä¸­")
                    # è¿”å›ç©ºåˆ—è¡¨ï¼Œè¡¨ç¤ºä¸éœ€è¦é‡æ–°å¯åŠ¨STARTèŠ‚ç‚¹
                    return []
                
                # å°è¯•ä¸åŒçš„æŸ¥è¯¢æ–¹å¼
                alt_query = """
                SELECT ni.*, n.type as node_type, n.name as node_name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.workflow_instance_id = $1
                AND n.type IN ('start', 'START')
                AND ni.status IN ('pending', 'PENDING')
                AND ni.is_deleted = FALSE
                AND n.is_deleted = FALSE
                ORDER BY ni.created_at ASC
                """
                alt_start_nodes = await node_instance_repo.db.fetch_all(alt_query, workflow_instance_id)
                logger.trace(f"å¤‡ç”¨æŸ¥è¯¢æ‰¾åˆ° {len(alt_start_nodes)} ä¸ªSTARTèŠ‚ç‚¹")
                if alt_start_nodes:
                    start_nodes = alt_start_nodes
            
            return start_nodes
            
        except Exception as e:
            logger.error(f"è·å–STARTèŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            return []
    
    async def _resume_workflow_execution(self, workflow_instance_id: uuid.UUID):
        """æ¢å¤å·¥ä½œæµæ‰§è¡Œï¼Œæ£€æŸ¥å¹¶è§¦å‘å‡†å¤‡å¥½çš„èŠ‚ç‚¹"""
        try:
            logger.trace(f"ğŸ”„ å¼€å§‹æ¢å¤å·¥ä½œæµæ‰§è¡Œ: {workflow_instance_id}")
            
            # æŸ¥æ‰¾æ‰€æœ‰pendingçŠ¶æ€çš„èŠ‚ç‚¹
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_instance_repo = NodeInstanceRepository()
            
            pending_query = """
            SELECT ni.*, n.type as node_type, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1
            AND ni.status IN ('pending', 'PENDING', 'waiting', 'WAITING')
            AND ni.is_deleted = FALSE
            AND n.is_deleted = FALSE
            ORDER BY ni.created_at ASC
            """
            
            pending_nodes = await node_instance_repo.db.fetch_all(pending_query, workflow_instance_id)
            logger.trace(f"æ‰¾åˆ° {len(pending_nodes)} ä¸ªå¾…å¤„ç†çŠ¶æ€çš„èŠ‚ç‚¹ (pending/waiting)")
            
            if pending_nodes:
                for node in pending_nodes:
                    node_name = node.get('node_name', 'æœªçŸ¥')
                    node_type = node.get('node_type', 'æœªçŸ¥')
                    logger.trace(f"  - å¾…å¤„ç†èŠ‚ç‚¹: {node_name} (ç±»å‹: {node_type}, çŠ¶æ€: {node.get('status', 'æœªçŸ¥')})")
                
                # ç¡®ä¿å·²å®Œæˆçš„STARTèŠ‚ç‚¹å·²é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
                await self._ensure_completed_start_nodes_notified(workflow_instance_id)
                
                # æ£€æŸ¥è¿™äº›èŠ‚ç‚¹çš„ä¾èµ–æ˜¯å¦å·²æ»¡è¶³ï¼Œå¦‚æœæ»¡è¶³åˆ™è§¦å‘æ‰§è¡Œ
                logger.trace(f"æ£€æŸ¥pendingèŠ‚ç‚¹çš„ä¾èµ–å…³ç³»")
                await self._check_and_trigger_ready_nodes(workflow_instance_id, pending_nodes)
            else:
                logger.trace(f"æ²¡æœ‰æ‰¾åˆ°pendingçŠ¶æ€çš„èŠ‚ç‚¹ï¼Œå·¥ä½œæµå¯èƒ½å·²å®Œæˆæˆ–å‡ºç°å¼‚å¸¸")
                
        except Exception as e:
            logger.error(f"æ¢å¤å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
    
    async def _ensure_completed_start_nodes_notified(self, workflow_instance_id: uuid.UUID):
        """ç¡®ä¿å·²å®Œæˆçš„STARTèŠ‚ç‚¹å·²é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        try:
            logger.trace(f"ğŸ” [STARTèŠ‚ç‚¹ä¿®å¤] æ£€æŸ¥å·²å®Œæˆçš„STARTèŠ‚ç‚¹æ˜¯å¦å·²é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
            
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_instance_repo = NodeInstanceRepository()
            
            # æŸ¥æ‰¾å·²å®Œæˆçš„STARTèŠ‚ç‚¹
            completed_start_query = """
            SELECT ni.*, n.type as node_type, n.name as node_name, n.node_id
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1
            AND LOWER(n.type) = 'start'
            AND ni.status IN ('completed', 'COMPLETED')
            AND ni.is_deleted = FALSE
            AND n.is_deleted = FALSE
            ORDER BY ni.completed_at ASC
            """
            
            completed_start_nodes = await node_instance_repo.db.fetch_all(completed_start_query, workflow_instance_id)
            logger.trace(f"  - æ‰¾åˆ° {len(completed_start_nodes)} ä¸ªå·²å®Œæˆçš„STARTèŠ‚ç‚¹")
            
            # ååºåˆ—åŒ–JSONå­—æ®µ
            for i, node in enumerate(completed_start_nodes):
                completed_start_nodes[i] = node_instance_repo._deserialize_json_fields(dict(node))
            
            if not completed_start_nodes:
                logger.trace(f"  âŒ æ²¡æœ‰æ‰¾åˆ°å·²å®Œæˆçš„STARTèŠ‚ç‚¹")
                return
            
            for start_node in completed_start_nodes:
                node_instance_id = start_node['node_instance_id']
                node_id = start_node['node_id']
                node_name = start_node.get('node_name', 'æœªçŸ¥')
                output_data = start_node.get('output_data', {})
                
                logger.trace(f"  ğŸ“‹ å¤„ç†STARTèŠ‚ç‚¹: {node_name}")
                logger.trace(f"    - node_instance_id: {node_instance_id}")
                logger.trace(f"    - node_id: {node_id}")
                
                # æ£€æŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­æ˜¯å¦å·²ç»è®°å½•äº†è¿™ä¸ªèŠ‚ç‚¹çš„å®ŒæˆçŠ¶æ€
                dependency_info = self.context_manager.get_node_dependency_info(node_instance_id)
                if dependency_info:
                    logger.trace(f"    - èŠ‚ç‚¹ä¾èµ–ä¿¡æ¯å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦å·²åœ¨completed_nodesä¸­")
                    workflow_context = self.context_manager.contexts.get(workflow_instance_id, None)
                    if workflow_context:
                        completed_nodes = workflow_context.execution_context.get('completed_nodes', set())
                    else:
                        completed_nodes = set()
                    
                    if node_id not in completed_nodes:
                        logger.trace(f"  ğŸ”§ [STARTèŠ‚ç‚¹ä¿®å¤] STARTèŠ‚ç‚¹ {node_name} å·²å®Œæˆä½†æœªé€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œæ­£åœ¨ä¿®å¤...")
                        
                        # ç¡®ä¿output_dataåŒ…å«task_description
                        if isinstance(output_data, dict) and 'task_description' not in output_data:
                            # ä»èŠ‚ç‚¹å®šä¹‰ä¸­è·å–task_description
                            task_description = start_node.get('task_description', '')
                            if not task_description:
                                from ..repositories.node.node_repository import NodeRepository
                                node_repo = NodeRepository()
                                node_data = await node_repo.get_node_by_id(node_id)
                                if node_data:
                                    task_description = node_data.get('task_description', '')
                            
                            # ç¡®ä¿output_dataæ˜¯å­—å…¸ç±»å‹ï¼Œå¹¶æ·»åŠ task_description
                            if not isinstance(output_data, dict):
                                output_data = {}
                            output_data['task_description'] = task_description
                            logger.trace(f"    - è¡¥å……task_description: {task_description[:50]}...")
                        
                        # æ‰‹åŠ¨é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
                        await self.context_manager.mark_node_completed(
                            workflow_instance_id, 
                            node_id, 
                            node_instance_id, 
                            output_data
                        )
                        
                        logger.trace(f"  âœ… [STARTèŠ‚ç‚¹ä¿®å¤] å·²é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨STARTèŠ‚ç‚¹ {node_name} çš„å®ŒæˆçŠ¶æ€")
                    else:
                        logger.trace(f"  âœ… STARTèŠ‚ç‚¹ {node_name} å·²åœ¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­æ ‡è®°ä¸ºå®Œæˆ")
                else:
                    logger.warning(f"  âš ï¸ STARTèŠ‚ç‚¹ {node_name} çš„ä¾èµ–ä¿¡æ¯ä¸å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦é‡æ–°æ³¨å†Œ")
            
            logger.trace(f"âœ… [STARTèŠ‚ç‚¹ä¿®å¤] å·²å®Œæˆçš„STARTèŠ‚ç‚¹é€šçŸ¥æ£€æŸ¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ [STARTèŠ‚ç‚¹ä¿®å¤] ç¡®ä¿STARTèŠ‚ç‚¹é€šçŸ¥å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
    
    async def _check_and_trigger_ready_nodes(self, workflow_instance_id: uuid.UUID, pending_nodes: List[Dict]):
        """æ£€æŸ¥å¹¶è§¦å‘å‡†å¤‡å¥½çš„èŠ‚ç‚¹"""
        try:
            logger.trace(f"æ£€æŸ¥ {len(pending_nodes)} ä¸ªpendingèŠ‚ç‚¹çš„ä¾èµ–å…³ç³»")
            
            for node in pending_nodes:
                node_instance_id = node['node_instance_id']
                node_name = node.get('node_name', 'æœªçŸ¥')
                
                # æ£€æŸ¥èŠ‚ç‚¹ä¾èµ–æ˜¯å¦æ»¡è¶³
                if await self._check_node_dependencies_satisfied(workflow_instance_id, node_instance_id):
                    logger.trace(f"âœ… èŠ‚ç‚¹ {node_name} çš„ä¾èµ–å·²æ»¡è¶³ï¼Œè§¦å‘æ‰§è¡Œ")
                    await self._execute_node_when_ready(workflow_instance_id, node_instance_id)
                else:
                    logger.trace(f"â³ èŠ‚ç‚¹ {node_name} çš„ä¾èµ–å°šæœªæ»¡è¶³ï¼Œç­‰å¾…ä¸­")
                    
        except Exception as e:
            logger.error(f"æ£€æŸ¥å’Œè§¦å‘å‡†å¤‡å¥½çš„èŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
    
    # _collect_task_context_data æ–¹æ³•å·²è¢« WorkflowContextManager.get_task_context_data æ›¿æ¢

    async def _check_node_dependencies_satisfied(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹çš„ä¾èµ–æ˜¯å¦å·²æ»¡è¶³ï¼ˆä¿®å¤ç‰ˆï¼šä¸¥æ ¼æ£€æŸ¥ä¾èµ–é¡ºåºï¼‰"""
        try:
            # ğŸ” é¦–å…ˆæ£€æŸ¥å·¥ä½œæµä¸Šä¸‹æ–‡æ˜¯å¦å­˜åœ¨
            if workflow_instance_id not in self.context_manager.contexts:
                logger.warning(f"âš ï¸ [ä¾èµ–æ£€æŸ¥] å·¥ä½œæµä¸Šä¸‹æ–‡ {workflow_instance_id} ä¸å­˜åœ¨ï¼Œè·³è¿‡èŠ‚ç‚¹ {node_instance_id}")
                return False
            
            # ğŸ” ä¸¥æ ¼æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€ - é˜²æ­¢é‡å¤æ‰§è¡Œ
            node_state = self.context_manager.node_completion_status.get(node_instance_id)
            if node_state in ['EXECUTING', 'COMPLETED']:
                logger.trace(f"ğŸš« [ä¾èµ–æ£€æŸ¥] èŠ‚ç‚¹ {node_instance_id} å†…å­˜çŠ¶æ€ä¸º {node_state}ï¼Œè·³è¿‡è§¦å‘")
                return False
            
            # ğŸ” åŒé‡æ£€æŸ¥ï¼šæ•°æ®åº“çŠ¶æ€éªŒè¯
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_instance_repo = NodeInstanceRepository()
            
            node_info = await node_instance_repo.get_instance_by_id(node_instance_id)
            if node_info and node_info.get('status') in ['running', 'completed']:
                logger.trace(f"ğŸš« [ä¾èµ–æ£€æŸ¥-DB] èŠ‚ç‚¹ {node_instance_id} æ•°æ®åº“çŠ¶æ€ä¸º {node_info.get('status')}ï¼Œè·³è¿‡è§¦å‘")
                return False
            
            # ğŸ” è·å–èŠ‚ç‚¹ä¾èµ–ä¿¡æ¯ï¼ˆä¿®å¤ç‰ˆï¼šæ”¯æŒé™çº§æŸ¥è¯¢ï¼‰
            deps = self.context_manager.get_node_dependency_info(node_instance_id)
            if not deps:
                logger.warning(f"âš ï¸ [ä¾èµ–æ£€æŸ¥] èŠ‚ç‚¹ {node_instance_id} åœ¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­æ²¡æœ‰ä¾èµ–ä¿¡æ¯ï¼Œå°è¯•ä»æ•°æ®åº“æ¢å¤")
                
                # ğŸ”„ é™çº§ç­–ç•¥ï¼šä»æ•°æ®åº“é‡æ–°æ„å»ºä¾èµ–ä¿¡æ¯
                try:
                    await self._rebuild_node_dependencies_from_db(workflow_instance_id, node_instance_id)
                    
                    # é‡æ–°å°è¯•è·å–ä¾èµ–ä¿¡æ¯
                    deps = self.context_manager.get_node_dependency_info(node_instance_id)
                    if not deps:
                        logger.error(f"âŒ [ä¾èµ–æ£€æŸ¥] æ— æ³•ä»æ•°æ®åº“æ¢å¤èŠ‚ç‚¹ {node_instance_id} çš„ä¾èµ–ä¿¡æ¯")
                        return False
                    else:
                        logger.info(f"âœ… [ä¾èµ–æ£€æŸ¥] æˆåŠŸä»æ•°æ®åº“æ¢å¤èŠ‚ç‚¹ {node_instance_id} çš„ä¾èµ–ä¿¡æ¯")
                except Exception as e:
                    logger.error(f"âŒ [ä¾èµ–æ£€æŸ¥] ä»æ•°æ®åº“æ¢å¤ä¾èµ–ä¿¡æ¯å¤±è´¥: {e}")
                    return False
            
            node_id = deps.get('node_id')
            upstream_nodes = deps.get('upstream_nodes', [])
            
            # ğŸ” å¦‚æœæ²¡æœ‰ä¸Šæ¸¸ä¾èµ–ï¼ˆSTARTèŠ‚ç‚¹ï¼‰ï¼Œæ£€æŸ¥æ˜¯å¦å¯ä»¥æ‰§è¡Œ
            if not upstream_nodes:
                # STARTèŠ‚ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦å·²ç»åœ¨ä¸Šä¸‹æ–‡ä¸­æ ‡è®°ä¸ºå®Œæˆ
                context = self.context_manager.contexts[workflow_instance_id]
                if node_id in context.execution_context.get('completed_nodes', set()):
                    logger.trace(f"ğŸš« [ä¾èµ–æ£€æŸ¥] STARTèŠ‚ç‚¹ {node_instance_id} å·²åœ¨ä¸Šä¸‹æ–‡ä¸­å®Œæˆ")
                    return False
                logger.trace(f"âœ… [ä¾èµ–æ£€æŸ¥] STARTèŠ‚ç‚¹ {node_instance_id} æ— ä¾èµ–ï¼Œå¯ä»¥æ‰§è¡Œ")
                return True
            
            # ğŸ” ä¸¥æ ¼æ£€æŸ¥æ‰€æœ‰ä¸Šæ¸¸ä¾èµ–çš„å®ŒæˆçŠ¶æ€
            context = self.context_manager.contexts[workflow_instance_id]
            completed_nodes = context.execution_context.get('completed_nodes', set())
            
            # æ£€æŸ¥æ¯ä¸ªä¸Šæ¸¸èŠ‚ç‚¹æ˜¯å¦éƒ½å·²å®Œæˆ
            all_upstream_completed = True
            completed_count = 0
            
            for upstream_node_id in upstream_nodes:
                # æ£€æŸ¥ä¸Šä¸‹æ–‡çŠ¶æ€
                if upstream_node_id in completed_nodes:
                    completed_count += 1
                    logger.trace(f"  âœ… ä¸Šæ¸¸èŠ‚ç‚¹ {upstream_node_id} åœ¨ä¸Šä¸‹æ–‡ä¸­å·²å®Œæˆ")
                else:
                    # åŒé‡æ£€æŸ¥ï¼šéªŒè¯æ•°æ®åº“çŠ¶æ€
                    upstream_query = """
                    SELECT ni.status, ni.node_instance_id, n.name
                    FROM node_instance ni 
                    JOIN node n ON ni.node_id = n.node_id
                    WHERE ni.node_id = $1 
                    AND ni.workflow_instance_id = $2 
                    AND ni.is_deleted = FALSE
                    ORDER BY ni.created_at DESC LIMIT 1
                    """
                    
                    upstream_result = await node_instance_repo.db.fetch_one(
                        upstream_query, upstream_node_id, workflow_instance_id
                    )
                    
                    if upstream_result and upstream_result.get('status') == 'completed':
                        completed_count += 1
                        logger.trace(f"  âœ… ä¸Šæ¸¸èŠ‚ç‚¹ {upstream_node_id} åœ¨æ•°æ®åº“ä¸­å·²å®Œæˆ")
                        # åŒæ­¥åˆ°ä¸Šä¸‹æ–‡ï¼ˆä¿®å¤çŠ¶æ€ä¸ä¸€è‡´ï¼‰
                        context['completed_nodes'].add(upstream_node_id)
                    else:
                        all_upstream_completed = False
                        status = upstream_result.get('status') if upstream_result else 'not_found'
                        name = upstream_result.get('name') if upstream_result else 'Unknown'
                        logger.trace(f"  âŒ ä¸Šæ¸¸èŠ‚ç‚¹ {upstream_node_id} ({name}) çŠ¶æ€ä¸º {status}ï¼Œä¾èµ–æœªæ»¡è¶³")
                        break
            
            # ğŸ” æœ€ç»ˆä¾èµ–æ£€æŸ¥ç»“æœ
            dependencies_satisfied = all_upstream_completed and completed_count == len(upstream_nodes)
            
            if dependencies_satisfied:
                # å†æ¬¡ç¡®è®¤èŠ‚ç‚¹æœªè¢«æ‰§è¡Œ
                if node_id in context.execution_context.get('completed_nodes', set()):
                    logger.trace(f"ğŸš« [ä¾èµ–æ£€æŸ¥] èŠ‚ç‚¹ {node_instance_id} å·²åœ¨ä¸Šä¸‹æ–‡ä¸­å®Œæˆï¼Œè·³è¿‡")
                    return False
                
                logger.trace(f"âœ… [ä¾èµ–æ£€æŸ¥] èŠ‚ç‚¹ {node_instance_id} æ‰€æœ‰ä¾èµ–å·²æ»¡è¶³ ({completed_count}/{len(upstream_nodes)})")
                return True
            else:
                logger.trace(f"â³ [ä¾èµ–æ£€æŸ¥] èŠ‚ç‚¹ {node_instance_id} ä¾èµ–æœªæ»¡è¶³ ({completed_count}/{len(upstream_nodes)})")
                return False
                
        except Exception as e:
            logger.error(f"âŒ [ä¾èµ–æ£€æŸ¥] æ£€æŸ¥èŠ‚ç‚¹ä¾èµ–å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return False
                
    async def _rebuild_node_dependencies_from_db(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """ä»æ•°æ®åº“é‡æ–°æ„å»ºèŠ‚ç‚¹ä¾èµ–ä¿¡æ¯ï¼ˆä¿®å¤æ–¹æ³•ï¼‰"""
        try:
            logger.debug(f"ğŸ”„ [ä¾èµ–é‡å»º] å¼€å§‹ä»æ•°æ®åº“é‡å»ºèŠ‚ç‚¹ {node_instance_id} çš„ä¾èµ–ä¿¡æ¯")
            
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_repo = NodeInstanceRepository()
            
            # è·å–èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯
            node_instance = await node_repo.get_instance_by_id(node_instance_id)
            if not node_instance:
                logger.error(f"âŒ [ä¾èµ–é‡å»º] èŠ‚ç‚¹å®ä¾‹ä¸å­˜åœ¨: {node_instance_id}")
                return False
            
            node_id = node_instance['node_id']
            logger.debug(f"  èŠ‚ç‚¹ID: {node_id}")
            
            # æŸ¥è¯¢ä¸Šæ¸¸è¿æ¥å…³ç³»
            upstream_query = """
            SELECT DISTINCT 
                nc.from_node_id as upstream_node_id,
                n.name as upstream_node_name,
                n.type as upstream_node_type
            FROM node_connection nc
            JOIN node n ON nc.from_node_id = n.node_id
            JOIN node_instance ni ON ni.node_id = n.node_id
            WHERE nc.to_node_id = $1 
            AND ni.workflow_instance_id = $2
            AND ni.is_deleted = FALSE
            ORDER BY n.name
            """
            
            upstream_connections = await node_repo.db.fetch_all(
                upstream_query, node_id, workflow_instance_id
            )
            
            logger.debug(f"  æŸ¥è¯¢åˆ° {len(upstream_connections)} ä¸ªä¸Šæ¸¸è¿æ¥")
            
            upstream_node_ids = []
            for upstream in upstream_connections:
                upstream_node_id = upstream['upstream_node_id']
                upstream_node_ids.append(upstream_node_id)
                logger.debug(f"    ä¸Šæ¸¸èŠ‚ç‚¹: {upstream.get('upstream_node_name', 'Unknown')} (node_id: {upstream_node_id})")
            
            # é‡æ–°æ³¨å†Œä¾èµ–å…³ç³»
            await self.context_manager.register_node_dependencies(
                workflow_instance_id,
                node_instance_id,
                node_id,
                upstream_node_ids
            )
            
            logger.debug(f"âœ… [ä¾èµ–é‡å»º] æˆåŠŸé‡å»ºèŠ‚ç‚¹ {node_instance_id} çš„ä¾èµ–ä¿¡æ¯: {len(upstream_node_ids)} ä¸ªä¸Šæ¸¸èŠ‚ç‚¹")
            return True
            
        except Exception as e:
            logger.error(f"âŒ [ä¾èµ–é‡å»º] é‡å»ºä¾èµ–ä¿¡æ¯å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return False
    
    async def _try_recover_node_context_state(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """å°è¯•æ¢å¤èŠ‚ç‚¹çš„ä¸Šä¸‹æ–‡çŠ¶æ€"""
        try:
            logger.debug(f"ğŸ”„ [çŠ¶æ€æ¢å¤] å°è¯•æ¢å¤èŠ‚ç‚¹ {node_instance_id} çš„ä¸Šä¸‹æ–‡çŠ¶æ€")
            
            # æ£€æŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ˜¯å¦æœ‰ç”Ÿå‘½å‘¨æœŸä¸€è‡´æ€§æ£€æŸ¥æ–¹æ³•
            if hasattr(self.context_manager, 'ensure_context_lifecycle_consistency'):
                await self.context_manager.ensure_context_lifecycle_consistency(workflow_instance_id)
                logger.debug(f"âœ… [çŠ¶æ€æ¢å¤] å®Œæˆå·¥ä½œæµç”Ÿå‘½å‘¨æœŸä¸€è‡´æ€§æ£€æŸ¥")
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥é‡æ–°åˆå§‹åŒ–ä¸Šä¸‹æ–‡
            if workflow_instance_id not in self.context_manager.contexts:
                logger.info(f"ğŸ”„ [çŠ¶æ€æ¢å¤] é‡æ–°åˆå§‹åŒ–å·¥ä½œæµä¸Šä¸‹æ–‡: {workflow_instance_id}")
                await self.context_manager.initialize_workflow_context(workflow_instance_id, restore_from_snapshot=True)
                
                # é‡æ–°æ³¨å†Œä¾èµ–å…³ç³»
                await self._rebuild_workflow_dependencies(workflow_instance_id)
            
        except Exception as e:
            logger.error(f"âŒ [çŠ¶æ€æ¢å¤] æ¢å¤èŠ‚ç‚¹ä¸Šä¸‹æ–‡çŠ¶æ€å¤±è´¥: {e}")
    
    async def _rebuild_workflow_dependencies(self, workflow_instance_id: uuid.UUID):
        """é‡å»ºå·¥ä½œæµçš„ä¾èµ–å…³ç³»"""
        try:
            logger.debug(f"ğŸ”§ [ä¾èµ–é‡å»º] å¼€å§‹é‡å»ºå·¥ä½œæµ {workflow_instance_id} çš„ä¾èµ–å…³ç³»")
            
            # è·å–å·¥ä½œæµçš„æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_repo = NodeInstanceRepository()
            
            nodes_query = """
            SELECT ni.node_instance_id, ni.node_id, n.type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 AND ni.is_deleted = FALSE
            ORDER BY ni.created_at
            """
            
            nodes = await node_repo.db.fetch_all(nodes_query, workflow_instance_id)
            
            for node in nodes:
                node_instance_id = node['node_instance_id']
                node_id = node['node_id']
                
                # è·å–ä¸Šæ¸¸ä¾èµ–
                upstream_query = """
                SELECT nc.from_node_id
                FROM node_connection nc
                WHERE nc.to_node_id = $1
                """
                
                upstream_results = await node_repo.db.fetch_all(upstream_query, node_id)
                upstream_nodes = [result['from_node_id'] for result in upstream_results]
                
                # é‡æ–°æ³¨å†Œä¾èµ–
                await self.context_manager.register_node_dependencies(
                    node_instance_id, node_id, workflow_instance_id, upstream_nodes
                )
                
                logger.trace(f"ğŸ”§ [ä¾èµ–é‡å»º] èŠ‚ç‚¹ {node_instance_id} ä¾èµ–å·²é‡å»º: {len(upstream_nodes)} ä¸ªä¸Šæ¸¸èŠ‚ç‚¹")
            
            logger.debug(f"âœ… [ä¾èµ–é‡å»º] å·¥ä½œæµ {workflow_instance_id} ä¾èµ–å…³ç³»é‡å»ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ [ä¾èµ–é‡å»º] é‡å»ºä¾èµ–å…³ç³»å¤±è´¥: {e}")
    
    async def _execute_start_node_directly(self, workflow_instance_id: uuid.UUID, start_node: Dict[str, Any]):
        """ç›´æ¥æ‰§è¡ŒSTARTèŠ‚ç‚¹"""
        try:
            node_instance_id = start_node['node_instance_id']
            node_name = start_node.get('node_name', 'æœªçŸ¥')
            logger.trace(f"â–¶ï¸ å¼€å§‹ç›´æ¥æ‰§è¡ŒSTARTèŠ‚ç‚¹: {node_name} (ID: {node_instance_id})")
            
            # æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
            logger.trace(f"  æ­¥éª¤1: æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€ä¸º RUNNING")
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceUpdate, NodeInstanceStatus
            
            node_instance_repo = NodeInstanceRepository()
            
            # æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
            update_data = NodeInstanceUpdate(
                status=NodeInstanceStatus.RUNNING
            )
            await node_instance_repo.update_node_instance(node_instance_id, update_data)
            logger.trace(f"  âœ… èŠ‚ç‚¹çŠ¶æ€æ›´æ–°ä¸º RUNNING æˆåŠŸ")
            
            # STARTèŠ‚ç‚¹æ²¡æœ‰å®é™…ä»»åŠ¡ï¼Œç›´æ¥å®Œæˆï¼Œä½†è¦åŒ…å«task_descriptionä¾›ä¸‹æ¸¸ä½¿ç”¨
            logger.trace(f"  æ­¥éª¤2: STARTèŠ‚ç‚¹æ— å®é™…ä»»åŠ¡ï¼Œç›´æ¥æ ‡è®°ä¸º COMPLETED")
            
            # è·å–èŠ‚ç‚¹çš„task_description
            task_description = start_node.get('task_description', '')
            if not task_description:
                # å¦‚æœèŠ‚ç‚¹å®ä¾‹æ²¡æœ‰task_descriptionï¼Œä»èŠ‚ç‚¹å®šä¹‰ä¸­è·å–
                from ..repositories.node.node_repository import NodeRepository
                node_repo = NodeRepository()
                node_data = await node_repo.get_node_by_id(start_node['node_id'])
                if node_data:
                    task_description = node_data.get('task_description', '')
            
            completed_data = NodeInstanceUpdate(
                status=NodeInstanceStatus.COMPLETED,
                output_data={
                    'message': 'STARTèŠ‚ç‚¹è‡ªåŠ¨å®Œæˆ',
                    'task_description': task_description,  # æ·»åŠ task_descriptionä¾›ä¸‹æ¸¸èŠ‚ç‚¹ä½¿ç”¨
                    'completed_at': datetime.utcnow().isoformat()
                }
            )
            await node_instance_repo.update_node_instance(node_instance_id, completed_data)
            logger.trace(f"  âœ… èŠ‚ç‚¹çŠ¶æ€æ›´æ–°ä¸º COMPLETED æˆåŠŸ")
            
            # æ­¥éª¤3: é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨èŠ‚ç‚¹å®Œæˆ
            logger.trace(f"  æ­¥éª¤3: é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨STARTèŠ‚ç‚¹å®Œæˆ")
            node_instance_data = await node_instance_repo.get_instance_by_id(node_instance_id)
            if node_instance_data and self.context_manager:
                node_id = node_instance_data['node_id']
                output_data = completed_data.output_data
                
                logger.trace(f"    - é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨: node_id={node_id}")
                logger.trace(f"    - ä¼ é€’çš„output_dataç±»å‹: {type(output_data)}")
                logger.trace(f"    - ä¼ é€’çš„output_dataå†…å®¹: {output_data}")
                await self.context_manager.mark_node_completed(
                    workflow_instance_id, node_id, node_instance_id, output_data
                )
                logger.trace(f"    âœ… ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€šçŸ¥å®Œæˆ")
            else:
                logger.warning(f"    âš ï¸ æ— æ³•é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨: node_instance_data={node_instance_data is not None}, context_manager={self.context_manager is not None}")
            
            # è·å–ä¸‹æ¸¸èŠ‚ç‚¹å¹¶å¯åŠ¨æ‰§è¡Œï¼ˆè¿™ä¸ªæ–¹æ³•å¯èƒ½æ˜¯é‡å¤çš„ï¼Œä¸Šä¸‹æ–‡ç®¡ç†å™¨å·²ç»å¤„ç†äº†ï¼‰
            logger.trace(f"  æ­¥éª¤4: è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹æ‰§è¡Œï¼ˆé€šè¿‡_trigger_downstream_nodesï¼‰")
            await self._trigger_downstream_nodes(workflow_instance_id, start_node)
            logger.trace(f"  âœ… ä¸‹æ¸¸èŠ‚ç‚¹è§¦å‘å®Œæˆ")
            
            logger.trace(f"  âœ… STARTèŠ‚ç‚¹æ‰§è¡Œå®Œæˆ: {node_name} (ID: {node_instance_id})")
            
        except Exception as e:
            node_name = start_node.get('node_name', 'æœªçŸ¥')
            logger.error(f"âŒ æ‰§è¡ŒSTARTèŠ‚ç‚¹å¤±è´¥ {node_name}: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆè¯¦æƒ…: {traceback.format_exc()}")
            raise
    
    async def _trigger_downstream_nodes(self, workflow_instance_id: uuid.UUID, completed_node: Dict[str, Any]):
        """è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹æ‰§è¡Œ"""
        try:
            logger.trace(f"è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹æ‰§è¡Œï¼Œå·²å®ŒæˆèŠ‚ç‚¹: {completed_node.get('node_base_id')}")
            
            # 1. è·å–å·¥ä½œæµå®ä¾‹ä¸Šä¸‹æ–‡
            logger.trace(f"è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹æ‰§è¡Œï¼Œå·²å®ŒæˆèŠ‚ç‚¹: {completed_node.get('node_id')}")
            
            # ä½¿ç”¨ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¤„ç†ä¾èµ–å…³ç³»
            
        except Exception as e:
            logger.error(f"è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    async def _execute_node_when_ready(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """å½“èŠ‚ç‚¹å‡†å¤‡å¥½æ—¶æ‰§è¡ŒèŠ‚ç‚¹"""
        try:
            logger.trace(f"ğŸš€ [èŠ‚ç‚¹æ‰§è¡Œ] å¼€å§‹æ‰§è¡ŒèŠ‚ç‚¹: {node_instance_id}")
            logger.trace(f"  - å·¥ä½œæµå®ä¾‹: {workflow_instance_id}")
            
            # é¦–å…ˆæ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å·²ç»å®Œæˆæˆ–æ­£åœ¨æ‰§è¡Œï¼Œé˜²æ­¢é‡å¤æ‰§è¡Œ
            node_status = self.context_manager.node_completion_status.get(node_instance_id)
            if node_status in ['COMPLETED', 'EXECUTING']:
                logger.warning(f"ğŸ”„ [èŠ‚ç‚¹æ‰§è¡Œ-é˜²é‡å¤] èŠ‚ç‚¹ {node_instance_id} çŠ¶æ€ä¸º {node_status}ï¼Œè·³è¿‡é‡å¤æ‰§è¡Œ")
                return
            
            # æ ‡è®°èŠ‚ç‚¹ä¸ºæ‰§è¡Œä¸­çŠ¶æ€
            self.context_manager.node_completion_status[node_instance_id] = 'EXECUTING'
            logger.trace(f"  - èŠ‚ç‚¹çŠ¶æ€å·²æ ‡è®°ä¸º: EXECUTING")
            
            # é¦–å…ˆæ£€æŸ¥å·¥ä½œæµä¸Šä¸‹æ–‡æ˜¯å¦ä»ç„¶å­˜åœ¨
            if workflow_instance_id not in self.context_manager.contexts:
                logger.warning(f"âŒ [èŠ‚ç‚¹æ‰§è¡Œ] å·¥ä½œæµä¸Šä¸‹æ–‡ {workflow_instance_id} å·²è¢«æ¸…ç†ï¼ŒèŠ‚ç‚¹æ‰§è¡Œå–æ¶ˆ")
                
                # ğŸ”„ å°è¯•æ¢å¤ä¸Šä¸‹æ–‡
                try:
                    logger.info(f"ğŸ”„ [èŠ‚ç‚¹æ‰§è¡Œ] å°è¯•æ¢å¤å·¥ä½œæµä¸Šä¸‹æ–‡: {workflow_instance_id}")
                    await self._try_recover_node_context_state(workflow_instance_id, node_instance_id)
                    
                    # å†æ¬¡æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦æ¢å¤
                    if workflow_instance_id not in self.context_manager.contexts:
                        logger.error(f"âŒ [èŠ‚ç‚¹æ‰§è¡Œ] æ— æ³•æ¢å¤å·¥ä½œæµä¸Šä¸‹æ–‡ï¼ŒèŠ‚ç‚¹æ‰§è¡Œç»ˆæ­¢")
                        # æ¢å¤çŠ¶æ€ä¸ºPENDING
                        self.context_manager.node_completion_status[node_instance_id] = 'PENDING'
                        return
                    else:
                        logger.info(f"âœ… [èŠ‚ç‚¹æ‰§è¡Œ] å·¥ä½œæµä¸Šä¸‹æ–‡æ¢å¤æˆåŠŸ")
                except Exception as recovery_error:
                    logger.error(f"âŒ [èŠ‚ç‚¹æ‰§è¡Œ] ä¸Šä¸‹æ–‡æ¢å¤å¤±è´¥: {recovery_error}")
                    # æ¢å¤çŠ¶æ€ä¸ºPENDING
                    self.context_manager.node_completion_status[node_instance_id] = 'PENDING'
                    return
            
            # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å‡†å¤‡å¥½æ‰§è¡Œ
            is_ready = self.context_manager.is_node_ready_to_execute(node_instance_id)
            logger.trace(f"  - èŠ‚ç‚¹å°±ç»ªçŠ¶æ€æ£€æŸ¥: {is_ready}")
            
            if not is_ready:
                logger.warning(f"âŒ [èŠ‚ç‚¹æ‰§è¡Œ] èŠ‚ç‚¹ {node_instance_id} å°šæœªå‡†å¤‡å¥½æ‰§è¡Œ")
                # æ¢å¤çŠ¶æ€ä¸ºPENDING
                self.context_manager.node_completion_status[node_instance_id] = 'PENDING'
                return
            
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            dep_info = self.context_manager.get_node_dependency_info(node_instance_id)
            logger.trace(f"  - ä¾èµ–ä¿¡æ¯è·å–: {'æˆåŠŸ' if dep_info else 'å¤±è´¥'}")
            
            if not dep_info:
                logger.error(f"âŒ [èŠ‚ç‚¹æ‰§è¡Œ] æ— æ³•è·å–èŠ‚ç‚¹ {node_instance_id} çš„ä¾èµ–ä¿¡æ¯")
                return
            
            node_id = dep_info.get('node_id')  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
            logger.trace(f"  - èŠ‚ç‚¹ID: {node_id}")
            logger.trace(f"  - ä¾èµ–æ•°é‡: {dep_info.get('dependency_count', 0)}")
            logger.trace(f"  - å·²å®Œæˆä¸Šæ¸¸: {len(dep_info.get('completed_upstream', set()))}")
            
            # æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
            logger.trace(f"ğŸ“ [èŠ‚ç‚¹æ‰§è¡Œ] æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ...")
            await self.context_manager.mark_node_executing(
                workflow_instance_id, node_id, node_instance_id  # ä½¿ç”¨node_id
            )
            
            # è·å–èŠ‚ç‚¹çš„ä¸Šæ¸¸ä¸Šä¸‹æ–‡
            logger.trace(f"ğŸ” [èŠ‚ç‚¹æ‰§è¡Œ] æ”¶é›†ä¸Šæ¸¸ä¸Šä¸‹æ–‡æ•°æ®...")
            upstream_context = await self.context_manager.get_node_upstream_context(
                workflow_instance_id, node_instance_id
            )
            logger.trace(f"  - ä¸Šæ¸¸ç»“æœæ•°é‡: {len(upstream_context.get('immediate_upstream_results', {}))}")
            
            # æ›´æ–°èŠ‚ç‚¹çš„ä»»åŠ¡å®ä¾‹ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡æ•°æ®
            logger.trace(f"ğŸ“ [èŠ‚ç‚¹æ‰§è¡Œ] æ›´æ–°ä»»åŠ¡ä¸Šä¸‹æ–‡æ•°æ®...")
            await self._update_node_tasks_with_context(node_instance_id, upstream_context)
            
            # æ‰§è¡ŒèŠ‚ç‚¹çš„ä»»åŠ¡
            logger.trace(f"âš¡ [èŠ‚ç‚¹æ‰§è¡Œ] å¼€å§‹æ‰§è¡ŒèŠ‚ç‚¹ä»»åŠ¡...")
            await self._execute_node_tasks(workflow_instance_id, node_instance_id)
            
            logger.trace(f"âœ… [èŠ‚ç‚¹æ‰§è¡Œ] èŠ‚ç‚¹ {node_instance_id} æ‰§è¡Œæµç¨‹å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ [èŠ‚ç‚¹æ‰§è¡Œ] æ‰§è¡ŒèŠ‚ç‚¹ {node_instance_id} å¤±è´¥: {e}")
            import traceback
            logger.error(f"  å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            
            # æ ‡è®°èŠ‚ç‚¹å¤±è´¥
            dep_info = self.context_manager.get_node_dependency_info(node_instance_id)
            if dep_info:
                node_id = dep_info.get('node_id', dep_info.get('node_base_id'))  # å…¼å®¹å¤„ç†
                await self.context_manager.mark_node_failed(
                    workflow_instance_id, 
                    node_id, 
                    node_instance_id,
                    {'error': str(e)}
                )
    
    async def _update_node_tasks_with_context(self, node_instance_id: uuid.UUID, upstream_context: Dict[str, Any]):
        """æ›´æ–°èŠ‚ç‚¹ä»»åŠ¡çš„ä¸Šä¸‹æ–‡æ•°æ®ï¼Œå¹¶åŒæ­¥æ›´æ–°èŠ‚ç‚¹çš„è¾“å…¥æ•°æ®"""
        try:
            # æ„å»ºå®Œæ•´çš„ä»»åŠ¡ä¸Šä¸‹æ–‡ - ä¿®å¤æ•°æ®æ ¼å¼è½¬æ¢é—®é¢˜
            immediate_upstream_results = upstream_context.get('immediate_upstream_results', {})
            logger.trace(f"ğŸ”„ [æ•°æ®æ ¼å¼è½¬æ¢] åŸå§‹ä¸Šæ¸¸ç»“æœ: {immediate_upstream_results}")
            
            task_context = {
                'immediate_upstream': immediate_upstream_results,  # ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨immediate_upstream_results
                'workflow_global': upstream_context.get('workflow_global', {}),
                'node_info': {
                    'node_instance_id': str(node_instance_id),
                    'upstream_node_count': upstream_context.get('upstream_node_count', 0)
                }
            }
            
            logger.trace(f"ğŸ”„ [æ•°æ®æ ¼å¼è½¬æ¢] æœ€ç»ˆä»»åŠ¡ä¸Šä¸‹æ–‡åŒ…å« {len(immediate_upstream_results)} ä¸ªä¸Šæ¸¸èŠ‚ç‚¹æ•°æ®")
            
            # é¦–å…ˆæ›´æ–°èŠ‚ç‚¹å®ä¾‹çš„è¾“å…¥æ•°æ®ï¼ˆç”¨äºå‰ç«¯æ˜¾ç¤ºï¼‰
            logger.trace(f"ğŸ“ [èŠ‚ç‚¹ä¸Šä¸‹æ–‡] æ›´æ–°èŠ‚ç‚¹ {node_instance_id} çš„è¾“å…¥æ•°æ®")
            logger.trace(f"   - ä¸Šæ¸¸ç»“æœæ•°é‡: {len(task_context.get('immediate_upstream', {}))}")
            logger.trace(f"   - å·¥ä½œæµå…¨å±€æ•°æ®: {len(task_context.get('workflow_global', {}).get('global_data', {}))}")
            
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceUpdate
            node_instance_repo = NodeInstanceRepository()
            
            node_update = NodeInstanceUpdate(input_data=task_context)
            await node_instance_repo.update_node_instance(node_instance_id, node_update)
            logger.trace(f"   âœ… èŠ‚ç‚¹è¾“å…¥æ•°æ®å·²æ›´æ–°ï¼šåŒ…å« {len(task_context)} ä¸ªé¡¶çº§å­—æ®µ")
            
            # ç„¶åè·å–èŠ‚ç‚¹çš„æ‰€æœ‰ä»»åŠ¡å¹¶æ›´æ–°å®ƒä»¬çš„ä¸Šä¸‹æ–‡
            tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
            
            for task in tasks:
                
                # å°†ä¸Šä¸‹æ–‡è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²ï¼ˆæ•°æ®åº“input_dataå­—æ®µæ˜¯TEXTç±»å‹ï¼‰
                from ..utils.helpers import safe_json_dumps
                task_context_json = safe_json_dumps(task_context)
                
                # æ›´æ–°ä»»åŠ¡çš„è¾“å…¥æ•°æ®ï¼ˆä½†ä¸æ”¹å˜å·²å®Œæˆæˆ–å¤±è´¥ä»»åŠ¡çš„çŠ¶æ€ï¼‰
                current_status = task.get('status', 'PENDING')
                
                # åªæœ‰PENDINGçŠ¶æ€çš„ä»»åŠ¡æ‰éœ€è¦æ›´æ–°çŠ¶æ€
                if current_status == 'PENDING':
                    new_status = TaskInstanceStatus.ASSIGNED if task.get('assigned_user_id') or task.get('assigned_agent_id') else TaskInstanceStatus.PENDING
                    update_data = TaskInstanceUpdate(
                        input_data=task_context_json,
                        status=new_status
                    )
                    logger.warning(f"ä»»åŠ¡ {task['task_instance_id']} çŠ¶æ€æ›´æ–°: {current_status} â†’ {new_status.value}")
                    logger.warning(f"ä»»åŠ¡ {task['task_instance_id']} ä¸Šä¸‹æ–‡æ•°æ®: {len(task_context_json)} å­—ç¬¦")
                else:
                    # å·²å®Œæˆ/å¤±è´¥/è¿›è¡Œä¸­çš„ä»»åŠ¡åªæ›´æ–°ä¸Šä¸‹æ–‡ï¼Œä¸æ”¹å˜çŠ¶æ€
                    update_data = TaskInstanceUpdate(
                        input_data=task_context_json
                    )
                    logger.warning(f"ä»»åŠ¡ {task['task_instance_id']} çŠ¶æ€ä¿æŒ: {current_status}ï¼ˆä»…æ›´æ–°ä¸Šä¸‹æ–‡ï¼‰")
                    logger.warning(f"ä»»åŠ¡ {task['task_instance_id']} ä¸Šä¸‹æ–‡æ•°æ®: {len(task_context_json)} å­—ç¬¦")
                
                await self.task_instance_repo.update_task(task['task_instance_id'], update_data)
                logger.warning(f"æ›´æ–°ä»»åŠ¡ {task['task_instance_id']} çš„ä¸Šä¸‹æ–‡æ•°æ®")
                
        except Exception as e:
            logger.error(f"æ›´æ–°èŠ‚ç‚¹ä»»åŠ¡ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            raise
    
    async def _execute_node_tasks(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """æ‰§è¡ŒèŠ‚ç‚¹çš„ä»»åŠ¡"""
        try:
            # è·å–èŠ‚ç‚¹çš„æ‰€æœ‰ä»»åŠ¡
            tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
            
            if not tasks:
                # è·å–èŠ‚ç‚¹ä¿¡æ¯åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ›å»ºä»»åŠ¡
                from ..repositories.instance.node_instance_repository import NodeInstanceRepository
                node_repo = NodeInstanceRepository()
                node_instance_data = await node_repo.get_instance_by_id(node_instance_id)
                
                if not node_instance_data:
                    logger.error(f"æ— æ³•è·å–èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯: {node_instance_id}")
                    return
                
                # è·å–èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
                node_query = """
                SELECT n.*, ni.workflow_instance_id
                FROM node n 
                JOIN node_instance ni ON n.node_id = ni.node_id
                WHERE ni.node_instance_id = $1
                """
                node_info = await self.task_instance_repo.db.fetch_one(node_query, node_instance_id)
                
                if not node_info:
                    logger.error(f"æ— æ³•è·å–èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯: {node_instance_id}")
                    return
                
                # å¦‚æœæ˜¯PROCESSORèŠ‚ç‚¹ä½†æ²¡æœ‰ä»»åŠ¡ï¼Œéœ€è¦å…ˆåˆ›å»ºä»»åŠ¡ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                if node_info['type'].upper() == 'PROCESSOR':
                    logger.trace(f"ğŸ”§ PROCESSORèŠ‚ç‚¹ {node_info['name']} æ²¡æœ‰ä»»åŠ¡ï¼Œå¼€å§‹åˆ›å»ºä»»åŠ¡...")
                    
                    # æ„é€ èŠ‚ç‚¹æ•°æ®ç”¨äºä»»åŠ¡åˆ›å»º
                    created_node = {
                        'node_instance_id': node_instance_id,
                        'node_type': node_info['type'],
                        'node_data': {
                            'node_id': node_info['node_id'],
                            'name': node_info['name'],
                            'description': node_info.get('description', ''),
                            'task_description': node_info.get('task_description', ''),
                            'input_data': {}
                        }
                    }
                    
                    logger.trace(f"ğŸ“‹ å¼€å§‹ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡ï¼ŒèŠ‚ç‚¹æ•°æ®: {created_node}")
                    
                    try:
                        # ä¸ºè¿™ä¸ªèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
                        await self._create_tasks_for_nodes([created_node], workflow_instance_id)
                        logger.trace(f"âœ… èŠ‚ç‚¹ {node_info['name']} ä»»åŠ¡åˆ›å»ºå®Œæˆ")
                    except Exception as task_creation_error:
                        logger.error(f"âŒ èŠ‚ç‚¹ {node_info['name']} ä»»åŠ¡åˆ›å»ºå¤±è´¥: {task_creation_error}")
                        import traceback
                        logger.error(f"ä»»åŠ¡åˆ›å»ºé”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                        # ç»§ç»­æ‰§è¡Œï¼Œä½†å¯èƒ½æ— æ³•æ‰¾åˆ°ä»»åŠ¡
                    
                    # é‡æ–°è·å–ä»»åŠ¡
                    tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
                    
                    if not tasks:
                        logger.error(f"âŒ PROCESSORèŠ‚ç‚¹ {node_info['name']} ä»»åŠ¡åˆ›å»ºå¤±è´¥ï¼Œæ²¡æœ‰é…ç½®å¤„ç†å™¨")
                        await self._complete_node_without_tasks(workflow_instance_id, node_instance_id)
                        return
                else:
                    # å¦‚æœæ˜¯STARTæˆ–ENDèŠ‚ç‚¹ç­‰éPROCESSORèŠ‚ç‚¹ï¼Œç›´æ¥æ ‡è®°å®Œæˆ
                    logger.trace(f"â­ï¸ éPROCESSORèŠ‚ç‚¹ {node_info.get('name', 'Unknown')} æ²¡æœ‰ä»»åŠ¡ï¼Œç›´æ¥æ ‡è®°å®Œæˆ")
                    await self._complete_node_without_tasks(workflow_instance_id, node_instance_id)
                    return
            
            # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            for task in tasks:
                if task['task_type'] == TaskInstanceType.AGENT.value:
                    # Agentä»»åŠ¡ï¼šæäº¤ç»™AgentTaskServiceå¤„ç†
                    await self._execute_agent_task(task)
                elif task['task_type'] == TaskInstanceType.HUMAN.value:
                    # Humanä»»åŠ¡ï¼šè°ƒç”¨_execute_taskæ–¹æ³•å¤„ç†ï¼ˆåŒ…å«ç”¨æˆ·é€šçŸ¥ï¼‰
                    await self._execute_task(task)
                    logger.trace(f"Humanä»»åŠ¡ {task['task_instance_id']} å·²åˆ†é…å¹¶é€šçŸ¥ç”¨æˆ·")
                elif task['task_type'] == TaskInstanceType.MIXED.value:
                    # Mixedä»»åŠ¡ï¼šå…ˆåˆ†é…ç»™ç”¨æˆ·ï¼ŒåŒæ—¶æä¾›AIè¾…åŠ©
                    await self._execute_mixed_task(task)
            
            # æ³¨å†Œä»»åŠ¡å®Œæˆç›‘å¬
            await self._register_node_completion_monitor(workflow_instance_id, node_instance_id)
            
        except Exception as e:
            logger.error(f"æ‰§è¡ŒèŠ‚ç‚¹ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _complete_node_without_tasks(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """å®Œæˆæ²¡æœ‰ä»»åŠ¡çš„èŠ‚ç‚¹ï¼ˆå¦‚STARTã€ENDèŠ‚ç‚¹ï¼‰"""
        try:
            from datetime import datetime as dt
            from ..models.instance import NodeInstanceStatus, NodeInstanceUpdate
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            
            # è·å–node_idç”¨äºæ ‡è®°å®Œæˆ
            node_repo = NodeInstanceRepository()
            node_instance_data = await node_repo.get_instance_by_id(node_instance_id)
            if not node_instance_data:
                logger.error(f"æ— æ³•æ‰¾åˆ°èŠ‚ç‚¹å®ä¾‹: {node_instance_id}")
                return
            
            node_id = node_instance_data['node_id']
            
            # æ ‡è®°èŠ‚ç‚¹å®Œæˆ
            output_data = {
                'completed_at': dt.utcnow().isoformat(),
                'node_type': 'system',
                'message': 'ç³»ç»ŸèŠ‚ç‚¹è‡ªåŠ¨å®Œæˆ'
            }
            
            await self.context_manager.mark_node_completed(
                workflow_instance_id, node_id, node_instance_id, output_data
            )
            
            # åŒæ—¶æ›´æ–°æ•°æ®åº“ä¸­çš„èŠ‚ç‚¹å®ä¾‹çŠ¶æ€
            try:
                node_repo = NodeInstanceRepository()
                node_update = NodeInstanceUpdate(
                    status=NodeInstanceStatus.COMPLETED,
                    output_data=output_data,
                    completed_at=dt.utcnow()
                )
                await node_repo.update_node_instance(node_instance_id, node_update)
                logger.trace(f"ğŸ’¾ [ç³»ç»ŸèŠ‚ç‚¹] èŠ‚ç‚¹å®ä¾‹ {node_instance_id} æ•°æ®åº“çŠ¶æ€å·²æ›´æ–°ä¸ºCOMPLETED")
            except Exception as e:
                logger.error(f"âŒ [ç³»ç»ŸèŠ‚ç‚¹] æ›´æ–°èŠ‚ç‚¹å®ä¾‹æ•°æ®åº“çŠ¶æ€å¤±è´¥: {e}")
            
            logger.trace(f"âœ… ç³»ç»ŸèŠ‚ç‚¹ {node_id} è‡ªåŠ¨å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å®Œæˆç³»ç»ŸèŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _execute_agent_task(self, task: Dict[str, Any]):
        """æ‰§è¡ŒAgentä»»åŠ¡"""
        try:
            task_id = task['task_instance_id']
            logger.trace(f"ğŸš€ [EXECUTION-ENGINE] å¼€å§‹æ‰§è¡ŒAgentä»»åŠ¡: {task_id}")
            logger.trace(f"   - ä»»åŠ¡æ ‡é¢˜: {task.get('task_title', 'unknown')}")
            logger.trace(f"   - ä»»åŠ¡ç±»å‹: {task.get('task_type', 'unknown')}")
            logger.trace(f"   - å½“å‰çŠ¶æ€: {task.get('status', 'unknown')}")
            logger.trace(f"   - åˆ†é…Agent: {task.get('assigned_agent_id', 'none')}")
            logger.trace(f"   - å¤„ç†å™¨ID: {task.get('processor_id', 'none')}")
            
            # è°ƒç”¨AgentTaskServiceå¤„ç†ä»»åŠ¡
            logger.trace(f"ğŸ”„ [EXECUTION-ENGINE] è°ƒç”¨AgentTaskServiceå¤„ç†ä»»åŠ¡")
            await agent_task_service.process_agent_task(task_id)
            
            logger.trace(f"âœ… [EXECUTION-ENGINE] Agentä»»åŠ¡æ‰§è¡Œå®Œæˆ: {task_id}")
            
        except Exception as e:
            logger.error(f"âŒ [EXECUTION-ENGINE] æ‰§è¡ŒAgentä»»åŠ¡ {task['task_instance_id']} å¤±è´¥: {e}")
            import traceback
            logger.error(f"   - é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def _execute_mixed_task(self, task: Dict[str, Any]):
        """æ‰§è¡ŒMixedä»»åŠ¡ï¼ˆäººæœºåä½œï¼‰"""
        try:
            # Mixedä»»åŠ¡åˆ†é…ç»™ç”¨æˆ·ï¼ŒåŒæ—¶å¯åŠ¨AIè¾…åŠ©
            task_id = task['task_instance_id']
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºASSIGNEDï¼ˆåˆ†é…ç»™ç”¨æˆ·ï¼‰
            update_data = TaskInstanceUpdate(status=TaskInstanceStatus.ASSIGNED)
            await self.task_instance_repo.update_task(task_id, update_data)
            
            # å¯åŠ¨AIè¾…åŠ©ï¼ˆå¯é€‰ï¼‰
            asyncio.create_task(self._provide_ai_assistance(task))
            
            logger.trace(f"Mixedä»»åŠ¡ {task_id} å·²åˆ†é…ç»™ç”¨æˆ·ï¼ŒAIè¾…åŠ©å·²å¯åŠ¨")
            
        except Exception as e:
            logger.error(f"æ‰§è¡ŒMixedä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _provide_ai_assistance(self, task: Dict[str, Any]):
        """ä¸ºMixedä»»åŠ¡æä¾›AIè¾…åŠ©"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°AIè¾…åŠ©é€»è¾‘
            # ä¾‹å¦‚ï¼šåˆ†æä»»åŠ¡å†…å®¹ï¼Œæä¾›å»ºè®®ç­‰
            logger.trace(f"ä¸ºä»»åŠ¡ {task['task_instance_id']} æä¾›AIè¾…åŠ©")
            
        except Exception as e:
            logger.error(f"æä¾›AIè¾…åŠ©å¤±è´¥: {e}")
    
    async def _register_node_completion_monitor(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """æ³¨å†ŒèŠ‚ç‚¹å®Œæˆç›‘å¬å™¨ï¼ˆé˜²é‡å¤ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ´»è·ƒçš„ç›‘å¬å™¨
            if node_instance_id in self.active_monitors:
                logger.warning(f"ğŸ”„ [ç›‘å¬å™¨æ³¨å†Œ-é˜²é‡å¤] èŠ‚ç‚¹ {node_instance_id} å·²æœ‰æ´»è·ƒç›‘å¬å™¨ï¼Œè·³è¿‡é‡å¤æ³¨å†Œ")
                return
            
            logger.trace(f"ğŸ“‹ [ç›‘å¬å™¨æ³¨å†Œ] ä¸ºèŠ‚ç‚¹ {node_instance_id} æ³¨å†Œå®Œæˆç›‘å¬å™¨")
            logger.trace(f"   - å·¥ä½œæµå®ä¾‹: {workflow_instance_id}")
            
            # æ·»åŠ åˆ°æ´»è·ƒç›‘å¬å™¨é›†åˆ
            self.active_monitors.add(node_instance_id)
            
            # å¯åŠ¨èŠ‚ç‚¹å®Œæˆç›‘å¬åç¨‹
            task = asyncio.create_task(self._monitor_node_completion(workflow_instance_id, node_instance_id))
            logger.trace(f"âœ… [ç›‘å¬å™¨æ³¨å†Œ] èŠ‚ç‚¹ {node_instance_id} ç›‘å¬åç¨‹å·²å¯åŠ¨")
            
        except Exception as e:
            logger.error(f"âŒ [ç›‘å¬å™¨æ³¨å†Œ] æ³¨å†ŒèŠ‚ç‚¹å®Œæˆç›‘å¬å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _monitor_node_completion(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """ç›‘å¬èŠ‚ç‚¹å®Œæˆ"""
        try:
            logger.trace(f"ğŸ” [èŠ‚ç‚¹ç›‘å¬] å¼€å§‹ç›‘å¬èŠ‚ç‚¹å®Œæˆ: {node_instance_id}")
            
            while True:
                # æ£€æŸ¥èŠ‚ç‚¹çš„æ‰€æœ‰ä»»åŠ¡æ˜¯å¦å®Œæˆ
                tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
                
                if not tasks:
                    logger.trace(f"âš ï¸ [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} æ²¡æœ‰ä»»åŠ¡ï¼Œåœæ­¢ç›‘å¬")
                    break
                
                completed_tasks = [t for t in tasks if t['status'] == TaskInstanceStatus.COMPLETED.value]
                failed_tasks = [t for t in tasks if t['status'] == TaskInstanceStatus.FAILED.value]
                
                logger.trace(f"ğŸ“Š [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} ä»»åŠ¡çŠ¶æ€:")
                logger.trace(f"   - æ€»ä»»åŠ¡æ•°: {len(tasks)}")
                logger.trace(f"   - å·²å®Œæˆ: {len(completed_tasks)}")
                logger.trace(f"   - å¤±è´¥: {len(failed_tasks)}")
                
                # æ˜¾ç¤ºæ¯ä¸ªä»»åŠ¡çš„è¯¦ç»†çŠ¶æ€
                for i, task in enumerate(tasks):
                    task_id = task.get('task_instance_id', 'unknown')
                    task_status = task.get('status', 'unknown')
                    task_title = task.get('task_title', 'unknown')
                    logger.trace(f"   - ä»»åŠ¡{i+1}: {task_title} (ID: {task_id}) - çŠ¶æ€: {task_status}")
                
                if len(completed_tasks) == len(tasks):
                    # æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œæ ‡è®°èŠ‚ç‚¹å®Œæˆ
                    logger.trace(f"ğŸ‰ [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œå¼€å§‹æ ‡è®°èŠ‚ç‚¹å®Œæˆ")
                    output_data = await self._aggregate_node_output(completed_tasks)
                    
                    # æ£€æŸ¥context manageræ˜¯å¦å¯ç”¨
                    if self.context_manager is None:
                        logger.error(f"âŒ [èŠ‚ç‚¹ç›‘å¬] context_manager ä¸º Noneï¼Œæ— æ³•æ ‡è®°èŠ‚ç‚¹å®Œæˆ")
                        break
                    
                    # è·å–node_idç”¨äºä¾èµ–åŒ¹é…ï¼Œå› ä¸ºä¾èµ–å…³ç³»æ˜¯åŸºäºnode_idæ³¨å†Œçš„
                    from ..repositories.instance.node_instance_repository import NodeInstanceRepository
                    node_repo = NodeInstanceRepository()
                    node_instance_data = await node_repo.get_instance_by_id(node_instance_id)
                    node_id = node_instance_data['node_id'] if node_instance_data else None
                    
                    if node_id:
                        logger.trace(f"ğŸ¯ [èŠ‚ç‚¹ç›‘å¬] æ ‡è®°èŠ‚ç‚¹å®Œæˆ: node_id={node_id}")
                        await self.context_manager.mark_node_completed(
                            workflow_instance_id, node_id, node_instance_id, output_data
                        )
                    else:
                        logger.error(f"âŒ [èŠ‚ç‚¹ç›‘å¬] æ— æ³•è·å–node_idï¼Œæ— æ³•æ ‡è®°èŠ‚ç‚¹å®Œæˆ")
                        break
                    
                    # åŒæ—¶æ›´æ–°æ•°æ®åº“ä¸­çš„èŠ‚ç‚¹å®ä¾‹çŠ¶æ€
                    try:
                        from datetime import datetime
                        from ..models.instance import NodeInstanceStatus, NodeInstanceUpdate
                        from ..repositories.instance.node_instance_repository import NodeInstanceRepository
                        
                        node_repo = NodeInstanceRepository()
                        node_update = NodeInstanceUpdate(
                            status=NodeInstanceStatus.COMPLETED,
                            output_data=output_data,
                            completed_at=datetime.utcnow()
                        )
                        await node_repo.update_node_instance(node_instance_id, node_update)
                        logger.trace(f"ğŸ’¾ [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹å®ä¾‹ {node_instance_id} æ•°æ®åº“çŠ¶æ€å·²æ›´æ–°ä¸ºCOMPLETED")
                    except Exception as e:
                        logger.error(f"âŒ [èŠ‚ç‚¹ç›‘å¬] æ›´æ–°èŠ‚ç‚¹å®ä¾‹æ•°æ®åº“çŠ¶æ€å¤±è´¥: {e}")
                    
                    logger.trace(f"âœ… [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} å·²æ ‡è®°ä¸ºå®Œæˆï¼Œåœæ­¢ç›‘å¬")
                    # ä»æ´»è·ƒç›‘å¬å™¨é›†åˆä¸­ç§»é™¤
                    self.active_monitors.discard(node_instance_id)
                    break
                elif len(failed_tasks) > 0:
                    # æœ‰ä»»åŠ¡å¤±è´¥ï¼Œæ ‡è®°èŠ‚ç‚¹å¤±è´¥
                    logger.error(f"âŒ [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} æœ‰ä»»åŠ¡å¤±è´¥ï¼Œæ ‡è®°èŠ‚ç‚¹å¤±è´¥")
                    error_info = {'failed_tasks': [str(t['task_instance_id']) for t in failed_tasks]}
                    
                    # è·å–node_idç”¨äºæ ‡è®°å¤±è´¥
                    from ..repositories.instance.node_instance_repository import NodeInstanceRepository
                    node_repo = NodeInstanceRepository()
                    node_instance_data = await node_repo.get_instance_by_id(node_instance_id)
                    node_id = node_instance_data['node_id'] if node_instance_data else None
                    
                    if node_id:
                        await self.context_manager.mark_node_failed(
                            workflow_instance_id, node_id, node_instance_id, error_info
                        )
                    else:
                        logger.error(f"âŒ [èŠ‚ç‚¹ç›‘å¬] æ— æ³•è·å–node_idï¼Œæ— æ³•æ ‡è®°èŠ‚ç‚¹å¤±è´¥")
                    # ä»æ´»è·ƒç›‘å¬å™¨é›†åˆä¸­ç§»é™¤
                    self.active_monitors.discard(node_instance_id)
                    break
                
                # ç­‰å¾…5ç§’åå†æ¬¡æ£€æŸ¥
                logger.trace(f"â³ [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} ä»æœ‰ä»»åŠ¡æœªå®Œæˆï¼Œ5ç§’åå†æ¬¡æ£€æŸ¥")
                await asyncio.sleep(5)
                
        except Exception as e:
            logger.error(f"ç›‘å¬èŠ‚ç‚¹å®Œæˆå¤±è´¥: {e}")
            # å¼‚å¸¸æ—¶ä¹Ÿè¦ä»æ´»è·ƒç›‘å¬å™¨é›†åˆä¸­ç§»é™¤
            self.active_monitors.discard(node_instance_id)
        finally:
            # ç¡®ä¿ç›‘å¬å™¨è¢«æ¸…ç†
            self.active_monitors.discard(node_instance_id)
            logger.trace(f"ğŸ§¹ [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} ç›‘å¬å™¨å·²æ¸…ç†")
    
    def _make_json_serializable(self, obj):
        """å°†å¯¹è±¡è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–çš„å½¢å¼"""
        if isinstance(obj, uuid.UUID):
            return str(obj)
        elif isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, dict):
            return {k: self._make_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        else:
            return obj

    async def _aggregate_node_output(self, completed_tasks: List[Dict]) -> Dict[str, Any]:
        """èšåˆèŠ‚ç‚¹çš„è¾“å‡ºæ•°æ®"""
        try:
            aggregated = {
                'task_count': len(completed_tasks),
                'completed_at': datetime.utcnow().isoformat(),
                'task_results': []
            }
            
            combined_output = {}
            
            for task_index, task in enumerate(completed_tasks):
                task_result = {
                    'task_id': str(task['task_instance_id']),  # è½¬æ¢UUIDä¸ºå­—ç¬¦ä¸²
                    'task_title': task.get('task_title', ''),
                    'output_data': task.get('output_data', ''),  # ç°åœ¨æ˜¯æ–‡æœ¬æ ¼å¼
                    'result_summary': task.get('result_summary', '')
                }
                aggregated['task_results'].append(task_result)
                
                # åˆå¹¶ä»»åŠ¡è¾“å‡ºæ•°æ®ï¼ˆç°åœ¨æ˜¯æ–‡æœ¬æ ¼å¼ï¼‰
                if task.get('output_data'):
                    output_data = task['output_data']
                    # ä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºä¸€ä¸ªé”®å€¼å¯¹
                    task_key = f"task_{task_index + 1}_output"
                    combined_output[task_key] = str(output_data)
            
            aggregated['combined_output'] = combined_output
            
            return self._make_json_serializable(aggregated)
            
        except Exception as e:
            logger.error(f"èšåˆèŠ‚ç‚¹è¾“å‡ºå¤±è´¥: {e}")
            return {'error': str(e)}
    
    async def _on_nodes_ready_to_execute(self, workflow_instance_id: uuid.UUID, ready_node_instance_ids: List[uuid.UUID]):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å›è°ƒï¼šæœ‰èŠ‚ç‚¹å‡†å¤‡æ‰§è¡Œ"""
        try:
            logger.trace(f"å·¥ä½œæµ {workflow_instance_id} ä¸­æœ‰ {len(ready_node_instance_ids)} ä¸ªèŠ‚ç‚¹å‡†å¤‡æ‰§è¡Œ")
            
            # æ‰§è¡Œå‡†å¤‡å¥½çš„èŠ‚ç‚¹
            for node_instance_id in ready_node_instance_ids:
                await self._execute_node_when_ready(workflow_instance_id, node_instance_id)
                
        except Exception as e:
            logger.error(f"æ‰§è¡Œå‡†å¤‡å¥½çš„èŠ‚ç‚¹å¤±è´¥: {e}")
    
    async def _log_task_assignment_event(self, task_id: uuid.UUID, assigned_user_id: Optional[uuid.UUID], task_title: str):
        """è®°å½•ä»»åŠ¡åˆ†é…äº‹ä»¶"""
        try:
            event_data = {
                'event_type': 'task_assigned',
                'task_id': str(task_id),
                'assigned_user_id': str(assigned_user_id) if assigned_user_id else None,
                'task_title': task_title,
                'timestamp': now_utc().isoformat(),
                'status': 'success'
            }
            
            # è¿™é‡Œå¯ä»¥è®°å½•åˆ°äº‹ä»¶æ—¥å¿—è¡¨æˆ–å‘é€åˆ°æ¶ˆæ¯é˜Ÿåˆ—
            logger.trace(f"ğŸ“ ä»»åŠ¡åˆ†é…äº‹ä»¶è®°å½•: {event_data}")
            
            # è®°å½•åˆ°ä¸“é—¨çš„äº‹ä»¶æ—¥å¿—æ–‡ä»¶
            try:
                event_log_entry = f"{event_data['timestamp']}|{event_data['event_type']}|{event_data['task_id']}|{event_data['assigned_user_id']}|{task_title[:50]}"
                with open("task_events.log", "a", encoding="utf-8") as f:
                    f.write(event_log_entry + "\n")
                logger.warning(f"   äº‹ä»¶å·²è®°å½•åˆ°æ–‡ä»¶")
            except Exception as e:
                logger.warning(f"   äº‹ä»¶æ–‡ä»¶è®°å½•å¤±è´¥: {e}")
            
            # TODO: å¯ä»¥åœ¨è¿™é‡Œé›†æˆæ¶ˆæ¯é˜Ÿåˆ—ç³»ç»Ÿï¼Œå¦‚Redisã€RabbitMQç­‰
            # await self.message_queue.publish('task_assignments', event_data)
            
        except Exception as e:
            logger.error(f"è®°å½•ä»»åŠ¡åˆ†é…äº‹ä»¶å¤±è´¥: {e}")
    
    async def _log_workflow_execution_summary(self, workflow_instance_id: uuid.UUID):
        """è®°å½•å·¥ä½œæµæ‰§è¡Œæ‘˜è¦"""
        try:
            logger.trace(f"ğŸ“Š ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œæ‘˜è¦: {workflow_instance_id}")
            
            # è·å–å·¥ä½œæµå®ä¾‹ä¿¡æ¯
            instance = await self.workflow_instance_repo.get_instance_by_id(workflow_instance_id)
            if not instance:
                logger.warning(f"   å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨: {workflow_instance_id}")
                return
            
            # è·å–æ‰€æœ‰ä»»åŠ¡
            tasks = await self.task_instance_repo.get_tasks_by_workflow_instance(workflow_instance_id)
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_tasks = len(tasks)
            human_tasks = len([t for t in tasks if t['task_type'] == TaskInstanceType.HUMAN.value])
            agent_tasks = len([t for t in tasks if t['task_type'] == TaskInstanceType.AGENT.value])
            assigned_tasks = len([t for t in tasks if t['status'] in ['ASSIGNED', 'IN_PROGRESS', 'COMPLETED']])
            pending_tasks = len([t for t in tasks if t['status'] == 'PENDING'])
            
            # è¾“å‡ºæ‘˜è¦
            print(f"\nğŸ“Š ã€å·¥ä½œæµæ‰§è¡Œæ‘˜è¦ã€‘")
            print(f"å·¥ä½œæµå®ä¾‹: {instance.get('workflow_instance_name', 'Unknown')}")
            print(f"å®ä¾‹ID: {workflow_instance_id}")
            print(f"çŠ¶æ€: {instance.get('status', 'Unknown')}")
            print(f"æ€»ä»»åŠ¡æ•°: {total_tasks}")
            print(f"  - äººå·¥ä»»åŠ¡: {human_tasks}")
            print(f"  - Agentä»»åŠ¡: {agent_tasks}")
            print(f"  - å·²åˆ†é…: {assigned_tasks}")
            print(f"  - ç­‰å¾…ä¸­: {pending_tasks}")
            print(f"åˆ›å»ºæ—¶é—´: {instance.get('created_at', 'Unknown')}")
            print("=" * 50)
            
            # åˆ—å‡ºæ‰€æœ‰å·²åˆ†é…çš„äººå·¥ä»»åŠ¡
            human_assigned_tasks = [t for t in tasks if t['task_type'] == TaskInstanceType.HUMAN.value and t.get('assigned_user_id')]
            if human_assigned_tasks:
                print(f"ğŸ“‹ å·²åˆ†é…çš„äººå·¥ä»»åŠ¡:")
                for i, task in enumerate(human_assigned_tasks, 1):
                    print(f"  {i}. {task['task_title']}")
                    print(f"     ç”¨æˆ·: {task.get('assigned_user_id')}")
                    print(f"     çŠ¶æ€: {task['status']}")
                print("=" * 50)
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œæ‘˜è¦å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
    
    async def _notify_user_new_task(self, user_id: uuid.UUID, task_id: uuid.UUID, task_title: str):
        """é€šçŸ¥ç”¨æˆ·æœ‰æ–°ä»»åŠ¡åˆ†é…"""
        try:
            logger.trace(f"ğŸ”” å¼€å§‹å‘é€ä»»åŠ¡é€šçŸ¥ç»™ç”¨æˆ·: {user_id}")
            
            # è·å–ç”¨æˆ·ä¿¡æ¯ç”¨äºé€šçŸ¥
            user_info = await self.user_repo.get_by_id(user_id, id_column="user_id")
            username = user_info.get('username', 'Unknown') if user_info else 'Unknown'
            
            notification_data = {
                'user_id': str(user_id),
                'username': username,
                'task_id': str(task_id),
                'task_title': task_title,
                'notification_type': 'new_task_assigned',
                'timestamp': now_utc().isoformat(),
                'message': f'æ‚¨æœ‰æ–°çš„ä»»åŠ¡: {task_title}',
                'action_url': f'/tasks/{task_id}'
            }
            
            logger.trace(f"ğŸ“¨ é€šçŸ¥æ•°æ®å‡†å¤‡å®Œæˆ:")
            logger.trace(f"   - ç”¨æˆ·: {username} ({user_id})")
            logger.trace(f"   - ä»»åŠ¡: {task_title}")
            logger.trace(f"   - æ—¶é—´: {notification_data['timestamp']}")
            
            # æ–¹å¼1: æ§åˆ¶å°é€šçŸ¥ï¼ˆç”¨äºå¼€å‘è°ƒè¯•ï¼‰
            print(f"\nğŸ”” ã€ç”¨æˆ·é€šçŸ¥ã€‘")
            print(f"ç”¨æˆ·: {username} ({user_id})")
            print(f"æ¶ˆæ¯: æ‚¨æœ‰æ–°çš„ä»»åŠ¡åˆ†é…")
            print(f"ä»»åŠ¡: {task_title}")
            print(f"ä»»åŠ¡ID: {task_id}")
            print(f"æ—¶é—´: {notification_data['timestamp']}")
            print(f"æ“ä½œ: è¯·ç™»å½•ç³»ç»ŸæŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…")
            print("=" * 50)
            
            # æ–¹å¼2: è®°å½•åˆ°æ•°æ®åº“ï¼ˆç”¨æˆ·é€šçŸ¥å†å²ï¼‰
            try:
                await self._store_user_notification(notification_data)
                logger.trace(f"   âœ… é€šçŸ¥å·²å­˜å‚¨åˆ°æ•°æ®åº“")
            except Exception as e:
                logger.warning(f"   âš ï¸  å­˜å‚¨é€šçŸ¥å¤±è´¥: {e}")
            
            # æ–¹å¼3: æ–‡ä»¶æ—¥å¿—è®°å½•ï¼ˆå¯ç”¨äºå…¶ä»–ç³»ç»Ÿè¯»å–ï¼‰
            try:
                notification_log_entry = f"{now_utc().isoformat()}|TASK_ASSIGNED|{user_id}|{username}|{task_id}|{task_title}"
                with open("user_notifications.log", "a", encoding="utf-8") as f:
                    f.write(notification_log_entry + "\n")
                logger.trace(f"   âœ… é€šçŸ¥å·²è®°å½•åˆ°æ–‡ä»¶")
            except Exception as e:
                logger.warning(f"   âš ï¸  æ–‡ä»¶è®°å½•å¤±è´¥: {e}")
            
            # TODO: æ–¹å¼4: å®æ—¶æ¨é€ï¼ˆæœªæ¥å®ç°ï¼‰
            # å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€å®ç°ï¼š
            # 1. WebSocket æ¨é€: await self.websocket_manager.send_to_user(user_id, notification_data)
            # 2. Server-Sent Events (SSE): await self.sse_manager.send_event(user_id, notification_data)
            # 3. æ¶ˆæ¯é˜Ÿåˆ—: await self.message_queue.publish(f"user.{user_id}.notifications", notification_data)
            # 4. é‚®ä»¶é€šçŸ¥: await self.email_service.send_task_notification(user_info.get('email'), notification_data)
            
            logger.trace(f"   ğŸ‰ ç”¨æˆ·é€šçŸ¥å¤„ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å‘é€ç”¨æˆ·é€šçŸ¥å¤±è´¥: {e}")
            import traceback
            logger.error(f"   å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
    
    async def _store_user_notification(self, notification_data: dict):
        """å­˜å‚¨ç”¨æˆ·é€šçŸ¥åˆ°æ•°æ®åº“ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰"""
        try:
            # è¿™é‡Œå¯ä»¥å­˜å‚¨åˆ°ä¸“é—¨çš„é€šçŸ¥è¡¨ä¸­
            # å¦‚æœæ²¡æœ‰é€šçŸ¥è¡¨ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªç®€å•çš„è®°å½•è¡¨
            logger.warning(f"å­˜å‚¨é€šçŸ¥æ•°æ®: {notification_data}")
            # æš‚æ—¶è·³è¿‡æ•°æ®åº“å­˜å‚¨ï¼Œé¿å…è¡¨ç»“æ„ä¾èµ–
        except Exception as e:
            logger.warning(f"å­˜å‚¨ç”¨æˆ·é€šçŸ¥å¤±è´¥: {e}")
    
    # ================================================================================
    # å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶ - æ ¸å¿ƒæ–¹æ³•
    # ================================================================================
    
    async def _check_node_prerequisites(self, workflow_instance_id: uuid.UUID, 
                                      node_instance_id: uuid.UUID) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹çš„å‰ç½®æ¡ä»¶æ˜¯å¦æ»¡è¶³ï¼ˆä¿®å¤ç‰ˆï¼šåŒé‡éªŒè¯ï¼‰"""
        try:
            logger.trace(f"ğŸ” æ£€æŸ¥èŠ‚ç‚¹å‰ç½®æ¡ä»¶: {node_instance_id}")
            
            # ä»æ•°æ®åº“æŸ¥è¯¢èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_repo = NodeInstanceRepository()
            node_instance = await node_repo.get_instance_by_id(node_instance_id)
            
            if not node_instance:
                logger.error(f"âŒ èŠ‚ç‚¹å®ä¾‹ä¸å­˜åœ¨: {node_instance_id}")
                return False
            
            node_id = node_instance['node_id']
            logger.trace(f"  èŠ‚ç‚¹ID: {node_id}")
            
            # ğŸ”’ ä¸¥æ ¼æ£€æŸ¥ï¼šé˜²æ­¢é‡å¤æ‰§è¡Œ
            current_status = node_instance.get('status')
            if current_status in ['running', 'completed', 'failed']:
                logger.trace(f"  ğŸš« èŠ‚ç‚¹å·²å¤„äº {current_status} çŠ¶æ€ï¼Œè·³è¿‡æ£€æŸ¥")
                return False  # å·²å¤„ç†è¿‡çš„èŠ‚ç‚¹ä¸å†å¤„ç†
            
            # ğŸ” åŒé‡æ£€æŸ¥ï¼šä¸Šä¸‹æ–‡ç®¡ç†å™¨çŠ¶æ€
            if hasattr(self.context_manager, 'contexts') and workflow_instance_id in self.context_manager.contexts:
                context = self.context_manager.contexts[workflow_instance_id]
                if node_id in context.execution_context.get('completed_nodes', set()):
                    logger.trace(f"  ğŸš« èŠ‚ç‚¹åœ¨ä¸Šä¸‹æ–‡ä¸­å·²å®Œæˆï¼Œè·³è¿‡æ£€æŸ¥")
                    return False
                if node_id in context.execution_context.get('current_executing_nodes', set()):
                    logger.trace(f"  ğŸš« èŠ‚ç‚¹åœ¨ä¸Šä¸‹æ–‡ä¸­æ­£åœ¨æ‰§è¡Œï¼Œè·³è¿‡æ£€æŸ¥")
                    return False
            
            # æŸ¥è¯¢è¯¥èŠ‚ç‚¹çš„å‰ç½®èŠ‚ç‚¹ï¼ˆä½¿ç”¨æ›´ä¸¥æ ¼çš„æŸ¥è¯¢ï¼‰
            prerequisite_query = '''
            SELECT source_n.node_id as prerequisite_node_id, source_n.name as prerequisite_name,
                   source_ni.node_instance_id as prerequisite_instance_id, source_ni.status as prerequisite_status,
                   c.workflow_id
            FROM node_connection c
            JOIN node source_n ON c.from_node_id = source_n.node_id  
            JOIN node target_n ON c.to_node_id = target_n.node_id
            JOIN node_instance source_ni ON source_n.node_id = source_ni.node_id
            WHERE target_n.node_id = $1 
              AND source_ni.workflow_instance_id = $2
              AND source_ni.is_deleted = FALSE
            ORDER BY source_n.name
            '''
            
            prerequisites = await self.workflow_instance_repo.db.fetch_all(
                prerequisite_query, node_id, workflow_instance_id
            )
            
            logger.trace(f"  æ‰¾åˆ° {len(prerequisites)} ä¸ªå‰ç½®èŠ‚ç‚¹")
            
            # å¦‚æœæ²¡æœ‰å‰ç½®èŠ‚ç‚¹ï¼ˆå¦‚STARTèŠ‚ç‚¹ï¼‰ï¼Œéœ€è¦å†æ¬¡æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
            if not prerequisites:
                # å¯¹äºSTARTèŠ‚ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦å·²ç»è¢«å¤„ç†è¿‡
                if current_status == 'completed':
                    logger.trace(f"  ğŸš« STARTèŠ‚ç‚¹å·²å®Œæˆï¼Œè·³è¿‡")
                    return False
                logger.trace(f"  âœ… æ— å‰ç½®èŠ‚ç‚¹ï¼ˆSTARTèŠ‚ç‚¹ï¼‰ï¼Œæ»¡è¶³æ¡ä»¶")
                return True
            
            # æ£€æŸ¥æ‰€æœ‰å‰ç½®èŠ‚ç‚¹æ˜¯å¦éƒ½å·²å®Œæˆ
            all_completed = True
            completed_count = 0
            
            for prerequisite in prerequisites:
                status = prerequisite['prerequisite_status']
                name = prerequisite['prerequisite_name']
                prereq_node_id = prerequisite['prerequisite_node_id']
                
                logger.trace(f"    å‰ç½®èŠ‚ç‚¹ {name} (node_id: {prereq_node_id}): {status}")
                
                if status == 'completed':
                    completed_count += 1
                    
                    # ğŸ” åŒé‡éªŒè¯ï¼šæ£€æŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­çš„çŠ¶æ€
                    if hasattr(self.context_manager, 'contexts') and workflow_instance_id in self.context_manager.contexts:
                        context = self.context_manager.contexts[workflow_instance_id]
                        if prereq_node_id not in context.execution_context.get('completed_nodes', set()):
                            logger.warning(f"    âš ï¸ å‰ç½®èŠ‚ç‚¹ {name} æ•°æ®åº“æ˜¾ç¤ºå·²å®Œæˆä½†ä¸Šä¸‹æ–‡æœªæ›´æ–°ï¼ŒåŒæ­¥çŠ¶æ€")
                            # åŒæ­¥çŠ¶æ€åˆ°ä¸Šä¸‹æ–‡
                            context.execution_context['completed_nodes'].add(prereq_node_id)
                    
                    logger.trace(f"    âœ… å‰ç½®èŠ‚ç‚¹ {name} å·²å®Œæˆ")
                else:
                    all_completed = False
                    logger.trace(f"    âŒ å‰ç½®èŠ‚ç‚¹ {name} æœªå®Œæˆ: {status}")
            
            # æœ€ç»ˆç»“æœæ£€æŸ¥
            if all_completed and completed_count == len(prerequisites):
                logger.trace(f"  âœ… æ‰€æœ‰å‰ç½®èŠ‚ç‚¹å·²å®Œæˆ ({completed_count}/{len(prerequisites)})ï¼Œæ»¡è¶³ä»»åŠ¡åˆ›å»ºæ¡ä»¶")
                return True
            else:
                logger.trace(f"  â³ å‰ç½®èŠ‚ç‚¹æœªå…¨éƒ¨å®Œæˆ ({completed_count}/{len(prerequisites)})ï¼Œç­‰å¾…ä¸­")
                return False
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥èŠ‚ç‚¹å‰ç½®æ¡ä»¶å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return False
    
    async def _create_tasks_when_ready(self, workflow_instance_id: uuid.UUID, 
                                     node_instance_id: uuid.UUID) -> bool:
        """å½“èŠ‚ç‚¹æ»¡è¶³å‰ç½®æ¡ä»¶æ—¶åˆ›å»ºä»»åŠ¡"""
        try:
            logger.trace(f"ğŸ¯ å°è¯•ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡: {node_instance_id}")
            
            # æ£€æŸ¥å‰ç½®æ¡ä»¶
            prerequisites_met = await self._check_node_prerequisites(workflow_instance_id, node_instance_id)
            if not prerequisites_met:
                logger.trace(f"  â³ å‰ç½®æ¡ä»¶æœªæ»¡è¶³ï¼Œæš‚ä¸åˆ›å»ºä»»åŠ¡")
                return False
            
            # è·å–èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_repo = NodeInstanceRepository()
            node_instance = await node_repo.get_instance_by_id(node_instance_id)
            
            if not node_instance:
                logger.error(f"âŒ èŠ‚ç‚¹å®ä¾‹ä¸å­˜åœ¨: {node_instance_id}")
                return False
            
            # è·å–èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
            node = await self.node_repo.get_node_by_id(node_instance['node_id'])
            if not node:
                logger.error(f"âŒ èŠ‚ç‚¹ä¸å­˜åœ¨: {node_instance['node_id']}")
                return False
            
            # åªä¸ºPROCESSORèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
            if node['type'] != NodeType.PROCESSOR.value:
                logger.trace(f"  â­ï¸ èŠ‚ç‚¹ç±»å‹ä¸æ˜¯PROCESSOR ({node['type']})ï¼Œè‡ªåŠ¨å®Œæˆ")
                
                # å¯¹äºéPROCESSORèŠ‚ç‚¹ï¼ˆå¦‚ENDèŠ‚ç‚¹ï¼‰ï¼Œç›´æ¥æ ‡è®°ä¸ºå®Œæˆ
                if node['type'] == NodeType.END.value:
                    await self._execute_end_node(workflow_instance_id, node_instance_id)
                elif node['type'] == NodeType.START.value:
                    from ..models.instance import NodeInstanceUpdate, NodeInstanceStatus
                    update_data = NodeInstanceUpdate(status=NodeInstanceStatus.COMPLETED)
                    await node_repo.update_node_instance(node_instance_id, update_data)
                    
                    # ä¿®å¤ï¼šSTARTèŠ‚ç‚¹å®Œæˆæ—¶ä¹Ÿéœ€è¦è°ƒç”¨mark_node_completedå­˜å‚¨è¾“å‡ºæ•°æ®
                    logger.trace(f"ğŸš€ STARTèŠ‚ç‚¹å®Œæˆï¼Œå­˜å‚¨è¾“å‡ºæ•°æ®åˆ°WorkflowContextManager")
                    task_description = node.get('task_description', 'å¼€å§‹èŠ‚ç‚¹å·²å®Œæˆ')
                    start_output_data = {
                        'task_result': task_description,  # å°†task_descriptionä½œä¸ºè¾“å‡ºç»“æœä¼ é€’ç»™ä¸‹æ¸¸
                        'task_summary': 'STARTèŠ‚ç‚¹å¤„ç†å®Œæˆ',
                        'execution_time': 0,
                        'completion_time': datetime.utcnow().isoformat()
                    }
                    logger.trace(f"  - STARTèŠ‚ç‚¹è¾“å‡ºæ•°æ®: {start_output_data}")
                    
                    await self.context_manager.mark_node_completed(
                        workflow_instance_id=workflow_instance_id,
                        node_id=node['node_id'],
                        node_instance_id=node_instance_id,
                        output_data=start_output_data
                    )
                else:
                    logger.error(f"error node type:{node['type']}")

                # ç»§ç»­æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹
                await self._check_downstream_nodes_for_task_creation(workflow_instance_id)
                return True
            
            # æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€ï¼Œå¦‚æœå·²å®Œæˆæˆ–æ­£åœ¨è¿è¡Œåˆ™æ— éœ€å¤„ç†
            current_status = node_instance['status']
            if current_status in ['completed', 'running', 'failed']:
                logger.trace(f"  âœ… èŠ‚ç‚¹çŠ¶æ€ä¸º{current_status}ï¼Œæ— éœ€é‡å¤å¤„ç†")
                return True
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»åˆ›å»ºè¿‡ä»»åŠ¡
            existing_tasks_query = '''
            SELECT task_instance_id FROM task_instance 
            WHERE node_instance_id = $1 AND is_deleted = FALSE
            '''
            existing_tasks = await self.task_instance_repo.db.fetch_all(existing_tasks_query, node_instance_id)
            
            if existing_tasks:
                logger.trace(f"  âœ… ä»»åŠ¡å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤åˆ›å»º")
                return True
            
            # å¯¹äºå·²ç»æ˜¯pendingçŠ¶æ€çš„èŠ‚ç‚¹ï¼Œé¿å…é‡å¤è®¾ç½®
            if current_status == 'pending':
                logger.trace(f"  â„¹ï¸ èŠ‚ç‚¹å·²æ˜¯pendingçŠ¶æ€ï¼Œè·³è¿‡çŠ¶æ€æ›´æ–°ç›´æ¥åˆ›å»ºä»»åŠ¡")
                # è·³è¿‡çŠ¶æ€æ›´æ–°ï¼Œç›´æ¥è¿›å…¥ä»»åŠ¡åˆ›å»ºæµç¨‹
            else:
                # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå‡†å¤‡ä¸­
                from ..models.instance import NodeInstanceUpdate, NodeInstanceStatus
                update_data = NodeInstanceUpdate(status=NodeInstanceStatus.PENDING)
                
                # æ·»åŠ é‡è¯•æœºåˆ¶æ¥å¤„ç†å¯èƒ½çš„æ—¶åºé—®é¢˜
                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        result = await node_repo.update_node_instance(node_instance_id, update_data)
                        if result:
                            logger.trace(f"  âœ… èŠ‚ç‚¹çŠ¶æ€æ›´æ–°ä¸ºpendingæˆåŠŸ")
                            break
                        elif attempt < max_retries - 1:
                            logger.warning(f"èŠ‚ç‚¹å®ä¾‹æ›´æ–°å¤±è´¥ï¼Œå°è¯• {attempt + 1}/{max_retries}ï¼Œç­‰å¾…åé‡è¯•...")
                            await asyncio.sleep(0.1)  # çŸ­æš‚ç­‰å¾…
                        else:
                            logger.error(f"èŠ‚ç‚¹å®ä¾‹æ›´æ–°å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                            # ç»§ç»­æ‰§è¡Œï¼Œä¸å› ä¸ºçŠ¶æ€æ›´æ–°å¤±è´¥è€Œä¸­æ–­æ•´ä¸ªæµç¨‹
                    except Exception as e:
                        if attempt < max_retries - 1:
                            logger.warning(f"èŠ‚ç‚¹å®ä¾‹æ›´æ–°å¼‚å¸¸ï¼Œå°è¯• {attempt + 1}/{max_retries}: {e}")
                            await asyncio.sleep(0.1)
                        else:
                            logger.error(f"èŠ‚ç‚¹å®ä¾‹æ›´æ–°å¼‚å¸¸ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                            # ç»§ç»­æ‰§è¡Œ
            
            # ä¸ºè¯¥èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
            created_node = {
                'node_instance_id': node_instance_id,
                'node_id': node['node_id'],  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
                'node_type': node['type'],
                'node_data': node
            }
            
            await self._create_tasks_for_nodes([created_node], workflow_instance_id)
            
            logger.trace(f"  âœ… èŠ‚ç‚¹ä»»åŠ¡åˆ›å»ºå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºèŠ‚ç‚¹ä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return False
    
    async def _check_downstream_nodes_for_task_creation(self, workflow_instance_id: uuid.UUID):
        """æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹æ˜¯å¦å¯ä»¥åˆ›å»ºä»»åŠ¡"""
        try:
            logger.trace(f"ğŸ”„ æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹ä»»åŠ¡åˆ›å»ºæœºä¼š")
            
            # æŸ¥è¯¢å·¥ä½œæµä¸­æ‰€æœ‰ç­‰å¾…çŠ¶æ€çš„èŠ‚ç‚¹
            waiting_nodes_query = '''
            SELECT ni.node_instance_id, ni.node_id, n.name, n.type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 
              AND ni.status = 'pending'
              AND ni.is_deleted = FALSE
            '''
            
            waiting_nodes = await self.workflow_instance_repo.db.fetch_all(
                waiting_nodes_query, workflow_instance_id
            )
            
            logger.trace(f"  æ‰¾åˆ° {len(waiting_nodes)} ä¸ªç­‰å¾…ä¸­çš„èŠ‚ç‚¹")
            
            # ä¸ºæ¯ä¸ªç­‰å¾…èŠ‚ç‚¹æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆ›å»ºä»»åŠ¡
            for node in waiting_nodes:
                node_instance_id = node['node_instance_id']
                node_name = node['name']
                
                logger.trace(f"  æ£€æŸ¥èŠ‚ç‚¹: {node_name} ({node_instance_id})")
                
                # å°è¯•åˆ›å»ºä»»åŠ¡
                created = await self._create_tasks_when_ready(workflow_instance_id, node_instance_id)
                if created:
                    logger.trace(f"    âœ… èŠ‚ç‚¹ {node_name} ä»»åŠ¡åˆ›å»ºæˆåŠŸ")
                else:
                    logger.trace(f"    â³ èŠ‚ç‚¹ {node_name} æ¡ä»¶æœªæ»¡è¶³")
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _execute_end_node(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """æ‰§è¡ŒENDèŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆï¼šä¸¥æ ¼ä¾èµ–æ£€æŸ¥ï¼‰"""
        try:
            logger.trace(f"ğŸ æ‰§è¡ŒENDèŠ‚ç‚¹: {node_instance_id}")
            
            # ğŸ”’ ä¸¥æ ¼æ£€æŸ¥ï¼šé˜²æ­¢é‡å¤æ‰§è¡Œ  
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceUpdate, NodeInstanceStatus
            
            node_repo = NodeInstanceRepository()
            node_info = await node_repo.get_instance_by_id(node_instance_id)
            
            if not node_info:
                logger.error(f"âŒ [ENDèŠ‚ç‚¹] èŠ‚ç‚¹å®ä¾‹ä¸å­˜åœ¨: {node_instance_id}")
                return
            
            # æ£€æŸ¥èŠ‚ç‚¹å½“å‰çŠ¶æ€
            current_status = node_info.get('status')
            if current_status in ['running', 'completed']:
                logger.trace(f"ğŸš« [ENDèŠ‚ç‚¹] èŠ‚ç‚¹å·²å¤„äº {current_status} çŠ¶æ€ï¼Œè·³è¿‡æ‰§è¡Œ")
                return
            
            # ğŸ” åŒé‡ä¾èµ–æ£€æŸ¥ï¼šä¸Šä¸‹æ–‡ç®¡ç†å™¨ + æ•°æ®åº“
            node_id = node_info['node_id']
            
            # 1. æ£€æŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„å‡†å¤‡çŠ¶æ€
            is_ready = self.context_manager.is_node_ready_to_execute(node_instance_id)
            if not is_ready:
                logger.warning(f"âŒ [ENDèŠ‚ç‚¹] èŠ‚ç‚¹ {node_instance_id} åœ¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­æœªå‡†å¤‡å°±ç»ª")
                return
            
            # 2. æ£€æŸ¥æ•°æ®åº“ä¾èµ–çŠ¶æ€
            dependencies_satisfied = await self._check_node_dependencies_satisfied(workflow_instance_id, node_instance_id)
            if not dependencies_satisfied:
                logger.warning(f"âŒ [ENDèŠ‚ç‚¹] èŠ‚ç‚¹ {node_instance_id} ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•æ‰§è¡Œ")
                return
            
            logger.trace(f"âœ… [ENDèŠ‚ç‚¹] ä¾èµ–æ£€æŸ¥é€šè¿‡ï¼Œå¼€å§‹æ‰§è¡Œ")
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            logger.trace(f"ğŸƒ [ENDèŠ‚ç‚¹] æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­")
            update_data = NodeInstanceUpdate(status=NodeInstanceStatus.RUNNING)
            await node_repo.update_node_instance(node_instance_id, update_data)
            
            # æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
            await self.context_manager.mark_node_executing(
                workflow_instance_id=workflow_instance_id,
                node_id=node_id,
                node_instance_id=node_instance_id
            )
            
            # æ”¶é›†å®Œæ•´çš„å·¥ä½œæµä¸Šä¸‹æ–‡
            logger.trace(f"ğŸ“‹ [ENDèŠ‚ç‚¹] æ”¶é›†å·¥ä½œæµä¸Šä¸‹æ–‡")
            context_data = await self._collect_workflow_context(workflow_instance_id)
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå®Œæˆï¼Œå¹¶ä¿å­˜ä¸Šä¸‹æ–‡æ•°æ®
            logger.trace(f"âœ… [ENDèŠ‚ç‚¹] æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ")
            final_update = NodeInstanceUpdate(
                status=NodeInstanceStatus.COMPLETED,
                output_data=context_data
            )
            await node_repo.update_node_instance(node_instance_id, final_update)
            
            # é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨èŠ‚ç‚¹å®Œæˆ
            logger.trace(f"ğŸ‰ [ENDèŠ‚ç‚¹] é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨èŠ‚ç‚¹å®Œæˆ")
            await self.context_manager.mark_node_completed(
                workflow_instance_id=workflow_instance_id,
                node_id=node_id,
                node_instance_id=node_instance_id,
                output_data=context_data
            )
            
            logger.trace(f"âœ… ENDèŠ‚ç‚¹æ‰§è¡Œå®Œæˆ")
            
            # æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å¯ä»¥å®Œæˆ
            await self._check_workflow_completion(workflow_instance_id)
            
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡ŒENDèŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _collect_workflow_context(self, workflow_instance_id: uuid.UUID) -> Dict[str, Any]:
        """æ”¶é›†å·¥ä½œæµçš„å®Œæ•´ä¸Šä¸‹æ–‡"""
        try:
            logger.trace(f"ğŸ“‹ æ”¶é›†å·¥ä½œæµä¸Šä¸‹æ–‡: {workflow_instance_id}")
            
            # è·å–æ‰€æœ‰å·²å®Œæˆçš„èŠ‚ç‚¹å®ä¾‹åŠå…¶è¾“å‡º
            context_query = '''
            SELECT ni.node_instance_id, ni.output_data, n.name as node_name, n.type as node_type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 
              AND ni.status = 'completed'
              AND ni.is_deleted = FALSE
            ORDER BY ni.created_at
            '''
            
            completed_nodes = await self.workflow_instance_repo.db.fetch_all(
                context_query, workflow_instance_id
            )
            
            # è·å–æ‰€æœ‰å·²å®Œæˆçš„ä»»åŠ¡å®ä¾‹åŠå…¶è¾“å‡º  
            task_context_query = '''
            SELECT ti.task_instance_id, ti.output_data, ti.task_title, ti.result_summary,
                   n.name as node_name, n.type as node_type
            FROM task_instance ti
            JOIN node_instance ni ON ti.node_instance_id = ni.node_instance_id
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 
              AND ti.status = 'completed'
              AND ti.is_deleted = FALSE
            ORDER BY ti.completed_at
            '''
            
            completed_tasks = await self.task_instance_repo.db.fetch_all(
                task_context_query, workflow_instance_id
            )
            
            # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
            context_data = {
                'workflow_instance_id': str(workflow_instance_id),
                'completed_at': now_utc().isoformat(),
                'nodes_context': {},
                'tasks_context': {},
                'execution_summary': {
                    'total_nodes': len(completed_nodes),
                    'total_tasks': len(completed_tasks)
                }
            }
            
            # æ·»åŠ èŠ‚ç‚¹ä¸Šä¸‹æ–‡
            for node in completed_nodes:
                node_id = str(node['node_instance_id'])
                context_data['nodes_context'][node_id] = {
                    'node_name': node['node_name'],
                    'node_type': node['node_type'],
                    'output_data': node['output_data'] or {}
                }
            
            # æ·»åŠ ä»»åŠ¡ä¸Šä¸‹æ–‡
            for task in completed_tasks:
                task_id = str(task['task_instance_id'])
                context_data['tasks_context'][task_id] = {
                    'task_title': task['task_title'],
                    'node_name': task['node_name'],
                    'node_type': task['node_type'],
                    'output_data': task['output_data'] or {},
                    'result_summary': task['result_summary']
                }
            
            logger.trace(f"âœ… ä¸Šä¸‹æ–‡æ”¶é›†å®Œæˆ: {len(completed_nodes)} ä¸ªèŠ‚ç‚¹, {len(completed_tasks)} ä¸ªä»»åŠ¡")
            return context_data
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†å·¥ä½œæµä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {}
    
    async def _check_workflow_completion(self, workflow_instance_id: uuid.UUID):
        """æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å¯ä»¥å®Œæˆ"""
        try:
            logger.trace(f"ğŸ æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€: {workflow_instance_id}")
            
            # æŸ¥è¯¢æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹çš„çŠ¶æ€
            nodes_status_query = '''
            SELECT ni.node_instance_id, ni.status, n.name, n.type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 AND ni.is_deleted = FALSE
            '''
            
            all_nodes = await self.workflow_instance_repo.db.fetch_all(
                nodes_status_query, workflow_instance_id
            )
            
            logger.trace(f"  å·¥ä½œæµæ€»èŠ‚ç‚¹æ•°: {len(all_nodes)}")
            
            # æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹æ˜¯å¦éƒ½å·²å®Œæˆ
            completed_nodes = [n for n in all_nodes if n['status'] == 'completed']
            failed_nodes = [n for n in all_nodes if n['status'] == 'failed']
            
            logger.trace(f"  å·²å®ŒæˆèŠ‚ç‚¹: {len(completed_nodes)}")
            logger.trace(f"  å¤±è´¥èŠ‚ç‚¹: {len(failed_nodes)}")
            
            # å¦‚æœæœ‰å¤±è´¥èŠ‚ç‚¹ï¼Œæ ‡è®°å·¥ä½œæµä¸ºå¤±è´¥
            if failed_nodes:
                from ..models.instance import WorkflowInstanceUpdate, WorkflowInstanceStatus
                update_data = WorkflowInstanceUpdate(
                    status=WorkflowInstanceStatus.FAILED,
                    error_message=f"å·¥ä½œæµåŒ…å« {len(failed_nodes)} ä¸ªå¤±è´¥èŠ‚ç‚¹"
                )
                await self.workflow_instance_repo.update_instance(workflow_instance_id, update_data)
                logger.trace(f"âŒ å·¥ä½œæµæ ‡è®°ä¸ºå¤±è´¥")
                return
            
            # å¦‚æœæ‰€æœ‰èŠ‚ç‚¹éƒ½å·²å®Œæˆï¼Œæ ‡è®°å·¥ä½œæµä¸ºå®Œæˆ
            if len(completed_nodes) == len(all_nodes):
                from ..models.instance import WorkflowInstanceUpdate, WorkflowInstanceStatus
                update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.COMPLETED)
                await self.workflow_instance_repo.update_instance(workflow_instance_id, update_data)
                logger.trace(f"âœ… å·¥ä½œæµæ ‡è®°ä¸ºå®Œæˆ")
            else:
                logger.trace(f"â³ å·¥ä½œæµä»åœ¨è¿›è¡Œä¸­: {len(completed_nodes)}/{len(all_nodes)} èŠ‚ç‚¹å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")

    # =============================================================================
    # æ–°æ¶æ„æ–¹æ³• - æ”¯æŒWorkflowInstanceContext
    # =============================================================================
    
    async def _create_node_instances_with_new_context(self, 
                                                    workflow_context, 
                                                    workflow_instance_id: uuid.UUID, 
                                                    workflow_base_id: uuid.UUID,
                                                    nodes: List[Dict[str, Any]]):
        """ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡ç®¡ç†å™¨åˆ›å»ºèŠ‚ç‚¹å®ä¾‹"""
        try:
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceCreate, NodeInstanceStatus
            
            node_instance_repo = NodeInstanceRepository()
            
            for node in nodes:
                # 1. åˆ›å»ºèŠ‚ç‚¹å®ä¾‹
                node_instance_data = NodeInstanceCreate(
                    workflow_instance_id=workflow_instance_id,
                    node_id=node['node_id'],
                    node_base_id=node['node_base_id'],
                    node_instance_name=f"{node['name']}_instance",
                    task_description=node.get('task_description', ''),
                    status=NodeInstanceStatus.PENDING,
                    input_data={},
                    output_data={},
                    error_message=None,
                    retry_count=0
                )
                
                node_instance = await node_instance_repo.create_node_instance(node_instance_data)
                if not node_instance:
                    logger.error(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¤±è´¥: {node['name']}")
                    continue
                
                node_instance_id = node_instance['node_instance_id']
                logger.trace(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹: {node['name']} (ID: {node_instance_id})")
                
                # 2. è·å–ä¸Šæ¸¸ä¾èµ– - æš‚æ—¶ä½¿ç”¨ç©ºåˆ—è¡¨
                upstream_node_ids = []
                
                # 3. åœ¨æ–°ä¸Šä¸‹æ–‡ä¸­æ³¨å†Œä¾èµ–
                await workflow_context.register_node_dependencies(
                    node_instance_id,
                    node['node_id'],  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
                    upstream_node_ids
                )
                
                # 4. ä¸ºå¤„ç†å™¨èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹
                if node['type'] == NodeType.PROCESSOR.value:
                    await self._create_tasks_for_node_new_context(node, node_instance_id, workflow_instance_id)
                
            logger.trace(f"âœ… ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡åˆ›å»ºäº† {len(nodes)} ä¸ªèŠ‚ç‚¹å®ä¾‹")
            
        except Exception as e:
            logger.error(f"ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¤±èµ…: {e}")
            raise
    
    async def _create_tasks_for_node_new_context(self, node: Dict[str, Any], 
                                               node_instance_id: uuid.UUID,
                                               workflow_instance_id: uuid.UUID):
        """ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹ï¼ˆæ–°æ¶æ„ï¼‰"""
        try:
            # è·å–èŠ‚ç‚¹çš„å¤„ç†å™¨ï¼ˆä¿®å¤ï¼šä½¿ç”¨node_idï¼‰  
            processors = await self._get_node_processors(node['node_id'])
            
            for processor in processors:
                # æ ¹æ®å¤„ç†å™¨ç±»å‹ç¡®å®šä»»åŠ¡ç±»å‹å’Œåˆ†é…
                processor_type = processor.get('processor_type', processor.get('type', 'HUMAN'))
                task_type = self._determine_task_type(processor_type)
                assigned_user_id = processor.get('user_id')
                assigned_agent_id = processor.get('agent_id')
                
                # æ·»åŠ è°ƒè¯•æ—¥å¿—
                logger.trace(f"ğŸ” [ä»»åŠ¡åˆ›å»º] å¤„ç†å™¨ä¿¡æ¯:")
                logger.trace(f"   - å¤„ç†å™¨åç§°: {processor.get('name', 'Unknown')}")
                logger.trace(f"   - å¤„ç†å™¨ç±»å‹: '{processor_type}' -> ä»»åŠ¡ç±»å‹: {task_type.value}")
                logger.trace(f"   - åˆ†é…ç”¨æˆ·: {assigned_user_id}")
                logger.trace(f"   - åˆ†é…Agent: {assigned_agent_id}")
                
                # åˆ›å»ºä»»åŠ¡å®ä¾‹
                task_title = node['name']
                task_description = node.get('task_description') or node.get('description') or f"æ‰§è¡ŒèŠ‚ç‚¹ {node['name']} çš„ä»»åŠ¡"
                
                task_data = TaskInstanceCreate(
                    workflow_instance_id=workflow_instance_id,
                    node_instance_id=node_instance_id,
                    processor_id=processor.get('processor_id'),
                    task_type=task_type,
                    task_title=task_title,
                    task_description=task_description,
                    assigned_user_id=assigned_user_id,
                    assigned_agent_id=assigned_agent_id,
                    estimated_duration=processor.get('estimated_duration', 30),
                    input_data="{}",  # ç©ºçš„JSONå­—ç¬¦ä¸²
                    context_data=""   # ç©ºå­—ç¬¦ä¸²
                )
                
                task_instance = await self.task_instance_repo.create_task(task_data)
                if task_instance:
                    task_id = task_instance['task_instance_id']
                    logger.trace(f"åˆ›å»ºä»»åŠ¡å®ä¾‹: {task_title} (ID: {task_id}, ç±»å‹: {task_type})")
                else:
                    logger.error(f"åˆ›å»ºä»»åŠ¡å®ä¾‹å¤±è´¥: {task_title}")
                
        except Exception as e:
            logger.error(f"ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹å¤±è´¥: {e}")
            raise
    
    async def _start_workflow_execution_with_new_context(self, 
                                                       workflow_context,
                                                       workflow_instance_id: uuid.UUID,
                                                       workflow_base_id: uuid.UUID):
        """ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ"""
        try:
            # è·å–å‡†å¤‡æ‰§è¡Œçš„èŠ‚ç‚¹ï¼ˆSTARTèŠ‚ç‚¹ï¼‰
            ready_nodes = await workflow_context.get_ready_nodes()
            
            logger.trace(f"æ‰¾åˆ° {len(ready_nodes)} ä¸ªå‡†å¤‡æ‰§è¡Œçš„èŠ‚ç‚¹")
            
            for node_instance_id in ready_nodes:
                try:
                    # æ‰§è¡ŒèŠ‚ç‚¹
                    await self._execute_node_with_new_context(workflow_context, node_instance_id)
                    logger.trace(f"å¯åŠ¨èŠ‚ç‚¹æ‰§è¡Œ: {node_instance_id}")
                    
                except Exception as e:
                    logger.error(f"å¯åŠ¨èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥ {node_instance_id}: {e}")
            
        except Exception as e:
            logger.error(f"ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡å¯åŠ¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    async def _execute_node_with_new_context(self, workflow_context, node_instance_id: uuid.UUID):
        """ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡æ‰§è¡ŒèŠ‚ç‚¹"""
        try:
            # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å‡†å¤‡å¥½æ‰§è¡Œ
            if not workflow_context.is_node_ready_to_execute(node_instance_id):
                logger.warning(f"èŠ‚ç‚¹ {node_instance_id} å°šæœªå‡†å¤‡å¥½æ‰§è¡Œ")
                return
            
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            dep_info = workflow_context.get_node_dependency_info(node_instance_id)
            if not dep_info:
                logger.error(f"æ— æ³•è·å–èŠ‚ç‚¹ {node_instance_id} çš„ä¾èµ–ä¿¡æ¯")
                return
            
            node_id = dep_info['node_id']  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
            
            # æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
            await workflow_context.mark_node_executing(node_id, node_instance_id)
            
            # è·å–èŠ‚ç‚¹çš„ä»»åŠ¡å®ä¾‹
            tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
            
            if not tasks:
                # æ— ä»»åŠ¡èŠ‚ç‚¹ï¼ˆå¦‚STARTæˆ–ENDèŠ‚ç‚¹ï¼‰
                output_data = {'message': f'Node {node_id} executed without tasks'}
                triggered_nodes = await workflow_context.mark_node_completed(
                    node_id, node_instance_id, output_data
                )
                
                # å¤„ç†è§¦å‘çš„ä¸‹æ¸¸èŠ‚ç‚¹
                for triggered_node_id in triggered_nodes:
                    await self._execute_node_with_new_context(workflow_context, triggered_node_id)
                
            else:
                # æœ‰ä»»åŠ¡çš„èŠ‚ç‚¹ï¼Œå¯åŠ¨ä»»åŠ¡æ‰§è¡Œ
                for task in tasks:
                    await self._execute_task(task)
                
                logger.trace(f"èŠ‚ç‚¹ {node_id} çš„ {len(tasks)} ä¸ªä»»åŠ¡å·²å¯åŠ¨")
            
        except Exception as e:
            logger.error(f"ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡æ‰§è¡ŒèŠ‚ç‚¹ {node_instance_id} å¤±è´¥: {e}")
            # æ ‡è®°èŠ‚ç‚¹å¤±è´¥
            if 'dep_info' in locals() and dep_info:
                await workflow_context.mark_node_failed(
                    dep_info['node_id'],  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
                    node_instance_id,
                    {'error': str(e)}
                )
            raise
    
    async def _log_workflow_execution_summary_new(self, workflow_context, workflow_instance_id: uuid.UUID):
        """ç”Ÿæˆæ–°æ¶æ„çš„æ‰§è¡Œæ‘˜è¦"""
        try:
            status = await workflow_context.get_workflow_status()
            
            logger.trace(f"\nğŸ“ˆ ã€å·¥ä½œæµæ‰§è¡Œæ‘˜è¦ - æ–°æ¶æ„ã€‘")
            logger.trace(f"  å®ä¾‹ ID: {workflow_instance_id}")
            logger.trace(f"  çŠ¶æ€: {status['status']}")
            logger.trace(f"  æ€»èŠ‚ç‚¹æ•°: {status['total_nodes']}")
            logger.trace(f"  å·²å®Œæˆ: {status['completed_nodes']}")
            logger.trace(f"  æ‰§è¡Œä¸­: {status['executing_nodes']}")
            logger.trace(f"  å¾…æ‰§è¡Œ: {status['pending_nodes']}")
            logger.trace(f"  å¤±è´¥: {status['failed_nodes']}")
            logger.trace(f"  æ¶æ„ç±»å‹: WorkflowInstanceContext")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ–°æ¶æ„æ‰§è¡Œæ‘˜è¦å¤±è´¥: {e}")
    
    async def get_execution_stats(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œå¼•æ“ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'is_running': self.is_running,
            'architecture': 'new_context_management',
            'features': {
                'instance_isolation': True,
                'thread_safe': True,
                'auto_cleanup': True,
                'resource_management': True
            }
        }
        
        if hasattr(self, 'resource_cleanup_manager') and self.resource_cleanup_manager:
            cleanup_stats = self.resource_cleanup_manager.get_cleanup_stats()
            stats['resource_cleanup'] = cleanup_stats
        
        return stats

    async def _trigger_downstream_nodes_new_architecture(self, workflow_instance_id: uuid.UUID, completed_node: Dict[str, Any], context):
        """ä½¿ç”¨æ–°æ¶æ„è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹"""
        try:
            node_id = completed_node.get('node_id')
            if not node_id:
                logger.warning("completed_node ç¼ºå°‘ node_id")
                return
            
            # æŸ¥è¯¢ä¸‹æ¸¸èŠ‚ç‚¹
            workflow_base_id = context.workflow_base_id
            downstream_query = """
            SELECT DISTINCT nc.to_node_id as downstream_node_id
            FROM node_connection nc
            WHERE nc.from_node_id = $1
            ORDER BY nc.to_node_id
            """
            downstream_results = await self.workflow_instance_repo.db.fetch_all(
                downstream_query, node_id
            )
            downstream_nodes = [result['downstream_node_id'] for result in downstream_results]
            
            logger.trace(f"æ‰¾åˆ° {len(downstream_nodes)} ä¸ªä¸‹æ¸¸èŠ‚ç‚¹éœ€è¦æ£€æŸ¥")
            
            for downstream_node_id in downstream_nodes:
                await self._check_and_trigger_node_new_architecture(
                    workflow_instance_id, downstream_node_id, context
                )
            
        except Exception as e:
            logger.error(f"æ–°æ¶æ„è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    async def _check_and_trigger_node_new_architecture(self, workflow_instance_id: uuid.UUID, node_id: uuid.UUID, context):
        """æ£€æŸ¥å¹¶è§¦å‘å•ä¸ªèŠ‚ç‚¹ï¼ˆæ–°æ¶æ„ï¼‰"""
        try:
            # è·å–è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰ä¸Šæ¸¸ä¾èµ–
            upstream_query = """
            SELECT DISTINCT nc.from_node_id as upstream_node_id
            FROM node_connection nc
            WHERE nc.to_node_id = $1
            ORDER BY nc.from_node_id
            """
            upstream_results = await self.workflow_instance_repo.db.fetch_all(
                upstream_query, node_id
            )
            upstream_nodes = [result['upstream_node_id'] for result in upstream_results]
            
            # æ£€æŸ¥æ‰€æœ‰ä¸Šæ¸¸èŠ‚ç‚¹æ˜¯å¦éƒ½å·²å®Œæˆ
            all_upstream_completed = True
            for upstream_node_id in upstream_nodes:
                if upstream_node_id not in context.completed_nodes:
                    all_upstream_completed = False
                    break
            
            if all_upstream_completed:
                # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºpendingå¹¶åˆ›å»ºä»»åŠ¡
                await self._update_node_status_to_pending(workflow_instance_id, node_id)
                logger.trace(f"èŠ‚ç‚¹ {node_id} æ‰€æœ‰ä¾èµ–å·²æ»¡è¶³ï¼ŒçŠ¶æ€æ›´æ–°ä¸ºpending")
            else:
                logger.trace(f"èŠ‚ç‚¹ {node_id} ä»æœ‰æœªå®Œæˆçš„ä¸Šæ¸¸ä¾èµ–")
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥å¹¶è§¦å‘èŠ‚ç‚¹å¤±è´¥: {e}")

    async def _trigger_downstream_nodes_legacy(self, workflow_instance_id: uuid.UUID, completed_node: Dict[str, Any]):
        """ä½¿ç”¨æ—§æ¶æ„è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰"""
        try:
            node_id = completed_node.get('node_id')
            if not node_id:
                logger.warning("completed_node ç¼ºå°‘ node_id")
                return
            
            # é€šè¿‡ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€šçŸ¥èŠ‚ç‚¹å®Œæˆ
            if self.context_manager:
                self.context_manager.mark_node_completed(
                    workflow_instance_id, 
                    node_id,  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
                    completed_node.get('output_data', {})
                )
                logger.trace(f"é€šè¿‡æ—§æ¶æ„ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ ‡è®°èŠ‚ç‚¹ {node_id} å®Œæˆ")
            
            # æŸ¥è¯¢æ•°æ®åº“è·å–ä¸‹æ¸¸èŠ‚ç‚¹
            workflow_instance = await self.workflow_instance_repo.get_workflow_instance(workflow_instance_id)
            if not workflow_instance:
                logger.error(f"æœªæ‰¾åˆ°å·¥ä½œæµå®ä¾‹: {workflow_instance_id}")
                return
            
            # æŸ¥è¯¢è¯¥å·¥ä½œæµçš„æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹
            all_node_instances_query = """
                SELECT ni.*, n.type as node_type, n.name as node_name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.workflow_instance_id = $1
                AND ni.status = 'pending'
                AND ni.is_deleted = FALSE
            """
            
            waiting_nodes = await self.workflow_instance_repo.db.fetch_all(
                all_node_instances_query, 
                workflow_instance_id
            )
            
            logger.trace(f"æ‰¾åˆ° {len(waiting_nodes)} ä¸ªç­‰å¾…ä¸­çš„èŠ‚ç‚¹")
            
            # æ£€æŸ¥æ¯ä¸ªç­‰å¾…çš„èŠ‚ç‚¹æ˜¯å¦å¯ä»¥æ‰§è¡Œ
            for node in waiting_nodes:
                await self._check_node_dependencies_and_trigger(
                    workflow_instance_id, node['node_instance_id'], node['node_id']
                )
                
        except Exception as e:
            logger.error(f"æ—§æ¶æ„è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    async def _check_node_dependencies_and_trigger(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID, node_id: uuid.UUID):
        """æ£€æŸ¥èŠ‚ç‚¹ä¾èµ–å¹¶è§¦å‘æ‰§è¡Œ"""
        try:
            # è·å–å·¥ä½œæµç‰ˆæœ¬IDç”¨äºæŸ¥è¯¢è¿æ¥å…³ç³»
            workflow_instance = await self.workflow_instance_repo.get_instance_by_id(workflow_instance_id)
            workflow_id = workflow_instance['workflow_id'] if workflow_instance else None
            
            if not workflow_id:
                logger.error(f"æ— æ³•è·å–å·¥ä½œæµç‰ˆæœ¬ID: {workflow_instance_id}")
                return
            
            # æŸ¥è¯¢è¯¥èŠ‚ç‚¹çš„ä¸Šæ¸¸ä¾èµ–ï¼ˆä½¿ç”¨node_connectionè¡¨ï¼Œè¿™æ˜¯æ­£ç¡®çš„ä¾èµ–å…³ç³»æ¥æºï¼‰
            dependencies_query = """
                SELECT nc.from_node_id as upstream_node_id, ni_upstream.status as upstream_status
                FROM node_connection nc
                LEFT JOIN node_instance ni_upstream ON (
                    nc.from_node_id = ni_upstream.node_id 
                    AND ni_upstream.workflow_instance_id = $1
                )
                WHERE nc.to_node_id = $2 AND nc.workflow_id = $3
            """
            
            dependencies = await self.workflow_instance_repo.db.fetch_all(
                dependencies_query, 
                workflow_instance_id, node_id, workflow_id
            )
            
            # æ£€æŸ¥æ‰€æœ‰ä¸Šæ¸¸èŠ‚ç‚¹æ˜¯å¦å·²å®Œæˆ
            all_dependencies_met = True
            for dep in dependencies:
                if dep['upstream_status'] not in ['completed', 'COMPLETED']:
                    all_dependencies_met = False
                    logger.trace(f"èŠ‚ç‚¹ {node_id} çš„ä¸Šæ¸¸èŠ‚ç‚¹ {dep['upstream_node_id']} çŠ¶æ€ä¸º {dep['upstream_status']}")
                    break
            
            if all_dependencies_met:
                # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºpending
                await self._update_node_status_to_pending(workflow_instance_id, node_id)
                logger.trace(f"èŠ‚ç‚¹ {node_id} æ‰€æœ‰ä¾èµ–å·²æ»¡è¶³ï¼ŒçŠ¶æ€æ›´æ–°ä¸ºpending")
            else:
                logger.trace(f"èŠ‚ç‚¹ {node_id} ä¾èµ–æœªæ»¡è¶³ï¼Œç»§ç»­ç­‰å¾…")
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥èŠ‚ç‚¹ä¾èµ–å¤±è´¥: {e}")

    async def _update_node_status_to_pending(self, workflow_instance_id: uuid.UUID, node_id: uuid.UUID):
        """æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºpendingå¹¶åˆ›å»ºç›¸åº”ä»»åŠ¡"""
        try:
            # æŸ¥æ‰¾èŠ‚ç‚¹å®ä¾‹
            find_node_query = """
                SELECT ni.*, n.type as node_type, n.name as node_name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.workflow_instance_id = $1 AND ni.node_id = $2
            """
            
            node_instance = await self.workflow_instance_repo.db.fetch_one(
                find_node_query, workflow_instance_id, node_id
            )
            
            if not node_instance:
                logger.error(f"æœªæ‰¾åˆ°èŠ‚ç‚¹å®ä¾‹: workflow_instance_id={workflow_instance_id}, node_id={node_id}")
                return
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
            update_query = """
                UPDATE node_instance 
                SET status = 'pending', updated_at = CURRENT_TIMESTAMP
                WHERE node_instance_id = $1
            """
            
            await self.workflow_instance_repo.db.execute(
                update_query, 
                node_instance['node_instance_id']
            )
            
            # ä¸ºpendingçš„èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
            await self._create_tasks_for_pending_node(node_instance)
            
            logger.trace(f"èŠ‚ç‚¹ {node_id} çŠ¶æ€å·²æ›´æ–°ä¸ºpendingï¼Œä»»åŠ¡å·²åˆ›å»º")
            
        except Exception as e:
            logger.error(f"æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºpendingå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    async def _create_tasks_for_pending_node(self, node_instance: Dict[str, Any]):
        """ä¸ºpendingçŠ¶æ€çš„èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡"""
        try:
            node_type = node_instance.get('node_type', '').lower()
            node_instance_id = node_instance['node_instance_id']
            node_id = node_instance.get('node_id')
            
            # å¯¹äºSTART, ENDç­‰èŠ‚ç‚¹ï¼Œä¸éœ€è¦åˆ›å»ºä»»åŠ¡å®ä¾‹
            if node_type in ['start', 'end']:
                logger.trace(f"   èŠ‚ç‚¹ç±»å‹ {node_type} ä¸éœ€è¦ä»»åŠ¡å®ä¾‹ï¼Œè·³è¿‡")
                return
            
            # å¯¹äºprocessorç±»å‹èŠ‚ç‚¹ï¼Œéœ€è¦æŸ¥è¯¢å¤„ç†å™¨ç±»å‹æ¥ç¡®å®šä»»åŠ¡ç±»å‹
            task_type = None
            if node_type == 'processor':
                # æŸ¥è¯¢èŠ‚ç‚¹å…³è”çš„å¤„ç†å™¨ä¿¡æ¯
                processor_query = """
                    SELECT p.type as processor_type, p.user_id, p.agent_id
                    FROM node_processor np
                    LEFT JOIN processor p ON np.processor_id = p.processor_id
                    WHERE np.node_id = %s
                    LIMIT 1
                """
                processor_info = await self.task_instance_repo.db.fetch_one(processor_query, node_id)
                
                if processor_info:
                    processor_type = processor_info['processor_type'].lower() if processor_info['processor_type'] else None
                    if processor_type == 'human':
                        task_type = TaskInstanceType.HUMAN
                    elif processor_type == 'agent':
                        task_type = TaskInstanceType.AGENT
                    elif processor_type == 'mixed':
                        task_type = TaskInstanceType.MIXED
                    else:
                        logger.warning(f"æœªçŸ¥çš„å¤„ç†å™¨ç±»å‹: {processor_type}")
                        return
                else:
                    logger.warning(f"èŠ‚ç‚¹ {node_id} æ²¡æœ‰å…³è”çš„å¤„ç†å™¨ï¼Œæ— æ³•åˆ›å»ºä»»åŠ¡")
                    return
            elif node_type == 'human':
                task_type = TaskInstanceType.HUMAN
            elif node_type == 'agent':
                task_type = TaskInstanceType.AGENT
            elif node_type == 'mixed':
                task_type = TaskInstanceType.MIXED
            else:
                logger.trace(f"   èŠ‚ç‚¹ç±»å‹ {node_type} ä¸éœ€è¦ä»»åŠ¡å®ä¾‹ï¼Œè·³è¿‡")
                return
                
            if not task_type:
                logger.error(f"æ— æ³•ç¡®å®šèŠ‚ç‚¹ {node_id} çš„ä»»åŠ¡ç±»å‹")
                return
            
            # åˆ›å»ºä»»åŠ¡å®ä¾‹ - éœ€è¦è·å–æ›´å¤šå¿…è¦çš„ä¿¡æ¯
            workflow_instance_id = node_instance['workflow_instance_id']
            
            # è·å–å¤„ç†å™¨ä¿¡æ¯ç”¨äºä»»åŠ¡åˆ†é…
            processor_info = None
            if task_type == TaskInstanceType.HUMAN:
                processor_query = """
                    SELECT p.processor_id, p.user_id
                    FROM node_processor np
                    LEFT JOIN processor p ON np.processor_id = p.processor_id
                    WHERE np.node_id = %s AND p.type = 'human'
                    LIMIT 1
                """
                processor_info = await self.task_instance_repo.db.fetch_one(processor_query, node_id)
            elif task_type == TaskInstanceType.AGENT:
                processor_query = """
                    SELECT p.processor_id, p.agent_id
                    FROM node_processor np
                    LEFT JOIN processor p ON np.processor_id = p.processor_id
                    WHERE np.node_id = %s AND p.type = 'agent'
                    LIMIT 1
                """
                processor_info = await self.task_instance_repo.db.fetch_one(processor_query, node_id)
            
            if not processor_info:
                logger.error(f"æ‰¾ä¸åˆ°èŠ‚ç‚¹ {node_id} çš„å¤„ç†å™¨ä¿¡æ¯")
                return
                
            # æ„é€ ç¬¦åˆTaskInstanceCreateæ¨¡å‹çš„æ•°æ®
            task_data = TaskInstanceCreate(
                node_instance_id=node_instance_id,
                workflow_instance_id=workflow_instance_id,
                processor_id=processor_info['processor_id'],
                task_type=task_type,
                task_title=f"Task for {node_instance.get('node_instance_name', 'Unknown')}",
                task_description=node_instance.get('task_description', f"Auto-generated task for node {node_instance_id}"),
                input_data=str(node_instance.get('input_data', {})),  # è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
                assigned_user_id=processor_info.get('user_id') if task_type == TaskInstanceType.HUMAN else None,
                assigned_agent_id=processor_info.get('agent_id') if task_type == TaskInstanceType.AGENT else None,
                estimated_duration=30  # é»˜è®¤30åˆ†é’Ÿ
            )
            
            task_instance = await self.task_instance_repo.create_task(task_data)
            if task_instance:
                # task_instance is a dict, get the ID from it
                task_instance_id = task_instance.get('task_instance_id') if isinstance(task_instance, dict) else task_instance.task_instance_id
                logger.trace(f"âœ… ä¸ºèŠ‚ç‚¹ {node_instance_id} åˆ›å»ºäº† {task_type} ç±»å‹çš„ä»»åŠ¡: {task_instance_id}")
                
                if task_type == TaskInstanceType.HUMAN and processor_info.get('user_id'):
                    logger.info(f"ğŸ¯ äººå·¥ä»»åŠ¡å·²åˆ†é…ç»™ç”¨æˆ· {processor_info['user_id']}: {task_data.task_title}")
            else:
                logger.error(f"âŒ ä»»åŠ¡åˆ›å»ºå¤±è´¥")
            
        except Exception as e:
            logger.error(f"ä¸ºpendingèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    async def _cancel_running_tasks(self, instance_id: uuid.UUID):
        """å–æ¶ˆæ­£åœ¨è¿è¡Œçš„å¼‚æ­¥ä»»åŠ¡"""
        try:
            # æŸ¥æ‰¾æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡å®ä¾‹
            running_tasks_query = """
                SELECT ti.*, ni.workflow_instance_id
                FROM task_instance ti
                JOIN node_instance ni ON ti.node_instance_id = ni.node_instance_id
                WHERE ni.workflow_instance_id = $1
                AND ti.status IN ('running', 'RUNNING', 'assigned', 'ASSIGNED')
            """
            
            running_tasks = await self.task_instance_repo.db.fetch_all(
                running_tasks_query, 
                instance_id
            )
            
            logger.trace(f"æ‰¾åˆ° {len(running_tasks)} ä¸ªæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡éœ€è¦å–æ¶ˆ")
            
            for task in running_tasks:
                try:
                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå–æ¶ˆ
                    task_id = task['task_instance_id']
                    update_query = """
                        UPDATE task_instance 
                        SET status = 'cancelled', 
                            error_message = 'å·¥ä½œæµè¢«å–æ¶ˆ',
                            updated_at = CURRENT_TIMESTAMP
                        WHERE task_instance_id = $1
                    """
                    
                    await self.task_instance_repo.db.execute(update_query, task_id)
                    logger.trace(f"å·²å–æ¶ˆä»»åŠ¡: {task_id}")
                    
                except Exception as e:
                    logger.error(f"å–æ¶ˆä»»åŠ¡ {task.get('task_instance_id')} å¤±è´¥: {e}")
            
        except Exception as e:
            logger.error(f"å–æ¶ˆè¿è¡Œä»»åŠ¡å¤±è´¥: {e}")

    async def _cancel_instance_context_tasks(self, context):
        """å–æ¶ˆå®ä¾‹ä¸Šä¸‹æ–‡ä¸­çš„ä»»åŠ¡"""
        try:
            # æ ‡è®°æ‰€æœ‰æœªå®Œæˆçš„èŠ‚ç‚¹ä¸ºå–æ¶ˆçŠ¶æ€
            for node_id, node_info in context.node_dependencies.items():
                if node_id not in context.completed_nodes:
                    # æ·»åŠ åˆ°å®ŒæˆèŠ‚ç‚¹é›†åˆä¸­ï¼Œé˜²æ­¢åç»­æ‰§è¡Œ
                    context.completed_nodes.add(node_id)
                    logger.trace(f"æ ‡è®°èŠ‚ç‚¹ {node_id} ä¸ºå·²å–æ¶ˆ")
            
            # æ¸…ç†ä¸Šä¸‹æ–‡çŠ¶æ€
            context.current_executing_nodes.clear()
            
        except Exception as e:
            logger.error(f"å–æ¶ˆå®ä¾‹ä¸Šä¸‹æ–‡ä»»åŠ¡å¤±è´¥: {e}")

    async def _notify_services_workflow_cancelled(self, instance_id: uuid.UUID):
        """é€šçŸ¥ç›¸å…³æœåŠ¡å·¥ä½œæµå·²å–æ¶ˆ"""
        try:
            # é€šçŸ¥Agentä»»åŠ¡æœåŠ¡ï¼ˆå¦‚æœæœ‰ç›¸å…³æ–¹æ³•ï¼‰
            try:
                from .agent_task_service import agent_task_service
                # æ£€æŸ¥æ˜¯å¦æœ‰å–æ¶ˆæ–¹æ³•ï¼Œå¦‚æœæ²¡æœ‰åˆ™è·³è¿‡
                if hasattr(agent_task_service, 'cancel_workflow_tasks'):
                    await agent_task_service.cancel_workflow_tasks(instance_id)
                else:
                    logger.trace("Agentä»»åŠ¡æœåŠ¡æ²¡æœ‰cancel_workflow_tasksæ–¹æ³•ï¼Œè·³è¿‡é€šçŸ¥")
            except Exception as e:
                logger.warning(f"é€šçŸ¥Agentä»»åŠ¡æœåŠ¡å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ: {e}")
            
            # æ¸…ç†æ‰§è¡Œé˜Ÿåˆ—ä¸­çš„ç›¸å…³ä»»åŠ¡
            await self._remove_workflow_from_queue(instance_id)
            
            logger.trace(f"å·²é€šçŸ¥ç›¸å…³æœåŠ¡å·¥ä½œæµ {instance_id} å–æ¶ˆ")
            
        except Exception as e:
            logger.error(f"é€šçŸ¥æœåŠ¡å·¥ä½œæµå–æ¶ˆå¤±è´¥: {e}")

    async def _remove_workflow_from_queue(self, instance_id: uuid.UUID):
        """ä»æ‰§è¡Œé˜Ÿåˆ—ä¸­ç§»é™¤å·¥ä½œæµç›¸å…³ä»»åŠ¡"""
        try:
            # åˆ›å»ºæ–°çš„é˜Ÿåˆ—æ¥å­˜å‚¨ä¸éœ€è¦å–æ¶ˆçš„ä»»åŠ¡
            temp_queue = asyncio.Queue()
            cancelled_count = 0
            
            # å¤„ç†ç°æœ‰é˜Ÿåˆ—ä¸­çš„æ‰€æœ‰é¡¹ç›®
            while not self.execution_queue.empty():
                try:
                    item = self.execution_queue.get_nowait()
                    
                    # æ£€æŸ¥æ˜¯å¦å±äºè¦å–æ¶ˆçš„å·¥ä½œæµ
                    if item.get('workflow_instance_id') == instance_id:
                        cancelled_count += 1
                        logger.trace(f"ä»é˜Ÿåˆ—ä¸­ç§»é™¤ä»»åŠ¡: {item.get('task_instance_id')}")
                    else:
                        # ä¿ç•™å…¶ä»–å·¥ä½œæµçš„ä»»åŠ¡
                        await temp_queue.put(item)
                        
                except asyncio.QueueEmpty:
                    break
            
            # å°†ä¿ç•™çš„ä»»åŠ¡æ”¾å›åŸé˜Ÿåˆ—
            while not temp_queue.empty():
                try:
                    item = temp_queue.get_nowait()
                    await self.execution_queue.put(item)
                except asyncio.QueueEmpty:
                    break
            
            if cancelled_count > 0:
                logger.trace(f"ä»æ‰§è¡Œé˜Ÿåˆ—ä¸­ç§»é™¤äº† {cancelled_count} ä¸ªå¾…æ‰§è¡Œä»»åŠ¡")
                
        except Exception as e:
            logger.error(f"ä»æ‰§è¡Œé˜Ÿåˆ—ç§»é™¤ä»»åŠ¡å¤±è´¥: {e}")

    # =============================================================================
    # äººå·¥ä»»åŠ¡ç®¡ç†æ–¹æ³• (å·²æ•´åˆåˆ°ç»Ÿä¸€æœåŠ¡)
    # =============================================================================
    
    async def get_user_tasks(self, user_id: uuid.UUID, 
                           status: Optional[TaskInstanceStatus] = None,
                           limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·çš„ä»»åŠ¡åˆ—è¡¨"""
        try:
            logger.info(f"ğŸ” [ä»»åŠ¡æŸ¥è¯¢] å¼€å§‹æŸ¥è¯¢ç”¨æˆ·ä»»åŠ¡:")
            logger.info(f"   - ç”¨æˆ·ID: {user_id}")
            logger.info(f"   - çŠ¶æ€è¿‡æ»¤: {status.value if status else 'å…¨éƒ¨'}")
            logger.info(f"   - é™åˆ¶æ•°é‡: {limit}")
            
            tasks = await self.task_instance_repo.get_human_tasks_for_user(user_id, status, limit)
            
            logger.info(f"ğŸ“Š [ä»»åŠ¡æŸ¥è¯¢] æŸ¥è¯¢ç»“æœ: æ‰¾åˆ° {len(tasks)} ä¸ªä»»åŠ¡")
            
            # æ·»åŠ ä»»åŠ¡ä¼˜å…ˆçº§å’Œæˆªæ­¢æ—¶é—´ç­‰é™„åŠ ä¿¡æ¯
            # for i, task in enumerate(tasks, 1):
            #     logger.info(f"   ä»»åŠ¡{i}: {task.get('task_title')} | çŠ¶æ€: {task.get('status')} | ID: {task.get('task_instance_id')}")
            #     task = await self._enrich_task_info(task)
            
            if len(tasks) == 0:
                logger.warning(f"âš ï¸ [ä»»åŠ¡æŸ¥è¯¢] ç”¨æˆ· {user_id} æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä»»åŠ¡")
            
            return tasks
            
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def get_task_details(self, task_id: uuid.UUID, user_id: uuid.UUID) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡è¯¦æƒ…"""
        try:
            logger.info(f"ğŸ” [ä»»åŠ¡è¯¦æƒ…] å¼€å§‹æŸ¥è¯¢ä»»åŠ¡è¯¦æƒ…:")
            logger.info(f"   - ä»»åŠ¡ID: {task_id}")
            logger.info(f"   - ç”¨æˆ·ID: {user_id}")
            
            # è·å–ä»»åŠ¡åŸºç¡€ä¿¡æ¯
            task = await self.task_instance_repo.get_task_by_id(task_id)
            if not task:
                logger.warning(f"âš ï¸ [ä»»åŠ¡è¯¦æƒ…] ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                return None
            
            # éªŒè¯ä»»åŠ¡åˆ†é…ç»™è¯¥ç”¨æˆ·
            assigned_user_id = task.get('assigned_user_id')
            user_id_str = str(user_id)
            assigned_user_id_str = str(assigned_user_id) if assigned_user_id else None
            
            logger.info(f"   - åˆ†é…ç”¨æˆ·ID: {assigned_user_id} (ç±»å‹: {type(assigned_user_id)})")
            logger.info(f"   - è¯·æ±‚ç”¨æˆ·ID: {user_id} (ç±»å‹: {type(user_id)})")
            logger.info(f"   - å­—ç¬¦ä¸²æ¯”è¾ƒ: '{assigned_user_id_str}' vs '{user_id_str}'")
            
            if assigned_user_id_str != user_id_str:
                logger.warning(f"âš ï¸ [ä»»åŠ¡è¯¦æƒ…] ç”¨æˆ· {user_id_str} æ— æƒé™è®¿é—®ä»»åŠ¡ {task_id}")
                logger.warning(f"   - åˆ†é…ç»™ç”¨æˆ·: {assigned_user_id_str}")
                return None
            
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            node_info = await self._get_node_info(task.get('node_instance_id'))
            if node_info:
                task['node_info'] = node_info
            
            # è·å–å¤„ç†å™¨ä¿¡æ¯
            processor_info = await self._get_processor_info(task.get('processor_id'))
            if processor_info:
                task['processor_info'] = processor_info
            
            # è·å–ä¸Šæ¸¸ä¸Šä¸‹æ–‡
            upstream_context = await self._get_upstream_context(task)
            task['upstream_context'] = upstream_context
            
            # ä¸°å¯Œä»»åŠ¡ä¿¡æ¯
            task = await self._enrich_task_info(task)
            
            logger.info(f"âœ… [ä»»åŠ¡è¯¦æƒ…] ä»»åŠ¡è¯¦æƒ…æŸ¥è¯¢æˆåŠŸ")
            return task
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}")
            raise
    
    async def start_human_task(self, task_id: uuid.UUID, user_id: uuid.UUID) -> Dict[str, Any]:
        """å¼€å§‹äººå·¥ä»»åŠ¡"""
        try:
            logger.info(f"ğŸš€ [ä»»åŠ¡å¼€å§‹] ç”¨æˆ·å¼€å§‹ä»»åŠ¡:")
            logger.info(f"   - ä»»åŠ¡ID: {task_id}")
            logger.info(f"   - ç”¨æˆ·ID: {user_id}")
            
            # è·å–ä»»åŠ¡ä¿¡æ¯
            logger.info(f"ğŸ” [ä»»åŠ¡å¼€å§‹] æ­£åœ¨æŸ¥è¯¢ä»»åŠ¡ä¿¡æ¯...")
            task = await self.task_instance_repo.get_task_by_id(task_id)
            if not task:
                logger.error(f"âŒ [ä»»åŠ¡å¼€å§‹] ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                return {"success": False, "message": "ä»»åŠ¡ä¸å­˜åœ¨"}
            
            logger.info(f"ğŸ“‹ [ä»»åŠ¡å¼€å§‹] æ‰¾åˆ°ä»»åŠ¡ä¿¡æ¯:")
            logger.info(f"   - ä»»åŠ¡æ ‡é¢˜: {task.get('task_title')}")
            logger.info(f"   - å½“å‰çŠ¶æ€: {task.get('status')}")
            logger.info(f"   - åˆ†é…ç”¨æˆ·ID: {task.get('assigned_user_id')}")
            logger.info(f"   - ä»»åŠ¡ç±»å‹: {task.get('task_type')}")
            
            # éªŒè¯æƒé™
            logger.info(f"ğŸ” [ä»»åŠ¡å¼€å§‹] éªŒè¯ç”¨æˆ·æƒé™...")
            assigned_user_id = task.get('assigned_user_id')
            logger.info(f"   - è¯·æ±‚ç”¨æˆ·ID: {user_id} (ç±»å‹: {type(user_id)})")
            logger.info(f"   - åˆ†é…ç”¨æˆ·ID: {assigned_user_id} (ç±»å‹: {type(assigned_user_id)})")
            
            # ç»Ÿä¸€è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¿›è¡Œæ¯”è¾ƒ
            user_id_str = str(user_id)
            assigned_user_id_str = str(assigned_user_id) if assigned_user_id else None
            logger.info(f"   - å­—ç¬¦ä¸²æ¯”è¾ƒ: '{user_id_str}' vs '{assigned_user_id_str}'")
            
            if assigned_user_id_str != user_id_str:
                logger.error(f"âŒ [ä»»åŠ¡å¼€å§‹] æƒé™éªŒè¯å¤±è´¥:")
                logger.error(f"   - è¯·æ±‚ç”¨æˆ·ID(str): {user_id_str}")
                logger.error(f"   - åˆ†é…ç”¨æˆ·ID(str): {assigned_user_id_str}")
                return {"success": False, "message": "æ‚¨æ— æƒé™æ“ä½œæ­¤ä»»åŠ¡"}
            logger.info(f"âœ… [ä»»åŠ¡å¼€å§‹] æƒé™éªŒè¯é€šè¿‡")
            
            # éªŒè¯çŠ¶æ€
            logger.info(f"ğŸ“Š [ä»»åŠ¡å¼€å§‹] éªŒè¯ä»»åŠ¡çŠ¶æ€...")
            current_status = task.get('status')
            # æ”¯æŒå¤§å°å†™çŠ¶æ€åŒ¹é…
            allowed_statuses = ['PENDING', 'ASSIGNED', 'pending', 'assigned']
            if current_status not in allowed_statuses:
                logger.error(f"âŒ [ä»»åŠ¡å¼€å§‹] çŠ¶æ€éªŒè¯å¤±è´¥:")
                logger.error(f"   - å½“å‰çŠ¶æ€: {current_status}")
                logger.error(f"   - å…è®¸çš„çŠ¶æ€: {allowed_statuses}")
                return {"success": False, "message": f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸å¼€å§‹: {current_status}"}
            logger.info(f"âœ… [ä»»åŠ¡å¼€å§‹] çŠ¶æ€éªŒè¯é€šè¿‡")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            logger.info(f"ğŸ’¾ [ä»»åŠ¡å¼€å§‹] å‡†å¤‡æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸º IN_PROGRESS...")
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.IN_PROGRESS,
                started_at=now_utc()
            )
            
            logger.info(f"ğŸ“ [ä»»åŠ¡å¼€å§‹] è°ƒç”¨æ•°æ®åº“æ›´æ–°...")
            result = await self.task_instance_repo.update_task(task_id, update_data)
            logger.info(f"ğŸ’¾ [ä»»åŠ¡å¼€å§‹] æ•°æ®åº“æ›´æ–°ç»“æœ: {result}")
            
            if result:
                logger.info(f"âœ… [ä»»åŠ¡å¼€å§‹] ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°ä¸º IN_PROGRESS")
                
                # éªŒè¯æ›´æ–°ç»“æœ
                logger.info(f"ğŸ” [ä»»åŠ¡å¼€å§‹] éªŒè¯æ›´æ–°ç»“æœ...")
                updated_task = await self.task_instance_repo.get_task_by_id(task_id)
                if updated_task:
                    logger.info(f"ğŸ“Š [ä»»åŠ¡å¼€å§‹] æ›´æ–°åçš„ä»»åŠ¡çŠ¶æ€: {updated_task.get('status')}")
                    logger.info(f"ğŸ“Š [ä»»åŠ¡å¼€å§‹] æ›´æ–°åçš„å¼€å§‹æ—¶é—´: {updated_task.get('started_at')}")
                else:
                    logger.error(f"âŒ [ä»»åŠ¡å¼€å§‹] æ— æ³•è·å–æ›´æ–°åçš„ä»»åŠ¡ä¿¡æ¯")
                
                success_result = {
                    "success": True,
                    "message": "ä»»åŠ¡å·²å¼€å§‹",
                    "task_id": str(task_id),
                    "status": "IN_PROGRESS",
                    "started_at": now_utc().isoformat()
                }
                logger.info(f"ğŸ‰ [ä»»åŠ¡å¼€å§‹] è¿”å›æˆåŠŸç»“æœ: {success_result}")
                return success_result
            else:
                logger.error(f"âŒ [ä»»åŠ¡å¼€å§‹] æ•°æ®åº“æ›´æ–°å¤±è´¥")
                return {"success": False, "message": "å¯åŠ¨ä»»åŠ¡å¤±è´¥"}
                
        except Exception as e:
            logger.error(f"ğŸ’¥ [ä»»åŠ¡å¼€å§‹] å¼‚å¸¸å‘ç”Ÿ: {type(e).__name__}: {str(e)}")
            import traceback
            logger.error(f"ğŸ“„ [ä»»åŠ¡å¼€å§‹] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def submit_human_task_result(self, task_id: uuid.UUID, user_id: uuid.UUID,
                                     result_data: Dict[str, Any], result_summary: Optional[str] = None) -> Dict[str, Any]:
        """æäº¤äººå·¥ä»»åŠ¡ç»“æœ"""
        try:
            logger.info(f"ğŸ“ [ä»»åŠ¡æäº¤] ç”¨æˆ·æäº¤ä»»åŠ¡ç»“æœ:")
            logger.info(f"   - ä»»åŠ¡ID: {task_id}")
            logger.info(f"   - ç”¨æˆ·ID: {user_id}")
            logger.info(f"   - ç»“æœæ•°æ®: {result_data}")
            logger.info(f"   - ç»“æœé”®æ•°é‡: {len(result_data.keys()) if isinstance(result_data, dict) else 'N/A'}")
            
            # è·å–ä»»åŠ¡ä¿¡æ¯
            logger.info(f"ğŸ” [ä»»åŠ¡æäº¤] æ­£åœ¨æŸ¥è¯¢ä»»åŠ¡ä¿¡æ¯...")
            task = await self.task_instance_repo.get_task_by_id(task_id)
            if not task:
                logger.error(f"âŒ [ä»»åŠ¡æäº¤] ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                return {"success": False, "message": "ä»»åŠ¡ä¸å­˜åœ¨"}
            
            logger.info(f"ğŸ“‹ [ä»»åŠ¡æäº¤] æ‰¾åˆ°ä»»åŠ¡ä¿¡æ¯:")
            logger.info(f"   - ä»»åŠ¡æ ‡é¢˜: {task.get('task_title')}")
            logger.info(f"   - å½“å‰çŠ¶æ€: {task.get('status')}")
            logger.info(f"   - åˆ†é…ç”¨æˆ·ID: {task.get('assigned_user_id')}")
            logger.info(f"   - ä»»åŠ¡ç±»å‹: {task.get('task_type')}")
            
            # éªŒè¯æƒé™
            logger.info(f"ğŸ” [ä»»åŠ¡æäº¤] éªŒè¯ç”¨æˆ·æƒé™...")
            assigned_user_id = task.get('assigned_user_id')
            logger.info(f"   - è¯·æ±‚ç”¨æˆ·ID: {user_id} (ç±»å‹: {type(user_id)})")
            logger.info(f"   - åˆ†é…ç”¨æˆ·ID: {assigned_user_id} (ç±»å‹: {type(assigned_user_id)})")
            
            # ç»Ÿä¸€è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¿›è¡Œæ¯”è¾ƒ
            user_id_str = str(user_id)
            assigned_user_id_str = str(assigned_user_id) if assigned_user_id else None
            logger.info(f"   - å­—ç¬¦ä¸²æ¯”è¾ƒ: '{user_id_str}' vs '{assigned_user_id_str}'")
            
            if assigned_user_id_str != user_id_str:
                logger.error(f"âŒ [ä»»åŠ¡æäº¤] æƒé™éªŒè¯å¤±è´¥:")
                logger.error(f"   - è¯·æ±‚ç”¨æˆ·ID(str): {user_id_str}")
                logger.error(f"   - åˆ†é…ç”¨æˆ·ID(str): {assigned_user_id_str}")
                return {"success": False, "message": "æ‚¨æ— æƒé™æ“ä½œæ­¤ä»»åŠ¡"}
            logger.info(f"âœ… [ä»»åŠ¡æäº¤] æƒé™éªŒè¯é€šè¿‡")
            
            # éªŒè¯çŠ¶æ€
            logger.info(f"ğŸ“Š [ä»»åŠ¡æäº¤] éªŒè¯ä»»åŠ¡çŠ¶æ€...")
            current_status = task.get('status')
            # æ”¯æŒå¤§å°å†™çŠ¶æ€åŒ¹é…
            allowed_statuses = ['IN_PROGRESS', 'ASSIGNED', 'in_progress', 'assigned']
            if current_status not in allowed_statuses:
                logger.error(f"âŒ [ä»»åŠ¡æäº¤] çŠ¶æ€éªŒè¯å¤±è´¥:")
                logger.error(f"   - å½“å‰çŠ¶æ€: {current_status}")
                logger.error(f"   - å…è®¸çš„çŠ¶æ€: {allowed_statuses}")
                return {"success": False, "message": f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æäº¤: {current_status}"}
            logger.info(f"âœ… [ä»»åŠ¡æäº¤] çŠ¶æ€éªŒè¯é€šè¿‡")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€å’Œç»“æœ
            logger.info(f"ğŸ’¾ [ä»»åŠ¡æäº¤] å‡†å¤‡æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸º COMPLETED...")
            
            # å°†å­—å…¸è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²ä»¥ç¬¦åˆæ¨¡å‹è¦æ±‚
            import json
            output_data_str = json.dumps(result_data, ensure_ascii=False) if result_data else "{}"
            logger.info(f"   - è¾“å‡ºæ•°æ®å­—ç¬¦ä¸²é•¿åº¦: {len(output_data_str)}")
            
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.COMPLETED,
                output_data=output_data_str,
                result_summary=result_summary,
                completed_at=now_utc()
            )
            
            result = await self.task_instance_repo.update_task(task_id, update_data)
            if result:
                logger.info(f"âœ… [ä»»åŠ¡æäº¤] ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°ä¸º COMPLETED")
                
                # è·å–æ›´æ–°åçš„ä»»åŠ¡
                updated_task = await self.task_instance_repo.get_task_by_id(task_id)
                
                # ç»Ÿä¸€å¤„ç†ä»»åŠ¡å®Œæˆ - é¿å…é‡å¤è°ƒç”¨ mark_node_completed
                await self._handle_task_completion_unified(task, updated_task, result_data, "human")
                
                return {
                    "success": True,
                    "message": "ä»»åŠ¡ç»“æœå·²æäº¤",
                    "task_id": str(task_id),
                    "status": "COMPLETED"
                }
            else:
                logger.error(f"âŒ [ä»»åŠ¡æäº¤] æ•°æ®åº“æ›´æ–°å¤±è´¥")
                return {"success": False, "message": "æäº¤ä»»åŠ¡ç»“æœå¤±è´¥"}
                
        except Exception as e:
            logger.error(f"æäº¤äººå·¥ä»»åŠ¡ç»“æœå¤±è´¥: {e}")
            raise
    
    async def pause_human_task(self, task_id: uuid.UUID, user_id: uuid.UUID,
                             pause_reason: Optional[str] = None) -> Dict[str, Any]:
        """æš‚åœäººå·¥ä»»åŠ¡"""
        try:
            logger.info(f"â¸ï¸ [ä»»åŠ¡æš‚åœ] ç”¨æˆ·æš‚åœä»»åŠ¡:")
            logger.info(f"   - ä»»åŠ¡ID: {task_id}")
            logger.info(f"   - ç”¨æˆ·ID: {user_id}")
            logger.info(f"   - æš‚åœåŸå› : {pause_reason}")
            
            # è·å–ä»»åŠ¡ä¿¡æ¯
            task = await self.task_instance_repo.get_task_by_id(task_id)
            if not task:
                return {"success": False, "message": "ä»»åŠ¡ä¸å­˜åœ¨"}
            
            # éªŒè¯æƒé™
            assigned_user_id = task.get('assigned_user_id')
            user_id_str = str(user_id)
            assigned_user_id_str = str(assigned_user_id) if assigned_user_id else None
            
            if assigned_user_id_str != user_id_str:
                return {"success": False, "message": "æ‚¨æ— æƒé™æ“ä½œæ­¤ä»»åŠ¡"}
            
            # éªŒè¯çŠ¶æ€ - æ”¯æŒå¤§å°å†™åŒ¹é…
            current_status = task.get('status')
            if current_status not in ['IN_PROGRESS', 'in_progress']:
                return {"success": False, "message": f"åªæœ‰è¿›è¡Œä¸­çš„ä»»åŠ¡å¯ä»¥æš‚åœï¼Œå½“å‰çŠ¶æ€: {current_status}"}
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.PAUSED,
                paused_reason=pause_reason,
                paused_at=now_utc()
            )
            
            result = await self.task_instance_repo.update_task(task_id, update_data)
            if result:
                logger.info(f"âœ… [ä»»åŠ¡æš‚åœ] ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°ä¸º PAUSED")
                return {
                    "success": True,
                    "message": "ä»»åŠ¡å·²æš‚åœ",
                    "task_id": str(task_id),
                    "status": "PAUSED"
                }
            else:
                return {"success": False, "message": "æš‚åœä»»åŠ¡å¤±è´¥"}
                
        except Exception as e:
            logger.error(f"æš‚åœäººå·¥ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def cancel_human_task(self, task_id: uuid.UUID, user_id: uuid.UUID,
                              cancel_reason: Optional[str] = None) -> Dict[str, Any]:
        """å–æ¶ˆäººå·¥ä»»åŠ¡"""
        try:
            logger.info(f"ğŸš« [ä»»åŠ¡å–æ¶ˆ] ç”¨æˆ·å–æ¶ˆä»»åŠ¡:")
            logger.info(f"   - ä»»åŠ¡ID: {task_id}")
            logger.info(f"   - ç”¨æˆ·ID: {user_id}")
            logger.info(f"   - å–æ¶ˆåŸå› : {cancel_reason}")
            
            # è·å–ä»»åŠ¡ä¿¡æ¯
            task = await self.task_instance_repo.get_task_by_id(task_id)
            if not task:
                return {"success": False, "message": "ä»»åŠ¡ä¸å­˜åœ¨"}
            
            # éªŒè¯æƒé™
            assigned_user_id = task.get('assigned_user_id')
            user_id_str = str(user_id)
            assigned_user_id_str = str(assigned_user_id) if assigned_user_id else None
            
            if assigned_user_id_str != user_id_str:
                return {"success": False, "message": "æ‚¨æ— æƒé™æ“ä½œæ­¤ä»»åŠ¡"}
            
            # éªŒè¯çŠ¶æ€ - æ”¯æŒå¤§å°å†™åŒ¹é…
            current_status = task.get('status')
            if current_status in ['COMPLETED', 'CANCELLED', 'FAILED', 'completed', 'cancelled', 'failed']:
                return {"success": False, "message": f"ä»»åŠ¡å·²ç»“æŸï¼Œæ— æ³•å–æ¶ˆï¼Œå½“å‰çŠ¶æ€: {current_status}"}
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.CANCELLED,
                error_message=cancel_reason or "ç”¨æˆ·å–æ¶ˆ",
                cancelled_at=now_utc()
            )
            
            result = await self.task_instance_repo.update_task(task_id, update_data)
            if result:
                logger.info(f"âœ… [ä»»åŠ¡å–æ¶ˆ] ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°ä¸º CANCELLED")
                return {
                    "success": True,
                    "message": "ä»»åŠ¡å·²å–æ¶ˆ",
                    "task_id": str(task_id),
                    "status": "CANCELLED"
                }
            else:
                return {"success": False, "message": "å–æ¶ˆä»»åŠ¡å¤±è´¥"}
                
        except Exception as e:
            logger.error(f"å–æ¶ˆäººå·¥ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    # é€šç”¨ä»»åŠ¡æ“ä½œæ–¹æ³•ï¼ˆä¸ºAPIå±‚æä¾›å…¼å®¹æ¥å£ï¼‰
    async def pause_task(self, task_id: uuid.UUID, user_id: uuid.UUID, reason: Optional[str] = None) -> Dict[str, Any]:
        """æš‚åœä»»åŠ¡ï¼ˆé€šç”¨æ¥å£ï¼‰"""
        return await self.pause_human_task(task_id, user_id, reason)
    
    async def cancel_task(self, task_id: uuid.UUID, user_id: uuid.UUID, reason: Optional[str] = None) -> Dict[str, Any]:
        """å–æ¶ˆä»»åŠ¡ï¼ˆé€šç”¨æ¥å£ï¼‰"""
        return await self.cancel_human_task(task_id, user_id, reason)
    
    async def request_help(self, task_id: uuid.UUID, user_id: uuid.UUID, help_message: str) -> Dict[str, Any]:
        """è¯·æ±‚å¸®åŠ©"""
        try:
            logger.info(f"ğŸ†˜ [è¯·æ±‚å¸®åŠ©] ç”¨æˆ·è¯·æ±‚å¸®åŠ©:")
            logger.info(f"   - ä»»åŠ¡ID: {task_id}")
            logger.info(f"   - ç”¨æˆ·ID: {user_id}")
            logger.info(f"   - å¸®åŠ©ä¿¡æ¯: {help_message}")
            
            # è·å–ä»»åŠ¡ä¿¡æ¯
            task = await self.task_instance_repo.get_task_by_id(task_id)
            if not task:
                return {"success": False, "message": "ä»»åŠ¡ä¸å­˜åœ¨"}
            
            # éªŒè¯æƒé™
            assigned_user_id = task.get('assigned_user_id')
            user_id_str = str(user_id)
            assigned_user_id_str = str(assigned_user_id) if assigned_user_id else None
            
            if assigned_user_id_str != user_id_str:
                return {"success": False, "message": "æ‚¨æ— æƒé™æ“ä½œæ­¤ä»»åŠ¡"}
            
            # è®°å½•å¸®åŠ©è¯·æ±‚åˆ°ä»»åŠ¡å®ä¾‹çš„context_dataä¸­
            current_context = task.get('context_data', {})
            if 'help_requests' not in current_context:
                current_context['help_requests'] = []
            
            help_request = {
                'timestamp': now_utc().isoformat(),
                'message': help_message,
                'status': 'pending'
            }
            current_context['help_requests'].append(help_request)
            
            # æ›´æ–°ä»»åŠ¡
            update_data = TaskInstanceUpdate(context_data=current_context)
            result = await self.task_instance_repo.update_task(task_id, update_data)
            
            if result:
                logger.info(f"âœ… [è¯·æ±‚å¸®åŠ©] å¸®åŠ©è¯·æ±‚å·²è®°å½•")
                return {
                    "success": True,
                    "message": "å¸®åŠ©è¯·æ±‚å·²æäº¤",
                    "task_id": str(task_id),
                    "help_request": help_request
                }
            else:
                return {"success": False, "message": "æäº¤å¸®åŠ©è¯·æ±‚å¤±è´¥"}
                
        except Exception as e:
            logger.error(f"è¯·æ±‚å¸®åŠ©å¤±è´¥: {e}")
            raise
    
    async def reject_task(self, task_id: uuid.UUID, user_id: uuid.UUID, reason: str) -> Dict[str, Any]:
        """æ‹’ç»ä»»åŠ¡"""
        try:
            logger.info(f"ğŸš« [æ‹’ç»ä»»åŠ¡] ç”¨æˆ·æ‹’ç»ä»»åŠ¡:")
            logger.info(f"   - ä»»åŠ¡ID: {task_id}")
            logger.info(f"   - ç”¨æˆ·ID: {user_id}")
            logger.info(f"   - æ‹’ç»åŸå› : {reason}")
            
            # è·å–ä»»åŠ¡ä¿¡æ¯
            task = await self.task_instance_repo.get_task_by_id(task_id)
            if not task:
                return {"success": False, "message": "ä»»åŠ¡ä¸å­˜åœ¨"}
            
            # éªŒè¯æƒé™
            assigned_user_id = task.get('assigned_user_id')
            user_id_str = str(user_id)
            assigned_user_id_str = str(assigned_user_id) if assigned_user_id else None
            
            if assigned_user_id_str != user_id_str:
                return {"success": False, "message": "æ‚¨æ— æƒé™æ“ä½œæ­¤ä»»åŠ¡"}
            
            # éªŒè¯çŠ¶æ€ - æ”¯æŒå¤§å°å†™åŒ¹é…
            current_status = task.get('status')
            if current_status not in ['PENDING', 'ASSIGNED', 'pending', 'assigned']:
                return {"success": False, "message": f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æ‹’ç»: {current_status}"}
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºæ‹’ç»
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.CANCELLED,
                error_message=f"ç”¨æˆ·æ‹’ç»: {reason}",
                cancelled_at=now_utc()
            )
            
            result = await self.task_instance_repo.update_task(task_id, update_data)
            if result:
                logger.info(f"âœ… [æ‹’ç»ä»»åŠ¡] ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°ä¸º CANCELLED")
                
                # TODO: è¿™é‡Œå¯ä»¥æ·»åŠ é‡æ–°åˆ†é…ä»»åŠ¡çš„é€»è¾‘
                
                return {
                    "success": True,
                    "message": "ä»»åŠ¡å·²æ‹’ç»",
                    "task_id": str(task_id),
                    "status": "CANCELLED"
                }
            else:
                return {"success": False, "message": "æ‹’ç»ä»»åŠ¡å¤±è´¥"}
                
        except Exception as e:
            logger.error(f"æ‹’ç»ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def get_task_history(self, user_id: uuid.UUID, 
                             days: int = 30, limit: int = 100) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·ä»»åŠ¡å†å²"""
        try:
            logger.info(f"ğŸ“œ [ä»»åŠ¡å†å²] æŸ¥è¯¢ç”¨æˆ·ä»»åŠ¡å†å²:")
            logger.info(f"   - ç”¨æˆ·ID: {user_id}")
            logger.info(f"   - å¤©æ•°: {days}")
            logger.info(f"   - é™åˆ¶: {limit}")
            
            tasks = await self.task_instance_repo.get_user_task_history(user_id, days, limit)
            
            # ä¸°å¯Œä»»åŠ¡ä¿¡æ¯
            for task in tasks:
                task = await self._enrich_task_info(task)
            
            logger.info(f"âœ… [ä»»åŠ¡å†å²] æ‰¾åˆ° {len(tasks)} æ¡å†å²è®°å½•")
            return tasks
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡å†å²å¤±è´¥: {e}")
            raise
    
    async def get_task_statistics(self, user_id: uuid.UUID) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        try:
            logger.info(f"ğŸ“Š [ä»»åŠ¡ç»Ÿè®¡] æŸ¥è¯¢ç”¨æˆ·ä»»åŠ¡ç»Ÿè®¡:")
            logger.info(f"   - ç”¨æˆ·ID: {user_id}")
            
            stats = await self.task_instance_repo.get_user_task_statistics(user_id)
            
            logger.info(f"âœ… [ä»»åŠ¡ç»Ÿè®¡] ç»Ÿè®¡ä¿¡æ¯æŸ¥è¯¢æˆåŠŸ")
            return stats
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {e}")
            raise
    
    # =============================================================================
    # è¾…åŠ©æ–¹æ³• (å·²æ•´åˆåˆ°ç»Ÿä¸€æœåŠ¡)
    # =============================================================================
    
    async def _get_node_info(self, node_instance_id: Optional[uuid.UUID]) -> Optional[Dict[str, Any]]:
        """è·å–èŠ‚ç‚¹ä¿¡æ¯"""
        if not node_instance_id:
            return None
            
        try:
            query = """
            SELECT ni.*, n.name as node_name, n.type as node_type, n.description
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.node_instance_id = $1
            """
            return await self.task_instance_repo.db.fetch_one(query, node_instance_id)
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    async def _get_processor_info(self, processor_id: Optional[uuid.UUID]) -> Optional[Dict[str, Any]]:
        """è·å–å¤„ç†å™¨ä¿¡æ¯"""
        if not processor_id:
            return None
            
        try:
            query = """
            SELECT p.*, u.username, a.agent_name
            FROM processor p
            LEFT JOIN "user" u ON p.user_id = u.user_id
            LEFT JOIN agent a ON p.agent_id = a.agent_id
            WHERE p.processor_id = $1
            """
            return await self.processor_repo.db.fetch_one(query, processor_id)
        except Exception as e:
            logger.error(f"è·å–å¤„ç†å™¨ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    async def _get_upstream_context(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–ä¸Šæ¸¸ä¸Šä¸‹æ–‡"""
        try:
            workflow_instance_id = task.get('workflow_instance_id')
            node_instance_id = task.get('node_instance_id')
            
            if not workflow_instance_id or not node_instance_id:
                return {}
            
            # ä½¿ç”¨ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†å™¨è·å–ä¸Šæ¸¸ä¸Šä¸‹æ–‡
            return await self.context_manager.get_node_upstream_context(
                workflow_instance_id, node_instance_id
            )
        except Exception as e:
            logger.error(f"è·å–ä¸Šæ¸¸ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return {}
    
    async def _enrich_task_info(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸°å¯Œä»»åŠ¡ä¿¡æ¯"""
        try:
            # æ·»åŠ æ‰§è¡Œæ—¶é—´ç­‰è®¡ç®—å­—æ®µ
            if task.get('started_at') and not task.get('completed_at'):
                execution_time = (now_utc() - task['started_at']).total_seconds() / 60
                task['execution_time_minutes'] = round(execution_time, 2)
            
            # æ·»åŠ ä»»åŠ¡ä¼˜å…ˆçº§
            task['priority'] = self._calculate_task_priority(task)
            
            # æ·»åŠ æˆªæ­¢æ—¶é—´
            task['due_date'] = self._calculate_due_date(task)
            
            return task
        except Exception as e:
            logger.error(f"ä¸°å¯Œä»»åŠ¡ä¿¡æ¯å¤±è´¥: {e}")
            return task
    
    def _calculate_task_priority(self, task: Dict[str, Any]) -> str:
        """è®¡ç®—ä»»åŠ¡ä¼˜å…ˆçº§"""
        try:
            # åŸºäºä»»åŠ¡ç±»å‹å’Œåˆ›å»ºæ—¶é—´è®¡ç®—ä¼˜å…ˆçº§
            created_at = task.get('created_at')
            if not created_at:
                return "normal"
            
            age_hours = (now_utc() - created_at).total_seconds() / 3600
            
            if age_hours > 24:
                return "high"
            elif age_hours > 8:
                return "medium"
            else:
                return "normal"
        except Exception:
            return "normal"
    
    def _calculate_due_date(self, task: Dict[str, Any]) -> Optional[str]:
        """è®¡ç®—æˆªæ­¢æ—¶é—´"""
        try:
            created_at = task.get('created_at')
            estimated_duration = task.get('estimated_duration', 60)  # é»˜è®¤60åˆ†é’Ÿ
            
            if created_at:
                due_date = created_at + timedelta(minutes=estimated_duration)
                return due_date.isoformat()
            return None
        except Exception:
            return None
    
    async def _handle_task_completion_unified(self, task: Dict[str, Any], 
                                            updated_task: Dict[str, Any],
                                            output_data: str,
                                            task_type: str):
        """ç»Ÿä¸€å¤„ç†ä»»åŠ¡å®Œæˆ - é¿å…é‡å¤è°ƒç”¨ mark_node_completed"""
        try:
            logger.info(f"ğŸ”„ [ç»Ÿä¸€ä»»åŠ¡å®Œæˆ] å¤„ç†{task_type}ä»»åŠ¡å®Œæˆ: {task['task_instance_id']}")
            
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            node_query = """
            SELECT n.node_id 
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.node_instance_id = $1
            """
            node_info = await self.task_instance_repo.db.fetch_one(node_query, task['node_instance_id'])
            
            if not node_info:
                logger.error(f"âŒ æ— æ³•æ‰¾åˆ°èŠ‚ç‚¹ä¿¡æ¯: {task['node_instance_id']}")
                return
            
            # æ„é€ è¾“å‡ºæ•°æ®
            completion_output = {
                "message": f"{task_type}ä»»åŠ¡å®Œæˆ",
                "task_type": task_type,
                "output_data": output_data,
                "completed_at": updated_task.get('completed_at').isoformat() if updated_task.get('completed_at') else None,
                "task_id": str(task['task_instance_id'])
            }
            
            # åªåœ¨è¿™é‡Œè°ƒç”¨ä¸€æ¬¡ mark_node_completed - é¿å…é‡å¤
            await self.context_manager.mark_node_completed(
                workflow_instance_id=task['workflow_instance_id'],
                node_id=node_info['node_id'],
                node_instance_id=task['node_instance_id'],
                output_data=completion_output
            )
            
            logger.info(f"âœ… [ç»Ÿä¸€ä»»åŠ¡å®Œæˆ] {task_type}ä»»åŠ¡å®Œæˆå¤„ç†æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"ğŸ’¥ [ç»Ÿä¸€ä»»åŠ¡å®Œæˆ] å¤„ç†å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")


# å…¨å±€æ‰§è¡Œå¼•æ“å®ä¾‹
execution_engine = ExecutionEngine()