"""
å·¥ä½œæµTabè¡¥å…¨é¢„æµ‹æœåŠ¡
åŸºäºç°æœ‰AIå·¥ä½œæµç”Ÿæˆå™¨ï¼Œæä¾›å¢é‡é¢„æµ‹å’Œæ™ºèƒ½å»ºè®®åŠŸèƒ½
"""

import json
import uuid
from typing import Dict, Any, List, Optional
from loguru import logger
import asyncio

from .ai_workflow_generator import AIWorkflowGeneratorService
from ..utils.exceptions import ValidationError


class WorkflowTabPredictionService:
    """å·¥ä½œæµTabè¡¥å…¨é¢„æµ‹æœåŠ¡"""

    def __init__(self):
        # å¤ç”¨ç°æœ‰çš„AIç”Ÿæˆå™¨
        self.ai_generator = AIWorkflowGeneratorService(prompt_mode="tab_completion")

        # é¢„æµ‹ç¼“å­˜
        self.prediction_cache = {}
        self.cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜

        logger.info("ğŸ”® å·¥ä½œæµTabé¢„æµ‹æœåŠ¡åˆå§‹åŒ–å®Œæˆ")

    async def predict_next_nodes(
        self,
        context_summary: str,
        max_suggestions: int = 3
    ) -> List[Dict[str, Any]]:
        """
        åŸºäºå·¥ä½œæµä¸Šä¸‹æ–‡é¢„æµ‹ä¸‹ä¸€ä¸ªå¯èƒ½çš„èŠ‚ç‚¹

        Args:
            context_summary: å·¥ä½œæµä¸Šä¸‹æ–‡æ‘˜è¦
            max_suggestions: æœ€å¤§å»ºè®®æ•°é‡

        Returns:
            List[Dict]: èŠ‚ç‚¹å»ºè®®åˆ—è¡¨
        """
        try:
            logger.info(f"ğŸ”® [TAB-PREDICT] å¼€å§‹é¢„æµ‹ä¸‹ä¸€ä¸ªèŠ‚ç‚¹")
            logger.info(f"ğŸ”® [TAB-PREDICT] ä¸Šä¸‹æ–‡æ‘˜è¦: {context_summary[:200]}...")

            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"nodes_{hash(context_summary)}_{max_suggestions}"
            if cache_key in self.prediction_cache:
                cached_result = self.prediction_cache[cache_key]
                if cached_result['timestamp'] + self.cache_ttl > asyncio.get_event_loop().time():
                    logger.info(f"ğŸ”® [TAB-PREDICT] ä½¿ç”¨ç¼“å­˜ç»“æœ")
                    return cached_result['data']

            # æ„å»ºèŠ‚ç‚¹é¢„æµ‹çš„ç‰¹æ®Šprompt
            node_prediction_prompt = self._build_node_prediction_prompt(context_summary, max_suggestions)

            # è°ƒç”¨AI API
            ai_response = await self.ai_generator._call_real_api(node_prediction_prompt)

            # è§£æèŠ‚ç‚¹å»ºè®®
            node_suggestions = self._parse_node_suggestions(ai_response)

            # ç¼“å­˜ç»“æœ
            self.prediction_cache[cache_key] = {
                'data': node_suggestions,
                'timestamp': asyncio.get_event_loop().time()
            }

            logger.info(f"ğŸ”® [TAB-PREDICT] âœ… èŠ‚ç‚¹é¢„æµ‹å®Œæˆï¼Œå»ºè®®æ•°é‡: {len(node_suggestions)}")
            return node_suggestions

        except Exception as e:
            logger.error(f"ğŸ”® [TAB-PREDICT] âŒ èŠ‚ç‚¹é¢„æµ‹å¤±è´¥: {str(e)}")
            return []

    async def predict_next_connections(
        self,
        context_summary: str,
        source_node_id: str,
        max_suggestions: int = 3
    ) -> List[Dict[str, Any]]:
        """
        é¢„æµ‹ä»æŒ‡å®šèŠ‚ç‚¹å‡ºå‘çš„å¯èƒ½è¿æ¥

        Args:
            context_summary: å·¥ä½œæµä¸Šä¸‹æ–‡æ‘˜è¦
            source_node_id: æºèŠ‚ç‚¹ID
            max_suggestions: æœ€å¤§å»ºè®®æ•°é‡

        Returns:
            List[Dict]: è¿æ¥å»ºè®®åˆ—è¡¨
        """
        try:
            logger.info(f"ğŸ”® [TAB-PREDICT] å¼€å§‹é¢„æµ‹èŠ‚ç‚¹è¿æ¥")
            logger.info(f"ğŸ”® [TAB-PREDICT] æºèŠ‚ç‚¹: {source_node_id}")

            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"edges_{hash(context_summary)}_{source_node_id}_{max_suggestions}"
            if cache_key in self.prediction_cache:
                cached_result = self.prediction_cache[cache_key]
                if cached_result['timestamp'] + self.cache_ttl > asyncio.get_event_loop().time():
                    logger.info(f"ğŸ”® [TAB-PREDICT] ä½¿ç”¨ç¼“å­˜ç»“æœ")
                    return cached_result['data']

            # æ„å»ºè¿æ¥é¢„æµ‹çš„ç‰¹æ®Šprompt
            connection_prediction_prompt = self._build_connection_prediction_prompt(
                context_summary, source_node_id, max_suggestions
            )

            # è°ƒç”¨AI API
            ai_response = await self.ai_generator._call_real_api(connection_prediction_prompt)

            # è§£æè¿æ¥å»ºè®®
            connection_suggestions = self._parse_connection_suggestions(ai_response, source_node_id)

            # ç¼“å­˜ç»“æœ
            self.prediction_cache[cache_key] = {
                'data': connection_suggestions,
                'timestamp': asyncio.get_event_loop().time()
            }

            logger.info(f"ğŸ”® [TAB-PREDICT] âœ… è¿æ¥é¢„æµ‹å®Œæˆï¼Œå»ºè®®æ•°é‡: {len(connection_suggestions)}")
            return connection_suggestions

        except Exception as e:
            logger.error(f"ğŸ”® [TAB-PREDICT] âŒ è¿æ¥é¢„æµ‹å¤±è´¥: {str(e)}")
            return []

    async def predict_workflow_completion(
        self,
        context_summary: str,
        partial_description: str
    ) -> List[Dict[str, Any]]:
        """
        é¢„æµ‹å·¥ä½œæµçš„å®Œæ•´ç»“æ„

        Args:
            context_summary: å½“å‰å·¥ä½œæµçŠ¶æ€
            partial_description: éƒ¨åˆ†ä»»åŠ¡æè¿°

        Returns:
            List[Dict]: å®Œæ•´å·¥ä½œæµå»ºè®®
        """
        try:
            logger.info(f"ğŸ”® [TAB-PREDICT] å¼€å§‹é¢„æµ‹å·¥ä½œæµå®Œæ•´ç»“æ„")

            completion_prompt = self._build_workflow_completion_prompt(context_summary, partial_description)
            ai_response = await self.ai_generator._call_real_api(completion_prompt)

            # è§£æå®Œæ•´å·¥ä½œæµå»ºè®®
            workflow_suggestions = self._parse_workflow_completion(ai_response)

            logger.info(f"ğŸ”® [TAB-PREDICT] âœ… å·¥ä½œæµå®Œæ•´æ€§é¢„æµ‹å®Œæˆ")
            return workflow_suggestions

        except Exception as e:
            logger.error(f"ğŸ”® [TAB-PREDICT] âŒ å·¥ä½œæµå®Œæ•´æ€§é¢„æµ‹å¤±è´¥: {str(e)}")
            return []

    def _build_node_prediction_prompt(self, context_summary: str, max_suggestions: int) -> str:
        """æ„å»ºèŠ‚ç‚¹é¢„æµ‹çš„prompt"""
        return f"""ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµè®¾è®¡åŠ©æ‰‹ã€‚åŸºäºå½“å‰å·¥ä½œæµçŠ¶æ€ï¼Œé¢„æµ‹ç”¨æˆ·å¯èƒ½éœ€è¦æ·»åŠ çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚

å½“å‰å·¥ä½œæµçŠ¶æ€:
{context_summary}

è¯·é¢„æµ‹æœ€å¤š{max_suggestions}ä¸ªå¯èƒ½çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ï¼Œè¿”å›JSONæ ¼å¼:

{{
  "suggestions": [
    {{
      "type": "start|processor|end",
      "name": "èŠ‚ç‚¹åç§°",
      "description": "èŠ‚ç‚¹æè¿°",
      "confidence": 0.85,
      "reasoning": "å»ºè®®æ­¤èŠ‚ç‚¹çš„ç†ç”±",
      "processor_type": "human|agent|null",
      "suggested_position": {{"x": 200, "y": 300}}
    }}
  ]
}}

è¦æ±‚:
1. æ ¹æ®å·¥ä½œæµå®Œæ•´æ€§åˆ†ææœ€éœ€è¦çš„èŠ‚ç‚¹ç±»å‹
2. confidenceè¡¨ç¤ºç½®ä¿¡åº¦(0-1)
3. reasoningè¦ç®€æ´æ˜ç¡®
4. è€ƒè™‘å…¸å‹çš„å·¥ä½œæµæ¨¡å¼
5. ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSON"""

    def _build_connection_prediction_prompt(self, context_summary: str, source_node_id: str, max_suggestions: int) -> str:
        """æ„å»ºè¿æ¥é¢„æµ‹çš„prompt"""
        return f"""ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµè®¾è®¡åŠ©æ‰‹ã€‚åŸºäºå½“å‰å·¥ä½œæµçŠ¶æ€ï¼Œé¢„æµ‹ä»æŒ‡å®šèŠ‚ç‚¹å‡ºå‘çš„å¯èƒ½è¿æ¥ã€‚

å½“å‰å·¥ä½œæµçŠ¶æ€:
{context_summary}

æºèŠ‚ç‚¹ID: {source_node_id}

è¯·é¢„æµ‹æœ€å¤š{max_suggestions}ä¸ªå¯èƒ½çš„è¿æ¥ç›®æ ‡ï¼Œè¿”å›JSONæ ¼å¼:

{{
  "suggestions": [
    {{
      "target_node_type": "start|processor|end",
      "target_node_name": "ç›®æ ‡èŠ‚ç‚¹åç§°",
      "connection_type": "normal|conditional|parallel",
      "confidence": 0.90,
      "reasoning": "å»ºè®®æ­¤è¿æ¥çš„ç†ç”±",
      "condition_config": {{"description": "æ¡ä»¶æè¿°"}}
    }}
  ]
}}

è¦æ±‚:
1. åˆ†ææºèŠ‚ç‚¹ç±»å‹å’Œå½“å‰å·¥ä½œæµé€»è¾‘
2. å»ºè®®åˆç†çš„ç›®æ ‡èŠ‚ç‚¹ç±»å‹
3. ç¡®å®šè¿æ¥ç±»å‹(æ™®é€š/æ¡ä»¶/å¹¶è¡Œ)
4. confidenceè¡¨ç¤ºç½®ä¿¡åº¦(0-1)
5. ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSON"""

    def _build_workflow_completion_prompt(self, context_summary: str, partial_description: str) -> str:
        """æ„å»ºå·¥ä½œæµå®Œæ•´æ€§é¢„æµ‹çš„prompt"""
        return f"""ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµè®¾è®¡åŠ©æ‰‹ã€‚åŸºäºå½“å‰å·¥ä½œæµçŠ¶æ€å’Œéƒ¨åˆ†ä»»åŠ¡æè¿°ï¼Œé¢„æµ‹å®Œæ•´çš„å·¥ä½œæµç»“æ„ã€‚

å½“å‰å·¥ä½œæµçŠ¶æ€:
{context_summary}

ä»»åŠ¡æè¿°(éƒ¨åˆ†):
{partial_description}

è¯·é¢„æµ‹å®Œæ•´çš„å·¥ä½œæµç»“æ„ï¼Œè¿”å›JSONæ ¼å¼:

{{
  "completion_suggestions": [
    {{
      "missing_nodes": [
        {{
          "type": "start|processor|end",
          "name": "èŠ‚ç‚¹åç§°",
          "description": "èŠ‚ç‚¹åŠŸèƒ½æè¿°",
          "priority": "high|medium|low"
        }}
      ],
      "missing_connections": [
        {{
          "from_node": "æºèŠ‚ç‚¹åç§°",
          "to_node": "ç›®æ ‡èŠ‚ç‚¹åç§°",
          "connection_type": "normal|conditional|parallel",
          "priority": "high|medium|low"
        }}
      ],
      "overall_confidence": 0.80,
      "completion_reasoning": "æ•´ä½“å®Œå–„å»ºè®®"
    }}
  ]
}}

è¦æ±‚:
1. åˆ†æå½“å‰å·¥ä½œæµçš„å®Œæ•´æ€§
2. è¯†åˆ«ç¼ºå¤±çš„å…³é”®èŠ‚ç‚¹å’Œè¿æ¥
3. æŒ‰ä¼˜å…ˆçº§æ’åºå»ºè®®
4. ç¡®ä¿å·¥ä½œæµé€»è¾‘åˆç†
5. ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSON"""

    def _parse_node_suggestions(self, ai_response: str) -> List[Dict[str, Any]]:
        """è§£æèŠ‚ç‚¹å»ºè®®å“åº”"""
        try:
            # æ¸…ç†å“åº”æ ¼å¼
            response_text = ai_response.strip()
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]
            response_text = response_text.strip()

            # è§£æJSON
            parsed_response = json.loads(response_text)
            suggestions = parsed_response.get("suggestions", [])

            # éªŒè¯å’Œæ ‡å‡†åŒ–å»ºè®®
            validated_suggestions = []
            for suggestion in suggestions:
                if self._validate_node_suggestion(suggestion):
                    validated_suggestions.append({
                        "id": f"suggested_{uuid.uuid4().hex[:8]}",
                        "type": suggestion.get("type", "processor"),
                        "name": suggestion.get("name", "æœªå‘½åèŠ‚ç‚¹"),
                        "description": suggestion.get("description", ""),
                        "confidence": float(suggestion.get("confidence", 0.5)),
                        "reasoning": suggestion.get("reasoning", "AIå»ºè®®"),
                        "processor_type": suggestion.get("processor_type"),
                        "suggested_position": suggestion.get("suggested_position", {"x": 200, "y": 200})
                    })

            return validated_suggestions

        except json.JSONDecodeError as e:
            logger.error(f"ğŸ”® [PARSE] JSONè§£æå¤±è´¥: {e}")
            logger.error(f"ğŸ”® [PARSE] åŸå§‹å“åº”: {ai_response[:500]}...")
            return []
        except Exception as e:
            logger.error(f"ğŸ”® [PARSE] èŠ‚ç‚¹å»ºè®®è§£æå¤±è´¥: {e}")
            return []

    def _parse_connection_suggestions(self, ai_response: str, source_node_id: str) -> List[Dict[str, Any]]:
        """è§£æè¿æ¥å»ºè®®å“åº”"""
        try:
            # æ¸…ç†å“åº”æ ¼å¼
            response_text = ai_response.strip()
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]
            response_text = response_text.strip()

            # è§£æJSON
            parsed_response = json.loads(response_text)
            suggestions = parsed_response.get("suggestions", [])

            # éªŒè¯å’Œæ ‡å‡†åŒ–å»ºè®®
            validated_suggestions = []
            for suggestion in suggestions:
                if self._validate_connection_suggestion(suggestion):
                    validated_suggestions.append({
                        "id": f"edge_suggested_{uuid.uuid4().hex[:8]}",
                        "source_node_id": source_node_id,
                        "target_node_type": suggestion.get("target_node_type", "processor"),
                        "target_node_name": suggestion.get("target_node_name", "ç›®æ ‡èŠ‚ç‚¹"),
                        "connection_type": suggestion.get("connection_type", "normal"),
                        "confidence": float(suggestion.get("confidence", 0.5)),
                        "reasoning": suggestion.get("reasoning", "AIå»ºè®®"),
                        "condition_config": suggestion.get("condition_config")
                    })

            return validated_suggestions

        except json.JSONDecodeError as e:
            logger.error(f"ğŸ”® [PARSE] JSONè§£æå¤±è´¥: {e}")
            return []
        except Exception as e:
            logger.error(f"ğŸ”® [PARSE] è¿æ¥å»ºè®®è§£æå¤±è´¥: {e}")
            return []

    def _parse_workflow_completion(self, ai_response: str) -> List[Dict[str, Any]]:
        """è§£æå·¥ä½œæµå®Œæ•´æ€§å»ºè®®å“åº”"""
        try:
            # æ¸…ç†å“åº”æ ¼å¼
            response_text = ai_response.strip()
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]
            response_text = response_text.strip()

            # è§£æJSON
            parsed_response = json.loads(response_text)
            suggestions = parsed_response.get("completion_suggestions", [])

            return suggestions

        except json.JSONDecodeError as e:
            logger.error(f"ğŸ”® [PARSE] JSONè§£æå¤±è´¥: {e}")
            return []
        except Exception as e:
            logger.error(f"ğŸ”® [PARSE] å·¥ä½œæµå®Œæ•´æ€§å»ºè®®è§£æå¤±è´¥: {e}")
            return []

    def _validate_node_suggestion(self, suggestion: Dict[str, Any]) -> bool:
        """éªŒè¯èŠ‚ç‚¹å»ºè®®çš„æœ‰æ•ˆæ€§"""
        required_fields = ["type", "name"]
        for field in required_fields:
            if field not in suggestion:
                return False

        # éªŒè¯èŠ‚ç‚¹ç±»å‹
        valid_types = ["start", "processor", "end"]
        if suggestion["type"] not in valid_types:
            return False

        # éªŒè¯ç½®ä¿¡åº¦
        confidence = suggestion.get("confidence", 0)
        if not isinstance(confidence, (int, float)) or confidence < 0 or confidence > 1:
            return False

        return True

    def _validate_connection_suggestion(self, suggestion: Dict[str, Any]) -> bool:
        """éªŒè¯è¿æ¥å»ºè®®çš„æœ‰æ•ˆæ€§"""
        required_fields = ["target_node_type", "connection_type"]
        for field in required_fields:
            if field not in suggestion:
                return False

        # éªŒè¯è¿æ¥ç±»å‹
        valid_connection_types = ["normal", "conditional", "parallel"]
        if suggestion["connection_type"] not in valid_connection_types:
            return False

        return True

    def clear_cache(self):
        """æ¸…ç©ºé¢„æµ‹ç¼“å­˜"""
        self.prediction_cache.clear()
        logger.info("ğŸ”® [CACHE] é¢„æµ‹ç¼“å­˜å·²æ¸…ç©º")


# å…¨å±€é¢„æµ‹æœåŠ¡å®ä¾‹
tab_prediction_service = WorkflowTabPredictionService()