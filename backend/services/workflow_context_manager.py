"""
å·¥ä½œæµä¸Šä¸‹æ–‡ç®¡ç†å™¨
ç»Ÿä¸€ç®¡ç†æ•´ä¸ªå·¥ä½œæµçš„æ‰§è¡Œä¸Šä¸‹æ–‡å’Œæ•°æ®æµ
"""

import uuid
from datetime import datetime
from typing import Dict, List, Any, Set, Optional
import asyncio
import logging
import sys
import json
from loguru import logger
logger.remove()
logger.add(sys.stderr, level="DEBUG", enqueue=True)  # ä¿®å¤Windows GBKç¼–ç é—®é¢˜

# å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
from ..models.instance import WorkflowInstanceStatus, WorkflowInstanceUpdate


def _serialize_for_json(obj):
    """å°†å¯¹è±¡åºåˆ—åŒ–ä¸ºJSONå…¼å®¹æ ¼å¼"""
    if isinstance(obj, uuid.UUID):
        return str(obj)
    elif isinstance(obj, datetime):
        return obj.isoformat()
    elif isinstance(obj, dict):
        # å¤„ç†å­—å…¸æ—¶ï¼Œç¡®ä¿é”®å’Œå€¼éƒ½è¢«åºåˆ—åŒ–
        result = {}
        for key, value in obj.items():
            # åºåˆ—åŒ–é”®ï¼ˆå¦‚æœé”®æ˜¯UUIDï¼‰
            serialized_key = str(key) if isinstance(key, uuid.UUID) else key
            # åºåˆ—åŒ–å€¼
            serialized_value = _serialize_for_json(value)
            result[serialized_key] = serialized_value
        return result
    elif isinstance(obj, (list, tuple, set)):
        return [_serialize_for_json(item) for item in obj]
    else:
        return obj


class WorkflowContextManager:
    """å®è§‚å·¥ä½œæµä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self):
        # å·¥ä½œæµçº§åˆ«çš„å…¨å±€ä¸Šä¸‹æ–‡
        self.workflow_contexts: Dict[uuid.UUID, Dict[str, Any]] = {}
        
        # èŠ‚ç‚¹ä¾èµ–å…³ç³»ç®¡ç†
        self.node_dependencies: Dict[uuid.UUID, Dict[str, Any]] = {}
        
        # èŠ‚ç‚¹å®ŒæˆçŠ¶æ€è¿½è¸ª
        self.node_completion_status: Dict[uuid.UUID, str] = {}
        
        # å¾…è§¦å‘çš„èŠ‚ç‚¹é˜Ÿåˆ—
        self.pending_triggers: Dict[uuid.UUID, Set[uuid.UUID]] = {}
        
        # å›è°ƒå‡½æ•°æ³¨å†Œ
        self.completion_callbacks: List[callable] = []
        
        # ğŸ”’ å¼‚æ­¥é”ç®¡ç†ï¼šä¸ºæ¯ä¸ªå·¥ä½œæµå®ä¾‹ç»´æŠ¤ç‹¬ç«‹çš„é”
        self._workflow_locks: Dict[uuid.UUID, asyncio.Lock] = {}
        self._locks_lock = asyncio.Lock()  # ä¿æŠ¤é”å­—å…¸æœ¬èº«çš„é”
    
    async def _get_workflow_lock(self, workflow_instance_id: uuid.UUID) -> asyncio.Lock:
        """è·å–æˆ–åˆ›å»ºå·¥ä½œæµå®ä¾‹çš„å¼‚æ­¥é”"""
        async with self._locks_lock:
            if workflow_instance_id not in self._workflow_locks:
                self._workflow_locks[workflow_instance_id] = asyncio.Lock()
            return self._workflow_locks[workflow_instance_id]
    
    async def initialize_workflow_context(self, workflow_instance_id: uuid.UUID):
        """åˆå§‹åŒ–å·¥ä½œæµä¸Šä¸‹æ–‡"""
        # è·å–å¼€å§‹èŠ‚ç‚¹çš„ä»»åŠ¡æè¿°ä¿¡æ¯
        start_node_info = await self._get_start_node_task_descriptions(workflow_instance_id)
        
        self.workflow_contexts[workflow_instance_id] = {
            'global_data': {
                'start_node_descriptions': start_node_info  # åŒ…å«å¼€å§‹èŠ‚ç‚¹çš„ä»»åŠ¡æè¿°ä¿¡æ¯
            },
            'node_outputs': {},  # node_base_id -> output_data
            'execution_path': [],  # å·²æ‰§è¡Œçš„èŠ‚ç‚¹è·¯å¾„
            'execution_start_time': datetime.utcnow().isoformat(),
            'current_executing_nodes': set(),
            'completed_nodes': set(),
            'failed_nodes': set()
        }
        
        # åˆå§‹åŒ–å·¥ä½œæµçš„å¾…è§¦å‘é˜Ÿåˆ—
        self.pending_triggers[workflow_instance_id] = set()
        
        logger.trace(f"Initialized workflow context for {workflow_instance_id}")
        logger.trace(f"  - åŒ…å« {len(start_node_info)} ä¸ªå¼€å§‹èŠ‚ç‚¹æè¿°ä¿¡æ¯")
    
    async def _get_start_node_task_descriptions(self, workflow_instance_id: uuid.UUID) -> Dict[str, Any]:
        """è·å–å¼€å§‹èŠ‚ç‚¹çš„ä»»åŠ¡æè¿°ä¿¡æ¯"""
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            
            node_instance_repo = NodeInstanceRepository()
            
            # æŸ¥è¯¢å¼€å§‹èŠ‚ç‚¹åŠå…¶ä»»åŠ¡æè¿°
            query = """
                SELECT ni.node_instance_id, ni.node_id, n.name as node_name,
                       n.task_description, ni.task_description as instance_task_description
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.workflow_instance_id = $1
                AND LOWER(n.type) = 'start'
                AND ni.is_deleted = FALSE
                AND n.is_deleted = FALSE
                ORDER BY ni.created_at ASC
            """
            
            start_nodes = await node_instance_repo.db.fetch_all(query, workflow_instance_id)
            
            start_node_info = {}
            for node in start_nodes:
                node_id = str(node['node_id'])
                node_instance_id = str(node['node_instance_id'])
                
                # ä¼˜å…ˆä½¿ç”¨å®ä¾‹çº§ä»»åŠ¡æè¿°ï¼Œç„¶åæ˜¯èŠ‚ç‚¹çº§ä»»åŠ¡æè¿°
                task_description = (
                    node.get('instance_task_description') or 
                    node.get('task_description') or 
                    f"å¼€å§‹èŠ‚ç‚¹ {node.get('node_name', 'æœªå‘½å')} çš„ä»»åŠ¡"
                )
                logger.trace(f"  - èŠ‚ç‚¹ {node.get('node_name')} çš„ä»»åŠ¡æè¿°: {task_description}")
                
                start_node_info[node_id] = {
                    'node_instance_id': node_instance_id,
                    'node_name': node.get('node_name', 'æœªå‘½å'),
                    'task_description': task_description,
                    'raw_descriptions': {
                        'instance_task_description': node.get('instance_task_description'),
                        'task_description': node.get('task_description')
                    }
                }
                
                logger.trace(f"ğŸ¯ [å¼€å§‹èŠ‚ç‚¹æè¿°] æ”¶é›†èŠ‚ç‚¹ {node.get('node_name')}: {task_description[:50]}...")
            
            return start_node_info
            
        except Exception as e:
            logger.error(f"è·å–å¼€å§‹èŠ‚ç‚¹ä»»åŠ¡æè¿°å¤±è´¥: {e}")
            return {}
    
    async def register_node_dependencies(self, 
                                       node_instance_id: uuid.UUID,
                                       node_id: uuid.UUID,  # æ”¹ä¸ºnode_idå‚æ•°
                                       workflow_instance_id: uuid.UUID, 
                                       upstream_nodes: List[uuid.UUID]):
        """æ³¨å†ŒèŠ‚ç‚¹çš„ä¸€é˜¶ä¾èµ–å…³ç³»"""
        self.node_dependencies[node_instance_id] = {
            'node_id': node_id,  # å­˜å‚¨node_idè€Œä¸æ˜¯node_base_id
            'workflow_instance_id': workflow_instance_id,
            'upstream_nodes': upstream_nodes,
            'completed_upstream': set(),
            'ready_to_execute': len(upstream_nodes) == 0,  # STARTèŠ‚ç‚¹æ— ä¾èµ–
            'dependency_count': len(upstream_nodes)
        }
        
        # åˆå§‹åŒ–èŠ‚ç‚¹çŠ¶æ€
        self.node_completion_status[node_instance_id] = 'PENDING'
        
        logger.trace(f"ğŸ“‹ [ä¾èµ–æ³¨å†Œ] èŠ‚ç‚¹å®ä¾‹ {node_instance_id}:")
        logger.trace(f"  - node_id: {node_id}")
        logger.trace(f"  - ä¸Šæ¸¸ä¾èµ–æ•°é‡: {len(upstream_nodes)}")
        logger.trace(f"  - ä¸Šæ¸¸èŠ‚ç‚¹åˆ—è¡¨: {upstream_nodes}")
        logger.trace(f"  - åˆå§‹çŠ¶æ€: {'Ready' if len(upstream_nodes) == 0 else 'Waiting'}")
        
        # å¦‚æœæ˜¯STARTèŠ‚ç‚¹ï¼ˆæ— ä¾èµ–ï¼‰ï¼Œç«‹å³æ ‡è®°ä¸ºready
        if len(upstream_nodes) == 0:
            logger.trace(f"ğŸš€ [ä¾èµ–æ³¨å†Œ] STARTèŠ‚ç‚¹ {node_instance_id} æ— ä¾èµ–ï¼Œå¯ç«‹å³æ‰§è¡Œ")
    
    def print_dependency_summary(self, workflow_instance_id: uuid.UUID):
        """æ‰“å°ä¾èµ–å…³ç³»æ€»ç»“"""
        logger.trace(f"ğŸ“Š [ä¾èµ–æ€»ç»“] å·¥ä½œæµ {workflow_instance_id} çš„ä¾èµ–å…³ç³»:")
        
        workflow_nodes = [(nid, deps) for nid, deps in self.node_dependencies.items() 
                         if deps['workflow_instance_id'] == workflow_instance_id]
        
        logger.trace(f"  - èŠ‚ç‚¹æ€»æ•°: {len(workflow_nodes)}")
        
        for i, (node_instance_id, deps) in enumerate(workflow_nodes, 1):
            node_id = deps.get('node_id', 'Unknown')
            upstream_count = len(deps['upstream_nodes'])
            completed_count = len(deps['completed_upstream'])
            status = 'Ready' if deps['ready_to_execute'] else 'Waiting'
            
            logger.trace(f"  èŠ‚ç‚¹ {i}: {node_instance_id}")
            logger.trace(f"    - node_id: {node_id}")
            logger.trace(f"    - ä¾èµ–çŠ¶æ€: {status} ({completed_count}/{upstream_count})")
            logger.trace(f"    - ä¸Šæ¸¸èŠ‚ç‚¹: {deps['upstream_nodes']}")
            logger.trace(f"    - å·²å®Œæˆä¸Šæ¸¸: {list(deps['completed_upstream'])}")
        
        logger.trace(f"ğŸ“Š [ä¾èµ–æ€»ç»“] å®Œæˆ")
    
    async def mark_node_completed(self, 
                                workflow_instance_id: uuid.UUID,
                                node_id: uuid.UUID,  # æ”¹ä¸ºnode_idå‚æ•°
                                node_instance_id: uuid.UUID,
                                output_data: Dict[str, Any]):
        """æ ‡è®°èŠ‚ç‚¹å®Œæˆå¹¶æ›´æ–°ä¸Šä¸‹æ–‡ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œé˜²é‡å¤ï¼‰"""
        # ğŸ”’ è·å–å·¥ä½œæµé”ï¼Œç¡®ä¿åŸå­æ€§æ“ä½œ
        workflow_lock = await self._get_workflow_lock(workflow_instance_id)
        
        async with workflow_lock:
            if workflow_instance_id not in self.workflow_contexts:
                logger.warning(f"âš ï¸ [èŠ‚ç‚¹å®Œæˆ] å·¥ä½œæµä¸Šä¸‹æ–‡ä¸å­˜åœ¨ {workflow_instance_id}ï¼Œå¯èƒ½å·²è¢«æ¸…ç†ã€‚èŠ‚ç‚¹ {node_id} ä»ç„¶æ ‡è®°ä¸ºå®Œæˆã€‚")
                # å³ä½¿ä¸Šä¸‹æ–‡ä¸å­˜åœ¨ï¼Œä¹Ÿæ›´æ–°èŠ‚ç‚¹å®ŒæˆçŠ¶æ€
                self.node_completion_status[node_instance_id] = 'COMPLETED'
                return
            
            # åŒé‡æ£€æŸ¥ï¼šæ£€æŸ¥èŠ‚ç‚¹å®ä¾‹çŠ¶æ€å’Œå·¥ä½œæµä¸Šä¸‹æ–‡çŠ¶æ€
            node_instance_already_completed = self.node_completion_status.get(node_instance_id) == 'COMPLETED'
            context = self.workflow_contexts[workflow_instance_id]
            workflow_context_already_completed = node_id in context['completed_nodes']
            
            # å¦‚æœä»»ä½•ä¸€ç§çŠ¶æ€æ˜¾ç¤ºå·²å®Œæˆï¼Œåˆ™è·³è¿‡å¤„ç†
            if node_instance_already_completed or workflow_context_already_completed:
                logger.warning(f"ğŸ”„ [èŠ‚ç‚¹å®Œæˆ-é‡å¤] èŠ‚ç‚¹ {node_id} (å®ä¾‹: {node_instance_id}) å·²ç»å®Œæˆï¼Œè·³è¿‡é‡å¤å¤„ç†")
                logger.trace(f"  - èŠ‚ç‚¹å®ä¾‹çŠ¶æ€å·²å®Œæˆ: {node_instance_already_completed}")
                logger.trace(f"  - å·¥ä½œæµä¸Šä¸‹æ–‡å·²å®Œæˆ: {workflow_context_already_completed}")
                return
            
            # è¿›è¡ŒèŠ‚ç‚¹å®Œæˆå¤„ç†
            logger.trace(f"ğŸ‰ [èŠ‚ç‚¹å®Œæˆ] èŠ‚ç‚¹ {node_id} åœ¨å·¥ä½œæµ {workflow_instance_id} ä¸­å®Œæˆ")
            
            # æ›´æ–°å·¥ä½œæµä¸Šä¸‹æ–‡
            logger.debug(f"ğŸ“Š [èŠ‚ç‚¹å®Œæˆ] å­˜å‚¨èŠ‚ç‚¹è¾“å‡ºæ•°æ®:")
            logger.debug(f"  - node_id: {node_id}")
            logger.debug(f"  - output_dataç±»å‹: {type(output_data)}")
            logger.debug(f"  - output_dataå†…å®¹: {output_data}")
            
            # å…³é”®è°ƒè¯•ä¿¡æ¯
            logger.trace(f"âœ… [ä¸Šä¸‹æ–‡å­˜å‚¨] èŠ‚ç‚¹ {node_id} çš„è¾“å‡ºæ•°æ®å·²å­˜å‚¨åˆ°å·¥ä½œæµä¸Šä¸‹æ–‡:")
            logger.trace(f"  - æ•°æ®ç±»å‹: {type(output_data)}")
            logger.trace(f"  - æ•°æ®å¤§å°: {len(str(output_data))} å­—ç¬¦")
            if isinstance(output_data, dict):
                logger.trace(f"  - å­—å…¸é”®: {list(output_data.keys())}")
            logger.debug(f"  - å®Œæ•´æ•°æ®: {output_data}")
            
            context['node_outputs'][node_id] = output_data
            context['execution_path'].append(str(node_id))  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²é¿å…UUIDåºåˆ—åŒ–é—®é¢˜
            context['completed_nodes'].add(node_id)
            
            # ä»æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹ä¸­ç§»é™¤
            if node_id in context['current_executing_nodes']:
                context['current_executing_nodes'].remove(node_id)
            
            # æ›´æ–°å®ŒæˆçŠ¶æ€
            self.node_completion_status[node_instance_id] = 'COMPLETED'
            
            logger.debug(f"ğŸ“Š [èŠ‚ç‚¹å®Œæˆ] ä¸Šä¸‹æ–‡æ›´æ–°å®Œæˆ:")
            logger.trace(f"  - å·²å®ŒæˆèŠ‚ç‚¹æ•°: {len(context['completed_nodes'])}")
            logger.debug(f"  - æ‰§è¡Œè·¯å¾„: {context['execution_path']}")
            logger.trace(f"  - å·¥ä½œæµä¸Šä¸‹æ–‡ä¸­ç°æœ‰ {len(context['node_outputs'])} ä¸ªèŠ‚ç‚¹è¾“å‡º")
            
            # æ£€æŸ¥å¹¶è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹
            logger.debug(f"ğŸ” [èŠ‚ç‚¹å®Œæˆ] å¼€å§‹æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹è§¦å‘...")
            logger.trace(f"ğŸ”” [ä¸Šä¸‹æ–‡ä¼ é€’] èŠ‚ç‚¹ {node_id} å®Œæˆï¼Œå°†æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹çš„ä¸Šä¸‹æ–‡ä¼ é€’")
            should_check_completion = False
            
            # æ‰“å°å½“å‰ä¾èµ–å…³ç³»çŠ¶æ€
            self.print_dependency_summary(workflow_instance_id)
        
        # ğŸ”“ åœ¨é”å¤–æ‰§è¡Œä¸‹æ¸¸æ£€æŸ¥å’Œå·¥ä½œæµå®Œæˆæ£€æŸ¥ï¼Œé¿å…æ­»é”
        try:
            # åªæœ‰çœŸæ­£æ–°å®Œæˆçš„èŠ‚ç‚¹æ‰æ£€æŸ¥å¹¶è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹
            await self._check_and_trigger_downstream_nodes(
                workflow_instance_id, node_id
            )
            
            # ç«‹å³æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€ï¼Œå‡å°‘å»¶è¿Ÿ
            await self._check_workflow_completion(workflow_instance_id)
        except Exception as e:
            logger.error(f"âŒ [èŠ‚ç‚¹å®Œæˆ] ä¸‹æ¸¸æ£€æŸ¥å¤±è´¥: {e}")
            # å³ä½¿ä¸‹æ¸¸æ£€æŸ¥å¤±è´¥ï¼ŒèŠ‚ç‚¹å®ŒæˆçŠ¶æ€ä¹Ÿå·²ç»æ­£ç¡®æ›´æ–°
    
    async def mark_node_failed(self,
                             workflow_instance_id: uuid.UUID,
                             node_id: uuid.UUID,  # æ”¹ä¸ºnode_idå‚æ•°
                             node_instance_id: uuid.UUID,
                             error_info: Dict[str, Any]):
        """æ ‡è®°èŠ‚ç‚¹å¤±è´¥ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        # ğŸ”’ è·å–å·¥ä½œæµé”ï¼Œç¡®ä¿åŸå­æ€§æ“ä½œ
        workflow_lock = await self._get_workflow_lock(workflow_instance_id)
        
        async with workflow_lock:
            if workflow_instance_id not in self.workflow_contexts:
                logger.warning(f"âš ï¸ [èŠ‚ç‚¹å¤±è´¥] å·¥ä½œæµä¸Šä¸‹æ–‡ä¸å­˜åœ¨ {workflow_instance_id}ï¼ŒèŠ‚ç‚¹ {node_id} ä»æ ‡è®°ä¸ºå¤±è´¥")
                self.node_completion_status[node_instance_id] = 'FAILED'
                return
            
            logger.error(f"âŒ [èŠ‚ç‚¹å¤±è´¥] èŠ‚ç‚¹ {node_id} åœ¨å·¥ä½œæµ {workflow_instance_id} ä¸­å¤±è´¥: {error_info}")
            
            context = self.workflow_contexts[workflow_instance_id]
            context['failed_nodes'].add(node_id)
            
            # ä»æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹ä¸­ç§»é™¤
            if node_id in context['current_executing_nodes']:
                context['current_executing_nodes'].remove(node_id)
            
            # æ›´æ–°å¤±è´¥çŠ¶æ€
            self.node_completion_status[node_instance_id] = 'FAILED'
    
    async def mark_node_executing(self,
                                workflow_instance_id: uuid.UUID,
                                node_id: uuid.UUID,  # æ”¹ä¸ºnode_idå‚æ•°
                                node_instance_id: uuid.UUID):
        """æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        # ğŸ”’ è·å–å·¥ä½œæµé”ï¼Œç¡®ä¿åŸå­æ€§æ“ä½œ
        workflow_lock = await self._get_workflow_lock(workflow_instance_id)
        
        async with workflow_lock:
            if workflow_instance_id not in self.workflow_contexts:
                logger.warning(f"âš ï¸ [èŠ‚ç‚¹æ‰§è¡Œ] å·¥ä½œæµä¸Šä¸‹æ–‡ä¸å­˜åœ¨ {workflow_instance_id}ï¼ŒèŠ‚ç‚¹ {node_id} ä»æ ‡è®°ä¸ºæ‰§è¡Œä¸­")
                self.node_completion_status[node_instance_id] = 'EXECUTING'
                return
            
            logger.trace(f"âš¡ [èŠ‚ç‚¹æ‰§è¡Œ] èŠ‚ç‚¹ {node_id} åœ¨å·¥ä½œæµ {workflow_instance_id} ä¸­å¼€å§‹æ‰§è¡Œ")
            
            context = self.workflow_contexts[workflow_instance_id]
            context['current_executing_nodes'].add(node_id)
            
            self.node_completion_status[node_instance_id] = 'EXECUTING'
    
    async def _check_and_trigger_downstream_nodes(self, 
                                                workflow_instance_id: uuid.UUID,
                                                completed_node_id: uuid.UUID):
        """æ£€æŸ¥å¹¶è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹"""
        # logger.trace(f"ğŸ” [ä¸‹æ¸¸æ£€æŸ¥] æ£€æŸ¥èŠ‚ç‚¹ {completed_node_id} çš„ä¸‹æ¸¸ä¾èµ–...")
        # logger.trace(f"  - å·¥ä½œæµå®ä¾‹: {workflow_instance_id}")
        # logger.trace(f"  - å·²å®Œæˆçš„èŠ‚ç‚¹ID: {completed_node_id}")
        # logger.trace(f"  - å·²å®ŒæˆèŠ‚ç‚¹IDç±»å‹: {type(completed_node_id)}")
        
        triggered_nodes = []
        checked_nodes = 0
        
        # éå†æ‰€æœ‰èŠ‚ç‚¹ä¾èµ–ï¼Œæ‰¾åˆ°ä»¥å½“å‰èŠ‚ç‚¹ä¸ºä¸Šæ¸¸çš„èŠ‚ç‚¹
        logger.trace(f"ğŸ” [ä¸‹æ¸¸æ£€æŸ¥] éå†æ‰€æœ‰å·²æ³¨å†Œçš„èŠ‚ç‚¹ä¾èµ– (æ€»æ•°: {len(self.node_dependencies)}):")
        for node_instance_id, deps in self.node_dependencies.items():
            checked_nodes += 1
            # logger.trace(f"  æ£€æŸ¥èŠ‚ç‚¹ {checked_nodes}/{len(self.node_dependencies)}: {node_instance_id}")
            # logger.trace(f"    - å·¥ä½œæµåŒ¹é…: {deps['workflow_instance_id'] == workflow_instance_id}")
            # logger.trace(f"    - ä¸Šæ¸¸èŠ‚ç‚¹åˆ—è¡¨: {deps['upstream_nodes']}")
            # logger.trace(f"    - ä¸Šæ¸¸èŠ‚ç‚¹ç±»å‹: {[type(x) for x in deps['upstream_nodes']]}")
            # logger.trace(f"    - å®ŒæˆèŠ‚ç‚¹åœ¨ä¸Šæ¸¸ä¸­: {completed_node_id in deps['upstream_nodes']}")
            
            # è¯¦ç»†æ£€æŸ¥æ¯ä¸ªä¸Šæ¸¸èŠ‚ç‚¹
            for i, upstream_node in enumerate(deps['upstream_nodes']):
                is_match = upstream_node == completed_node_id
                logger.trace(f"      ä¸Šæ¸¸èŠ‚ç‚¹{i+1}: {upstream_node} == {completed_node_id} ? {is_match}")
            
            if (deps['workflow_instance_id'] == workflow_instance_id and 
                completed_node_id in deps['upstream_nodes']):
                
                logger.trace(f"  âœ… [ä¸‹æ¸¸æ£€æŸ¥] æ‰¾åˆ°ä¸‹æ¸¸èŠ‚ç‚¹: {node_instance_id}")
                
                # æ ‡è®°è¯¥ä¸Šæ¸¸èŠ‚ç‚¹å·²å®Œæˆ
                deps['completed_upstream'].add(completed_node_id)
                # logger.trace(f"    - å·²å®Œæˆä¸Šæ¸¸: {deps['completed_upstream']}")
                # logger.trace(f"    - éœ€è¦ä¸Šæ¸¸: {deps['upstream_nodes']}")
                # logger.trace(f"    - å®Œæˆè¿›åº¦: {len(deps['completed_upstream'])}/{len(deps['upstream_nodes'])}")
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä¸Šæ¸¸èŠ‚ç‚¹éƒ½å·²å®Œæˆ
                if len(deps['completed_upstream']) == len(deps['upstream_nodes']):
                    logger.trace(f"  âœ… [ä¸‹æ¸¸æ£€æŸ¥] æ‰€æœ‰ä¸Šæ¸¸èŠ‚ç‚¹å·²å®Œæˆï¼Œè®¾ç½®ready_to_execute=True")
                    deps['ready_to_execute'] = True
                    
                    # æ·»åŠ åˆ°å¾…è§¦å‘é˜Ÿåˆ—
                    self.pending_triggers[workflow_instance_id].add(node_instance_id)
                    triggered_nodes.append(node_instance_id)
                    
                    # logger.trace(f"ğŸš€ [ä¸‹æ¸¸æ£€æŸ¥] èŠ‚ç‚¹ {deps['node_id']} å‡†å¤‡æ‰§è¡Œ - æ‰€æœ‰ä¸Šæ¸¸ä¾èµ–å·²å®Œæˆ")
                    # logger.trace(f"    - ready_to_executeæ ‡å¿—å·²è®¾ç½®ä¸º: {deps['ready_to_execute']}")
                else:
                    logger.trace(f"â³ [ä¸‹æ¸¸æ£€æŸ¥] èŠ‚ç‚¹ {deps['node_id']} ä»éœ€ç­‰å¾…æ›´å¤šä¸Šæ¸¸èŠ‚ç‚¹å®Œæˆ")
                    # logger.trace(f"    - éœ€è¦: {len(deps['upstream_nodes'])} ä¸ªä¸Šæ¸¸èŠ‚ç‚¹")
                    # logger.trace(f"    - å·²å®Œæˆ: {len(deps['completed_upstream'])} ä¸ªä¸Šæ¸¸èŠ‚ç‚¹")
        
        # logger.trace(f"ğŸ“Š [ä¸‹æ¸¸æ£€æŸ¥] æ£€æŸ¥å®Œæˆ:")
        # logger.trace(f"  - æ£€æŸ¥çš„èŠ‚ç‚¹æ•°: {checked_nodes}")
        # logger.trace(f"  - è§¦å‘çš„èŠ‚ç‚¹æ•°: {len(triggered_nodes)}")
        # logger.trace(f"  - è§¦å‘çš„èŠ‚ç‚¹åˆ—è¡¨: {triggered_nodes}")
        
        # é€šçŸ¥å›è°ƒå‡½æ•°æœ‰æ–°çš„èŠ‚ç‚¹å‡†å¤‡æ‰§è¡Œ
        if triggered_nodes:
            logger.trace(f"ğŸ”” [ä¸‹æ¸¸æ£€æŸ¥] é€šçŸ¥å›è°ƒå‡½æ•°æœ‰ {len(triggered_nodes)} ä¸ªèŠ‚ç‚¹å‡†å¤‡æ‰§è¡Œ")
            await self._notify_completion_callbacks(workflow_instance_id, triggered_nodes)
        else:
            logger.trace(f"âŒ [ä¸‹æ¸¸æ£€æŸ¥] æ²¡æœ‰æ‰¾åˆ°å¯è§¦å‘çš„ä¸‹æ¸¸èŠ‚ç‚¹")
    
    async def get_ready_nodes(self, workflow_instance_id: uuid.UUID) -> List[uuid.UUID]:
        """è·å–å‡†å¤‡æ‰§è¡Œçš„èŠ‚ç‚¹å®ä¾‹IDåˆ—è¡¨"""
        if workflow_instance_id not in self.pending_triggers:
            return []
        
        ready_nodes = list(self.pending_triggers[workflow_instance_id])
        # æ¸…ç©ºå¾…è§¦å‘é˜Ÿåˆ—
        self.pending_triggers[workflow_instance_id].clear()
        
        return ready_nodes
    
    async def get_node_upstream_context(self, 
                                      workflow_instance_id: uuid.UUID,
                                      node_instance_id: uuid.UUID) -> Dict[str, Any]:
        """è·å–èŠ‚ç‚¹çš„ä¸€é˜¶ä¸Šæ¸¸ä¸Šä¸‹æ–‡æ•°æ®"""
        if node_instance_id not in self.node_dependencies:
            return {'immediate_upstream_results': {}, 'upstream_node_count': 0}
        
        deps = self.node_dependencies[node_instance_id]
        upstream_nodes = deps['upstream_nodes']
        
        # è·å–å·¥ä½œæµä¸Šä¸‹æ–‡
        workflow_context = self.workflow_contexts.get(workflow_instance_id, {})
        node_outputs = workflow_context.get('node_outputs', {})
        
        # æ”¶é›†ä¸€é˜¶ä¸Šæ¸¸èŠ‚ç‚¹çš„è¾“å‡ºæ•°æ®
        upstream_results = {}
        logger.trace(f"ğŸ” [ä¸Šæ¸¸ä¸Šä¸‹æ–‡] æ”¶é›†èŠ‚ç‚¹ {node_instance_id} çš„ä¸Šæ¸¸è¾“å‡º:")
        logger.trace(f"  - ä¸Šæ¸¸èŠ‚ç‚¹åˆ—è¡¨: {upstream_nodes}")
        logger.trace(f"  - å¯ç”¨è¾“å‡ºèŠ‚ç‚¹: {list(node_outputs.keys())}")
        
        for upstream_node_id in upstream_nodes:
            if upstream_node_id in node_outputs:
                output_data = node_outputs[upstream_node_id]
                logger.trace(f"  âœ… æ‰¾åˆ°ä¸Šæ¸¸èŠ‚ç‚¹ {upstream_node_id} è¾“å‡º:")
                logger.trace(f"     - è¾“å‡ºæ•°æ®ç±»å‹: {type(output_data)}")
                logger.trace(f"     - è¾“å‡ºæ•°æ®å†…å®¹: {output_data}")
                upstream_results[str(upstream_node_id)] = output_data
            else:
                logger.warning(f"  âŒ ä¸Šæ¸¸èŠ‚ç‚¹ {upstream_node_id} è¾“å‡ºæœªæ‰¾åˆ°")
        
        return {
            'immediate_upstream_results': upstream_results,
            'upstream_node_count': len(upstream_nodes),
            'workflow_global': {
                'execution_path': workflow_context.get('execution_path', []),
                'global_data': workflow_context.get('global_data', {}),
                'execution_start_time': workflow_context.get('execution_start_time')
            }
        }
    
    async def get_task_context_data(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡æ‰§è¡Œæ‰€éœ€çš„å®Œæ•´ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆå…¼å®¹ExecutionServiceæ ¼å¼ï¼‰"""
        try:
            logger.debug(f"ğŸ” [ä¸Šä¸‹æ–‡æ”¶é›†-DEBUG] å¼€å§‹ä¸ºèŠ‚ç‚¹ {node_instance_id} æ”¶é›†ä¸Šä¸‹æ–‡")
            logger.debug(f"  - workflow_instance_id: {workflow_instance_id}")
            logger.debug(f"  - èŠ‚ç‚¹ä¾èµ–å­—å…¸ä¸­æ˜¯å¦å­˜åœ¨: {node_instance_id in self.node_dependencies}")
            logger.debug(f"  - å·¥ä½œæµä¸Šä¸‹æ–‡ä¸­æ˜¯å¦å­˜åœ¨: {workflow_instance_id in self.workflow_contexts}")
            
            if workflow_instance_id in self.workflow_contexts:
                workflow_context = self.workflow_contexts[workflow_instance_id]
                node_outputs = workflow_context.get('node_outputs', {})
                logger.debug(f"  - å·¥ä½œæµå·²æœ‰è¾“å‡ºçš„èŠ‚ç‚¹æ•°é‡: {len(node_outputs)}")
                logger.debug(f"  - å·¥ä½œæµå·²æœ‰è¾“å‡ºçš„èŠ‚ç‚¹ID: {list(node_outputs.keys())}")
            
            context_data = {}
            
            # 1. è·å–å·¥ä½œæµä¿¡æ¯
            if workflow_instance_id in self.workflow_contexts:
                workflow_context = self.workflow_contexts[workflow_instance_id]
                
                # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
                from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
                workflow_repo = WorkflowInstanceRepository()
                workflow_instance = await workflow_repo.get_instance_by_id(workflow_instance_id)
                
                if workflow_instance:
                    created_at = workflow_instance.get('created_at')
                    context_data['workflow'] = {
                        'name': workflow_instance.get('workflow_name'),
                        'instance_name': workflow_instance.get('instance_name'), 
                        'status': workflow_instance.get('status'),
                        'input_data': workflow_instance.get('input_data', {}),
                        'created_at': created_at.isoformat() if hasattr(created_at, 'isoformat') else str(created_at),
                        'start_node_descriptions': workflow_context.get('global_data', {}).get('start_node_descriptions', {})
                    }
            
            # 2. è·å–ä¸Šæ¸¸èŠ‚ç‚¹è¾“å‡ºæ•°æ®
            if node_instance_id in self.node_dependencies:
                deps = self.node_dependencies[node_instance_id] 
                upstream_nodes = deps['upstream_nodes']
                workflow_context = self.workflow_contexts.get(workflow_instance_id, {})
                node_outputs = workflow_context.get('node_outputs', {})
                
                logger.trace(f"ğŸ” [ä¸Šä¸‹æ–‡æ”¶é›†] èŠ‚ç‚¹ {node_instance_id} çš„ä¸Šæ¸¸ä¾èµ–åˆ†æ:")
                logger.trace(f"  - ä¸Šæ¸¸èŠ‚ç‚¹æ•°é‡: {len(upstream_nodes)}")
                logger.trace(f"  - ä¸Šæ¸¸èŠ‚ç‚¹IDåˆ—è¡¨: {upstream_nodes}")
                logger.trace(f"  - å·¥ä½œæµå·²æœ‰è¾“å‡ºçš„èŠ‚ç‚¹: {list(node_outputs.keys())}")
                
                # ä»å†…å­˜ä¸­çš„èŠ‚ç‚¹è¾“å‡ºæ„å»ºä¸Šæ¸¸è¾“å‡ºåˆ—è¡¨
                upstream_outputs = []
                for upstream_node_id in upstream_nodes:
                    if upstream_node_id in node_outputs:
                        # è·å–èŠ‚ç‚¹åç§°ï¼ˆéœ€è¦æŸ¥è¯¢æ•°æ®åº“è·å–èŠ‚ç‚¹ä¿¡æ¯ï¼‰
                        node_name = await self._get_node_name_by_id(upstream_node_id)
                        output_data = node_outputs[upstream_node_id]
                        
                        logger.trace(f"  âœ… æ‰¾åˆ°ä¸Šæ¸¸èŠ‚ç‚¹è¾“å‡º: {node_name} ({upstream_node_id})")
                        logger.trace(f"     è¾“å‡ºæ•°æ®: {str(output_data)[:200]}...")
                        
                        upstream_outputs.append({
                            'node_name': node_name or f'Node_{str(upstream_node_id)[:8]}',
                            'node_instance_id': str(upstream_node_id),
                            'output_data': output_data,
                            'completed_at': None,  # æš‚æ—¶ä¸æä¾›å®Œæˆæ—¶é—´
                            'task_count': 1  # ç®€åŒ–å¤„ç†
                        })
                    else:
                        logger.warning(f"  âš ï¸ ä¸Šæ¸¸èŠ‚ç‚¹ {upstream_node_id} çš„è¾“å‡ºæ•°æ®æœªæ‰¾åˆ°")
                
                context_data['upstream_outputs'] = upstream_outputs
                logger.trace(f"  ğŸ“‹ æœ€ç»ˆä¸Šæ¸¸è¾“å‡ºæ•°é‡: {len(upstream_outputs)}")
            else:
                logger.warning(f"âš ï¸ [ä¸Šä¸‹æ–‡æ”¶é›†] èŠ‚ç‚¹ {node_instance_id} ä¸åœ¨ä¾èµ–å­—å…¸ä¸­")
                context_data['upstream_outputs'] = []
            
            # 3. è·å–å½“å‰èŠ‚ç‚¹ä¿¡æ¯
            if node_instance_id in self.node_dependencies:
                current_node_name = await self._get_node_name_by_instance_id(node_instance_id)
                current_node_type = await self._get_node_type_by_instance_id(node_instance_id)
                
                context_data['current_node'] = {
                    'name': current_node_name or 'Unknown',
                    'type': current_node_type or 'unknown',
                    'description': None,
                    'input_data': {},
                    'status': 'pending'
                }
            
            # 4. æ·»åŠ æ—¶é—´æˆ³
            from datetime import datetime
            context_data['context_generated_at'] = datetime.utcnow().isoformat()
            
            logger.trace(f"WorkflowContextManagerä¸ºèŠ‚ç‚¹ {node_instance_id} æ”¶é›†ä¸Šä¸‹æ–‡æ•°æ®: {len(context_data)} ä¸ªé¡¶çº§å­—æ®µ")
            return context_data
            
        except Exception as e:
            logger.error(f"WorkflowContextManageræ”¶é›†ä»»åŠ¡ä¸Šä¸‹æ–‡æ•°æ®å¤±è´¥: {e}")
            return {}
    
    async def _get_node_name_by_id(self, node_id: uuid.UUID) -> str:
        """æ ¹æ®node_idè·å–èŠ‚ç‚¹åç§°"""
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            from ..repositories.node.node_repository import NodeRepository
            node_repo = NodeRepository()
            
            # æŸ¥è¯¢èŠ‚ç‚¹ä¿¡æ¯
            query = "SELECT name FROM node WHERE node_id = $1"
            result = await node_repo.db.fetch_one(query, node_id)
            return result['name'] if result else None
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹åç§°å¤±è´¥: {e}")
            return None
    
    async def _get_node_name_by_instance_id(self, node_instance_id: uuid.UUID) -> str:
        """æ ¹æ®node_instance_idè·å–èŠ‚ç‚¹åç§°"""
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_repo = NodeInstanceRepository()
            
            query = """
            SELECT n.name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id  
            WHERE ni.node_instance_id = $1
            """
            result = await node_repo.db.fetch_one(query, node_instance_id)
            return result['name'] if result else None
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹å®ä¾‹åç§°å¤±è´¥: {e}")
            return None
    
    async def _get_node_type_by_instance_id(self, node_instance_id: uuid.UUID) -> str:
        """æ ¹æ®node_instance_idè·å–èŠ‚ç‚¹ç±»å‹"""
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_repo = NodeInstanceRepository()
            
            query = """
            SELECT n.type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.node_instance_id = $1
            """
            result = await node_repo.db.fetch_one(query, node_instance_id)
            return result['type'] if result else None
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹å®ä¾‹ç±»å‹å¤±è´¥: {e}")
            return None
    
    async def get_workflow_status(self, workflow_instance_id: uuid.UUID) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµæ•´ä½“çŠ¶æ€"""
        if workflow_instance_id not in self.workflow_contexts:
            return {'status': 'NOT_FOUND'}
        
        context = self.workflow_contexts[workflow_instance_id]
        
        # ç»Ÿè®¡èŠ‚ç‚¹çŠ¶æ€ - åªç»Ÿè®¡å½“å‰å·¥ä½œæµçš„èŠ‚ç‚¹
        workflow_nodes = [nid for nid, deps in self.node_dependencies.items() 
                         if deps['workflow_instance_id'] == workflow_instance_id]
        total_nodes = len(workflow_nodes)
        completed_nodes = len(context['completed_nodes'])
        failed_nodes = len(context['failed_nodes'])
        executing_nodes = len(context['current_executing_nodes'])
        pending_nodes = total_nodes - completed_nodes - failed_nodes - executing_nodes
        
        # ğŸ” è°ƒè¯•ï¼šæ‰“å°è¯¦ç»†çš„èŠ‚ç‚¹ä¿¡æ¯
        # logger.trace(f"ğŸ” [çŠ¶æ€è°ƒè¯•] å·¥ä½œæµ {workflow_instance_id} èŠ‚ç‚¹ç»Ÿè®¡:")
        # logger.trace(f"   - æ³¨å†Œçš„ä¾èµ–èŠ‚ç‚¹æ•°: {len(self.node_dependencies)}")
        # logger.trace(f"   - å½“å‰å·¥ä½œæµèŠ‚ç‚¹æ•°: {total_nodes}")
        # logger.trace(f"   - å·¥ä½œæµèŠ‚ç‚¹IDs: {workflow_nodes}")
        # logger.trace(f"   - å·²å®ŒæˆèŠ‚ç‚¹: {list(context['completed_nodes'])}")
        # logger.trace(f"   - æ‰§è¡Œä¸­èŠ‚ç‚¹: {list(context['current_executing_nodes'])}")
        # logger.trace(f"   - å¤±è´¥èŠ‚ç‚¹: {list(context['failed_nodes'])}")
        
        # åˆ¤æ–­å·¥ä½œæµæ•´ä½“çŠ¶æ€
        if failed_nodes > 0:
            overall_status = 'FAILED'
        elif completed_nodes == total_nodes and total_nodes > 0:
            # é¢å¤–éªŒè¯ï¼šæ£€æŸ¥æ•°æ®åº“ä¸­çš„å®é™…èŠ‚ç‚¹çŠ¶æ€ï¼Œé˜²æ­¢è¯¯åˆ¤
            overall_status = await self._verify_workflow_completion(workflow_instance_id, total_nodes, completed_nodes)
        elif executing_nodes > 0 or pending_nodes > 0:
            overall_status = 'RUNNING'
        else:
            overall_status = 'UNKNOWN'
        
        return {
            'status': overall_status,
            'total_nodes': total_nodes,
            'completed_nodes': completed_nodes,
            'failed_nodes': failed_nodes,
            'executing_nodes': executing_nodes,
            'pending_nodes': pending_nodes,
            'execution_path': context['execution_path'],
            'execution_start_time': context['execution_start_time']
        }
    
    async def _verify_workflow_completion(self, workflow_instance_id: uuid.UUID, 
                                        expected_total: int, context_completed: int) -> str:
        """éªŒè¯å·¥ä½œæµå®ŒæˆçŠ¶æ€ï¼Œé€šè¿‡æ•°æ®åº“æ ¸å®"""
        try:
            logger.trace(f"ğŸ” [å®ŒæˆéªŒè¯] éªŒè¯å·¥ä½œæµ {workflow_instance_id} å®ŒæˆçŠ¶æ€:")
            logger.trace(f"   - é¢„æœŸæ€»èŠ‚ç‚¹æ•°: {expected_total}")
            logger.trace(f"   - ä¸Šä¸‹æ–‡å·²å®Œæˆ: {context_completed}")
            
            # ä»æ•°æ®åº“æŸ¥è¯¢å®é™…çš„èŠ‚ç‚¹çŠ¶æ€
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_repo = NodeInstanceRepository()
            
            # æŸ¥è¯¢å·¥ä½œæµçš„æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹
            query = """
            SELECT ni.node_instance_id, ni.status, ni.node_instance_name as node_name
            FROM node_instance ni
            WHERE ni.workflow_instance_id = $1 AND ni.is_deleted = FALSE
            ORDER BY ni.created_at
            """
            
            db_nodes = await node_repo.db.fetch_all(query, workflow_instance_id)
            
            logger.trace(f"   - æ•°æ®åº“å®é™…èŠ‚ç‚¹æ•°: {len(db_nodes)}")
            
            # ç»Ÿè®¡æ•°æ®åº“ä¸­çš„èŠ‚ç‚¹çŠ¶æ€
            db_completed = 0
            db_pending = 0
            db_running = 0
            
            for node in db_nodes:
                status = node['status']
                logger.trace(f"     - {node.get('node_name', 'Unknown')}: {status}")
                
                if status == 'completed':
                    db_completed += 1
                elif status in ['pending', 'assigned']:
                    db_pending += 1
                elif status in ['running', 'in_progress']:
                    db_running += 1
            
            logger.trace(f"   - æ•°æ®åº“ç»Ÿè®¡: å®Œæˆ={db_completed}, å¾…å¤„ç†={db_pending}, æ‰§è¡Œä¸­={db_running}")
            
            # åˆ¤æ–­æ˜¯å¦çœŸæ­£å®Œæˆ
            if len(db_nodes) != expected_total:
                logger.warning(f"âš ï¸ [å®ŒæˆéªŒè¯] èŠ‚ç‚¹æ•°é‡ä¸åŒ¹é…: é¢„æœŸ{expected_total}, å®é™…{len(db_nodes)}")
                return 'RUNNING'  # èŠ‚ç‚¹æ•°é‡ä¸åŒ¹é…ï¼Œç»§ç»­è¿è¡Œ
            
            if db_completed == len(db_nodes) and len(db_nodes) > 0:
                logger.trace(f"âœ… [å®ŒæˆéªŒè¯] å·¥ä½œæµç¡®å®å·²å®Œæˆ: {db_completed}/{len(db_nodes)} èŠ‚ç‚¹å®Œæˆ")
                return 'COMPLETED'
            else:
                logger.trace(f"â³ [å®ŒæˆéªŒè¯] å·¥ä½œæµä»åœ¨è¿è¡Œ: {db_completed}/{len(db_nodes)} èŠ‚ç‚¹å®Œæˆ, {db_pending} å¾…å¤„ç†, {db_running} æ‰§è¡Œä¸­")
                return 'RUNNING'
                
        except Exception as e:
            logger.error(f"âŒ [å®ŒæˆéªŒè¯] éªŒè¯å¤±è´¥: {e}")
            # éªŒè¯å¤±è´¥æ—¶ä¿å®ˆå¤„ç†ï¼Œç»§ç»­è¿è¡Œ
            return 'RUNNING'
    
    def register_completion_callback(self, callback: callable):
        """æ³¨å†ŒèŠ‚ç‚¹å®Œæˆå›è°ƒå‡½æ•°"""
        self.completion_callbacks.append(callback)
    
    async def _notify_completion_callbacks(self, 
                                         workflow_instance_id: uuid.UUID,
                                         triggered_nodes: List[uuid.UUID]):
        """é€šçŸ¥å›è°ƒå‡½æ•°æœ‰æ–°èŠ‚ç‚¹å‡†å¤‡æ‰§è¡Œ"""
        for callback in self.completion_callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(workflow_instance_id, triggered_nodes)
                else:
                    callback(workflow_instance_id, triggered_nodes)
            except Exception as e:
                logger.error(f"Error in completion callback: {e}")
    
    
    def get_node_dependency_info(self, node_instance_id: uuid.UUID) -> Optional[Dict[str, Any]]:
        """è·å–èŠ‚ç‚¹çš„ä¾èµ–ä¿¡æ¯"""
        return self.node_dependencies.get(node_instance_id)
    
    def is_node_ready_to_execute(self, node_instance_id: uuid.UUID) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å‡†å¤‡å¥½æ‰§è¡Œ"""
        deps = self.node_dependencies.get(node_instance_id)
        
        logger.trace(f"ğŸ” [å°±ç»ªæ£€æŸ¥] æ£€æŸ¥èŠ‚ç‚¹ {node_instance_id} æ˜¯å¦å‡†å¤‡æ‰§è¡Œ:")
        if deps is None:
            logger.trace(f"  âŒ èŠ‚ç‚¹ä¾èµ–ä¿¡æ¯ä¸å­˜åœ¨")
            return False
        
        ready_flag = deps.get('ready_to_execute', False)
        upstream_nodes = deps.get('upstream_nodes', [])
        completed_upstream = deps.get('completed_upstream', set())
        
        logger.trace(f"  - ä¸Šæ¸¸èŠ‚ç‚¹æ•°: {len(upstream_nodes)}")
        logger.trace(f"  - å·²å®Œæˆä¸Šæ¸¸: {len(completed_upstream)}")
        logger.trace(f"  - ready_to_executeæ ‡å¿—: {ready_flag}")
        logger.trace(f"  - ä¸Šæ¸¸èŠ‚ç‚¹åˆ—è¡¨: {upstream_nodes}")
        logger.trace(f"  - å·²å®Œæˆåˆ—è¡¨: {list(completed_upstream)}")
        
        result = deps is not None and ready_flag
        logger.trace(f"  â¡ï¸ æœ€ç»ˆç»“æœ: {result}")
        return result
    
    async def _check_workflow_completion(self, workflow_instance_id: uuid.UUID):
        """æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å®Œæˆå¹¶æ›´æ–°æ•°æ®åº“çŠ¶æ€"""
        try:
            if workflow_instance_id not in self.workflow_contexts:
                return
            
            # è·å–å·¥ä½œæµçŠ¶æ€
            status_info = await self.get_workflow_status(workflow_instance_id)
            current_status = status_info.get('status')
            
            # logger.trace(f"ğŸ” [å·¥ä½œæµçŠ¶æ€æ£€æŸ¥] å·¥ä½œæµ {workflow_instance_id}:")
            # logger.trace(f"   - å½“å‰çŠ¶æ€: {current_status}")
            # logger.trace(f"   - æ€»èŠ‚ç‚¹æ•°: {status_info.get('total_nodes', 0)}")
            # logger.trace(f"   - å·²å®ŒæˆèŠ‚ç‚¹: {status_info.get('completed_nodes', 0)}")
            # logger.trace(f"   - å¤±è´¥èŠ‚ç‚¹: {status_info.get('failed_nodes', 0)}")
            # logger.trace(f"   - æ‰§è¡Œä¸­èŠ‚ç‚¹: {status_info.get('executing_nodes', 0)}")
            # logger.trace(f"   - å¾…å¤„ç†èŠ‚ç‚¹: {status_info.get('pending_nodes', 0)}")
            
            # æ˜¾ç¤ºè¯¦ç»†çš„èŠ‚ç‚¹çŠ¶æ€
            if workflow_instance_id in self.workflow_contexts:
                context = self.workflow_contexts[workflow_instance_id]
                # logger.trace(f"   - å·²å®ŒæˆèŠ‚ç‚¹åˆ—è¡¨: {list(context['completed_nodes'])}")
                # logger.trace(f"   - æ‰§è¡Œä¸­èŠ‚ç‚¹åˆ—è¡¨: {list(context['current_executing_nodes'])}")
                # logger.trace(f"   - å¤±è´¥èŠ‚ç‚¹åˆ—è¡¨: {list(context['failed_nodes'])}")
            
            # å¦‚æœå·¥ä½œæµå·²å®Œæˆæˆ–å¤±è´¥ï¼Œæ›´æ–°æ•°æ®åº“çŠ¶æ€
            if current_status in ['COMPLETED', 'FAILED']:
                logger.trace(f"ğŸ¯ [å·¥ä½œæµçŠ¶æ€æ£€æŸ¥] å·¥ä½œæµ {workflow_instance_id} éœ€è¦æ›´æ–°çŠ¶æ€ä¸º: {current_status}")
                
                # å»¶è¿Ÿå¯¼å…¥å·¥ä½œæµå®ä¾‹ä»“åº“é¿å…å¾ªç¯ä¾èµ–
                from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
                workflow_repo = WorkflowInstanceRepository()
                
                # å‡†å¤‡è¾“å‡ºæ•°æ®ï¼ˆåºåˆ—åŒ–UUIDç­‰å¯¹è±¡ï¼‰
                context = self.workflow_contexts[workflow_instance_id]
                raw_output_data = {
                    'completion_time': datetime.utcnow().isoformat(),
                    'node_outputs': context.get('node_outputs', {}),
                    'execution_path': context.get('execution_path', []),
                    'total_nodes': status_info.get('total_nodes', 0),
                    'completed_nodes': status_info.get('completed_nodes', 0),
                    'failed_nodes': status_info.get('failed_nodes', 0)
                }
                
                # åºåˆ—åŒ–UUIDå¯¹è±¡ä¸ºå­—ç¬¦ä¸²
                output_data = _serialize_for_json(raw_output_data)
                
                # æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€
                if current_status == 'COMPLETED':
                    update_data = WorkflowInstanceUpdate(
                        status=WorkflowInstanceStatus.COMPLETED,
                        output_data=output_data
                    )
                    logger.trace(f"âœ… [å·¥ä½œæµçŠ¶æ€æ£€æŸ¥] æ ‡è®°å·¥ä½œæµ {workflow_instance_id} ä¸ºå·²å®Œæˆ")
                else:  # FAILED
                    update_data = WorkflowInstanceUpdate(
                        status=WorkflowInstanceStatus.FAILED,
                        output_data=output_data,
                        error_message="å·¥ä½œæµä¸­æœ‰èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥"
                    )
                    logger.error(f"âŒ [å·¥ä½œæµçŠ¶æ€æ£€æŸ¥] æ ‡è®°å·¥ä½œæµ {workflow_instance_id} ä¸ºå¤±è´¥")
                
                # æ›´æ–°æ•°æ®åº“
                await workflow_repo.update_instance(workflow_instance_id, update_data)
                
                # ğŸ•’ å»¶è¿Ÿæ¸…ç†å·¥ä½œæµä¸Šä¸‹æ–‡ï¼Œç­‰å¾…å¼‚æ­¥ä»»åŠ¡å®Œæˆ
                # å¯¹äºCOMPLETEDçŠ¶æ€ï¼Œå¯ä»¥ç«‹å³æ¸…ç†ï¼›å¯¹äºFAILEDçŠ¶æ€ï¼Œéœ€è¦å»¶è¿Ÿæ¸…ç†ç­‰å¾…å¼‚æ­¥ä»»åŠ¡å®Œæˆ
                if current_status == 'COMPLETED':
                    await self.cleanup_workflow_context(workflow_instance_id)
                else:
                    await self._delayed_cleanup_workflow_context(workflow_instance_id)
                
            else:
                logger.trace(f"â³ [å·¥ä½œæµçŠ¶æ€æ£€æŸ¥] å·¥ä½œæµ {workflow_instance_id} ä»åœ¨è¿è¡Œä¸­")
                
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _delayed_cleanup_workflow_context(self, workflow_instance_id: uuid.UUID, delay_seconds: int = 3):
        """å»¶è¿Ÿæ¸…ç†å·¥ä½œæµä¸Šä¸‹æ–‡ï¼Œç­‰å¾…å¼‚æ­¥ä»»åŠ¡å®Œæˆ"""
        logger.trace(f"ğŸ•’ [å»¶è¿Ÿæ¸…ç†] å°†åœ¨ {delay_seconds} ç§’åæ¸…ç†å·¥ä½œæµä¸Šä¸‹æ–‡ {workflow_instance_id}")
        
        # è¾ƒçŸ­çš„å»¶è¿Ÿï¼Œé¿å…é˜»å¡æ­£å¸¸æ“ä½œ
        await asyncio.sleep(delay_seconds)
        
        # æ™ºèƒ½æ£€æŸ¥ï¼šå¦‚æœè¿˜æœ‰æœªå®Œæˆçš„èŠ‚ç‚¹ç›‘å¬å™¨ï¼Œå†ç­‰å¾…ä¸€æ¬¡
        max_retries = 2
        for attempt in range(max_retries):
            if workflow_instance_id in self.workflow_contexts:
                context = self.workflow_contexts[workflow_instance_id]
                executing_nodes = context.get('current_executing_nodes', set())
                
                if executing_nodes and attempt < max_retries - 1:
                    logger.warning(f"âš ï¸ [å»¶è¿Ÿæ¸…ç†] ä»æœ‰èŠ‚ç‚¹åœ¨æ‰§è¡Œ: {executing_nodes}ï¼Œå†ç­‰å¾… {delay_seconds} ç§’ (å°è¯• {attempt + 1}/{max_retries})")
                    await asyncio.sleep(delay_seconds)
                    continue
                elif executing_nodes:
                    logger.warning(f"âš ï¸ [å»¶è¿Ÿæ¸…ç†] å¼ºåˆ¶æ¸…ç†ï¼Œå¿½ç•¥ä»åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹: {executing_nodes}")
                break
            else:
                logger.trace(f"ğŸ“‹ [å»¶è¿Ÿæ¸…ç†] å·¥ä½œæµä¸Šä¸‹æ–‡å·²è¢«æ¸…ç†")
                return
        
        # æ‰§è¡Œæ¸…ç†
        await self.cleanup_workflow_context(workflow_instance_id)
        logger.trace(f"âœ… [å»¶è¿Ÿæ¸…ç†] å·¥ä½œæµä¸Šä¸‹æ–‡ {workflow_instance_id} æ¸…ç†å®Œæˆ")
    
    async def cleanup_workflow_context(self, workflow_instance_id: uuid.UUID):
        """æ¸…ç†å·¥ä½œæµä¸Šä¸‹æ–‡ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        try:
            # ğŸ”’ ä½¿ç”¨é”ç¡®ä¿æ¸…ç†è¿‡ç¨‹çš„åŸå­æ€§
            workflow_lock = await self._get_workflow_lock(workflow_instance_id)
            
            async with workflow_lock:
                # åˆ é™¤å·¥ä½œæµä¸Šä¸‹æ–‡
                if workflow_instance_id in self.workflow_contexts:
                    del self.workflow_contexts[workflow_instance_id]
                
                # åˆ é™¤å¾…è§¦å‘èŠ‚ç‚¹é˜Ÿåˆ—
                if workflow_instance_id in self.pending_triggers:
                    del self.pending_triggers[workflow_instance_id]
                
                # åˆ é™¤ç›¸å…³çš„èŠ‚ç‚¹ä¾èµ–ä¿¡æ¯
                to_remove = []
                for node_instance_id, deps in self.node_dependencies.items():
                    if deps['workflow_instance_id'] == workflow_instance_id:
                        to_remove.append(node_instance_id)
                
                for node_instance_id in to_remove:
                    del self.node_dependencies[node_instance_id]
                    if node_instance_id in self.node_completion_status:
                        del self.node_completion_status[node_instance_id]
            
            # ğŸ”“ åœ¨é”å¤–æ¸…ç†é”æœ¬èº«ï¼Œé¿å…æ­»é”
            async with self._locks_lock:
                if workflow_instance_id in self._workflow_locks:
                    del self._workflow_locks[workflow_instance_id]
            
            logger.trace(f"Cleaned up workflow context for {workflow_instance_id}")
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†å·¥ä½œæµä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            # å³ä½¿æ¸…ç†å¤±è´¥ï¼Œä¹Ÿå°è¯•å¼ºåˆ¶æ¸…ç†å…³é”®æ•°æ®
            try:
                if workflow_instance_id in self.workflow_contexts:
                    del self.workflow_contexts[workflow_instance_id]
                logger.warning(f"âš ï¸ å¼ºåˆ¶æ¸…ç†å·¥ä½œæµä¸Šä¸‹æ–‡: {workflow_instance_id}")
            except:
                pass