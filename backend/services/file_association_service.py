"""
æ–‡ä»¶å…³è”ç®¡ç†æœåŠ¡
File Association Management Service
"""

import uuid
from typing import Optional, List, Dict, Any
from datetime import datetime
from loguru import logger

from ..repositories.base import BaseRepository
from ..utils.database import get_db_manager
from ..models.file_attachment import (
    WorkflowFile, WorkflowFileCreate, WorkflowFileResponse,
    UserFile, UserFileCreate, UserFileResponse,
    NodeFile, NodeFileCreate, NodeFileResponse,
    NodeInstanceFile, NodeInstanceFileCreate, NodeInstanceFileResponse,
    TaskInstanceFile, TaskInstanceFileCreate, TaskInstanceFileResponse,
    AttachmentType, AccessType, FileBatchResponse
)
from ..utils.helpers import now_utc


class FileAssociationService:
    """æ–‡ä»¶å…³è”ç®¡ç†æœåŠ¡ - Linuså¼ç»Ÿä¸€è®¾è®¡"""
    
    def __init__(self):
        self.db = get_db_manager()
    
    def _process_datetime_fields(self, records: List[Any]) -> List[Dict[str, Any]]:
        """å¤„ç†æ•°æ®åº“è®°å½•ä¸­çš„datetimeå­—æ®µ - Linuså¼ç»Ÿä¸€å¤„ç†"""
        processed_records = []
        for record in records:
            record_dict = dict(record)
            # è½¬æ¢datetimeå­—æ®µä¸ºå­—ç¬¦ä¸²
            for key, value in record_dict.items():
                if isinstance(value, datetime):
                    record_dict[key] = value.isoformat() if value else None
            processed_records.append(record_dict)
        return processed_records
    
    # ==================== å·¥ä½œæµæ–‡ä»¶æ ¸å¿ƒç®¡ç† ====================
    
    async def create_workflow_file(self, file_data: WorkflowFileCreate) -> Optional[Dict[str, Any]]:
        """åˆ›å»ºå·¥ä½œæµæ–‡ä»¶è®°å½•"""
        try:
            # ç”ŸæˆUUIDä½œä¸ºfile_id
            file_id = str(uuid.uuid4())
            
            # MySQLå…¼å®¹çš„INSERTè¯­å¥
            insert_query = """
                INSERT INTO workflow_file (
                    file_id, filename, original_filename, file_path, file_size, 
                    content_type, file_hash, uploaded_by, created_at, updated_at
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, NOW(), NOW())
            """
            
            # æ‰§è¡Œæ’å…¥
            await self.db.execute(insert_query, 
                file_id,
                file_data.filename,
                file_data.original_filename,
                file_data.file_path,
                file_data.file_size,
                file_data.content_type,
                file_data.file_hash,
                file_data.uploaded_by
            )
            
            # æŸ¥è¯¢åˆšæ’å…¥çš„è®°å½•
            select_query = """
                SELECT file_id, filename, original_filename, file_path, file_size,
                       content_type, file_hash, uploaded_by, created_at, updated_at
                FROM workflow_file 
                WHERE file_id = $1
            """
            
            result = await self.db.fetch_one(select_query, file_id)
            
            if result:
                logger.info(f"åˆ›å»ºå·¥ä½œæµæ–‡ä»¶è®°å½•æˆåŠŸ: {file_data.filename}")
                return dict(result)
            return None
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå·¥ä½œæµæ–‡ä»¶è®°å½•å¤±è´¥: {e}")
            return None
    
    async def get_workflow_file_by_id(self, file_id: uuid.UUID) -> Optional[Dict[str, Any]]:
        """æ ¹æ®IDè·å–å·¥ä½œæµæ–‡ä»¶"""
        try:
            query = """
                SELECT wf.*, u.username as uploaded_by_name
                FROM workflow_file wf
                LEFT JOIN user u ON wf.uploaded_by = u.user_id
                WHERE wf.file_id = $1 AND wf.is_deleted = FALSE
            """
            
            result = await self.db.fetch_one(query, file_id)
            if result:
                # å¤„ç†å•ä¸ªè®°å½•çš„datetimeå­—æ®µ
                processed_result = self._process_datetime_fields([result])
                return processed_result[0] if processed_result else None
            return None
            
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµæ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    async def get_workflow_file_by_hash(self, file_hash: str) -> Optional[Dict[str, Any]]:
        """æ ¹æ®å“ˆå¸Œè·å–æ–‡ä»¶ - ç”¨äºå»é‡"""
        try:
            query = """
                SELECT * FROM workflow_file 
                WHERE file_hash = $1 AND is_deleted = FALSE
                LIMIT 1
            """
            
            result = await self.db.fetch_one(query, file_hash)
            return dict(result) if result else None
            
        except Exception as e:
            logger.error(f"æ ¹æ®å“ˆå¸Œè·å–æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    async def delete_workflow_file(self, file_id: uuid.UUID, hard_delete: bool = False) -> bool:
        """åˆ é™¤å·¥ä½œæµæ–‡ä»¶"""
        try:
            if hard_delete:
                # ç¡¬åˆ é™¤ - å®Œå…¨ä»æ•°æ®åº“ç§»é™¤
                query = "DELETE FROM workflow_file WHERE file_id = $1"
            else:
                # è½¯åˆ é™¤ - æ ‡è®°ä¸ºå·²åˆ é™¤
                query = """
                    UPDATE workflow_file 
                    SET is_deleted = TRUE, updated_at = NOW()
                    WHERE file_id = $1
                """
            
            result = await self.db.execute(query, file_id)
            logger.info(f"åˆ é™¤å·¥ä½œæµæ–‡ä»¶æˆåŠŸ: {file_id} ({'ç¡¬åˆ é™¤' if hard_delete else 'è½¯åˆ é™¤'})")
            return True
            
        except Exception as e:
            logger.error(f"åˆ é™¤å·¥ä½œæµæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    # ==================== ç”¨æˆ·æ–‡ä»¶å…³è”ç®¡ç† ====================
    
    async def associate_user_file(self, user_id: uuid.UUID, file_id: uuid.UUID, 
                                 access_type: AccessType = AccessType.OWNER) -> bool:
        """å…³è”ç”¨æˆ·å’Œæ–‡ä»¶"""
        try:
            # ç”ŸæˆUUIDä½œä¸ºuser_file_id - Linuså¼ä¿®å¤: æ•°æ®ç»“æ„è¦æ±‚å•¥å°±ç»™å•¥
            user_file_id = str(uuid.uuid4())
            
            # MySQLå…¼å®¹çš„UPSERTè¯­æ³•
            query = """
                INSERT INTO user_file (user_file_id, user_id, file_id, access_type)
                VALUES ($1, $2, $3, $4)
                ON DUPLICATE KEY UPDATE
                access_type = VALUES(access_type)
            """
            
            await self.db.execute(query, user_file_id, user_id, file_id, access_type.value)
            logger.info(f"ç”¨æˆ·æ–‡ä»¶å…³è”æˆåŠŸ: user={user_id}, file={file_id}")
            return True
            
        except Exception as e:
            logger.error(f"ç”¨æˆ·æ–‡ä»¶å…³è”å¤±è´¥: {e}")
            return False
    
    async def get_user_files(self, user_id: uuid.UUID, page: int = 1, 
                           page_size: int = 20, keyword: Optional[str] = None,
                           content_type: Optional[str] = None, sort_by: str = "created_at",
                           sort_order: str = "desc") -> Dict[str, Any]:
        """è·å–ç”¨æˆ·çš„æ‰€æœ‰æ–‡ä»¶"""
        try:
            offset = (page - 1) * page_size
            
            # æ„å»ºWHEREæ¡ä»¶
            where_conditions = ["uf.user_id = $1", "wf.is_deleted = FALSE"]
            params = [user_id]
            param_counter = 1
            
            # Linuså¼è°ƒè¯•: è®°å½•æŸ¥è¯¢å‚æ•°
            logger.info(f"get_user_files æŸ¥è¯¢å‚æ•°: user_id={user_id}, page={page}, page_size={page_size}")
            
            # å…³é”®è¯æœç´¢
            if keyword:
                param_counter += 1
                where_conditions.append(f"(wf.filename LIKE ${param_counter} OR wf.original_filename LIKE ${param_counter})")
                params.append(f"%{keyword}%")
            
            # å†…å®¹ç±»å‹è¿‡æ»¤
            if content_type:
                param_counter += 1
                where_conditions.append(f"wf.content_type LIKE ${param_counter}")
                params.append(f"{content_type}%")
            
            # æ„å»ºORDER BY
            valid_sort_fields = ["created_at", "filename", "file_size", "content_type"]
            sort_field = sort_by if sort_by in valid_sort_fields else "created_at"
            sort_direction = "DESC" if sort_order.upper() == "DESC" else "ASC"
            
            # è·å–æ–‡ä»¶åˆ—è¡¨
            query = f"""
                SELECT uf.*, wf.*, u.username as uploaded_by_name
                FROM user_file uf
                JOIN workflow_file wf ON uf.file_id = wf.file_id
                LEFT JOIN user u ON wf.uploaded_by = u.user_id
                WHERE {" AND ".join(where_conditions)}
                ORDER BY wf.{sort_field} {sort_direction}
                LIMIT ${param_counter + 1} OFFSET ${param_counter + 2}
            """
            
            params.extend([page_size, offset])
            
            # Linuså¼è°ƒè¯•: è®°å½•å®Œæ•´æŸ¥è¯¢
            logger.info(f"æ‰§è¡ŒæŸ¥è¯¢: {query}")
            logger.info(f"æŸ¥è¯¢å‚æ•°: {params}")
            
            files = await self.db.fetch_all(query, *params)
            
            # Linuså¼è°ƒè¯•: è®°å½•æŸ¥è¯¢ç»“æœ
            logger.info(f"æŸ¥è¯¢åˆ° {len(files)} ä¸ªæ–‡ä»¶")
            if files:
                for i, file in enumerate(files):
                    logger.info(f"æ–‡ä»¶ {i+1}: {dict(file)}")
            
            # è·å–æ€»æ•°
            count_query = f"""
                SELECT COUNT(*) as total
                FROM user_file uf
                JOIN workflow_file wf ON uf.file_id = wf.file_id
                WHERE {" AND ".join(where_conditions)}
            """
            
            count_params = params[:-2]  # ç§»é™¤LIMITå’ŒOFFSETå‚æ•°
            count_result = await self.db.fetch_one(count_query, *count_params)
            total = int(count_result['total']) if count_result else 0
            
            logger.info(f"æ–‡ä»¶æ€»æ•°: {total}")
            
            # å¤„ç†datetimeåºåˆ—åŒ– - Linuså¼ä¿®å¤: ä½¿ç”¨ç»Ÿä¸€å¤„ç†å‡½æ•°
            processed_files = self._process_datetime_fields(files)
            
            result = {
                'files': processed_files,
                'total': total,
                'page': page,
                'page_size': page_size,
                'total_pages': (total + page_size - 1) // page_size
            }
            
            logger.info(f"è¿”å›ç»“æœ: files={len(result['files'])}, total={result['total']}")
            return result
            
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·æ–‡ä»¶å¤±è´¥: {e}")
            return {'files': [], 'total': 0, 'page': page, 'page_size': page_size, 'total_pages': 0}
    
    # ==================== èŠ‚ç‚¹æ–‡ä»¶å…³è”ç®¡ç† ====================
    
    async def associate_node_file(self, node_id: uuid.UUID, file_id: uuid.UUID,
                                 attachment_type: AttachmentType = AttachmentType.INPUT) -> bool:
        """å…³è”èŠ‚ç‚¹å’Œæ–‡ä»¶"""
        try:
            # ç”ŸæˆUUIDä½œä¸ºnode_file_id - Linuså¼ä¿®å¤: æ•°æ®ç»“æ„è¦æ±‚å•¥å°±ç»™å•¥
            node_file_id = str(uuid.uuid4())
            
            # MySQLå…¼å®¹çš„UPSERTè¯­æ³•
            query = """
                INSERT INTO node_file (node_file_id, node_id, file_id, attachment_type)
                VALUES ($1, $2, $3, $4)
                ON DUPLICATE KEY UPDATE
                attachment_type = VALUES(attachment_type)
            """
            
            await self.db.execute(query, node_file_id, node_id, file_id, attachment_type.value)
            logger.info(f"èŠ‚ç‚¹æ–‡ä»¶å…³è”æˆåŠŸ: node={node_id}, file={file_id}")
            return True
            
        except Exception as e:
            logger.error(f"èŠ‚ç‚¹æ–‡ä»¶å…³è”å¤±è´¥: {e}")
            return False
    
    async def get_node_files(self, node_id: uuid.UUID) -> List[Dict[str, Any]]:
        """è·å–èŠ‚ç‚¹çš„æ‰€æœ‰æ–‡ä»¶"""
        try:
            query = """
                SELECT nf.*, wf.*, u.username as uploaded_by_name
                FROM node_file nf
                JOIN workflow_file wf ON nf.file_id = wf.file_id
                LEFT JOIN user u ON wf.uploaded_by = u.user_id
                WHERE nf.node_id = $1 AND wf.is_deleted = FALSE
                ORDER BY nf.created_at DESC
            """
            
            files = await self.db.fetch_all(query, node_id)
            return self._process_datetime_fields(files)
            
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    async def remove_node_file_association(self, node_id: uuid.UUID, file_id: uuid.UUID) -> bool:
        """ç§»é™¤èŠ‚ç‚¹æ–‡ä»¶å…³è”"""
        try:
            query = "DELETE FROM node_file WHERE node_id = $1 AND file_id = $2"
            await self.db.execute(query, node_id, file_id)
            logger.info(f"ç§»é™¤èŠ‚ç‚¹æ–‡ä»¶å…³è”æˆåŠŸ: node={node_id}, file={file_id}")
            return True
            
        except Exception as e:
            logger.error(f"ç§»é™¤èŠ‚ç‚¹æ–‡ä»¶å…³è”å¤±è´¥: {e}")
            return False

    async def inherit_node_files_to_instance(self, node_id: uuid.UUID, node_instance_id: uuid.UUID) -> bool:
        """
        å°†èŠ‚ç‚¹è®¾è®¡æ—¶çš„é™„ä»¶ç»§æ‰¿åˆ°èŠ‚ç‚¹å®ä¾‹
        Critical: åœ¨ node_instance åˆ›å»ºæ—¶å¿…é¡»è°ƒç”¨æ­¤æ–¹æ³•
        """
        try:
            # ğŸ”§ Linuså¼ä¿®å¤: é€šè¿‡node_idæ‰¾åˆ°node_base_idï¼Œç„¶åç»§æ‰¿é™„ä»¶
            inherit_query = """
                INSERT INTO node_instance_file (node_instance_file_id, node_instance_id, file_id, attachment_type)
                SELECT UUID(), %s, nf.file_id, nf.attachment_type
                FROM node_file nf
                JOIN node n ON nf.node_id = n.node_base_id
                WHERE n.node_id = %s
            """
            
            result = await self.db.execute(inherit_query, node_instance_id, node_id)
            
            # éªŒè¯ç»§æ‰¿ç»“æœ
            count_query = """
                SELECT COUNT(*) as inherited_count
                FROM node_instance_file nif
                WHERE nif.node_instance_id = %s
            """
            count_result = await self.db.fetch_one(count_query, node_instance_id)
            inherited_count = count_result['inherited_count'] if count_result else 0
            
            logger.info(f"âœ… [é™„ä»¶ç»§æ‰¿] èŠ‚ç‚¹ {node_id} -> å®ä¾‹ {node_instance_id}: ç»§æ‰¿äº† {inherited_count} ä¸ªé™„ä»¶")
            return True
            
        except Exception as e:
            logger.error(f"âŒ [é™„ä»¶ç»§æ‰¿] èŠ‚ç‚¹é™„ä»¶ç»§æ‰¿å¤±è´¥: {e}")
            return False
    
    # ==================== èŠ‚ç‚¹å®ä¾‹æ–‡ä»¶å…³è”ç®¡ç† ====================
    
    async def associate_node_instance_file(self, node_instance_id: uuid.UUID, file_id: uuid.UUID,
                                         attachment_type: AttachmentType = AttachmentType.INPUT) -> bool:
        """å…³è”èŠ‚ç‚¹å®ä¾‹å’Œæ–‡ä»¶"""
        try:
            # MySQLå…¼å®¹è¯­æ³• - ä½¿ç”¨IGNOREå¿½ç•¥é‡å¤æ’å…¥
            query = """
                INSERT IGNORE INTO node_instance_file (node_instance_id, file_id, attachment_type)
                VALUES ($1, $2, $3)
            """
            
            await self.db.execute(query, node_instance_id, file_id, attachment_type.value)
            logger.info(f"èŠ‚ç‚¹å®ä¾‹æ–‡ä»¶å…³è”æˆåŠŸ: node_instance={node_instance_id}, file={file_id}")
            return True
            
        except Exception as e:
            logger.error(f"èŠ‚ç‚¹å®ä¾‹æ–‡ä»¶å…³è”å¤±è´¥: {e}")
            return False
    
    async def get_node_instance_files(self, node_instance_id: uuid.UUID, 
                                    attachment_type: Optional[AttachmentType] = None) -> List[Dict[str, Any]]:
        """è·å–èŠ‚ç‚¹å®ä¾‹çš„æ–‡ä»¶"""
        try:
            base_query = """
                SELECT nif.*, wf.*, u.username as uploaded_by_name
                FROM node_instance_file nif
                JOIN workflow_file wf ON nif.file_id = wf.file_id
                LEFT JOIN user u ON wf.uploaded_by = u.user_id
                WHERE nif.node_instance_id = $1 AND wf.is_deleted = FALSE
            """
            
            if attachment_type:
                query = base_query + " AND nif.attachment_type = $2 ORDER BY nif.created_at DESC"
                files = await self.db.fetch_all(query, node_instance_id, attachment_type.value)
            else:
                query = base_query + " ORDER BY nif.created_at DESC"
                files = await self.db.fetch_all(query, node_instance_id)
                
            return self._process_datetime_fields(files)
            
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹å®ä¾‹æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    # ==================== ä»»åŠ¡å®ä¾‹æ–‡ä»¶å…³è”ç®¡ç† ====================
    
    async def associate_task_instance_file(self, task_instance_id: uuid.UUID, file_id: uuid.UUID,
                                         uploaded_by: uuid.UUID, 
                                         attachment_type: AttachmentType = AttachmentType.INPUT) -> bool:
        """å…³è”ä»»åŠ¡å®ä¾‹å’Œæ–‡ä»¶"""
        try:
            # ğŸ”§ Linuså¼ä¿®å¤: æ­£ç¡®å¤„ç†ä¸»é”®IDå’ŒMySQLè¯­æ³•
            task_instance_file_id = str(uuid.uuid4())
            
            # MySQLå…¼å®¹è¯­æ³• - ä¿®å¤å‚æ•°å ä½ç¬¦
            query = """
                INSERT IGNORE INTO task_instance_file (task_instance_file_id, task_instance_id, file_id, uploaded_by, attachment_type)
                VALUES (%s, %s, %s, %s, %s)
            """
            
            await self.db.execute(query, task_instance_file_id, task_instance_id, file_id, uploaded_by, attachment_type.value)
            logger.info(f"ä»»åŠ¡å®ä¾‹æ–‡ä»¶å…³è”æˆåŠŸ: task_instance={task_instance_id}, file={file_id}")
            return True
            
        except Exception as e:
            logger.error(f"ä»»åŠ¡å®ä¾‹æ–‡ä»¶å…³è”å¤±è´¥: {e}")
            return False
    
    async def get_task_instance_files(self, task_instance_id: uuid.UUID,
                                    attachment_type: Optional[AttachmentType] = None) -> List[Dict[str, Any]]:
        """è·å–ä»»åŠ¡å®ä¾‹çš„æ–‡ä»¶"""
        try:
            base_query = """
                SELECT tif.*, wf.*, u1.username as uploaded_by_name, u2.username as file_uploader_name
                FROM task_instance_file tif
                JOIN workflow_file wf ON tif.file_id = wf.file_id
                LEFT JOIN user u1 ON tif.uploaded_by = u1.user_id
                LEFT JOIN user u2 ON wf.uploaded_by = u2.user_id
                WHERE tif.task_instance_id = $1 AND wf.is_deleted = FALSE
            """
            
            if attachment_type:
                query = base_query + " AND tif.attachment_type = $2 ORDER BY tif.created_at DESC"
                files = await self.db.fetch_all(query, task_instance_id, attachment_type.value)
            else:
                query = base_query + " ORDER BY tif.created_at DESC"
                files = await self.db.fetch_all(query, task_instance_id)
                
            return self._process_datetime_fields(files)
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡å®ä¾‹æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    # ==================== æ‰¹é‡æ“ä½œ ====================
    
    async def batch_associate_files(self, entity_type: str, entity_id: uuid.UUID, 
                                  file_ids: List[uuid.UUID], attachment_type: AttachmentType,
                                  uploaded_by: Optional[uuid.UUID] = None) -> FileBatchResponse:
        """æ‰¹é‡å…³è”æ–‡ä»¶åˆ°å®ä½“"""
        success_files = []
        failed_files = []
        
        for file_id in file_ids:
            try:
                success = False
                
                if entity_type == "node":
                    success = await self.associate_node_file(entity_id, file_id, attachment_type)
                elif entity_type == "node_instance":
                    success = await self.associate_node_instance_file(entity_id, file_id, attachment_type)
                elif entity_type == "task_instance" and uploaded_by:
                    success = await self.associate_task_instance_file(entity_id, file_id, uploaded_by, attachment_type)
                elif entity_type == "user" and uploaded_by:
                    success = await self.associate_user_file(uploaded_by, file_id, AccessType.OWNER)
                
                if success:
                    success_files.append(file_id)
                else:
                    failed_files.append({"file_id": file_id, "reason": "å…³è”æ“ä½œå¤±è´¥"})
                    
            except Exception as e:
                failed_files.append({"file_id": file_id, "reason": str(e)})
        
        return FileBatchResponse(
            success_count=len(success_files),
            failed_count=len(failed_files),
            success_files=[str(file_id) for file_id in success_files],  # Linuså¼ä¿®å¤: è½¬æ¢UUIDä¸ºå­—ç¬¦ä¸²
            failed_files=failed_files
        )
    
    # ==================== æƒé™éªŒè¯ ====================
    
    async def check_file_permission(self, file_id: uuid.UUID, user_id: uuid.UUID, 
                                  action: str = "read") -> bool:
        """æ£€æŸ¥ç”¨æˆ·å¯¹æ–‡ä»¶çš„æƒé™"""
        try:
            # Linuså¼è°ƒè¯•: è®°å½•æƒé™æ£€æŸ¥å‚æ•°
            logger.info(f"æ£€æŸ¥æ–‡ä»¶æƒé™: file_id={file_id}, user_id={user_id}, action={action}")
            
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ˜¯æ–‡ä»¶çš„ä¸Šä¼ è€…æˆ–æœ‰è®¿é—®æƒé™
            # Linuså¼ä¿®å¤: ä½¿ç”¨ä¸åŒçš„å‚æ•°å ä½ç¬¦é¿å…é‡å¤
            query = """
                SELECT 1 FROM workflow_file wf
                LEFT JOIN user_file uf ON wf.file_id = uf.file_id AND uf.user_id = $2
                WHERE wf.file_id = $1 AND wf.is_deleted = FALSE
                AND (wf.uploaded_by = $3 OR uf.user_id IS NOT NULL)
            """
            
            logger.info(f"æ‰§è¡Œæƒé™æŸ¥è¯¢: {query}")
            logger.info(f"æŸ¥è¯¢å‚æ•°: [{file_id}, {user_id}, {user_id}]")
            
            result = await self.db.fetch_one(query, file_id, user_id, user_id)
            has_permission = result is not None
            
            logger.info(f"æƒé™æ£€æŸ¥ç»“æœ: {has_permission}")
            return has_permission
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ–‡ä»¶æƒé™å¤±è´¥: {e}")
            return False
    
    # ==================== ç»Ÿè®¡å’Œæ¸…ç† ====================
    
    async def get_file_statistics(self, user_id: Optional[uuid.UUID] = None) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯"""
        try:
            base_condition = "WHERE wf.is_deleted = FALSE"
            params = []
            
            if user_id:
                base_condition += " AND wf.uploaded_by = $1"
                params.append(user_id)
            
            # æ€»æ–‡ä»¶æ•°å’Œå¤§å°
            stats_query = f"""
                SELECT 
                    COUNT(*) as total_files,
                    COALESCE(SUM(wf.file_size), 0) as total_size,
                    ROUND(COALESCE(SUM(wf.file_size), 0) / 1024.0 / 1024.0, 2) as total_size_mb
                FROM workflow_file wf
                {base_condition}
            """
            
            stats = await self.db.fetch_one(stats_query, *params)
            
            # æ–‡ä»¶ç±»å‹ç»Ÿè®¡
            type_query = f"""
                SELECT content_type, COUNT(*) as count
                FROM workflow_file wf
                {base_condition}
                GROUP BY content_type
                ORDER BY count DESC
                LIMIT 10
            """
            
            types = await self.db.fetch_all(type_query, *params)
            
            return {
                'total_files': int(stats['total_files']) if stats and stats['total_files'] else 0,
                'total_size': int(stats['total_size']) if stats and stats['total_size'] else 0,
                'total_size_mb': float(stats['total_size_mb']) if stats and stats['total_size_mb'] else 0.0,
                'file_type_stats': {t['content_type']: int(t['count']) for t in types}
            }
            
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶ç»Ÿè®¡å¤±è´¥: {e}")
            return {'total_files': 0, 'total_size': 0, 'total_size_mb': 0.0, 'file_type_stats': {}}


# å…¨å±€æ–‡ä»¶å…³è”æœåŠ¡å®ä¾‹
_file_association_service: Optional[FileAssociationService] = None

def get_file_association_service() -> FileAssociationService:
    """è·å–æ–‡ä»¶å…³è”æœåŠ¡å®ä¾‹"""
    global _file_association_service
    if _file_association_service is None:
        _file_association_service = FileAssociationService()
    return _file_association_service