"""
äººå·¥ä»»åŠ¡å¤„ç†æœåŠ¡
Human Task Processing Service
"""

import uuid
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta
from loguru import logger

from ..repositories.instance.task_instance_repository import TaskInstanceRepository
from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
from ..repositories.user.user_repository import UserRepository
from ..models.instance import (
    TaskInstanceUpdate, TaskInstanceStatus, TaskInstanceType
)
from ..utils.helpers import now_utc
from .workflow_context_manager import WorkflowContextManager
from .feishu_bot_service import feishu_bot_service


class HumanTaskService:
    """äººå·¥ä»»åŠ¡å¤„ç†æœåŠ¡"""
    
    def __init__(self):
        self.task_repo = TaskInstanceRepository()
        self.workflow_instance_repo = WorkflowInstanceRepository()
        self.user_repo = UserRepository()
        # é›†æˆç»Ÿä¸€çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        self.context_manager = WorkflowContextManager()
    
    async def get_user_tasks(self, user_id: uuid.UUID, 
                           status: Optional[TaskInstanceStatus] = None,
                           limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·çš„ä»»åŠ¡åˆ—è¡¨"""
        try:
            logger.info(f"ğŸ” [ä»»åŠ¡æŸ¥è¯¢] å¼€å§‹æŸ¥è¯¢ç”¨æˆ·ä»»åŠ¡:")
            logger.info(f"   - ç”¨æˆ·ID: {user_id}")
            logger.info(f"   - çŠ¶æ€è¿‡æ»¤: {status.value if status else 'å…¨éƒ¨'}")
            logger.info(f"   - é™åˆ¶æ•°é‡: {limit}")
            
            tasks = await self.task_repo.get_human_tasks_for_user(user_id, status, limit)
            
            logger.info(f"ğŸ“Š [ä»»åŠ¡æŸ¥è¯¢] æŸ¥è¯¢ç»“æœ: æ‰¾åˆ° {len(tasks)} ä¸ªä»»åŠ¡")
            
            # æ·»åŠ ä»»åŠ¡ä¼˜å…ˆçº§å’Œæˆªæ­¢æ—¶é—´ç­‰é™„åŠ ä¿¡æ¯
            for i, task in enumerate(tasks, 1):
                logger.info(f"   ä»»åŠ¡{i}: {task.get('task_title')} | çŠ¶æ€: {task.get('status')} | ID: {task.get('task_instance_id')}")
                task = await self._enrich_task_info(task)
            
            if len(tasks) == 0:
                logger.warning(f"âš ï¸ [ä»»åŠ¡æŸ¥è¯¢] ç”¨æˆ· {user_id} æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä»»åŠ¡")
                
                # é¢å¤–è¯Šæ–­ï¼šæŸ¥è¯¢è¯¥ç”¨æˆ·çš„æ‰€æœ‰ä»»åŠ¡ï¼ˆä¸é™ç±»å‹ï¼‰
                logger.info(f"ğŸ”§ [è¯Šæ–­] æŸ¥è¯¢ç”¨æˆ·çš„æ‰€æœ‰ç±»å‹ä»»åŠ¡...")
                try:
                    debug_query = """
                        SELECT task_instance_id, task_title, task_type, assigned_user_id, status
                        FROM task_instance 
                        WHERE assigned_user_id = $1 AND is_deleted = FALSE
                        ORDER BY created_at DESC LIMIT 10
                    """
                    debug_results = await self.task_repo.db.fetch_all(debug_query, user_id)
                    logger.info(f"ğŸ”§ [è¯Šæ–­] ç”¨æˆ·æ‰€æœ‰ä»»åŠ¡æ•°é‡: {len(debug_results)}")
                    for task in debug_results:
                        logger.info(f"   - {task['task_title']} | ç±»å‹: {task['task_type']} | çŠ¶æ€: {task['status']}")
                except Exception as debug_e:
                    logger.error(f"ğŸ”§ [è¯Šæ–­] è¯Šæ–­æŸ¥è¯¢å¤±è´¥: {debug_e}")
            
            logger.info(f"âœ… [ä»»åŠ¡æŸ¥è¯¢] è·å–ç”¨æˆ· {user_id} çš„ä»»åŠ¡åˆ—è¡¨å®Œæˆï¼Œå…± {len(tasks)} ä¸ªä»»åŠ¡")
            # å‘é€é£ä¹¦æœºå™¨äººé€šçŸ¥
            await self._send_feishu_notifications(user_id, tasks)
            return tasks
            
        except Exception as e:
            logger.error(f"âŒ [ä»»åŠ¡æŸ¥è¯¢] è·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            raise
    
    async def get_task_details(self, task_id: uuid.UUID, user_id: uuid.UUID) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡è¯¦ç»†ä¿¡æ¯"""
        try:
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                return None
            
            # éªŒè¯ä»»åŠ¡æ˜¯å¦åˆ†é…ç»™å½“å‰ç”¨æˆ·
            if task.get('assigned_user_id') != str(user_id):
                raise PermissionError("æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
            
            # ä¸°å¯Œä»»åŠ¡ä¿¡æ¯
            task = await self._enrich_task_info(task)
            
            # è·å–å·¥ä½œæµä¸Šä¸‹æ–‡ä¿¡æ¯
            workflow_instance = await self.workflow_instance_repo.get_instance_by_id(
                task['workflow_instance_id']
            )
            
            # è·å–å·¥ä½œæµåŸºæœ¬ä¿¡æ¯
            workflow_base = None
            if workflow_instance:
                from ..repositories.workflow.workflow_repository import WorkflowRepository
                workflow_repo = WorkflowRepository()
                workflow_base = await workflow_repo.get_workflow_by_base_id(
                    workflow_instance.get('workflow_base_id')
                )
            
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            node_info = await self._get_node_info(task.get('node_instance_id'))
            
            # è·å–å¤„ç†å™¨ä¿¡æ¯
            processor_info = await self._get_processor_info(task.get('processor_id'))
            
            # è§£æä¸Šæ¸¸ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            parsed_context_data = self._parse_context_data(task.get('context_data', ''))
            upstream_context = await self._get_upstream_context(task)
            
            # ğŸ†• è·å–å½“å‰ä»»åŠ¡çš„é™„ä»¶
            current_task_attachments = await self._get_current_task_attachments(task)
            
            # åˆ›å»ºå¢å¼ºçš„ä»»åŠ¡æè¿°ï¼ˆç»“åˆåŸå§‹æè¿°å’Œä¸Šæ¸¸ä¸Šä¸‹æ–‡ï¼‰
            enhanced_description = self._create_enhanced_description(
                task.get('task_description', ''), 
                parsed_context_data, 
                upstream_context
            )
            
            # è¿”å›ä¸æ‰€æœ‰processorç»Ÿä¸€çš„ä»»åŠ¡ç»“æ„ï¼Œä½†å¢åŠ å‰ç«¯éœ€è¦çš„ç»“æ„åŒ–æ•°æ®
            task_details = {
                # ===== æ ¸å¿ƒä»»åŠ¡ä¿¡æ¯ï¼ˆä¸Agent processorå®Œå…¨ä¸€è‡´ï¼‰=====
                'task_instance_id': task['task_instance_id'],
                'task_title': task.get('task_title', ''),
                'task_description': task.get('task_description', ''),
                'enhanced_description': enhanced_description,  # å¢å¼ºç‰ˆæè¿°ï¼ŒåŒ…å«ä¸Šæ¸¸ä¸Šä¸‹æ–‡
                'input_data': task.get('input_data', ''),      # ç»Ÿä¸€æ–‡æœ¬æ ¼å¼
                'context_data': parsed_context_data,           # è§£æåçš„ç»“æ„åŒ–æ•°æ®
                
                # ===== å‰ç«¯ç»“æ„åŒ–æ•°æ® =====
                'parsed_context_data': parsed_context_data,    # è§£æåçš„ä¸Šä¸‹æ–‡å¯¹è±¡
                'upstream_context': upstream_context,          # æ ¼å¼åŒ–çš„ä¸Šæ¸¸ä¸Šä¸‹æ–‡
                
                # ===== ä»»åŠ¡çŠ¶æ€å’Œåˆ†é… =====
                'task_type': task.get('task_type', 'HUMAN'),
                'status': task.get('status', 'PENDING'),
                'assigned_user_id': task.get('assigned_user_id'),
                'processor_id': task.get('processor_id'),
                
                # ===== æ—¶é—´ä¿¡æ¯ =====
                'created_at': task.get('created_at'),
                'assigned_at': task.get('assigned_at'),
                'started_at': task.get('started_at'),
                'completed_at': task.get('completed_at'),
                'estimated_duration': task.get('estimated_duration', 0),
                'actual_duration': task.get('actual_duration'),
                
                # ===== æ‰§è¡Œç»“æœ =====
                'output_data': task.get('output_data', ''),
                'result_summary': task.get('result_summary', ''),
                'error_message': task.get('error_message', ''),
                'retry_count': task.get('retry_count', 0),
                
                # ===== é™„åŠ ä¿¡æ¯ï¼ˆä»…ä¸ºäººç±»ç”¨æˆ·æä¾›æ›´å¥½çš„UIä½“éªŒï¼‰=====
                'workflow_name': workflow_base.get('name', '') if workflow_base else '',
                'node_name': node_info.get('node_name', '') if node_info else '',
                'processor_name': processor_info.get('name', '') if processor_info else '',
                
                # ğŸ†• ä»»åŠ¡é™„ä»¶ä¿¡æ¯
                'current_task_attachments': current_task_attachments,  # å½“å‰ä»»åŠ¡çš„é™„ä»¶
            }
            
            logger.info(f"è·å–ä»»åŠ¡è¯¦æƒ…: {task_details['task_title']} (ID: {task_id})")
            return task_details
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}")
            raise
    
    async def _get_node_info(self, node_instance_id: Optional[uuid.UUID]) -> Optional[Dict[str, Any]]:
        """è·å–èŠ‚ç‚¹ä¿¡æ¯"""
        if not node_instance_id:
            return None
            
        try:
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_instance_repo = NodeInstanceRepository()
            
            query = """
            SELECT ni.*, n.name as node_name, n.task_description as node_description, 
                   n.type as node_type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.node_instance_id = $1
            """
            
            result = await node_instance_repo.db.fetch_one(query, node_instance_id)
            return dict(result) if result else None
            
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    async def _get_processor_info(self, processor_id: Optional[uuid.UUID]) -> Optional[Dict[str, Any]]:
        """è·å–å¤„ç†å™¨ä¿¡æ¯"""
        if not processor_id:
            return None
            
        try:
            from ..repositories.processor.processor_repository import ProcessorRepository
            processor_repo = ProcessorRepository()
            
            processor = await processor_repo.get_processor_by_id(processor_id)
            return processor
            
        except Exception as e:
            logger.error(f"è·å–å¤„ç†å™¨ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    async def _get_upstream_context(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡çš„ä¸Šæ¸¸ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆæ”¯æŒå…¨å±€ä¸Šä¸‹æ–‡å’Œé™„ä»¶ï¼‰"""
        try:
            # ä»context_dataä¸­è·å–ä¸Šæ¸¸æ•°æ®ï¼ˆéœ€è¦å…ˆè§£æJSONå­—ç¬¦ä¸²ï¼‰
            raw_context_data = task.get('context_data', '')
            context_data = self._parse_context_data(raw_context_data)
            logger.info(f"è·å–ä¸Šæ¸¸ä¸Šä¸‹æ–‡ - context_data keys: {list(context_data.keys()) if isinstance(context_data, dict) else 'not dict'}")
            
            # ğŸ†• æ”¯æŒæ–°çš„å…¨å±€ä¸Šä¸‹æ–‡ç»“æ„
            immediate_upstream_results = context_data.get('immediate_upstream_results', {})
            all_upstream_results = context_data.get('all_upstream_results', {})
            
            # å…¼å®¹æ—§æ ¼å¼ï¼šå¤„ç†è€çš„upstream_outputså­—æ®µ
            upstream_outputs = context_data.get('upstream_outputs', [])
            formatted_immediate_upstream = {}
            
            if upstream_outputs:
                logger.info(f"ğŸ”„ [å…¼å®¹æ¨¡å¼] å¤„ç†æ—§æ ¼å¼upstream_outputsï¼Œå…±{len(upstream_outputs) if isinstance(upstream_outputs, (list, dict)) else 0}ä¸ªèŠ‚ç‚¹")
                
                # å¤„ç†åˆ—è¡¨æ ¼å¼çš„upstream_outputs
                if isinstance(upstream_outputs, list):
                    for i, node_data in enumerate(upstream_outputs):
                        if isinstance(node_data, dict):
                            node_base_id = node_data.get('node_base_id', f'unknown_{i}')
                            output_data = node_data.get('output_data', {})
                            
                            if output_data:  # åªæœ‰å½“èŠ‚ç‚¹æœ‰è¾“å‡ºæ•°æ®æ—¶æ‰åŒ…å«
                                formatted_immediate_upstream[node_base_id] = {
                                    'node_name': node_data.get('node_name', f'èŠ‚ç‚¹_{node_base_id[:8]}'),
                                    'output_data': output_data,
                                    'completed_at': node_data.get('completed_at', ''),
                                    'status': node_data.get('status', ''),
                                    'node_description': node_data.get('node_description', ''),
                                    'source': node_data.get('source', 'unknown'),
                                    'summary': self._extract_data_summary(output_data)
                                }
                                logger.info(f"æ‰¾åˆ°ä¸Šæ¸¸èŠ‚ç‚¹æ•°æ®: {node_base_id} - {node_data.get('node_name', 'æœªçŸ¥èŠ‚ç‚¹')}")
                
                # å…¼å®¹å­—å…¸æ ¼å¼
                elif isinstance(upstream_outputs, dict):
                    for node_base_id, node_data in upstream_outputs.items():
                        if isinstance(node_data, dict):
                            output_data = node_data.get('output_data', {})
                            if output_data:  # åªæœ‰å½“èŠ‚ç‚¹æœ‰è¾“å‡ºæ•°æ®æ—¶æ‰åŒ…å«
                                formatted_immediate_upstream[node_base_id] = {
                                    'node_name': node_data.get('node_name', f'èŠ‚ç‚¹_{node_base_id[:8]}'),
                                    'output_data': output_data,
                                    'completed_at': node_data.get('completed_at', ''),
                                    'status': node_data.get('status', ''),
                                    'summary': self._extract_data_summary(output_data)
                                }
            else:
                # ğŸ†• ä½¿ç”¨æ–°æ ¼å¼çš„immediate_upstream_results
                formatted_immediate_upstream = immediate_upstream_results
                logger.info(f"ğŸ†• [æ–°æ ¼å¼] ä½¿ç”¨immediate_upstream_resultsï¼Œå…±{len(immediate_upstream_results)}ä¸ªç›´æ¥ä¸Šæ¸¸èŠ‚ç‚¹")
            
            # ğŸ†• æ ¼å¼åŒ–å…¨å±€ä¸Šæ¸¸ç»“æœ
            formatted_all_upstream = all_upstream_results
            logger.info(f"ğŸŒ [å…¨å±€ä¸Šä¸‹æ–‡] å…¨å±€ä¸Šæ¸¸èŠ‚ç‚¹æ•°: {len(all_upstream_results)}")
            
            # ä»input_dataè·å–è¡¥å……ä¿¡æ¯ï¼ˆå¤„ç†æ–‡æœ¬æ ¼å¼ï¼‰
            input_data_raw = task.get('input_data', '{}')
            try:
                # å°è¯•å°†å­—ç¬¦ä¸²è§£æä¸ºå­—å…¸
                if isinstance(input_data_raw, str):
                    import json
                    input_data = json.loads(input_data_raw) if input_data_raw.strip() else {}
                else:
                    input_data = input_data_raw if isinstance(input_data_raw, dict) else {}
            except (json.JSONDecodeError, AttributeError):
                logger.warning(f"æ— æ³•è§£æinput_data: {input_data_raw}")
                input_data = {}
                
            workflow_global = input_data.get('workflow_global', {})
            workflow_info = context_data.get('workflow', {})
            
            # ğŸ†• è·å–ä¸Šä¸‹æ–‡ä¸­çš„é™„ä»¶ä¿¡æ¯
            context_attachments = await self._get_context_attachments(task)
            
            result = {
                'immediate_upstream_results': formatted_immediate_upstream,
                'all_upstream_results': formatted_all_upstream,  # ğŸ†• å…¨å±€ä¸Šæ¸¸ç»“æœ
                'upstream_node_count': len(formatted_immediate_upstream),
                'all_upstream_node_count': len(formatted_all_upstream),  # ğŸ†• å…¨å±€ä¸Šæ¸¸è®¡æ•°
                'workflow_global_data': workflow_global,
                'workflow_execution_path': workflow_global.get('execution_path', []),
                'workflow_start_time': workflow_info.get('created_at', ''),
                'workflow_name': workflow_info.get('name', ''),
                'has_upstream_data': len(formatted_immediate_upstream) > 0,
                'has_global_upstream_data': len(formatted_all_upstream) > 0,  # ğŸ†• å…¨å±€ä¸Šæ¸¸æ•°æ®æ ‡è¯†
                'context_attachments': context_attachments  # ğŸ†• ä¸Šä¸‹æ–‡é™„ä»¶
            }
            
            logger.info(f"ä¸Šæ¸¸ä¸Šä¸‹æ–‡ç»“æœ: immediate={result['upstream_node_count']}, global={result['all_upstream_node_count']}, attachments={len(context_attachments)}")
            return result
            
        except Exception as e:
            logger.error(f"è·å–ä¸Šæ¸¸ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {
                'immediate_upstream_results': {},
                'all_upstream_results': {},
                'upstream_node_count': 0,
                'all_upstream_node_count': 0,
                'workflow_global_data': {},
                'workflow_execution_path': [],
                'workflow_start_time': '',
                'workflow_name': '',
                'has_upstream_data': False,
                'has_global_upstream_data': False,
                'context_attachments': []
            }
    
    async def _get_context_attachments(self, task: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è·å–ä»»åŠ¡ä¸Šä¸‹æ–‡ä¸­çš„é™„ä»¶ä¿¡æ¯"""
        try:
            context_attachments = []
            
            # ä»ä»»åŠ¡çš„node_instance_idè·å–å…³è”çš„é™„ä»¶
            node_instance_id = task.get('node_instance_id')
            workflow_instance_id = task.get('workflow_instance_id')
            
            if node_instance_id or workflow_instance_id:
                from ..services.file_association_service import FileAssociationService
                file_service = FileAssociationService()
                
                # è·å–èŠ‚ç‚¹å…³è”çš„é™„ä»¶
                if node_instance_id:
                    node_files = await file_service.get_node_instance_files(node_instance_id)
                    for file_info in node_files:
                        context_attachments.append({
                            'file_id': file_info['file_id'],
                            'filename': file_info['original_filename'],
                            'file_size': file_info['file_size'],
                            'content_type': file_info['content_type'],
                            'created_at': file_info['created_at'],
                            'association_type': 'node',
                            'association_id': str(node_instance_id)
                        })
                
                # è·å–å·¥ä½œæµå…³è”çš„é™„ä»¶ï¼ˆæš‚æ—¶æ³¨é‡Šæ‰ï¼Œå› ä¸ºFileAssociationServiceæš‚æ— æ­¤æ–¹æ³•ï¼‰
                # if workflow_instance_id:
                #     workflow_files = await file_service.get_files_by_association('workflow', str(workflow_instance_id))
                #     for file_info in workflow_files:
                #         context_attachments.append({
                #             'file_id': file_info['file_id'],
                #             'filename': file_info['original_filename'],
                #             'file_size': file_info['file_size'],
                #             'content_type': file_info['content_type'],
                #             'created_at': file_info['created_at'],
                #             'association_type': 'workflow',
                #             'association_id': str(workflow_instance_id)
                #         })
                
                logger.info(f"ğŸ”— [é™„ä»¶æ”¶é›†] ä¸ºä»»åŠ¡ {task.get('task_instance_id')} æ”¶é›†äº† {len(context_attachments)} ä¸ªä¸Šä¸‹æ–‡é™„ä»¶")
            
            return context_attachments
            
        except Exception as e:
            logger.error(f"è·å–ä¸Šä¸‹æ–‡é™„ä»¶å¤±è´¥: {e}")
            return []
    
    async def _get_current_task_attachments(self, task: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è·å–å½“å‰ä»»åŠ¡çš„é™„ä»¶ä¿¡æ¯"""
        try:
            current_task_attachments = []
            
            # è·å–ä»»åŠ¡ID
            task_id = task.get('task_instance_id')
            node_instance_id = task.get('node_instance_id')
            
            if task_id or node_instance_id:
                from ..services.file_association_service import FileAssociationService
                file_service = FileAssociationService()
                
                # è·å–ç›´æ¥ä¸ä»»åŠ¡å…³è”çš„é™„ä»¶
                if task_id:
                    task_files = await file_service.get_task_instance_files(task_id)
                    for file_info in task_files:
                        current_task_attachments.append({
                            'file_id': file_info['file_id'],
                            'filename': file_info['original_filename'],
                            'file_size': file_info['file_size'],
                            'content_type': file_info['content_type'],
                            'created_at': file_info['created_at'],
                            'association_type': 'task_direct',
                            'association_id': str(task_id)
                        })
                
                # è·å–èŠ‚ç‚¹ç»‘å®šçš„é™„ä»¶
                if node_instance_id:
                    node_files = await file_service.get_node_instance_files(node_instance_id)
                    for file_info in node_files:
                        current_task_attachments.append({
                            'file_id': file_info['file_id'],
                            'filename': file_info['original_filename'],
                            'file_size': file_info['file_size'],
                            'content_type': file_info['content_type'],
                            'created_at': file_info['created_at'],
                            'association_type': 'node_binding',
                            'association_id': str(node_instance_id)
                        })
                
                logger.info(f"ğŸ”— [å½“å‰ä»»åŠ¡é™„ä»¶] ä¸ºä»»åŠ¡ {task_id} æ”¶é›†äº† {len(current_task_attachments)} ä¸ªé™„ä»¶")
            
            return current_task_attachments
            
        except Exception as e:
            logger.error(f"è·å–å½“å‰ä»»åŠ¡é™„ä»¶å¤±è´¥: {e}")
            return []
    
    def _extract_data_summary(self, output_data: Dict[str, Any]) -> str:
        """ä»è¾“å‡ºæ•°æ®ä¸­æå–æ‘˜è¦ä¿¡æ¯"""
        try:
            if not output_data:
                return "æ— è¾“å‡ºæ•°æ®"
            
            # å°è¯•æå–å¸¸è§çš„æ‘˜è¦å­—æ®µ
            if 'summary' in output_data:
                return str(output_data['summary'])
            elif 'result_summary' in output_data:
                return str(output_data['result_summary'])
            elif 'message' in output_data:
                return str(output_data['message'])
            elif 'description' in output_data:
                return str(output_data['description'])
            else:
                # ç”ŸæˆåŸºäºæ•°æ®å†…å®¹çš„ç®€è¦æ‘˜è¦
                data_keys = list(output_data.keys())
                if len(data_keys) <= 3:
                    return f"åŒ…å«æ•°æ®: {', '.join(data_keys)}"
                else:
                    return f"åŒ…å« {len(data_keys)} é¡¹æ•°æ®: {', '.join(data_keys[:3])}..."
                    
        except Exception as e:
            logger.error(f"æå–æ•°æ®æ‘˜è¦å¤±è´¥: {e}")
            return "æ•°æ®æ‘˜è¦ä¸å¯ç”¨"
    
    async def start_task(self, task_id: uuid.UUID, user_id: uuid.UUID) -> Dict[str, Any]:
        """å¼€å§‹æ‰§è¡Œä»»åŠ¡"""
        try:
            # éªŒè¯ä»»åŠ¡çŠ¶æ€å’Œæƒé™
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task.get('assigned_user_id') != str(user_id):
                raise PermissionError("æ— æƒæ‰§è¡Œæ­¤ä»»åŠ¡")
            
            if task['status'] not in [TaskInstanceStatus.ASSIGNED.value, TaskInstanceStatus.PENDING.value]:
                raise ValueError(f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸å¼€å§‹æ‰§è¡Œï¼Œå½“å‰çŠ¶æ€: {task['status']}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿›è¡Œä¸­
            update_data = TaskInstanceUpdate(status=TaskInstanceStatus.IN_PROGRESS)
            updated_task = await self.task_repo.update_task(task_id, update_data)
            
            if updated_task:
                logger.info(f"ç”¨æˆ· {user_id} å¼€å§‹æ‰§è¡Œä»»åŠ¡: {updated_task['task_title']}")
                return {
                    'task_id': task_id,
                    'status': TaskInstanceStatus.IN_PROGRESS.value,
                    'started_at': updated_task.get('started_at'),
                    'message': 'ä»»åŠ¡å·²å¼€å§‹æ‰§è¡Œ'
                }
            else:
                raise RuntimeError("æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥")
                
        except Exception as e:
            logger.error(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def submit_task_result(self, task_id: uuid.UUID, user_id: uuid.UUID,
                               result_data: Dict[str, Any], 
                               result_summary: Optional[str] = None) -> Dict[str, Any]:
        """æäº¤ä»»åŠ¡ç»“æœ"""
        try:
            logger.info(f"ğŸš€ å¼€å§‹å¤„ç†ä»»åŠ¡æäº¤:")
            logger.info(f"  ä»»åŠ¡ID: {task_id}")
            logger.info(f"  ç”¨æˆ·ID: {user_id}")
            logger.info(f"  ç»“æœæ•°æ®: {result_data}")
            logger.info(f"  ç»“æœæ‘˜è¦: {result_summary}")
            
            # éªŒè¯ä»»åŠ¡çŠ¶æ€å’Œæƒé™
            logger.info(f"ğŸ“‹ æŸ¥è¯¢ä»»åŠ¡ä¿¡æ¯...")
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                logger.error(f"âŒ ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            logger.info(f"âœ… ä»»åŠ¡æŸ¥è¯¢æˆåŠŸ:")
            logger.info(f"  ä»»åŠ¡æ ‡é¢˜: {task.get('task_title')}")
            logger.info(f"  å½“å‰çŠ¶æ€: {task['status']}")
            logger.info(f"  åˆ†é…ç”¨æˆ·: {task.get('assigned_user_id')}")
            logger.info(f"  å¼€å§‹æ—¶é—´: {task.get('started_at')}")
            
            if task.get('assigned_user_id') != str(user_id):
                logger.error(f"âŒ æƒé™ä¸è¶³: ä»»åŠ¡åˆ†é…ç»™ {task.get('assigned_user_id')}ï¼Œä½†æäº¤ç”¨æˆ·ä¸º {user_id}")
                raise PermissionError("æ— æƒæäº¤æ­¤ä»»åŠ¡")
            
            if task['status'] != TaskInstanceStatus.IN_PROGRESS.value:
                logger.error(f"âŒ ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æäº¤: æœŸæœ› {TaskInstanceStatus.IN_PROGRESS.value}ï¼Œå®é™… {task['status']}")
                raise ValueError(f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æäº¤ç»“æœï¼Œå½“å‰çŠ¶æ€: {task['status']}")
            
            # è®¡ç®—å®é™…æ‰§è¡Œæ—¶é—´
            actual_duration = None
            if task.get('started_at'):
                try:
                    logger.info(f"ğŸ“… å¤„ç†å¼€å§‹æ—¶é—´: {task['started_at']} (ç±»å‹: {type(task['started_at'])})")
                    started_at = task['started_at']
                    
                    # å¤„ç†ä¸åŒç±»å‹çš„æ—¶é—´æ•°æ®
                    if isinstance(started_at, str):
                        # å­—ç¬¦ä¸²ç±»å‹ï¼Œéœ€è¦è§£æ
                        start_time = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
                    elif hasattr(started_at, 'replace'):
                        # å·²ç»æ˜¯datetimeå¯¹è±¡
                        start_time = started_at
                    else:
                        logger.warning(f"âš ï¸ æ— æ³•å¤„ç†çš„å¼€å§‹æ—¶é—´ç±»å‹: {type(started_at)}")
                        start_time = None
                    
                    if start_time:
                        # ç¡®ä¿æ—¶é—´æœ‰æ—¶åŒºä¿¡æ¯
                        if start_time.tzinfo is None:
                            from ..utils.helpers import now_utc
                            current_time = now_utc()
                        else:
                            current_time = datetime.now().replace(tzinfo=start_time.tzinfo)
                        
                        actual_duration = int((current_time - start_time).total_seconds() / 60)
                        logger.info(f"â±ï¸ è®¡ç®—æ‰§è¡Œæ—¶é—´æˆåŠŸ: {actual_duration} åˆ†é’Ÿ")
                    
                except Exception as time_error:
                    logger.error(f"âŒ æ—¶é—´è®¡ç®—å¤±è´¥: {time_error}")
                    logger.error(f"åŸå§‹æ—¶é—´æ•°æ®: {repr(task['started_at'])}")
                    actual_duration = None
            
            # è½¬æ¢ç»“æœæ•°æ®ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼ˆä¸ç°æœ‰ä»»åŠ¡å­—æ®µå¯¹é½ï¼‰
            output_data_str = self._format_data_to_string(result_data)
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å®Œæˆ
            logger.info(f"ğŸ“ å‡†å¤‡æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å®Œæˆ...")
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.COMPLETED,
                output_data=output_data_str,
                result_summary=result_summary or "äººå·¥ä»»åŠ¡å®Œæˆ",
                actual_duration=actual_duration
            )
            logger.info(f"  æ›´æ–°æ•°æ®: {update_data}")
            
            updated_task = await self.task_repo.update_task(task_id, update_data)
            
            if updated_task:
                logger.info(f"âœ… ä»»åŠ¡çŠ¶æ€æ›´æ–°æˆåŠŸ:")
                logger.info(f"  ä»»åŠ¡æ ‡é¢˜: {updated_task['task_title']}")
                logger.info(f"  å®Œæˆæ—¶é—´: {updated_task.get('completed_at')}")
                logger.info(f"  æ‰§è¡Œæ—¶é•¿: {actual_duration} åˆ†é’Ÿ")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘ä¸‹æ¸¸ä»»åŠ¡ - ä½¿ç”¨ç»Ÿä¸€çš„ä¾èµ–ç®¡ç†
                logger.info(f"ğŸ”„ é€šè¿‡WorkflowContextManageræ£€æŸ¥ä¸‹æ¸¸ä»»åŠ¡...")
                await self._handle_task_completion_through_context_manager(task, updated_task, output_data_str)
                
                result = {
                    'task_id': task_id,
                    'status': TaskInstanceStatus.COMPLETED.value,
                    'completed_at': updated_task.get('completed_at'),
                    'actual_duration': actual_duration,
                    'message': 'ä»»åŠ¡ç»“æœå·²æäº¤'
                }
                logger.info(f"ğŸ‰ ä»»åŠ¡æäº¤å®Œæˆï¼Œè¿”å›ç»“æœ: {result}")
                return result
            else:
                logger.error(f"âŒ ä»»åŠ¡çŠ¶æ€æ›´æ–°å¤±è´¥: update_taskè¿”å›None")
                raise RuntimeError("æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥")
                
        except Exception as e:
            logger.error(f"ğŸ’¥ æäº¤ä»»åŠ¡ç»“æœå¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def pause_task(self, task_id: uuid.UUID, user_id: uuid.UUID,
                        pause_reason: Optional[str] = None) -> Dict[str, Any]:
        """æš‚åœä»»åŠ¡"""
        try:
            # éªŒè¯ä»»åŠ¡çŠ¶æ€å’Œæƒé™
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task.get('assigned_user_id') != str(user_id):
                raise PermissionError("æ— æƒæš‚åœæ­¤ä»»åŠ¡")
            
            if task['status'] != TaskInstanceStatus.IN_PROGRESS.value:
                raise ValueError(f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æš‚åœï¼Œå½“å‰çŠ¶æ€: {task['status']}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²åˆ†é…ï¼ˆä»è¿›è¡Œä¸­å›åˆ°åˆ†é…çŠ¶æ€ï¼‰
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.ASSIGNED,
                error_message=f"ä»»åŠ¡æš‚åœ: {pause_reason}" if pause_reason else "ä»»åŠ¡æš‚åœ"
            )
            
            updated_task = await self.task_repo.update_task(task_id, update_data)
            
            if updated_task:
                logger.info(f"ç”¨æˆ· {user_id} æš‚åœä»»åŠ¡: {updated_task['task_title']}")
                return {
                    'task_id': task_id,
                    'status': TaskInstanceStatus.ASSIGNED.value,
                    'message': 'ä»»åŠ¡å·²æš‚åœ'
                }
            else:
                raise RuntimeError("æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥")
                
        except Exception as e:
            logger.error(f"æš‚åœä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def request_help(self, task_id: uuid.UUID, user_id: uuid.UUID,
                          help_message: str) -> Dict[str, Any]:
        """è¯·æ±‚å¸®åŠ©"""
        try:
            # éªŒè¯ä»»åŠ¡æƒé™
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task.get('assigned_user_id') != str(user_id):
                raise PermissionError("æ— æƒä¸ºæ­¤ä»»åŠ¡è¯·æ±‚å¸®åŠ©")
            
            # è®°å½•å¸®åŠ©è¯·æ±‚ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å¯ä»¥åˆ›å»ºå¸®åŠ©è¯·æ±‚è¡¨ï¼‰
            help_request = {
                'task_id': task_id,
                'user_id': user_id,
                'help_message': help_message,
                'requested_at': now_utc(),
                'status': 'pending'
            }
            
            logger.info(f"ç”¨æˆ· {user_id} ä¸ºä»»åŠ¡ {task_id} è¯·æ±‚å¸®åŠ©: {help_message}")
            
            return {
                'task_id': task_id,
                'help_request_id': str(uuid.uuid4()),  # æ¨¡æ‹Ÿå¸®åŠ©è¯·æ±‚ID
                'message': 'å¸®åŠ©è¯·æ±‚å·²æäº¤'
            }
            
        except Exception as e:
            logger.error(f"è¯·æ±‚å¸®åŠ©å¤±è´¥: {e}")
            raise
    
    async def reject_task(self, task_id: uuid.UUID, user_id: uuid.UUID,
                         reject_reason: str) -> Dict[str, Any]:
        """æ‹’ç»ä»»åŠ¡"""
        try:
            # éªŒè¯ä»»åŠ¡çŠ¶æ€å’Œæƒé™
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task.get('assigned_user_id') != str(user_id):
                raise PermissionError("æ— æƒæ‹’ç»æ­¤ä»»åŠ¡")
            
            if task['status'] not in [TaskInstanceStatus.ASSIGNED.value, TaskInstanceStatus.PENDING.value]:
                raise ValueError(f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æ‹’ç»ï¼Œå½“å‰çŠ¶æ€: {task['status']}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²æ‹’ç»ï¼ˆæ ‡è®°ä¸ºå¤±è´¥çŠ¶æ€ï¼Œå¹¶è®°å½•æ‹’ç»åŸå› ï¼‰
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.FAILED,
                error_message=f"ä»»åŠ¡è¢«æ‹’ç»: {reject_reason}",
                result_summary="ä»»åŠ¡è¢«ç”¨æˆ·æ‹’ç»"
            )
            
            updated_task = await self.task_repo.update_task(task_id, update_data)
            
            if updated_task:
                logger.info(f"ç”¨æˆ· {user_id} æ‹’ç»ä»»åŠ¡: {updated_task['task_title']} - {reject_reason}")
                
                # é€šçŸ¥å·¥ä½œæµå¼•æ“ä»»åŠ¡è¢«æ‹’ç»ï¼Œå¯èƒ½éœ€è¦é‡æ–°åˆ†é…æˆ–å¤„ç†
                await self._notify_task_rejected(task_id, reject_reason)
                
                return {
                    'task_id': task_id,
                    'status': TaskInstanceStatus.FAILED.value,
                    'message': 'ä»»åŠ¡å·²æ‹’ç»'
                }
            else:
                raise RuntimeError("æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥")
                
        except Exception as e:
            logger.error(f"æ‹’ç»ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def cancel_task(self, task_id: uuid.UUID, user_id: uuid.UUID,
                         cancel_reason: Optional[str] = "ç”¨æˆ·å–æ¶ˆ") -> Dict[str, Any]:
        """å–æ¶ˆä»»åŠ¡"""
        try:
            # éªŒè¯ä»»åŠ¡çŠ¶æ€å’Œæƒé™
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task.get('assigned_user_id') != str(user_id):
                raise PermissionError("æ— æƒå–æ¶ˆæ­¤ä»»åŠ¡")
            
            if task['status'] in [TaskInstanceStatus.COMPLETED.value, TaskInstanceStatus.FAILED.value, TaskInstanceStatus.CANCELLED.value]:
                raise ValueError(f"ä»»åŠ¡å·²å®Œç»“ï¼Œæ— æ³•å–æ¶ˆã€‚å½“å‰çŠ¶æ€: {task['status']}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å–æ¶ˆ
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.CANCELLED,
                error_message=f"ä»»åŠ¡è¢«å–æ¶ˆ: {cancel_reason}",
                result_summary="ä»»åŠ¡è¢«ç”¨æˆ·å–æ¶ˆ"
            )
            
            updated_task = await self.task_repo.update_task(task_id, update_data)
            
            if updated_task:
                logger.info(f"ç”¨æˆ· {user_id} å–æ¶ˆä»»åŠ¡: {updated_task['task_title']} - {cancel_reason}")
                
                # é€šçŸ¥å·¥ä½œæµå¼•æ“ä»»åŠ¡è¢«å–æ¶ˆ
                await self._notify_task_cancelled(task_id, cancel_reason)
                
                return {
                    'task_id': task_id,
                    'status': TaskInstanceStatus.CANCELLED.value,
                    'message': 'ä»»åŠ¡å·²å–æ¶ˆ'
                }
            else:
                raise RuntimeError("æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥")
                
        except Exception as e:
            logger.error(f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def get_task_history(self, user_id: uuid.UUID, 
                             days: int = 30, limit: int = 100) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·ä»»åŠ¡å†å²"""
        try:
            # è·å–æŒ‡å®šå¤©æ•°å†…çš„å·²å®Œæˆä»»åŠ¡
            tasks = await self.task_repo.get_human_tasks_for_user(
                user_id, TaskInstanceStatus.COMPLETED, limit
            )
            
            # è¿‡æ»¤æŒ‡å®šå¤©æ•°å†…çš„ä»»åŠ¡
            cutoff_date = datetime.now() - timedelta(days=days)
            recent_tasks = []
            
            for task in tasks:
                if task.get('completed_at'):
                    completed_at = datetime.fromisoformat(task['completed_at'].replace('Z', '+00:00'))
                    if completed_at.replace(tzinfo=None) >= cutoff_date:
                        recent_tasks.append(task)
            
            logger.info(f"è·å–ç”¨æˆ· {user_id} çš„ä»»åŠ¡å†å²ï¼Œ{days}å¤©å†…å…± {len(recent_tasks)} ä¸ªä»»åŠ¡")
            return recent_tasks
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡å†å²å¤±è´¥: {e}")
            raise
    
    async def get_task_statistics(self, user_id: uuid.UUID) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·ä»»åŠ¡ç»Ÿè®¡"""
        try:
            # è·å–ç”¨æˆ·æ‰€æœ‰ä»»åŠ¡
            all_tasks = await self.task_repo.get_human_tasks_for_user(user_id, None, 1000)
            
            # ç»Ÿè®¡å„ç§çŠ¶æ€çš„ä»»åŠ¡æ•°é‡
            stats = {
                'total_tasks': len(all_tasks),
                'pending_tasks': 0,
                'assigned_tasks': 0,
                'in_progress_tasks': 0,
                'completed_tasks': 0,
                'failed_tasks': 0,
                'cancelled_tasks': 0,
                'average_completion_time': 0,
                'completion_rate': 0
            }
            
            total_duration = 0
            completed_count = 0
            
            for task in all_tasks:
                status = task['status']
                if status == TaskInstanceStatus.PENDING.value:
                    stats['pending_tasks'] += 1
                elif status == TaskInstanceStatus.ASSIGNED.value:
                    stats['assigned_tasks'] += 1
                elif status == TaskInstanceStatus.IN_PROGRESS.value:
                    stats['in_progress_tasks'] += 1
                elif status == TaskInstanceStatus.COMPLETED.value:
                    stats['completed_tasks'] += 1
                    completed_count += 1
                    if task.get('actual_duration'):
                        total_duration += task['actual_duration']
                elif status == TaskInstanceStatus.FAILED.value:
                    stats['failed_tasks'] += 1
                elif status == TaskInstanceStatus.CANCELLED.value:
                    stats['cancelled_tasks'] += 1
            
            # è®¡ç®—å¹³å‡å®Œæˆæ—¶é—´å’Œå®Œæˆç‡
            if completed_count > 0:
                stats['average_completion_time'] = total_duration / completed_count
                stats['completion_rate'] = (completed_count / len(all_tasks)) * 100
            
            logger.info(f"ç”Ÿæˆç”¨æˆ· {user_id} çš„ä»»åŠ¡ç»Ÿè®¡")
            return stats
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {e}")
            raise
    
    async def _enrich_task_info(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸°å¯Œä»»åŠ¡ä¿¡æ¯"""
        try:
            # è®¡ç®—ä»»åŠ¡ä¼˜å…ˆçº§æ ‡ç­¾
            priority = task.get('priority', 0)
            if priority >= 3:
                task['priority_label'] = 'é«˜ä¼˜å…ˆçº§'
            elif priority >= 2:
                task['priority_label'] = 'ä¸­ä¼˜å…ˆçº§'
            else:
                task['priority_label'] = 'ä½ä¼˜å…ˆçº§'
            
            # è®¡ç®—ä»»åŠ¡è€—æ—¶
            if task.get('started_at') and task.get('completed_at'):
                try:
                    # å¤„ç†ä¸åŒç±»å‹çš„æ—¶é—´æ•°æ®
                    started_at = task['started_at']
                    completed_at = task['completed_at']
                    
                    if isinstance(started_at, str):
                        start_time = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
                    else:
                        start_time = started_at
                    
                    if isinstance(completed_at, str):
                        end_time = datetime.fromisoformat(completed_at.replace('Z', '+00:00'))
                    else:
                        end_time = completed_at
                    
                    task['total_duration'] = int((end_time - start_time).total_seconds() / 60)
                except Exception as time_error:
                    logger.error(f"è®¡ç®—æ€»è€—æ—¶å¤±è´¥: {time_error}")
                    task['total_duration'] = 0
                    
            elif task.get('started_at') and task['status'] == TaskInstanceStatus.IN_PROGRESS.value:
                try:
                    started_at = task['started_at']
                    
                    if isinstance(started_at, str):
                        start_time = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
                    else:
                        start_time = started_at
                    
                    now_time = datetime.now().replace(tzinfo=start_time.tzinfo if start_time.tzinfo else None)
                    task['current_duration'] = int((now_time - start_time).total_seconds() / 60)
                except Exception as time_error:
                    logger.error(f"è®¡ç®—å½“å‰è€—æ—¶å¤±è´¥: {time_error}")
                    task['current_duration'] = 0
            
            # æ·»åŠ æˆªæ­¢æ—¶é—´ï¼ˆåŸºäºä¼°è®¡æ—¶é•¿ï¼‰
            if task.get('created_at') and task.get('estimated_duration'):
                try:
                    created_at = task['created_at']
                    
                    if isinstance(created_at, str):
                        created_time = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                    else:
                        created_time = created_at
                    
                    estimated_minutes = task['estimated_duration']
                    task['estimated_deadline'] = (created_time + timedelta(minutes=estimated_minutes)).isoformat()
                except Exception as time_error:
                    logger.error(f"è®¡ç®—æˆªæ­¢æ—¶é—´å¤±è´¥: {time_error}")
                    task['estimated_deadline'] = None
            
            return task
            
        except Exception as e:
            logger.error(f"ä¸°å¯Œä»»åŠ¡ä¿¡æ¯å¤±è´¥: {e}")
            return task
    
    async def _handle_task_completion_through_context_manager(self, task: dict, updated_task: dict, output_data: str = None):
        """é€šè¿‡WorkflowContextManagerç»Ÿä¸€å¤„ç†ä»»åŠ¡å®Œæˆ"""
        try:
            logger.info(f"ğŸ”„ é€šè¿‡ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¤„ç†ä»»åŠ¡å®Œæˆ: {task['task_instance_id']}")
            
            # è·å–èŠ‚ç‚¹åŸºç¡€ä¿¡æ¯ç”¨äºmark_node_completed
            node_query = '''
            SELECT n.node_id 
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.node_instance_id = $1
            '''
            node_info = await self.task_repo.db.fetch_one(node_query, task['node_instance_id'])
            
            if not node_info:
                logger.error(f"âŒ æ— æ³•æ‰¾åˆ°èŠ‚ç‚¹ä¿¡æ¯: {task['node_instance_id']}")
                return
            
            # æ„é€ è¾“å‡ºæ•°æ®
            output_data = {
                "message": "äººå·¥ä»»åŠ¡å®Œæˆ",
                "task_type": "human",
                "output_data": output_data if output_data else "{}",
                "completed_at": updated_task.get('completed_at').isoformat() if updated_task.get('completed_at') else None
            }
            
            # ä½¿ç”¨WorkflowContextManagerç»Ÿä¸€å¤„ç†ä»»åŠ¡å®Œæˆ
            await self.context_manager.mark_node_completed(
                workflow_instance_id=task['workflow_instance_id'],
                node_id=node_info['node_id'],
                node_instance_id=task['node_instance_id'],
                output_data=output_data
            )
            
            logger.info(f"âœ… ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†å™¨å·²å®Œæˆä»»åŠ¡å¤„ç†")
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¤„ç†å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    
    async def cancel_workflow_instance(self, instance_id: uuid.UUID, user_id: uuid.UUID, 
                                     cancel_reason: str = "ç”¨æˆ·å–æ¶ˆ") -> Dict[str, Any]:
        """å–æ¶ˆå·¥ä½œæµå®ä¾‹å¹¶çº§è”å–æ¶ˆæ‰€æœ‰ç›¸å…³ä»»åŠ¡"""
        try:
            logger.info(f"ğŸš« å¼€å§‹å–æ¶ˆå·¥ä½œæµå®ä¾‹:")
            logger.info(f"  å®ä¾‹ID: {instance_id}")
            logger.info(f"  æ“ä½œç”¨æˆ·: {user_id}")
            logger.info(f"  å–æ¶ˆåŸå› : {cancel_reason}")
            
            # 1. éªŒè¯å·¥ä½œæµå®ä¾‹æ˜¯å¦å­˜åœ¨å’Œæƒé™
            workflow_query = '''
            SELECT workflow_instance_id, executor_id, status, workflow_instance_name
            FROM workflow_instance 
            WHERE workflow_instance_id = $1 AND is_deleted = FALSE
            '''
            workflow = await self.task_repo.db.fetch_one(workflow_query, instance_id)
            
            if not workflow:
                logger.error(f"âŒ å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨: {instance_id}")
                raise ValueError("å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨")
            
            logger.info(f"âœ… å·¥ä½œæµå®ä¾‹æŸ¥è¯¢æˆåŠŸ:")
            logger.info(f"  å®ä¾‹åç§°: {workflow['workflow_instance_name']}")
            logger.info(f"  å½“å‰çŠ¶æ€: {workflow['status']}")
            logger.info(f"  æ‰§è¡Œè€…: {workflow['executor_id']}")
            
            # æ£€æŸ¥æƒé™ï¼ˆåªæœ‰æ‰§è¡Œè€…æˆ–ç®¡ç†å‘˜å¯ä»¥å–æ¶ˆï¼‰
            if workflow['executor_id'] != user_id:
                # TODO: è¿™é‡Œå¯ä»¥æ·»åŠ ç®¡ç†å‘˜æƒé™æ£€æŸ¥
                logger.error(f"âŒ æ— æƒå–æ¶ˆå·¥ä½œæµ: æ‰§è¡Œè€… {workflow['executor_id']}ï¼Œæ“ä½œè€… {user_id}")
                raise PermissionError("æ— æƒå–æ¶ˆæ­¤å·¥ä½œæµå®ä¾‹")
            
            # æ£€æŸ¥çŠ¶æ€æ˜¯å¦å…è®¸å–æ¶ˆ
            if workflow['status'] in ['completed', 'failed', 'cancelled']:
                logger.error(f"âŒ å·¥ä½œæµçŠ¶æ€ä¸å…è®¸å–æ¶ˆ: {workflow['status']}")
                raise ValueError(f"å·¥ä½œæµçŠ¶æ€ä¸å…è®¸å–æ¶ˆï¼Œå½“å‰çŠ¶æ€: {workflow['status']}")
            
            # 2. è·å–å·¥ä½œæµä¸‹çš„æ‰€æœ‰ä»»åŠ¡å®ä¾‹
            tasks_query = '''
            SELECT ti.task_instance_id, ti.status, ti.task_title, ti.assigned_user_id,
                   ni.node_instance_id, ni.node_name
            FROM task_instance ti
            JOIN node_instance ni ON ti.node_instance_id = ni.node_instance_id
            WHERE ni.workflow_instance_id = $1 AND ti.is_deleted = FALSE
            '''
            tasks = await self.task_repo.db.fetch_all(tasks_query, instance_id)
            
            logger.info(f"ğŸ“‹ å·¥ä½œæµä¸‹çš„ä»»åŠ¡æ•°é‡: {len(tasks)}")
            
            # 3. æ‰¹é‡å–æ¶ˆæ‰€æœ‰ç›¸å…³ä»»åŠ¡
            cancelled_tasks = []
            for task in tasks:
                task_id = task['task_instance_id']
                task_status = task['status']
                
                logger.info(f"  å¤„ç†ä»»åŠ¡: {task['task_title']} (çŠ¶æ€: {task_status})")
                
                # åªå–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
                if task_status not in ['completed', 'failed', 'cancelled']:
                    try:
                        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å–æ¶ˆ
                        update_task_query = '''
                        UPDATE task_instance 
                        SET status = 'cancelled', 
                            result_summary = $1,
                            updated_at = $2
                        WHERE task_instance_id = $3
                        '''
                        from ..utils.helpers import now_utc
                        await self.task_repo.db.execute(
                            update_task_query, 
                            f"å·¥ä½œæµå–æ¶ˆ: {cancel_reason}", 
                            now_utc(), 
                            task_id
                        )
                        
                        cancelled_tasks.append({
                            'task_id': task_id,
                            'task_title': task['task_title'],
                            'previous_status': task_status,
                            'assigned_user_id': task['assigned_user_id']
                        })
                        
                        logger.info(f"    âœ… ä»»åŠ¡å·²å–æ¶ˆ: {task['task_title']}")
                        
                    except Exception as task_error:
                        logger.error(f"    âŒ å–æ¶ˆä»»åŠ¡å¤±è´¥: {task_error}")
                else:
                    logger.info(f"    â­ï¸ ä»»åŠ¡å·²å®Œæˆï¼Œè·³è¿‡: {task['task_title']}")
            
            # 4. æ›´æ–°æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹çŠ¶æ€ä¸ºå·²å–æ¶ˆ
            nodes_query = '''
            UPDATE node_instance 
            SET status = 'cancelled', updated_at = $1
            WHERE workflow_instance_id = $2 AND status NOT IN ('completed', 'failed')
            '''
            from ..utils.helpers import now_utc
            await self.task_repo.db.execute(nodes_query, now_utc(), instance_id)
            logger.info(f"  âœ… èŠ‚ç‚¹å®ä¾‹çŠ¶æ€å·²æ›´æ–°ä¸ºcancelled")
            
            # 5. æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºå·²å–æ¶ˆ
            workflow_update_query = '''
            UPDATE workflow_instance 
            SET status = 'cancelled', 
                error_message = $1,
                updated_at = $2
            WHERE workflow_instance_id = $3
            '''
            await self.task_repo.db.execute(
                workflow_update_query, 
                cancel_reason, 
                now_utc(), 
                instance_id
            )
            logger.info(f"  âœ… å·¥ä½œæµå®ä¾‹çŠ¶æ€å·²æ›´æ–°ä¸ºcancelled")
            
            # 6. è¿”å›å–æ¶ˆç»“æœ
            result = {
                'workflow_instance_id': instance_id,
                'status': 'cancelled',
                'cancel_reason': cancel_reason,
                'cancelled_tasks_count': len(cancelled_tasks),
                'cancelled_tasks': cancelled_tasks,
                'cancelled_at': now_utc().isoformat(),
                'message': f'å·¥ä½œæµå®ä¾‹å·²å–æ¶ˆï¼Œå…±å–æ¶ˆ {len(cancelled_tasks)} ä¸ªä»»åŠ¡'
            }
            
            logger.info(f"ğŸ¯ å·¥ä½œæµå–æ¶ˆå®Œæˆ:")
            logger.info(f"  å–æ¶ˆçš„ä»»åŠ¡æ•°é‡: {len(cancelled_tasks)}")
            logger.info(f"  ç»“æœ: {result}")
            
            return result
            
        except Exception as e:
            logger.error(f"ğŸ’¥ å–æ¶ˆå·¥ä½œæµå®ä¾‹å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def _notify_task_rejected(self, task_id: uuid.UUID, reject_reason: str):
        """é€šçŸ¥å·¥ä½œæµå¼•æ“ä»»åŠ¡è¢«æ‹’ç»"""
        try:
            logger.info(f"ä»»åŠ¡ {task_id} è¢«æ‹’ç»: {reject_reason}")
            
            # è¿™é‡Œå¯ä»¥å®ç°ä»¥ä¸‹é€»è¾‘ï¼š
            # 1. é€šçŸ¥å·¥ä½œæµå¼•æ“ä»»åŠ¡å¤±è´¥
            # 2. å¯èƒ½éœ€è¦é‡æ–°åˆ†é…ä»»åŠ¡ç»™å…¶ä»–ç”¨æˆ·
            # 3. æˆ–è€…æ ‡è®°æ•´ä¸ªå·¥ä½œæµä¸ºå¤±è´¥çŠ¶æ€
            # 4. å‘é€é€šçŸ¥ç»™ç®¡ç†å‘˜æˆ–å…¶ä»–ç›¸å…³äººå‘˜
            
        except Exception as e:
            logger.error(f"é€šçŸ¥ä»»åŠ¡æ‹’ç»å¤±è´¥: {e}")
    
    async def _notify_task_cancelled(self, task_id: uuid.UUID, cancel_reason: str):
        """é€šçŸ¥å·¥ä½œæµå¼•æ“ä»»åŠ¡è¢«å–æ¶ˆ"""
        try:
            logger.info(f"ä»»åŠ¡ {task_id} è¢«å–æ¶ˆ: {cancel_reason}")
            
            # è¿™é‡Œå¯ä»¥å®ç°ä»¥ä¸‹é€»è¾‘ï¼š
            # 1. é€šçŸ¥å·¥ä½œæµå¼•æ“ä»»åŠ¡è¢«å–æ¶ˆ
            # 2. å¯èƒ½éœ€è¦æš‚åœæˆ–å–æ¶ˆæ•´ä¸ªå·¥ä½œæµå®ä¾‹
            # 3. æ¸…ç†ç›¸å…³èµ„æº
            # 4. å‘é€é€šçŸ¥ç»™ç›¸å…³äººå‘˜
            
        except Exception as e:
            logger.error(f"é€šçŸ¥ä»»åŠ¡å–æ¶ˆå¤±è´¥: {e}")
    
    async def assign_task_to_user(self, task_id: uuid.UUID, user_id: uuid.UUID, 
                                assigner_id: uuid.UUID) -> Dict[str, Any]:
        """å°†ä»»åŠ¡åˆ†é…ç»™ç”¨æˆ·ï¼ˆç®¡ç†å‘˜åŠŸèƒ½ï¼‰"""
        try:
            # éªŒè¯åˆ†é…è€…æƒé™ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
            assigner = await self.user_repo.get_user_by_id(assigner_id)
            if not assigner or assigner.get('role') not in ['admin', 'manager']:
                raise PermissionError("æ— æƒåˆ†é…ä»»åŠ¡")
            
            # éªŒè¯è¢«åˆ†é…ç”¨æˆ·å­˜åœ¨
            assignee = await self.user_repo.get_user_by_id(user_id)
            if not assignee:
                raise ValueError("è¢«åˆ†é…ç”¨æˆ·ä¸å­˜åœ¨")
            
            # è·å–ä»»åŠ¡ä¿¡æ¯éªŒè¯ç±»å‹
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            # éªŒè¯ä»»åŠ¡ç±»å‹ï¼šåªæœ‰HUMANå’ŒMIXEDç±»å‹å¯ä»¥åˆ†é…ç»™ç”¨æˆ·
            if task.get('task_type') not in [TaskInstanceType.HUMAN.value, TaskInstanceType.MIXED.value]:
                raise ValueError(f"ä»»åŠ¡ç±»å‹ {task.get('task_type')} ä¸èƒ½åˆ†é…ç»™ç”¨æˆ·")
            
            # ä½¿ç”¨ç°æœ‰çš„åˆ†é…æ–¹æ³•ï¼ˆä¿æŒä¸ç°æœ‰æ¶æ„ä¸€è‡´ï¼‰
            result = await self.task_repo.assign_task_to_user(task_id, user_id)
            
            if result:
                logger.info(f"ç®¡ç†å‘˜ {assigner_id} å°†ä»»åŠ¡ {task_id} åˆ†é…ç»™ç”¨æˆ· {user_id}")
                return {
                    'task_id': task_id,
                    'assigned_user_id': user_id,
                    'assigned_user_name': assignee.get('username'),
                    'message': 'ä»»åŠ¡åˆ†é…æˆåŠŸ'
                }
            else:
                raise RuntimeError("ä»»åŠ¡åˆ†é…å¤±è´¥")
                
        except Exception as e:
            logger.error(f"åˆ†é…ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _check_downstream_tasks(self, task_id: uuid.UUID):
        """æ£€æŸ¥ä¸‹æ¸¸ä»»åŠ¡ - å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶çš„æ ¸å¿ƒè§¦å‘ç‚¹"""
        try:
            logger.info(f"ğŸ”„ æ£€æŸ¥ä¸‹æ¸¸ä»»åŠ¡: {task_id}")
            
            # 1. è·å–ä»»åŠ¡ä¿¡æ¯å’Œç›¸å…³èŠ‚ç‚¹å®ä¾‹
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                logger.error(f"âŒ ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                return
            
            node_instance_id = task['node_instance_id']
            logger.info(f"  ä»»åŠ¡æ‰€å±èŠ‚ç‚¹å®ä¾‹: {node_instance_id}")
            
            # 2. è·å–èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯
            node_query = '''
            SELECT ni.workflow_instance_id, ni.node_id, ni.status as node_status,
                   n.name as node_name, n.type as node_type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.node_instance_id = $1
            '''
            node_result = await self.task_repo.db.fetch_one(node_query, node_instance_id)
            
            if not node_result:
                logger.error(f"âŒ èŠ‚ç‚¹å®ä¾‹ä¸å­˜åœ¨: {node_instance_id}")
                return
            
            workflow_instance_id = node_result['workflow_instance_id']
            node_name = node_result['node_name']
            logger.info(f"  èŠ‚ç‚¹: {node_name}, å·¥ä½œæµå®ä¾‹: {workflow_instance_id}")
            
            # 3. æ£€æŸ¥è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰ä»»åŠ¡æ˜¯å¦éƒ½å·²å®Œæˆ
            node_tasks_query = '''
            SELECT task_instance_id, status, task_title
            FROM task_instance
            WHERE node_instance_id = $1 AND is_deleted = FALSE
            '''
            node_tasks = await self.task_repo.db.fetch_all(node_tasks_query, node_instance_id)
            
            logger.info(f"  èŠ‚ç‚¹ {node_name} çš„ä»»åŠ¡æ€»æ•°: {len(node_tasks)}")
            
            completed_tasks = [t for t in node_tasks if t['status'] == 'completed']
            failed_tasks = [t for t in node_tasks if t['status'] == 'failed']
            
            logger.info(f"    å·²å®Œæˆä»»åŠ¡: {len(completed_tasks)}")
            logger.info(f"    å¤±è´¥ä»»åŠ¡: {len(failed_tasks)}")
            
            # 4. å¦‚æœæ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆï¼Œæ›´æ–°èŠ‚ç‚¹çŠ¶æ€å¹¶è§¦å‘ä¸‹æ¸¸æ£€æŸ¥
            if len(completed_tasks) == len(node_tasks) and len(node_tasks) > 0:
                logger.info(f"  âœ… èŠ‚ç‚¹ {node_name} çš„æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œæ›´æ–°èŠ‚ç‚¹çŠ¶æ€")
                
                # æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€ä¸ºå·²å®Œæˆ
                await self._update_node_instance_status(node_instance_id, 'completed')
                
                # è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹çš„ä»»åŠ¡åˆ›å»ºæ£€æŸ¥
                from ..services.execution_service import execution_engine
                await execution_engine._check_downstream_nodes_for_task_creation(workflow_instance_id)
                
                # æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€
                await execution_engine._check_workflow_completion(workflow_instance_id)
                
                logger.info(f"  ğŸ¯ ä¸‹æ¸¸ä»»åŠ¡æ£€æŸ¥å·²è§¦å‘")
                
            elif len(failed_tasks) > 0:
                logger.info(f"  âŒ èŠ‚ç‚¹ {node_name} æœ‰ä»»åŠ¡å¤±è´¥ï¼Œæ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå¤±è´¥")
                await self._update_node_instance_status(node_instance_id, 'failed')
                
                # æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€ï¼ˆå¯èƒ½æ ‡è®°ä¸ºå¤±è´¥ï¼‰
                from ..services.execution_service import execution_engine
                await execution_engine._check_workflow_completion(workflow_instance_id)
                
            else:
                logger.info(f"  â³ èŠ‚ç‚¹ {node_name} è¿˜æœ‰ä»»åŠ¡æœªå®Œæˆï¼Œç­‰å¾…ä¸­")
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ä¸‹æ¸¸ä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _update_node_instance_status(self, node_instance_id: uuid.UUID, status: str):
        """æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€"""
        try:
            logger.info(f"ğŸ“ æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€: {node_instance_id} -> {status}")
            
            from ..utils.helpers import now_utc
            update_query = '''
            UPDATE node_instance 
            SET status = $1, updated_at = $2
            WHERE node_instance_id = $3
            '''
            await self.task_repo.db.execute(update_query, status, now_utc(), node_instance_id)
            logger.info(f"  âœ… èŠ‚ç‚¹å®ä¾‹çŠ¶æ€æ›´æ–°æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€å¤±è´¥: {e}")
            raise
    
    def _format_data_to_string(self, data) -> str:
        """å°†ä»»æ„æ•°æ®æ ¼å¼åŒ–ä¸ºçº¯æ–‡æœ¬å­—ç¬¦ä¸²"""
        if data is None:
            return "æ— ç»“æœæ•°æ®"
        
        if isinstance(data, str):
            return data.strip()
        
        if isinstance(data, dict):
            # å°è¯•æå–æœ‰æ„ä¹‰çš„æ–‡æœ¬å†…å®¹
            text_fields = ['result', 'content', 'message', 'answer', 'output', 'description', 'summary']
            for field in text_fields:
                if field in data and data[field]:
                    return str(data[field]).strip()
            
            # å¦‚æœæ²¡æœ‰æ ‡å‡†å­—æ®µï¼Œå°†å­—å…¸è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬
            parts = []
            for key, value in data.items():
                if value is not None and str(value).strip():
                    parts.append(f"{key}: {value}")
            return "; ".join(parts) if parts else "ä»»åŠ¡å®Œæˆ"
        
        if isinstance(data, list):
            # å°†åˆ—è¡¨è½¬æ¢ä¸ºæ–‡æœ¬
            if all(isinstance(item, str) for item in data):
                return "; ".join(data)
            else:
                return "; ".join(str(item) for item in data)
        
        return str(data).strip()
    
    def _parse_context_data(self, context_data_str: str) -> dict:
        """è§£æcontext_data JSONå­—ç¬¦ä¸²ä¸ºå­—å…¸å¯¹è±¡"""
        if not context_data_str or not context_data_str.strip():
            return {}
        
        try:
            import json
            parsed_data = json.loads(context_data_str)
            logger.debug(f"æˆåŠŸè§£æcontext_data: {len(context_data_str)} å­—ç¬¦")
            return parsed_data if isinstance(parsed_data, dict) else {}
        except json.JSONDecodeError as e:
            logger.warning(f"è§£æcontext_data JSONå¤±è´¥: {e}")
            return {}
        except Exception as e:
            logger.warning(f"å¤„ç†context_dataæ—¶å‡ºé”™: {e}")
            return {}
    
    def _create_enhanced_description(self, original_description: str, 
                                   parsed_context: dict, 
                                   upstream_context: dict) -> str:
        """åˆ›å»ºå¢å¼ºçš„ä»»åŠ¡æè¿°ï¼Œç»“åˆåŸå§‹æè¿°å’Œä¸Šæ¸¸ä¸Šä¸‹æ–‡"""
        if not original_description:
            original_description = "è¯·å®Œæˆæ­¤ä»»åŠ¡"
        
        enhanced_parts = [original_description]
        
        # æ·»åŠ å·¥ä½œæµä¸Šä¸‹æ–‡ä¿¡æ¯
        if parsed_context.get('workflow'):
            workflow_info = parsed_context['workflow']
            if workflow_info.get('name'):
                enhanced_parts.append(f"\nğŸ“‹ **å·¥ä½œæµ**: {workflow_info['name']}")
                if workflow_info.get('workflow_instance_name'):
                    enhanced_parts.append(f"   å®ä¾‹: {workflow_info['workflow_instance_name']}")
        
        # æ·»åŠ ä¸Šæ¸¸èŠ‚ç‚¹è¾“å‡ºä¿¡æ¯
        upstream_outputs = parsed_context.get('upstream_outputs', [])
        if upstream_outputs:
            enhanced_parts.append(f"\nğŸ”— **ä¸Šæ¸¸èŠ‚ç‚¹è¾“å‡º** ({len(upstream_outputs)}ä¸ª):")
            for i, output in enumerate(upstream_outputs[:3], 1):  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                node_name = output.get('node_name', f'èŠ‚ç‚¹{i}')
                if output.get('output_data'):
                    # å°è¯•è§£æè¾“å‡ºæ•°æ®
                    try:
                        import json
                        output_data = json.loads(output['output_data']) if isinstance(output['output_data'], str) else output['output_data']
                        if isinstance(output_data, dict):
                            # è·å–æœ€é‡è¦çš„å­—æ®µæ˜¾ç¤º
                            key_fields = ['result', 'answer', 'output', 'content', 'message']
                            display_value = None
                            for field in key_fields:
                                if field in output_data:
                                    display_value = str(output_data[field])[:100]
                                    break
                            if not display_value and output_data:
                                # å–ç¬¬ä¸€ä¸ªéç©ºå€¼
                                for key, value in output_data.items():
                                    if value and str(value).strip():
                                        display_value = f"{key}: {str(value)[:100]}"
                                        break
                            if display_value:
                                enhanced_parts.append(f"   {i}. **{node_name}**: {display_value}")
                            else:
                                enhanced_parts.append(f"   {i}. **{node_name}**: å·²å®Œæˆ")
                        else:
                            enhanced_parts.append(f"   {i}. **{node_name}**: {str(output_data)[:100]}")
                    except:
                        enhanced_parts.append(f"   {i}. **{node_name}**: {str(output.get('output_data', ''))[:100]}")
                else:
                    enhanced_parts.append(f"   {i}. **{node_name}**: å·²å®Œæˆ")
            
            if len(upstream_outputs) > 3:
                enhanced_parts.append(f"   ... è¿˜æœ‰ {len(upstream_outputs) - 3} ä¸ªä¸Šæ¸¸èŠ‚ç‚¹")
        
        # æ·»åŠ å½“å‰èŠ‚ç‚¹ä¿¡æ¯
        if parsed_context.get('current_node'):
            current_node = parsed_context['current_node']
            if current_node.get('name'):
                enhanced_parts.append(f"\nğŸ¯ **å½“å‰èŠ‚ç‚¹**: {current_node['name']}")
                if current_node.get('description'):
                    enhanced_parts.append(f"   è¯´æ˜: {current_node['description']}")
        
        return '\n'.join(enhanced_parts)
    
    def _parse_context_data(self, context_data: str) -> dict:
        """è§£æä¸Šä¸‹æ–‡æ•°æ®å­—ç¬¦ä¸²ä¸ºç»“æ„åŒ–å¯¹è±¡"""
        try:
            if not context_data:
                return {}
            
            # å¦‚æœå·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥è¿”å›
            if isinstance(context_data, dict):
                return context_data
            
            # å°è¯•è§£æJSONå­—ç¬¦ä¸²
            if isinstance(context_data, str):
                import json
                try:
                    parsed = json.loads(context_data)
                    logger.info(f"æˆåŠŸè§£æcontext_dataï¼ŒåŒ…å«é”®: {list(parsed.keys()) if isinstance(parsed, dict) else 'not dict'}")
                    return parsed if isinstance(parsed, dict) else {}
                except json.JSONDecodeError as e:
                    logger.warning(f"æ— æ³•è§£æcontext_dataä¸ºJSON: {e}")
                    return {}
            
            logger.warning(f"ä¸æ”¯æŒçš„context_dataç±»å‹: {type(context_data)}")
            return {}
            
        except Exception as e:
            logger.error(f"è§£æcontext_dataå¤±è´¥: {e}")
            return {}
    


    async def _send_feishu_notifications(self, user_id: uuid.UUID, tasks: List[Dict[str, Any]]):
        """å‘é€é£ä¹¦æœºå™¨äººé€šçŸ¥"""
        try:
            if not tasks:
                return
            
            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_info = await self.user_repo.get_user_by_id(user_id)
            if not user_info:
                logger.warning(f"ç”¨æˆ· {user_id} ä¸å­˜åœ¨ï¼Œæ— æ³•å‘é€é£ä¹¦é€šçŸ¥")
                return
            
            # ä¸ºæ¯ä¸ªä»»åŠ¡å‘é€é€šçŸ¥
            for task in tasks:
                task_info = {
                    "task_title": task.get("task_title", "æœªå‘½åä»»åŠ¡"),
                    "workflow_name": task.get("workflow_name", "æœªçŸ¥å·¥ä½œæµ"),
                    "priority": task.get("priority", "æ™®é€š"),
                    "deadline": task.get("deadline"),
                    "status": task.get("status")
                }
                
                # å‘é€é£ä¹¦é€šçŸ¥
                await feishu_bot_service.send_task_notification(str(user_id), task_info)
            
            logger.info(f"æˆåŠŸå‘é€ {len(tasks)} ä¸ªä»»åŠ¡çš„é£ä¹¦é€šçŸ¥ç»™ç”¨æˆ· {user_id}")
            
        except Exception as e:
            logger.error(f"å‘é€é£ä¹¦é€šçŸ¥å¤±è´¥: {e}")
