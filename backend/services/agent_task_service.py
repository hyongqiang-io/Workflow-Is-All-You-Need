"""
Agentä»»åŠ¡å¤„ç†æœåŠ¡
Agent Task Processing Service
"""

import uuid
import json
import sys
import asyncio
from typing import Optional, Dict, Any, List
from datetime import datetime
from loguru import logger
logger.remove()
logger.add(sys.stderr, level="DEBUG", enqueue=True)  # ä¿®å¤Windows GBKç¼–ç é—®é¢˜

from ..repositories.instance.task_instance_repository import TaskInstanceRepository
from ..repositories.agent.agent_repository import AgentRepository
from ..models.instance import (
    TaskInstanceUpdate, TaskInstanceStatus, TaskInstanceType
)
from ..utils.helpers import now_utc
from ..utils.openai_client import openai_client
from .mcp_service import mcp_service


class AgentTaskService:
    """Agentä»»åŠ¡å¤„ç†æœåŠ¡"""
    
    def __init__(self):
        self.task_repo = TaskInstanceRepository()
        self.agent_repo = AgentRepository()
        
        # Agentä»»åŠ¡å¤„ç†é˜Ÿåˆ—
        self.processing_queue = asyncio.Queue()
        self.is_running = False
        self.max_concurrent_tasks = 5
        
        # ä»»åŠ¡å®Œæˆå›è°ƒåˆ—è¡¨
        self.completion_callbacks = []
    
    def register_completion_callback(self, callback):
        """æ³¨å†Œä»»åŠ¡å®Œæˆå›è°ƒ"""
        self.completion_callbacks.append(callback)
        logger.trace(f"æ³¨å†Œä»»åŠ¡å®Œæˆå›è°ƒ: {callback}")
    
    async def _notify_task_completion(self, task_id: uuid.UUID, result: Dict[str, Any]):
        """é€šçŸ¥ä»»åŠ¡å®Œæˆ"""
        try:
            for callback in self.completion_callbacks:
                try:
                    await callback.on_task_completed(task_id, result)
                except Exception as e:
                    logger.error(f"å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"é€šçŸ¥ä»»åŠ¡å®Œæˆå¤±è´¥: {e}")
    
    async def _notify_task_failure(self, task_id: uuid.UUID, error_message: str):
        """é€šçŸ¥ä»»åŠ¡å¤±è´¥"""
        try:
            for callback in self.completion_callbacks:
                try:
                    await callback.on_task_failed(task_id, error_message)
                except Exception as e:
                    logger.error(f"å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"é€šçŸ¥ä»»åŠ¡å¤±è´¥å¤±è´¥: {e}")
    
    async def start_service(self):
        """å¯åŠ¨Agentä»»åŠ¡å¤„ç†æœåŠ¡"""
        if self.is_running:
            logger.warning("Agentä»»åŠ¡å¤„ç†æœåŠ¡å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.is_running = True
        logger.trace("Agentä»»åŠ¡å¤„ç†æœåŠ¡å¯åŠ¨")
        
        # å¯åŠ¨ä»»åŠ¡å¤„ç†åç¨‹
        for i in range(self.max_concurrent_tasks):
            asyncio.create_task(self._process_agent_tasks())
        
        # å¯åŠ¨ä»»åŠ¡ç›‘æ§åç¨‹
        asyncio.create_task(self._monitor_pending_tasks())
    
    async def stop_service(self):
        """åœæ­¢Agentä»»åŠ¡å¤„ç†æœåŠ¡"""
        self.is_running = False
        logger.trace("Agentä»»åŠ¡å¤„ç†æœåŠ¡åœæ­¢")
    
    async def _has_active_workflows(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒçš„å·¥ä½œæµ"""
        try:
            from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
            workflow_repo = WorkflowInstanceRepository()
            
            # æŸ¥è¯¢è¿è¡Œä¸­çš„å·¥ä½œæµ
            active_workflows = await workflow_repo.db.fetch_all("""
                SELECT workflow_instance_id, status 
                FROM workflow_instance 
                WHERE status IN ('RUNNING', 'PENDING') 
                AND is_deleted = FALSE
                LIMIT 1
            """)
            
            return len(active_workflows) > 0
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ´»è·ƒå·¥ä½œæµå¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶å‡è®¾æœ‰æ´»è·ƒå·¥ä½œæµï¼Œç»§ç»­ç›‘æ§
    
    async def get_pending_agent_tasks(self, agent_id: Optional[uuid.UUID] = None, 
                                    limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–å¾…å¤„ç†çš„Agentä»»åŠ¡"""
        try:
            logger.trace(f"ğŸ” [AGENT-SERVICE] å¼€å§‹è·å–å¾…å¤„ç†Agentä»»åŠ¡")
            logger.trace(f"   - Agent ID: {agent_id if agent_id else 'æ‰€æœ‰Agent'}")  
            logger.trace(f"   - é™åˆ¶æ•°é‡: {limit}")
            
            tasks = await self.task_repo.get_agent_tasks_for_processing(agent_id, limit)
            
            logger.trace(f"ğŸ“‹ [AGENT-SERVICE] è·å–å¾…å¤„ç†Agentä»»åŠ¡å®Œæˆ")
            logger.trace(f"   - æ‰¾åˆ°ä»»åŠ¡æ•°é‡: {len(tasks)}")
            
            if tasks:
                logger.trace(f"   - ä»»åŠ¡è¯¦æƒ…:")
                for i, task in enumerate(tasks[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªä»»åŠ¡
                    task_id = task.get('task_instance_id', 'unknown')
                    task_title = task.get('task_title', 'unknown')
                    task_status = task.get('status', 'unknown')
                    logger.trace(f"     {i+1}. {task_title} (ID: {task_id}, çŠ¶æ€: {task_status})")
                if len(tasks) > 3:
                    logger.trace(f"     ... è¿˜æœ‰ {len(tasks) - 3} ä¸ªä»»åŠ¡")
            else:
                # å‡å°‘æ—¥å¿—é¢‘ç‡ï¼Œé¿å…åˆ·å±
                pass  # åœ¨ç›‘æ§å™¨ä¸­ä¼šç»Ÿä¸€å¤„ç†ç©ºæ£€æŸ¥çš„æ—¥å¿—
                
            return tasks
            
        except Exception as e:
            logger.error(f"âŒ [AGENT-SERVICE] è·å–å¾…å¤„ç†Agentä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            logger.error(f"   - é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def submit_task_to_agent(self, task_id: uuid.UUID) -> Dict[str, Any]:
        """å°†ä»»åŠ¡æäº¤ç»™Agentå¤„ç†"""
        try:
            # è·å–ä»»åŠ¡ä¿¡æ¯
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            # éªŒè¯ä»»åŠ¡ç±»å‹å’ŒçŠ¶æ€
            if task['task_type'] not in [TaskInstanceType.AGENT.value, TaskInstanceType.MIXED.value]:
                raise ValueError("ä»»åŠ¡ç±»å‹ä¸æ”¯æŒAgentå¤„ç†")
            
            if task['status'] != TaskInstanceStatus.PENDING.value:
                raise ValueError(f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æäº¤ç»™Agentï¼Œå½“å‰çŠ¶æ€: {task['status']}")
            
            # å°†ä»»åŠ¡åŠ å…¥å¤„ç†é˜Ÿåˆ—
            queue_item = {
                'task_id': task_id,
                'submitted_at': now_utc()
            }
            
            await self.processing_queue.put(queue_item)
            
            logger.trace(f"ä»»åŠ¡ {task_id} å·²æäº¤ç»™Agentå¤„ç†é˜Ÿåˆ—")
            return {
                'task_id': task_id,
                'status': 'queued',
                'message': 'ä»»åŠ¡å·²åŠ å…¥Agentå¤„ç†é˜Ÿåˆ—'
            }
            
        except Exception as e:
            logger.error(f"æäº¤ä»»åŠ¡ç»™Agentå¤±è´¥: {e}")
            raise
    
    async def process_agent_task(self, task_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªAgentä»»åŠ¡"""
        try:
            logger.trace(f"ğŸš€ [AGENT-PROCESS] å¼€å§‹å¤„ç†Agentä»»åŠ¡: {task_id}")
            
            # è·å–ä»»åŠ¡è¯¦æƒ…
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                logger.error(f"âŒ [AGENT-PROCESS] ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            logger.trace(f"ğŸ“‹ [AGENT-PROCESS] ä»»åŠ¡è¯¦æƒ…è·å–æˆåŠŸ:")
            logger.trace(f"   - ä»»åŠ¡æ ‡é¢˜: {task['task_title']}")
            logger.trace(f"   - ä»»åŠ¡ç±»å‹: {task.get('task_type', 'unknown')}")
            logger.trace(f"   - å½“å‰çŠ¶æ€: {task.get('status', 'unknown')}")
            logger.trace(f"   - å¤„ç†å™¨ID: {task.get('processor_id', 'none')}")
            logger.trace(f"   - åˆ†é…Agent ID: {task.get('assigned_agent_id', 'none')}")
            logger.trace(f"   - ä¼˜å…ˆçº§: {task.get('priority', 0)}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿›è¡Œä¸­
            logger.trace(f"â³ [AGENT-PROCESS] æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºIN_PROGRESS")
            update_data = TaskInstanceUpdate(status=TaskInstanceStatus.IN_PROGRESS)
            await self.task_repo.update_task(task_id, update_data)
            logger.trace(f"âœ… [AGENT-PROCESS] ä»»åŠ¡çŠ¶æ€æ›´æ–°æˆåŠŸ")
            
            start_time = datetime.now()
            logger.trace(f"â° [AGENT-PROCESS] ä»»åŠ¡å¼€å§‹æ—¶é—´: {start_time.isoformat()}")
            
            # è·å–Agentä¿¡æ¯
            agent_id = task.get('assigned_agent_id')
            logger.trace(f"ğŸ” [AGENT-PROCESS] æ£€æŸ¥Agentåˆ†é…: {agent_id}")
            
            # å¦‚æœä»»åŠ¡æ²¡æœ‰ç›´æ¥åˆ†é…Agentï¼Œå°è¯•ä»processorè·å–
            if not agent_id:
                processor_id = task.get('processor_id')
                logger.warning(f"âš ï¸ [AGENT-PROCESS] ä»»åŠ¡æœªç›´æ¥åˆ†é…Agentï¼Œå°è¯•ä»processorè·å–: {processor_id}")
                
                if processor_id:
                    # ä»processorè·å–å…³è”çš„agent
                    from ..repositories.processor.processor_repository import ProcessorRepository
                    processor_repo = ProcessorRepository()
                    processor = await processor_repo.get_processor_with_details(processor_id)
                    if processor and processor.get('agent_id'):
                        agent_id = processor['agent_id']
                        logger.trace(f"âœ… [AGENT-PROCESS] ä»processorè·å–åˆ°Agent ID: {agent_id}")
                    else:
                        logger.error(f"âŒ [AGENT-PROCESS] Processoræœªå…³è”Agent: {processor_id}")
                        raise ValueError(f"Processor {processor_id} æœªå…³è”Agent")
                else:
                    logger.error(f"âŒ [AGENT-PROCESS] ä»»åŠ¡æ—¢æ²¡æœ‰assigned_agent_idä¹Ÿæ²¡æœ‰processor_id")
                    raise ValueError("ä»»åŠ¡æœªåˆ†é…Agent")
            
            logger.trace(f"ğŸ¤– [AGENT-PROCESS] è·å–Agentè¯¦æƒ…: {agent_id}")
            agent = await self.agent_repo.get_agent_by_id(agent_id)
            if not agent:
                logger.error(f"âŒ [AGENT-PROCESS] Agentä¸å­˜åœ¨: {agent_id}")
                raise ValueError(f"Agentä¸å­˜åœ¨: {agent_id}")
            
            logger.trace(f"âœ… [AGENT-PROCESS] Agentè¯¦æƒ…è·å–æˆåŠŸ:")
            logger.trace(f"   - Agentåç§°: {agent.get('agent_name', 'unknown')}")
            logger.trace(f"   - æ¨¡å‹: {agent.get('model_name', 'unknown')}")
            logger.trace(f"   - Base URL: {agent.get('base_url', 'none')}")
            logger.trace(f"   - API Keyå­˜åœ¨: {'æ˜¯' if agent.get('api_key') else 'å¦'}")

            # è¯¦ç»†è°ƒè¯•ä»»åŠ¡æ•°æ®å­—æ®µ
            logger.trace(f"ğŸ” [AGENT-PROCESS] è¯¦ç»†è°ƒè¯•ä»»åŠ¡æ•°æ®å­—æ®µ:")
            logger.trace(f"   - ä»»åŠ¡å­—å…¸æ‰€æœ‰é”®: {list(task.keys())}")
            for key, value in task.items():
                if key in ['input_data', 'context_data', 'output_data']:
                    logger.trace(f"   - {key}: ç±»å‹={type(value)}, é•¿åº¦={len(str(value)) if value else 0}, å€¼='{str(value)[:100]}{'...' if value and len(str(value)) > 100 else ''}'")
                elif key in ['task_title', 'task_description', 'status']:
                    logger.trace(f"   - {key}: '{value}'")
            
            # å‡†å¤‡AIä»»åŠ¡æ•°æ® - å¤šæ•°æ®æºæ™ºèƒ½é€‰æ‹©
            logger.info(f"ğŸ“Š [AGENT-CONTEXT] å¼€å§‹åˆ†æä»»åŠ¡ä¸Šä¸‹æ–‡æ•°æ®")
            logger.trace(f"full task:{task}")
            task_input_data = task.get('input_data', '')
            task_context_data = task.get('context_data', '')
            
            logger.info(f"ğŸ“Š [AGENT-CONTEXT] åˆå§‹æ•°æ®æº:")
            logger.info(f"   - task_input_data: {len(str(task_input_data))} å­—ç¬¦, ç±»å‹: {type(task_input_data)}")
            logger.info(f"   - task_context_data: {len(str(task_context_data))} å­—ç¬¦, ç±»å‹: {type(task_context_data)}")
            if task_context_data:
                logger.info(f"   - context_data é¢„è§ˆ: {str(task_context_data)[:300]}...")
            
            # å°è¯•ä»èŠ‚ç‚¹å®ä¾‹è·å–æ•°æ®ï¼ˆè¿™æ˜¯UIæ˜¾ç¤ºçš„æ•°æ®æºï¼‰
            node_input_data = ""
            node_instance_id = task.get('node_instance_id')
            if node_instance_id:
                try:
                    from ..repositories.instance.node_instance_repository import NodeInstanceRepository
                    node_repo = NodeInstanceRepository()
                    node_instance = await node_repo.get_instance_by_id(node_instance_id)
                    if node_instance and node_instance.get('input_data'):
                        node_input_data = node_instance['input_data']
                        logger.info(f"   - ä»èŠ‚ç‚¹å®ä¾‹è·å–è¾“å…¥æ•°æ®: {len(node_input_data)} å­—ç¬¦")
                        logger.info(f"   - èŠ‚ç‚¹è¾“å…¥æ•°æ®é¢„è§ˆ: {str(node_input_data)[:300]}...")
                except Exception as e:
                    logger.warning(f"   - è·å–èŠ‚ç‚¹å®ä¾‹æ•°æ®å¤±è´¥: {e}")
            
            # æ•´åˆæ‰€æœ‰å¯ç”¨æ•°æ®æº
            data_sources = [
                ("node_input_data", node_input_data),
                ("task_context_data", task_context_data), 
                ("task_input_data", task_input_data)
            ]
            
            logger.trace(f"ğŸ“Š [AGENT-PROCESS] å¤šæ•°æ®æºåˆ†æ:")
            for source_name, source_data in data_sources:
                data_str = str(source_data) if source_data is not None else ""
                logger.trace(f"   - {source_name}: å¤§å°={len(data_str)} å­—ç¬¦, ç±»å‹={type(source_data)}")
                if data_str and len(data_str) > 0:
                    logger.trace(f"     é¢„è§ˆ: {data_str[:100]}{'...' if len(data_str) > 100 else ''}")
            
            # æ™ºèƒ½é€‰æ‹©æœ€ä½³æ•°æ®æºï¼šä¼˜å…ˆé€‰æ‹©å†…å®¹æœ€ä¸°å¯Œçš„
            actual_data = ""
            data_source = "none"
            
            for source_name, source_data in data_sources:
                # å°†æ•°æ®è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¿›è¡Œå¤„ç†
                data_str = str(source_data) if source_data is not None else ""
                if data_str and data_str.strip() and data_str.strip() != '{}' and data_str.strip() != 'None':
                    actual_data = data_str
                    data_source = source_name
                    logger.trace(f"   âœ… é€‰æ‹©{source_name}ä½œä¸ºæ•°æ®æº")
                    break
            
            if not actual_data:
                logger.warning(f"   âŒ æ‰€æœ‰æ•°æ®æºéƒ½ä¸ºç©º")
                
            logger.trace(f"   - å®é™…ä½¿ç”¨æ•°æ®æº: {data_source}")
            logger.trace(f"   - å®é™…æ•°æ®å¤§å°: {len(actual_data)} å­—ç¬¦")
            if actual_data and len(actual_data) > 0:
                logger.trace(f"   - å®é™…æ•°æ®é¢„è§ˆ: {actual_data[:200]}...")
            
            # æ„å»ºç³»ç»Ÿ Promptï¼ˆä½¿ç”¨ä»»åŠ¡çš„è¯¦ç»†æè¿°ï¼‰
            logger.trace(f"ğŸ”¨ [AGENT-PROCESS] æ„å»ºç³»ç»ŸPrompt")
            system_prompt = self._build_system_prompt(task)
            logger.trace(f"   - ç³»ç»ŸPrompté•¿åº¦: {len(system_prompt)} å­—ç¬¦")
            logger.trace(f"   - ç³»ç»ŸPrompté¢„è§ˆ: {system_prompt[:200]}...")
            
            # é¢„å¤„ç†ä¸Šæ¸¸ä¸Šä¸‹æ–‡ï¼ˆæ•´ç†æˆè¡¥å……ä¿¡æ¯ï¼‰
            logger.trace(f"ğŸ”„ [AGENT-PROCESS] é¢„å¤„ç†ä¸Šæ¸¸ä¸Šä¸‹æ–‡")
            logger.trace(f"   - ä¼ å…¥é¢„å¤„ç†çš„actual_data: {actual_data[:500] if actual_data else 'None'}...")
            context_info = self._preprocess_upstream_context(actual_data)
            logger.trace(f"   - ä¸Šä¸‹æ–‡ä¿¡æ¯é•¿åº¦: {len(context_info)} å­—ç¬¦")
            logger.trace(f"   - ä¸Šä¸‹æ–‡ä¿¡æ¯é¢„è§ˆ: {context_info[:200]}...")
            logger.trace(f"   - ä¸Šä¸‹æ–‡ä¿¡æ¯å®Œæ•´å†…å®¹: '{context_info}'")
            
            # æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼ˆä½œä¸ºä»»åŠ¡è¾“å…¥ï¼‰
            logger.trace(f"âœ‰ï¸ [AGENT-PROCESS] æ„å»ºç”¨æˆ·æ¶ˆæ¯")
            message_data = await self._build_user_message(task, context_info, agent)
            user_message = message_data['text_message']
            images = message_data.get('images', [])
            has_multimodal = message_data.get('has_multimodal_content', False)

            logger.trace(f"   - ç”¨æˆ·æ¶ˆæ¯é•¿åº¦: {len(user_message)} å­—ç¬¦")
            logger.trace(f"   - ç”¨æˆ·æ¶ˆæ¯é¢„è§ˆ: {user_message[:200]}...")
            if has_multimodal:
                logger.trace(f"   - åŒ…å«å¤šæ¨¡æ€å†…å®¹: {len(images)} ä¸ªå›¾ç‰‡")

            # æ•´ç†æˆAI Clientå¯æ¥æ”¶çš„æ•°æ®ç»“æ„
            ai_client_data = {
                'task_id': str(task_id),
                'system_prompt': system_prompt,
                'user_message': user_message,
                'images': images,  # æ–°å¢ï¼šå¤šæ¨¡æ€å›¾ç‰‡æ•°æ®
                'has_multimodal_content': has_multimodal,  # æ–°å¢ï¼šå¤šæ¨¡æ€æ ‡è¯†
                'task_metadata': {
                    'task_title': task['task_title'],
                    'task_description': task.get('task_description', '') or task.get('description', ''),
                    'estimated_duration': task.get('estimated_duration', 30)
                }
            }
            
            logger.trace(f"ğŸ“¦ [AGENT-PROCESS] AI Clientæ•°æ®å‡†å¤‡å®Œæˆ:")
            logger.trace(f"   - ä»»åŠ¡ID: {ai_client_data['task_id']}")
            logger.trace(f"   - ä»»åŠ¡æ ‡é¢˜: {ai_client_data['task_metadata']['task_title']}")
            logger.trace(f"   - ä»»åŠ¡æè¿°: {ai_client_data['task_metadata']['task_description'][:100] if ai_client_data['task_metadata']['task_description'] else 'æ— '}")
            logger.trace(f"   - ç³»ç»ŸPrompt: {len(ai_client_data['system_prompt'])} å­—ç¬¦")
            logger.trace(f"   - ç”¨æˆ·æ¶ˆæ¯: {len(ai_client_data['user_message'])} å­—ç¬¦")
            logger.trace(f"   - å…ƒæ•°æ®: {ai_client_data['task_metadata']}")
            
            # è°ƒç”¨Agentå¤„ç†
            logger.trace(f"ğŸš€ [AGENT-PROCESS] å¼€å§‹è°ƒç”¨Agent API")
            result = await self._call_agent_api(agent, ai_client_data)
            logger.trace(f"âœ… [AGENT-PROCESS] Agent APIè°ƒç”¨æˆåŠŸ")
            logger.trace(f"   - ç»“æœç±»å‹: {type(result)}")
            logger.trace(f"   - ç»“æœé”®: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
            
            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            end_time = datetime.now()
            actual_duration = int((end_time - start_time).total_seconds() / 60)
            
            logger.trace(f"â° [AGENT-PROCESS] ä»»åŠ¡æ‰§è¡Œå®Œæˆ:")
            logger.trace(f"   - å¼€å§‹æ—¶é—´: {start_time.isoformat()}")
            logger.trace(f"   - ç»“æŸæ—¶é—´: {end_time.isoformat()}")
            logger.trace(f"   - å®é™…ç”¨æ—¶: {actual_duration} åˆ†é’Ÿ")
            
            # å¤„ç†AIç”Ÿæˆçš„å›¾ç‰‡å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
            logger.trace(f"ğŸ–¼ï¸ [AI-IMAGE] æ£€æŸ¥AIå“åº”ä¸­çš„å›¾ç‰‡å†…å®¹")
            await self._process_ai_generated_images(task_id, result, agent)

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å®Œæˆï¼ˆå°†ç»“æœè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼ï¼‰
            logger.trace(f"ğŸ’¾ [AGENT-PROCESS] æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºCOMPLETED")

            # å°†ç»“æœè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼å­˜å‚¨
            output_text = result['result'] if isinstance(result, dict) and 'result' in result else str(result)
            result_summary = output_text[:500] + '...' if len(output_text) > 500 else output_text  # æ‘˜è¦ä¸ºå‰500å­—ç¬¦

            complete_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.COMPLETED,
                output_data=output_text,
                result_summary=result_summary,
                actual_duration=actual_duration
            )
            
            updated_task = await self.task_repo.update_task(task_id, complete_update)
            logger.trace(f"âœ… [AGENT-PROCESS] ä»»åŠ¡çŠ¶æ€æ›´æ–°ä¸ºCOMPLETEDæˆåŠŸ")
            
            if updated_task:
                logger.trace(f"ğŸ“‹ [AGENT-PROCESS] æ›´æ–°åä»»åŠ¡çŠ¶æ€: {updated_task.get('status', 'unknown')}")
            else:
                logger.warning(f"âš ï¸ [AGENT-PROCESS] ä»»åŠ¡æ›´æ–°è¿”å›ç©ºç»“æœ")
            
            # æ˜¾ç¤ºAgentè¾“å‡ºç»“æœ
            logger.trace(f"ğŸ¯ [AGENT-PROCESS] === AGENTè¾“å‡ºç»“æœ ===")
            logger.trace(f"   ğŸ“ ä»»åŠ¡æ ‡é¢˜: {task['task_title']}")
            logger.trace(f"   â±ï¸  å¤„ç†æ—¶é•¿: {actual_duration}åˆ†é’Ÿ")
            logger.trace(f"   ğŸ“Š ç»“æœå†…å®¹:")
            
            # æ˜¾ç¤ºæ–‡æœ¬ç»“æœ
            logger.trace(f"      ğŸ“„ è¾“å‡ºå†…å®¹: {output_text[:300]}{'...' if len(output_text) > 300 else ''}")
            
            # æ˜¾ç¤ºæ¨¡å‹ä½¿ç”¨ä¿¡æ¯
            if isinstance(result, dict):
                model_used = result.get('model_used', 'N/A')
                if model_used and model_used != 'N/A':
                    logger.trace(f"      ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_used}")
                
                token_usage = result.get('token_usage', {})
                if token_usage:
                    logger.trace(f"      ğŸ’° Tokenä½¿ç”¨: {token_usage}")
            
            logger.trace(f"ğŸ‰ [AGENT-PROCESS] Agentä»»åŠ¡å¤„ç†å®Œæˆ: {task['task_title']}")
            
            # é€šçŸ¥ä»»åŠ¡å®Œæˆå›è°ƒ
            completion_result = {
                'task_id': task_id,
                'status': TaskInstanceStatus.COMPLETED.value,
                'result': output_text,  # ä½¿ç”¨æ–‡æœ¬æ ¼å¼çš„ç»“æœ
                'duration': actual_duration,
                'message': 'Agentä»»åŠ¡å¤„ç†å®Œæˆ'
            }
            await self._notify_task_completion(task_id, completion_result)
            
            return completion_result
            
        except Exception as e:
            logger.error(f"å¤„ç†Agentä»»åŠ¡å¤±è´¥: {e}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            fail_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.FAILED,
                error_message=str(e)
            )
            await self.task_repo.update_task(task_id, fail_update)
            
            # é€šçŸ¥ä»»åŠ¡å¤±è´¥å›è°ƒ
            await self._notify_task_failure(task_id, str(e))
            
            raise
    
    async def _call_agent_api(self, agent: Dict[str, Any], 
                            ai_client_data: Dict[str, Any]) -> Dict[str, Any]:
        """è°ƒç”¨Agent APIå¤„ç†ä»»åŠ¡ï¼ˆä»…ä½¿ç”¨OpenAIè§„èŒƒï¼‰"""
        try:
            logger.trace(f"ğŸ”Œ [AGENT-API] å¼€å§‹è°ƒç”¨Agent API")
            
            # å…¼å®¹ä¸åŒAgentå¯¹è±¡æ ¼å¼
            agent_name = 'unknown'
            model_name = 'unknown'  
            base_url = 'none'
            
            if isinstance(agent, dict):
                agent_name = agent.get('agent_name', 'unknown')
                model_name = agent.get('model_name', 'unknown')
                base_url = agent.get('base_url', 'none')
            elif hasattr(agent, 'agent_name'):
                agent_name = getattr(agent, 'agent_name', 'unknown')
                model_name = getattr(agent, 'model_name', 'unknown')
                base_url = getattr(agent, 'base_url', 'none')
            
            logger.trace(f"   - Agent: {agent_name}")
            logger.trace(f"   - æ¨¡å‹: {model_name}")
            logger.trace(f"   - Base URL: {base_url}")
            logger.trace(f"   - ä»»åŠ¡ID: {ai_client_data.get('task_id', 'unknown')}")
            
            # ç»Ÿä¸€ä½¿ç”¨OpenAIè§„èŒƒæ ¼å¼å¤„ç†æ‰€æœ‰AIä»»åŠ¡
            result = await self._process_with_openai_format(agent, ai_client_data)
            
            logger.trace(f"âœ… [AGENT-API] Agent APIè°ƒç”¨æˆåŠŸ")
            logger.trace(f"   - è¿”å›ç»“æœç±»å‹: {type(result)}")
            if isinstance(result, dict):
                logger.trace(f"   - ç»“æœåŒ…å«çš„é”®: {list(result.keys())}")
                logger.trace(f"   - ç½®ä¿¡åº¦: {result.get('confidence_score', 'N/A')}")
                
            return result
                
        except Exception as e:
            logger.error(f"âŒ [AGENT-API] è°ƒç”¨Agent APIå¤±è´¥: {e}")
            import traceback
            logger.error(f"   - é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def _process_with_openai_format(self, agent: Dict[str, Any],
                                        ai_client_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨OpenAIè§„èŒƒæ ¼å¼å¤„ç†ä»»åŠ¡"""
        try:
            task_title = ai_client_data['task_metadata']['task_title']
            user_message = ai_client_data.get('user_message', '')
            logger.trace(f"ğŸš€ [OPENAI-FORMAT] ä½¿ç”¨OpenAIè§„èŒƒå¤„ç†ä»»åŠ¡: {task_title}")

            # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾åƒç”Ÿæˆè¯·æ±‚
            is_image_request = self._is_image_generation_request(user_message)

            if is_image_request:
                logger.info(f"ğŸ¨ [IMAGE-GEN] æ£€æµ‹åˆ°å›¾åƒç”Ÿæˆè¯·æ±‚")

                # æ£€æŸ¥Agentæ˜¯å¦æœ‰å›¾åƒç”Ÿæˆæƒé™
                agent_tags = agent.get('tags', []) if isinstance(agent, dict) else []
                has_image_permission = 'image-generation' in agent_tags

                if not has_image_permission:
                    logger.warning(f"âš ï¸ [IMAGE-GEN] Agentç¼ºå°‘å›¾åƒç”Ÿæˆæƒé™ï¼Œæ ‡ç­¾: {agent_tags}")
                    return {
                        'success': False,
                        'error': 'è¯¥Agentæ²¡æœ‰å›¾åƒç”Ÿæˆæƒé™ã€‚è¯·ä¸ºAgentæ·»åŠ  "image-generation" æ ‡ç­¾ä»¥å¯ç”¨å›¾åƒç”ŸæˆåŠŸèƒ½ã€‚',
                        'content': 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›¾åƒã€‚ç®¡ç†å‘˜éœ€è¦ä¸ºæˆ‘æ·»åŠ å›¾åƒç”Ÿæˆæƒé™ã€‚',
                        'permission_required': 'image-generation'
                    }

                # æ‰§è¡Œå›¾åƒç”Ÿæˆ - ä¼ é€’ä»»åŠ¡å…ƒæ•°æ®
                logger.info(f"âœ… [IMAGE-GEN] Agentå…·æœ‰å›¾åƒç”Ÿæˆæƒé™ï¼Œå¼€å§‹ç”Ÿæˆå›¾åƒ")
                task_id = ai_client_data.get('task_id')
                task_metadata = ai_client_data.get('task_metadata', {})
                if task_id and isinstance(task_id, str):
                    task_id = uuid.UUID(task_id)
                return await self._handle_image_generation(user_message, agent, task_id, task_metadata)

            # æ„å»ºç¬¦åˆOpenAI APIè§„èŒƒçš„è¯·æ±‚æ•°æ®
            logger.trace(f"ğŸ› ï¸ [OPENAI-FORMAT] æ„å»º OpenAI API è¯·æ±‚æ•°æ®")
            
            # ä» agent çš„ parameters ä¸­è·å–å‚æ•°
            if isinstance(agent, dict):
                agent_params = agent.get('parameters') or {}
                model_name = agent.get('model_name', 'gpt-3.5-turbo')
            elif hasattr(agent, 'parameters'):
                agent_params = agent.parameters or {}
                model_name = getattr(agent, 'model_name', 'gpt-3.5-turbo')
            else:
                logger.warning(f"âš ï¸ [OPENAI-FORMAT] æ— æ³•è·å–Agentå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                agent_params = {}
                model_name = 'gpt-3.5-turbo'
                
            temperature = agent_params.get('temperature', 0.7) if isinstance(agent_params, dict) else 0.7
            max_tokens = agent_params.get('max_tokens', 2000) if isinstance(agent_params, dict) else 2000
            
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            logger.trace(f"ğŸ”§ [OPENAI-FORMAT] Agentå‚æ•°:")
            logger.trace(f"   - model_name: {model_name}")
            logger.trace(f"   - agent_params: {agent_params}")
            logger.trace(f"   - temperature: {temperature}")
            logger.trace(f"   - max_tokens: {max_tokens}")
            logger.trace(f"   - Agentå®Œæ•´ä¿¡æ¯: {agent}")
            
            # è·å–Agentçš„MCPå·¥å…·
            agent_id = None
            if isinstance(agent, dict):
                agent_id = agent.get('agent_id')
            elif hasattr(agent, 'agent_id'):
                agent_id = agent.agent_id
            else:
                logger.warning(f"âš ï¸ [MCP-TOOLS] Agentå¯¹è±¡ç±»å‹æ— æ³•è¯†åˆ«: {type(agent)}, è·³è¿‡å·¥å…·è·å–")
                
            mcp_tools = []
            if agent_id:
                try:
                    logger.trace(f"ğŸ”§ [MCP-TOOLS] è·å–Agentçš„MCPå·¥å…·: {agent_id}")
                    logger.trace(f"   - Agentå¯¹è±¡ç±»å‹: {type(agent)}")
                    logger.trace(f"   - Agentæ˜¯å¦ä¸ºå­—å…¸: {isinstance(agent, dict)}")
                    if isinstance(agent, dict):
                        logger.trace(f"   - Agentå­—å…¸é”®: {list(agent.keys())}")
                    
                    logger.info(f"ğŸ”§ [AGENT-TASK] å¼€å§‹åŠ è½½Agentå·¥å…·")
                    logger.info(f"   - Agent ID: {agent_id}")
                    logger.info(f"   - Agentåç§°: {agent.get('agent_name', 'Unknown') if isinstance(agent, dict) else 'Unknown'}")
                    
                    mcp_tools = await mcp_service.get_agent_tools(agent_id)
                    
                    logger.info(f"ğŸ”§ [AGENT-TASK] MCPå·¥å…·åŠ è½½å®Œæˆ")
                    logger.info(f"   - åŠ è½½åˆ°çš„å·¥å…·æ•°é‡: {len(mcp_tools)}")
                    
                    for i, tool in enumerate(mcp_tools):
                        logger.info(f"   - å·¥å…· {i+1}: {tool.name if hasattr(tool, 'name') else tool.get('name', 'Unknown') if isinstance(tool, dict) else str(tool)}")
                        logger.info(f"     * æè¿°: {tool.description if hasattr(tool, 'description') else tool.get('description', 'No description') if isinstance(tool, dict) else 'No description'}")
                        if hasattr(tool, 'server_name'):
                            logger.info(f"     * æœåŠ¡å™¨: {tool.server_name}")
                        elif isinstance(tool, dict) and 'server_name' in tool:
                            logger.info(f"     * æœåŠ¡å™¨: {tool['server_name']}")
                    
                    if len(mcp_tools) == 0:
                        logger.warning(f"âš ï¸ [AGENT-TASK] Agentæ²¡æœ‰å¯ç”¨çš„å·¥å…·ï¼Œå°†ä½¿ç”¨æ™®é€šæ¨¡å¼")
                    else:
                        logger.info(f"âœ… [AGENT-TASK] Agentå·¥å…·åŠ è½½æˆåŠŸï¼Œè¿›å…¥å·¥å…·è°ƒç”¨æ¨¡å¼")
                    
                    logger.trace(f"   - æ‰¾åˆ°MCPå·¥å…·æ•°é‡: {len(mcp_tools)}")
                    
                    # æ£€æŸ¥å·¥å…·é€‰æ‹©æ¨¡å¼
                    tool_config = {}
                    if isinstance(agent, dict):
                        tool_config = agent.get('tool_config', {}) or {}
                    elif hasattr(agent, 'tool_config'):
                        tool_config = getattr(agent, 'tool_config', {}) or {}
                    
                    # ç¡®ä¿tool_configæ˜¯å­—å…¸ç±»å‹
                    if not isinstance(tool_config, dict):
                        logger.warning(f"âš ï¸ [MCP-TOOLS] tool_configä¸æ˜¯å­—å…¸ç±»å‹: {type(tool_config)}, ä½¿ç”¨é»˜è®¤é…ç½®")
                        tool_config = {}
                        
                    tool_selection = tool_config.get('tool_selection', 'auto')
                    
                    logger.trace(f"   - å·¥å…·é€‰æ‹©æ¨¡å¼: {tool_selection}")
                    
                    if tool_selection == 'disabled':
                        logger.trace(f"   - å·¥å…·è°ƒç”¨å·²ç¦ç”¨ï¼Œæ¸…ç©ºå·¥å…·åˆ—è¡¨")
                        mcp_tools = []
                    elif tool_selection == 'manual':
                        # åº”ç”¨å·¥å…·è¿‡æ»¤
                        allowed_tools = tool_config.get('allowed_tools', [])
                        blocked_tools = tool_config.get('blocked_tools', [])
                        
                        if allowed_tools:
                            mcp_tools = [tool for tool in mcp_tools if tool.name in allowed_tools]
                            logger.trace(f"   - åº”ç”¨å…è®¸åˆ—è¡¨åå·¥å…·æ•°é‡: {len(mcp_tools)}")
                        
                        if blocked_tools:
                            mcp_tools = [tool for tool in mcp_tools if tool.name not in blocked_tools]
                            logger.trace(f"   - åº”ç”¨ç¦ç”¨åˆ—è¡¨åå·¥å…·æ•°é‡: {len(mcp_tools)}")
                    
                    # æ˜¾ç¤ºæœ€ç»ˆå·¥å…·åˆ—è¡¨
                    if mcp_tools:
                        logger.trace(f"   - å¯ç”¨å·¥å…·:")
                        for i, tool in enumerate(mcp_tools[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
                            logger.trace(f"     {i+1}. {tool.name} ({tool.server_name})")
                        if len(mcp_tools) > 5:
                            logger.trace(f"     ... è¿˜æœ‰ {len(mcp_tools) - 5} ä¸ªå·¥å…·")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ [MCP-TOOLS] è·å–MCPå·¥å…·å¤±è´¥: {e}")
                    mcp_tools = []
            
            openai_request = {
                'messages': [
                    {
                        'role': 'system',
                        'content': ai_client_data['system_prompt']
                    },
                    {
                        'role': 'user', 
                        'content': ai_client_data['user_message']
                    }
                ],
                'model': model_name,
                'temperature': temperature,
                'max_tokens': max_tokens
            }
            
            # å¦‚æœæœ‰MCPå·¥å…·ï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­
            if mcp_tools:
                openai_tools = [tool.to_openai_format() for tool in mcp_tools]
                openai_request['tools'] = openai_tools
                openai_request['tool_choice'] = 'auto'
                logger.trace(f"ğŸ”§ [MCP-TOOLS] æ·»åŠ å·¥å…·åˆ°OpenAIè¯·æ±‚: {len(openai_tools)} ä¸ªå·¥å…·")
            
            logger.trace(f"   - æ¨¡å‹: {model_name}")
            logger.trace(f"   - æ¸©åº¦: {temperature}")
            logger.trace(f"   - æœ€å¤§token: {max_tokens}")
            logger.trace(f"   - æ¶ˆæ¯æ•°é‡: {len(openai_request['messages'])}")
            logger.trace(f"   - å·¥å…·æ•°é‡: {len(openai_request.get('tools', []))}")
            logger.trace(f"   - ç³»ç»Ÿæ¶ˆæ¯é•¿åº¦: {len(openai_request['messages'][0]['content'])}")
            logger.trace(f"   - ç”¨æˆ·æ¶ˆæ¯é•¿åº¦: {len(openai_request['messages'][1]['content'])}")
            
            # è°ƒç”¨OpenAIå®¢æˆ·ç«¯å¤„ç†ä»»åŠ¡ï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
            logger.trace(f"ğŸ”„ [OPENAI-FORMAT] è°ƒç”¨OpenAIå®¢æˆ·ç«¯")
            logger.trace(f"   - ä½¿ç”¨æ¨¡å‹: {openai_request['model']}")

            # è·å–Agentçš„é…ç½®ä¿¡æ¯åˆ›å»ºä¸“ç”¨å®¢æˆ·ç«¯
            agent_api_key = None
            agent_base_url = None

            if isinstance(agent, dict):
                agent_api_key = agent.get('api_key')
                agent_base_url = agent.get('base_url')
            elif hasattr(agent, 'api_key'):
                agent_api_key = getattr(agent, 'api_key', None)
                agent_base_url = getattr(agent, 'base_url', None)

            logger.trace(f"   - Agent Base URL: {agent_base_url}")
            logger.trace(f"   - Agent API Keyå­˜åœ¨: {'æ˜¯' if agent_api_key else 'å¦'}")

            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¸ºæ¯ä¸ªAgentåˆ›å»ºä¸“ç”¨çš„OpenAIClient
            from ..utils.openai_client import OpenAIClient

            agent_openai_client = OpenAIClient(
                api_key=agent_api_key,
                base_url=agent_base_url,
                model=model_name,
                temperature=temperature
            )

            logger.info(f"ğŸ”§ [AGENT-CLIENT] ä¸ºAgentåˆ›å»ºä¸“ç”¨OpenAIå®¢æˆ·ç«¯")
            logger.info(f"   - Base URL: {agent_base_url}")
            logger.info(f"   - æ¨¡å‹: {model_name}")
            logger.info(f"   - API Keyå­˜åœ¨: {'æ˜¯' if agent_api_key else 'å¦'}")
            logger.info(f"   - AgentåŸå§‹model_name: {agent.get('model_name') if isinstance(agent, dict) else getattr(agent, 'model_name', 'N/A')}")

            # è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆé˜²æ­¢å¡æ­»ï¼‰
            try:
                openai_result = await asyncio.wait_for(
                    self._process_with_tools(agent, openai_request, mcp_tools, agent_openai_client),
                    timeout=600  # 10åˆ†é’Ÿè¶…æ—¶ï¼ˆå·¥å…·è°ƒç”¨å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
                )
                logger.trace(f"âœ… [OPENAI-FORMAT] OpenAIå®¢æˆ·ç«¯è°ƒç”¨æˆåŠŸ")
            except asyncio.TimeoutError:
                logger.error(f"â° [OPENAI-FORMAT] OpenAI APIè°ƒç”¨è¶…æ—¶ï¼ˆ10åˆ†é’Ÿï¼‰")
                raise RuntimeError("OpenAI APIè°ƒç”¨è¶…æ—¶")
            except Exception as api_e:
                logger.error(f"âŒ [OPENAI-FORMAT] OpenAI APIè°ƒç”¨å¼‚å¸¸: {api_e}")
                raise
            
            if openai_result['success']:
                # ä»OpenAIæ ¼å¼çš„å›å¤ä¸­æå–æ–‡æœ¬ç»“æœ
                ai_response = openai_result['result']
                response_content = ai_response.get('content', '')
                
                # ç›´æ¥è¿”å›æ–‡æœ¬ç»“æœï¼Œä¸è¦æ±‚ç‰¹å®šæ ¼å¼
                model_used = openai_result.get('model', model_name)  # ä½¿ç”¨ä¹‹å‰è·å–çš„model_name
                result = {
                    'result': response_content,  # Agentçš„åŸå§‹è¾“å‡º
                    'model_used': model_used,
                    'token_usage': openai_result.get('usage', {})
                }
                
                logger.trace(f"OpenAIè§„èŒƒå¤„ç†å®Œæˆï¼Œè¿”å›æ–‡æœ¬ç»“æœ")
                return result
            else:
                # å¤„ç†å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                error_msg = openai_result.get('error', 'AIå¤„ç†å¤±è´¥')
                raise RuntimeError(f"AIå¤„ç†å¤±è´¥: {error_msg}")
            
        except Exception as e:
            logger.error(f"OpenAIè§„èŒƒå¤„ç†å¤±è´¥: {e}")
            raise
    
    
    
    async def _process_agent_tasks(self):
        """å¤„ç†Agentä»»åŠ¡çš„å·¥ä½œåç¨‹"""
        while self.is_running:
            try:
                # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
                queue_item = await asyncio.wait_for(
                    self.processing_queue.get(), timeout=5.0
                )
                
                task_id = queue_item['task_id']
                logger.trace(f"ä»é˜Ÿåˆ—å–å‡ºAgentä»»åŠ¡: {task_id}")
                
                # å¤„ç†ä»»åŠ¡
                await self.process_agent_task(task_id)
                
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"å¤„ç†Agentä»»åŠ¡åç¨‹å‡ºé”™: {e}")
                await asyncio.sleep(1)
    
    async def _monitor_pending_tasks(self):
        """ç›‘æ§å¾…å¤„ç†ä»»åŠ¡çš„åç¨‹ï¼ˆæ™ºèƒ½è°ƒåº¦ç‰ˆæœ¬ï¼‰"""
        consecutive_empty_checks = 0
        base_sleep_interval = 15  # åŸºç¡€æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰- ä¼˜åŒ–ä¸ºæ›´é¢‘ç¹
        max_sleep_interval = 120  # æœ€å¤§æ£€æŸ¥é—´éš”ï¼ˆ2åˆ†é’Ÿï¼‰- å‡å°‘æœ€å¤§å»¶è¿Ÿ
        
        while self.is_running:
            try:
                # åŠ¨æ€è°ƒæ•´æ£€æŸ¥é—´éš”
                if consecutive_empty_checks == 0:
                    sleep_interval = base_sleep_interval
                elif consecutive_empty_checks <= 3:
                    sleep_interval = base_sleep_interval * 2  # 60ç§’
                elif consecutive_empty_checks <= 6:
                    sleep_interval = base_sleep_interval * 4  # 120ç§’
                else:
                    sleep_interval = max_sleep_interval  # 300ç§’
                
                await asyncio.sleep(sleep_interval)
                
                # è·å–å¾…å¤„ç†çš„Agentä»»åŠ¡
                pending_tasks = await self.get_pending_agent_tasks(limit=10)
                
                if pending_tasks:
                    # æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œé‡ç½®è®¡æ•°å™¨
                    consecutive_empty_checks = 0
                    
                    # å°†å¾…å¤„ç†ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—
                    for task in pending_tasks:
                        if task['status'] == TaskInstanceStatus.PENDING.value:
                            queue_item = {
                                'task_id': task['task_instance_id'],
                                'submitted_at': now_utc()
                            }
                            await self.processing_queue.put(queue_item)
                            
                            logger.trace(f"è‡ªåŠ¨åŠ å…¥Agentä»»åŠ¡åˆ°å¤„ç†é˜Ÿåˆ—: {task['task_instance_id']}")
                else:
                    # æ²¡æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œå¢åŠ ç©ºæ£€æŸ¥è®¡æ•°
                    consecutive_empty_checks += 1
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒçš„å·¥ä½œæµ
                    has_active_workflows = await self._has_active_workflows()
                    
                    # å¦‚æœæ²¡æœ‰æ´»è·ƒå·¥ä½œæµï¼Œè¿›ä¸€æ­¥å»¶é•¿æ£€æŸ¥é—´éš”
                    if not has_active_workflows and consecutive_empty_checks > 10:
                        sleep_interval = min(sleep_interval * 2, 600)  # æœ€é•¿10åˆ†é’Ÿ
                    
                    # æ¯éš”ä¸€å®šæ¬¡æ•°æ‰è¾“å‡ºä¸€æ¬¡è­¦å‘Šï¼Œé¿å…æ—¥å¿—åˆ·å±
                    if consecutive_empty_checks in [1, 5, 10, 20] or consecutive_empty_checks % 50 == 0:
                        status_msg = "æ— æ´»è·ƒå·¥ä½œæµ" if not has_active_workflows else "æœ‰æ´»è·ƒå·¥ä½œæµ"
                        logger.trace(f"ğŸ” [AGENT-MONITOR] è¿ç»­ {consecutive_empty_checks} æ¬¡æœªæ‰¾åˆ°å¾…å¤„ç†ä»»åŠ¡ï¼Œ{status_msg}ï¼Œæ£€æŸ¥é—´éš”å·²è°ƒæ•´ä¸º {sleep_interval} ç§’")
                
            except Exception as e:
                logger.error(f"ç›‘æ§å¾…å¤„ç†ä»»åŠ¡å¤±è´¥: {e}")
                await asyncio.sleep(10)
                consecutive_empty_checks = 0  # é‡ç½®è®¡æ•°å™¨
    
    async def get_agent_task_statistics(self, agent_id: Optional[uuid.UUID] = None) -> Dict[str, Any]:
        """è·å–Agentä»»åŠ¡ç»Ÿè®¡"""
        try:
            # è·å–Agentçš„æ‰€æœ‰ä»»åŠ¡
            all_tasks = await self.task_repo.get_agent_tasks_for_processing(agent_id, 1000)
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = {
                'total_tasks': len(all_tasks),
                'pending_tasks': 0,
                'in_progress_tasks': 0,
                'completed_tasks': 0,
                'failed_tasks': 0,
                'average_processing_time': 0,
                'success_rate': 0,
                'queue_size': self.processing_queue.qsize()
            }
            
            total_duration = 0
            completed_count = 0
            
            for task in all_tasks:
                status = task['status']
                if status == TaskInstanceStatus.PENDING.value:
                    stats['pending_tasks'] += 1
                elif status == TaskInstanceStatus.IN_PROGRESS.value:
                    stats['in_progress_tasks'] += 1
                elif status == TaskInstanceStatus.COMPLETED.value:
                    stats['completed_tasks'] += 1
                    completed_count += 1
                    if task.get('actual_duration'):
                        total_duration += task['actual_duration']
                elif status == TaskInstanceStatus.FAILED.value:
                    stats['failed_tasks'] += 1
            
            # è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´å’ŒæˆåŠŸç‡
            if completed_count > 0:
                stats['average_processing_time'] = total_duration / completed_count
            
            if len(all_tasks) > 0:
                stats['success_rate'] = (completed_count / len(all_tasks)) * 100
            
            logger.trace(f"ç”ŸæˆAgentä»»åŠ¡ç»Ÿè®¡ï¼ŒæˆåŠŸç‡: {stats['success_rate']:.1f}%")
            return stats
            
        except Exception as e:
            logger.error(f"è·å–Agentä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {e}")
            raise
    
    async def retry_failed_task(self, task_id: uuid.UUID) -> Dict[str, Any]:
        """é‡è¯•å¤±è´¥çš„ä»»åŠ¡"""
        try:
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task['status'] != TaskInstanceStatus.FAILED.value:
                raise ValueError("åªèƒ½é‡è¯•å¤±è´¥çš„ä»»åŠ¡")
            
            # é‡ç½®ä»»åŠ¡çŠ¶æ€ä¸ºå¾…å¤„ç†
            reset_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.PENDING,
                error_message=None
            )
            await self.task_repo.update_task(task_id, reset_update)
            
            # é‡æ–°æäº¤åˆ°å¤„ç†é˜Ÿåˆ—
            await self.submit_task_to_agent(task_id)
            
            logger.trace(f"é‡è¯•å¤±è´¥ä»»åŠ¡: {task_id}")
            return {
                'task_id': task_id,
                'status': 'retry_queued',
                'message': 'å¤±è´¥ä»»åŠ¡å·²é‡æ–°åŠ å…¥å¤„ç†é˜Ÿåˆ—'
            }
            
        except Exception as e:
            logger.error(f"é‡è¯•å¤±è´¥ä»»åŠ¡å‡ºé”™: {e}")
            raise
    
    async def cancel_agent_task(self, task_id: uuid.UUID) -> Dict[str, Any]:
        """å–æ¶ˆAgentä»»åŠ¡"""
        try:
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task['status'] in [TaskInstanceStatus.COMPLETED.value, TaskInstanceStatus.CANCELLED.value]:
                raise ValueError("ä»»åŠ¡å·²å®Œæˆæˆ–å·²å–æ¶ˆï¼Œæ— æ³•å–æ¶ˆ")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å–æ¶ˆ
            cancel_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.CANCELLED,
                error_message="ä»»åŠ¡è¢«æ‰‹åŠ¨å–æ¶ˆ"
            )
            await self.task_repo.update_task(task_id, cancel_update)
            
            logger.trace(f"å–æ¶ˆAgentä»»åŠ¡: {task_id}")
            return {
                'task_id': task_id,
                'status': TaskInstanceStatus.CANCELLED.value,
                'message': 'ä»»åŠ¡å·²å–æ¶ˆ'
            }
            
        except Exception as e:
            logger.error(f"å–æ¶ˆAgentä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    def _build_system_prompt(self, task: Dict[str, Any]) -> str:
        """æ„å»ºç³»ç»ŸPromptï¼ˆåŒ…å«ä»»åŠ¡æè¿°å’Œå·¥å…·ä½¿ç”¨æŒ‡å¯¼ï¼‰"""
        try:
            task_description = task.get('task_description', 'æ— ä»»åŠ¡æè¿°')
            
            # å¢å¼ºçš„ç³»ç»Ÿpromptï¼ŒåŒ…å«å·¥å…·ä½¿ç”¨æŒ‡å¯¼
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ‹¥æœ‰å¤šç§å·¥å…·æ¥å¸®åŠ©å®Œæˆä»»åŠ¡ã€‚è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

{task_description}

é‡è¦æç¤ºï¼š
1. ä½ æœ‰å¯ç”¨çš„å·¥å…·æ¥è·å–å®æ—¶ä¿¡æ¯æˆ–æ‰§è¡Œç‰¹å®šæ“ä½œ
2. å½“éœ€è¦è·å–æœ€æ–°æ•°æ®ã€æ‰§è¡Œè®¡ç®—æˆ–è°ƒç”¨å¤–éƒ¨æœåŠ¡æ—¶ï¼Œè¯·ä¸»åŠ¨ä½¿ç”¨ç›¸åº”çš„å·¥å…·
3. å¦‚æœä»»åŠ¡æ¶‰åŠå¤©æ°”ã€æœç´¢ã€æ•°æ®æŸ¥è¯¢ç­‰ï¼Œä¼˜å…ˆä½¿ç”¨å·¥å…·è·å–å‡†ç¡®ä¿¡æ¯
4. ä½¿ç”¨å·¥å…·è·å–ä¿¡æ¯åï¼Œè¯·åŸºäºç»“æœä¸ºç”¨æˆ·æä¾›æœ‰ç”¨çš„å›ç­”
5. å¦‚æœå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œè¯·è¯´æ˜æƒ…å†µå¹¶å°½å¯èƒ½æä¾›æ›¿ä»£æ–¹æ¡ˆ

è¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»¥è‡ªç„¶ã€å‡†ç¡®çš„æ–¹å¼å®Œæˆä»»åŠ¡ã€‚å¦‚æœ‰å¿…è¦ï¼Œè¯·ä½¿ç”¨å¯ç”¨çš„å·¥å…·æ¥è·å–æœ€æ–°ã€æœ€å‡†ç¡®çš„ä¿¡æ¯ã€‚"""

            return system_prompt.strip()
            
        except Exception as e:
            logger.error(f"æ„å»ºç³»ç»Ÿpromptå¤±è´¥: {e}")
            return "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ‹¥æœ‰å¤šç§å·¥å…·æ¥å¸®åŠ©å®Œæˆä»»åŠ¡ã€‚å½“éœ€è¦è·å–å®æ—¶ä¿¡æ¯æ—¶ï¼Œè¯·ä¸»åŠ¨ä½¿ç”¨å¯ç”¨çš„å·¥å…·ã€‚è¯·å¸®åŠ©å®Œæˆåˆ†é…çš„ä»»åŠ¡ã€‚"
    
    def _preprocess_upstream_context(self, input_data: str) -> str:
        """é¢„å¤„ç†ä¸Šæ¸¸ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆä»…åŒ…å«å·¥ä½œæµæè¿°ã€èŠ‚ç‚¹åç§°ã€ä»»åŠ¡titleã€èŠ‚ç‚¹è¾“å‡ºå†…å®¹ï¼‰"""
        try:
            logger.debug(f"ğŸ” [ä¸Šä¸‹æ–‡é¢„å¤„ç†] ===== å¼€å§‹é¢„å¤„ç†ä¸Šæ¸¸ä¸Šä¸‹æ–‡ =====")
            logger.debug(f"  - è¾“å…¥æ•°æ®ç±»å‹: {type(input_data)}")
            
            # å®‰å…¨åœ°è®¡ç®—é•¿åº¦å’Œé¢„è§ˆ
            input_str = str(input_data) if input_data is not None else ""
            logger.debug(f"  - è¾“å…¥æ•°æ®é•¿åº¦: {len(input_str)}")
            logger.debug(f"  - è¾“å…¥æ•°æ®æ˜¯å¦ä¸ºç©º: {not input_data}")
            logger.debug(f"  - è¾“å…¥æ•°æ®é¢„è§ˆ: {input_str[:200]}{'...' if len(input_str) > 200 else ''}")
            logger.debug(f"  - è¾“å…¥æ•°æ®å®Œæ•´å†…å®¹: '{input_data}'")
            
            context_parts = []
            
            # æ™ºèƒ½å¤„ç†è¾“å…¥æ•°æ®ï¼šæ”¯æŒå­—å…¸ã€JSONå­—ç¬¦ä¸²å’Œæ™®é€šå­—ç¬¦ä¸²
            data_dict = {}
            try:
                if input_data:
                    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯å­—å…¸ç±»å‹
                    if isinstance(input_data, dict):
                        data_dict = input_data
                        logger.debug(f"  - è¾“å…¥æ•°æ®å·²æ˜¯å­—å…¸ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨")
                        logger.debug(f"  - å­—å…¸é¡¶çº§é”®: {list(data_dict.keys())}")
                    elif isinstance(input_data, str) and input_data.strip():
                        # å°è¯•è§£æJSONå­—ç¬¦ä¸²
                        try:
                            data_dict = json.loads(input_data)
                            logger.debug(f"  - JSONè§£ææˆåŠŸï¼Œæ•°æ®ç±»å‹: {type(data_dict)}")
                            logger.debug(f"  - JSONè§£æåé¡¶çº§é”®: {list(data_dict.keys()) if isinstance(data_dict, dict) else 'Not a dict'}")
                        except json.JSONDecodeError:
                            # å¦‚æœä¸æ˜¯æœ‰æ•ˆJSONï¼Œå°†æ•´ä¸ªå­—ç¬¦ä¸²ä½œä¸ºç®€å•ä¸Šä¸‹æ–‡
                            logger.debug(f"  - è¾“å…¥ä¸æ˜¯æœ‰æ•ˆJSONï¼Œä½œä¸ºæ™®é€šæ–‡æœ¬å¤„ç†")
                            context_parts.append(f"ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{input_data}")
                            return "\n".join(context_parts)
                    else:
                        # å…¶ä»–ç±»å‹è½¬ä¸ºå­—ç¬¦ä¸²å¤„ç†
                        input_str = str(input_data)
                        logger.debug(f"  - å…¶ä»–ç±»å‹æ•°æ®è½¬ä¸ºå­—ç¬¦ä¸²: {input_str[:100]}...")
                        context_parts.append(f"ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{input_str}")
                        return "\n".join(context_parts)
                else:
                    data_dict = {}
                    logger.debug(f"  - è¾“å…¥æ•°æ®ä¸ºç©ºï¼Œä½¿ç”¨ç©ºå­—å…¸")
            except Exception as e:
                logger.error(f"å¤„ç†è¾“å…¥æ•°æ®å¤±è´¥: {e}")
                return "ä¸Šä¸‹æ–‡ä¿¡æ¯å¤„ç†å¤±è´¥ï¼Œè¯·åŸºäºä»»åŠ¡æè¿°è¿›è¡Œå¤„ç†ã€‚"
            
            # 1. å·¥ä½œæµæè¿°
            workflow_global = data_dict.get('workflow_global', {})
            if workflow_global:
                workflow_description = workflow_global.get('workflow_description', '')
                if workflow_description:
                    context_parts.append(f"å·¥ä½œæµæè¿°ï¼š{workflow_description}")
            
            # 2. ä¸Šæ¸¸èŠ‚ç‚¹ä¿¡æ¯ï¼ˆèŠ‚ç‚¹åç§°ã€ä»»åŠ¡titleã€èŠ‚ç‚¹è¾“å‡ºå†…å®¹ï¼‰
            logger.debug(f"ğŸ” [ä¸Šä¸‹æ–‡é¢„å¤„ç†] è¾“å…¥æ•°æ®ç»“æ„: {data_dict}")
            
            # å…¼å®¹ä¸åŒçš„ä¸Šæ¸¸æ•°æ®å­—æ®µå
            immediate_upstream = data_dict.get('immediate_upstream_results', {})  # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
            upstream_outputs = data_dict.get('upstream_outputs', [])
            
            logger.debug(f"ğŸ” [ä¸Šä¸‹æ–‡é¢„å¤„ç†] immediate_upstream_resultsç±»å‹: {type(immediate_upstream)}, å†…å®¹: {immediate_upstream}")
            logger.debug(f"ğŸ” [ä¸Šä¸‹æ–‡é¢„å¤„ç†] upstream_outputsç±»å‹: {type(upstream_outputs)}, å†…å®¹: {upstream_outputs}")
            
            # å¤„ç†immediate_upstreamæ ¼å¼ï¼ˆæ—§æ ¼å¼ï¼‰
            if immediate_upstream:
                context_parts.append("\nä¸Šæ¸¸èŠ‚ç‚¹ä¿¡æ¯ï¼š")
                
                for node_id, node_data in immediate_upstream.items():
                    logger.trace(f"ğŸ“‹ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] å¤„ç†èŠ‚ç‚¹ {node_id[:8]}...")
                    logger.trace(f"  - åŸå§‹æ•°æ®ç±»å‹: {type(node_data)}")
                    logger.trace(f"  - åŸå§‹æ•°æ®å†…å®¹: {node_data}")
                    
                    # æ£€æŸ¥node_dataæ˜¯å¦å·²ç»æ˜¯å­—å…¸ç±»å‹
                    if isinstance(node_data, str):
                        try:
                            node_data = json.loads(node_data)
                            logger.trace(f"  - è§£æåæ•°æ®: {node_data}")
                        except json.JSONDecodeError:
                            logger.warning(f"  âŒ æ— æ³•è§£æèŠ‚ç‚¹æ•°æ®: {node_data[:100]}...")
                            continue
                    elif not isinstance(node_data, dict):
                        logger.warning(f"  âŒ èŠ‚ç‚¹æ•°æ®ç±»å‹ä¸æ­£ç¡®: {type(node_data)}")
                        continue
                    
                    node_name = node_data.get('node_name', f'èŠ‚ç‚¹_{node_id[:8]}')
                    
                    # æ£€æŸ¥å¤šç§å¯èƒ½çš„è¾“å‡ºå­—æ®µ - ä¿®å¤é€»è¾‘ï¼Œç¡®ä¿æ­£ç¡®æå–æ•°æ®
                    output_data = None
                    if 'task_result' in node_data:
                        output_data = node_data['task_result']
                    elif 'output_data' in node_data:
                        output_data = node_data['output_data']
                    elif 'result' in node_data:
                        output_data = node_data['result']
                    elif 'task_description' in node_data:
                        output_data = node_data['task_description']
                    
                    logger.trace(f"  - èŠ‚ç‚¹åç§°: {node_name}")
                    logger.trace(f"  - è¾“å‡ºæ•°æ®: {output_data}")
                    logger.trace(f"  - è¾“å‡ºæ•°æ®ç±»å‹: {type(output_data)}")
                    logger.trace(f"  - èŠ‚ç‚¹å®Œæ•´æ•°æ®: {node_data}")
                    
                    context_parts.append(f"\nèŠ‚ç‚¹ï¼š{node_name}")
                   
                    # è¾“å‡ºå†…å®¹ï¼ˆç®€åŒ–å±•ç¤ºï¼‰
                    if output_data is not None:
                        if isinstance(output_data, dict):
                            # å¯¹äºå­—å…¸ç±»å‹ï¼Œå°è¯•æå–æœ€é‡è¦çš„æ•°æ®
                            context_parts.append("è¾“å‡ºæ•°æ®ï¼š")
                            for key, value in output_data.items():
                                formatted_value = self._format_simple_output(value)
                                context_parts.append(f"- {key}: {formatted_value}")
                                logger.trace(f"  - æ·»åŠ å­—æ®µ {key}: {formatted_value[:100]}...")
                        else:
                            # å¯¹äºç®€å•ç±»å‹ï¼Œç›´æ¥æ˜¾ç¤º
                            formatted_output = self._format_simple_output(output_data)
                            context_parts.append(f"è¾“å‡ºæ•°æ®ï¼š{formatted_output}")
                            logger.trace(f"  - æ·»åŠ è¾“å‡º: {formatted_output}")
                            
                            # å¦‚æœæ˜¯æ•°å­—ï¼Œé¢å¤–æç¤º
                            try:
                                num_value = float(output_data)
                                context_parts.append(f"ï¼ˆè¿™æ˜¯ä¸€ä¸ªæ•°å€¼ï¼š{num_value}ï¼‰")
                                logger.trace(f"  - è¯†åˆ«ä¸ºæ•°å€¼: {num_value}")
                            except (ValueError, TypeError):
                                logger.trace(f"  - éæ•°å€¼ç±»å‹: {type(output_data)}")
                                pass
                    else:
                        context_parts.append("- æ— è¾“å‡ºå†…å®¹")
                        logger.trace(f"  - è¯¥èŠ‚ç‚¹æ— è¾“å‡ºå†…å®¹")
            
            # å¤„ç†upstream_outputsæ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼‰
            elif upstream_outputs and isinstance(upstream_outputs, list):
                context_parts.append("\nä¸Šæ¸¸èŠ‚ç‚¹ä¿¡æ¯ï¼š")
                
                for i, upstream_node in enumerate(upstream_outputs):
                    logger.trace(f"ğŸ“‹ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] å¤„ç†ä¸Šæ¸¸èŠ‚ç‚¹ {i+1}...")
                    logger.trace(f"  - èŠ‚ç‚¹æ•°æ®: {upstream_node}")
                    
                    if isinstance(upstream_node, dict):
                        node_name = upstream_node.get('node_name', f'ä¸Šæ¸¸èŠ‚ç‚¹_{i+1}')
                        output_data = upstream_node.get('output_data', '')
                        
                        context_parts.append(f"\nèŠ‚ç‚¹ï¼š{node_name}")
                        
                        if output_data:
                            formatted_output = self._format_simple_output(output_data)
                            context_parts.append(f"è¾“å‡ºæ•°æ®ï¼š{formatted_output}")
                            logger.trace(f"  - æ·»åŠ è¾“å‡º: {formatted_output[:100]}...")
                        else:
                            context_parts.append("- æ— è¾“å‡ºå†…å®¹")
                            logger.trace(f"  - è¯¥èŠ‚ç‚¹æ— è¾“å‡ºå†…å®¹")
                    else:
                        logger.warning(f"  âŒ ä¸Šæ¸¸èŠ‚ç‚¹æ•°æ®æ ¼å¼ä¸æ­£ç¡®: {upstream_node}")
            else:
                logger.debug(f"ğŸ” [ä¸Šä¸‹æ–‡é¢„å¤„ç†] æ²¡æœ‰æ‰¾åˆ°ä¸Šæ¸¸èŠ‚ç‚¹ä¿¡æ¯")
            
            final_context = "\n".join(context_parts) if context_parts else "æ— ä¸Šæ¸¸ä¸Šä¸‹æ–‡æ•°æ®ã€‚"
            logger.trace(f"ğŸ¯ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] context_partsé•¿åº¦: {len(context_parts)}")
            logger.trace(f"ğŸ¯ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] context_partså†…å®¹: {context_parts}")
            logger.trace(f"ğŸ¯ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] æœ€ç»ˆç”Ÿæˆçš„ä¸Šä¸‹æ–‡é•¿åº¦: {len(final_context)}")
            logger.trace(f"ğŸ¯ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] æœ€ç»ˆç”Ÿæˆçš„ä¸Šä¸‹æ–‡: {final_context}")
            return final_context
            
        except Exception as e:
            logger.error(f"âŒ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] é¢„å¤„ç†ä¸Šæ¸¸ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            import traceback
            logger.error(f"âŒ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return "ä¸Šä¸‹æ–‡ä¿¡æ¯å¤„ç†å¤±è´¥ï¼Œè¯·åŸºäºä»»åŠ¡æè¿°è¿›è¡Œå¤„ç†ã€‚"
    
    def _format_simple_output(self, data) -> str:
        """æ ¼å¼åŒ–è¾“å‡ºæ•°æ®ä¸ºç®€å•æ–‡æœ¬å½¢å¼"""
        try:
            if isinstance(data, dict):
                # å¯¹äºå­—å…¸ï¼Œå°è¯•æ‰¾åˆ°æœ€é‡è¦çš„å­—æ®µ
                if 'result' in data:
                    return str(data['result'])
                elif 'content' in data:
                    return str(data['content'])
                elif 'value' in data:
                    return str(data['value'])
                elif len(data) == 1:
                    # å¦‚æœåªæœ‰ä¸€ä¸ªé”®å€¼å¯¹ï¼Œç›´æ¥è¿”å›å€¼
                    return str(list(data.values())[0])
                else:
                    # è¿”å›ç®€åŒ–çš„å­—å…¸è¡¨ç¤º
                    return str(data)
            elif isinstance(data, list):
                if len(data) <= 3:
                    return str(data)
                else:
                    return f"åŒ…å«{len(data)}ä¸ªé¡¹ç›®çš„åˆ—è¡¨"
            else:
                return str(data)
        except:
            return "æ•°æ®"
    
    async def _build_user_message(self, task: Dict[str, Any], context_info: str, agent: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼ˆåŒ…å«ä»»åŠ¡æ ‡é¢˜ã€ä¸Šæ¸¸èŠ‚ç‚¹ä¿¡æ¯å’Œé™„ä»¶å†…å®¹ï¼‰
        æ”¯æŒå¤šæ¨¡æ€å†…å®¹ä¼ è¾“

        Returns:
            åŒ…å«text_messageã€imagesç­‰çš„å­—å…¸
        """
        try:
            message_parts = []

            # ä»»åŠ¡æ ‡é¢˜å’Œæè¿°
            logger.trace(f"ä¸Šä¸‹æ–‡ä¿¡æ¯: {context_info}")
            task_title = task.get('task_title', 'æœªå‘½åä»»åŠ¡')
            task_description = task.get('task_description', '') or task.get('description', '')

            message_parts.append(f"ä»»åŠ¡ï¼š{task_title}")
            if task_description and task_description.strip():
                message_parts.append(f"ä»»åŠ¡æè¿°ï¼š{task_description.strip()}")
                logger.debug(f"âœ… [æ¶ˆæ¯æ„å»º] æ·»åŠ ä»»åŠ¡æè¿°: {task_description[:100]}...")
            else:
                logger.debug(f"âš ï¸ [æ¶ˆæ¯æ„å»º] ä»»åŠ¡ç¼ºå°‘æè¿°ä¿¡æ¯")

            # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆä¸Šæ¸¸èŠ‚ç‚¹ä¿¡æ¯ï¼‰
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            invalid_context_messages = [
                "æ— ä¸Šæ¸¸ä¸Šä¸‹æ–‡æ•°æ®ã€‚",
                "ä¸Šä¸‹æ–‡ä¿¡æ¯å¤„ç†å¤±è´¥ï¼Œè¯·åŸºäºä»»åŠ¡æè¿°è¿›è¡Œå¤„ç†ã€‚",
                "ä¸Šä¸‹æ–‡ä¿¡æ¯æ ¼å¼é”™è¯¯ï¼Œè¯·åŸºäºä»»åŠ¡æè¿°è¿›è¡Œå¤„ç†ã€‚"
            ]

            logger.debug(f"ğŸ” [æ¶ˆæ¯æ„å»º] æ£€æŸ¥ä¸Šä¸‹æ–‡ä¿¡æ¯æœ‰æ•ˆæ€§...")
            logger.debug(f"  - context_infoå­˜åœ¨: {bool(context_info)}")
            logger.debug(f"  - context_infoé•¿åº¦: {len(context_info) if context_info else 0}")
            logger.debug(f"  - context_infoå†…å®¹: '{context_info}'")
            logger.debug(f"  - context_info.strip(): '{context_info.strip() if context_info else ''}'")
            logger.debug(f"  - æ˜¯å¦åœ¨æ— æ•ˆæ¶ˆæ¯åˆ—è¡¨ä¸­: {context_info.strip() in invalid_context_messages if context_info else False}")

            if context_info and context_info.strip() and context_info.strip() not in invalid_context_messages:
                message_parts.append("\nä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š")
                message_parts.append(context_info)
                logger.debug(f"âœ… [æ¶ˆæ¯æ„å»º] æ·»åŠ äº†æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œé•¿åº¦: {len(context_info)}")
            else:
                message_parts.append("\nå½“å‰æ²¡æœ‰ä¸Šæ¸¸èŠ‚ç‚¹æ•°æ®ã€‚")
                logger.warning(f"âš ï¸ [æ¶ˆæ¯æ„å»º] ä¸Šä¸‹æ–‡ä¿¡æ¯æ— æ•ˆæˆ–ä¸ºç©º: '{context_info}'")

            # å¤„ç†ä»»åŠ¡é™„ä»¶å†…å®¹ï¼ˆå¤šæ¨¡æ€æ”¯æŒï¼‰
            images = []
            try:
                task_id = task.get('task_instance_id')
                if task_id:
                    logger.debug(f"ğŸ“ [é™„ä»¶å¤„ç†] å¼€å§‹å¤„ç†ä»»åŠ¡é™„ä»¶, task_id: {task_id}")
                    attachment_result = await self._process_task_attachments(uuid.UUID(task_id), agent)

                    if attachment_result['has_content']:
                        if attachment_result['text_content']:
                            message_parts.append("\né™„ä»¶å†…å®¹ï¼š")
                            message_parts.append(attachment_result['text_content'])
                            logger.debug(f"âœ… [é™„ä»¶å¤„ç†] æˆåŠŸæ·»åŠ é™„ä»¶æ–‡æœ¬å†…å®¹ï¼Œé•¿åº¦: {len(attachment_result['text_content'])}")

                        # æå–å›¾ç‰‡æ•°æ®ç”¨äºå¤šæ¨¡æ€ä¼ è¾“
                        images = attachment_result.get('images', [])
                        if images:
                            logger.debug(f"ğŸ“· [é™„ä»¶å¤„ç†] æå–åˆ° {len(images)} ä¸ªå›¾ç‰‡ç”¨äºå¤šæ¨¡æ€ä¼ è¾“")
                    else:
                        logger.debug(f"â„¹ï¸ [é™„ä»¶å¤„ç†] å½“å‰ä»»åŠ¡æ— é™„ä»¶")
                else:
                    logger.debug(f"âš ï¸ [é™„ä»¶å¤„ç†] ä»»åŠ¡ç¼ºå°‘task_instance_idï¼Œè·³è¿‡é™„ä»¶å¤„ç†")
            except Exception as e:
                logger.error(f"âŒ [é™„ä»¶å¤„ç†] å¤„ç†é™„ä»¶æ—¶å‡ºé”™: {e}")
                # é™„ä»¶å¤„ç†å¤±è´¥ä¸åº”è¯¥å½±å“ä¸»æµç¨‹
                pass

            text_message = "\n".join(message_parts)

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯æ„å»ºå®Œæˆçš„æ—¥å¿—
            logger.info(f"ğŸ“ [æ¶ˆæ¯æ„å»º] === ç”¨æˆ·æ¶ˆæ¯æ„å»ºå®Œæˆ ===")
            logger.info(f"ğŸ“ [æ¶ˆæ¯æ„å»º] ä»»åŠ¡æ ‡é¢˜: {task_title}")
            logger.info(f"ğŸ“ [æ¶ˆæ¯æ„å»º] ä»»åŠ¡æè¿°: {task_description if task_description else 'æ— '}")
            logger.info(f"ğŸ“ [æ¶ˆæ¯æ„å»º] æœ€ç»ˆç”¨æˆ·æ¶ˆæ¯é•¿åº¦: {len(text_message)} å­—ç¬¦")
            logger.info(f"ğŸ“ [æ¶ˆæ¯æ„å»º] å®Œæ•´ç”¨æˆ·æ¶ˆæ¯å†…å®¹:")
            logger.info(f"--- å¼€å§‹ ---")
            logger.info(text_message)
            logger.info(f"--- ç»“æŸ ---")

            return {
                'text_message': text_message,
                'images': images,
                'has_multimodal_content': bool(images)
            }

        except Exception as e:
            logger.error(f"æ„å»ºç”¨æˆ·æ¶ˆæ¯å¤±è´¥: {e}")
            return {
                'text_message': f"ä»»åŠ¡ï¼š{task.get('task_title', 'æœªçŸ¥ä»»åŠ¡')}",
                'images': [],
                'has_multimodal_content': False
            }
    
    async def _process_with_tools(self, agent: Dict[str, Any],
                                openai_request: Dict[str, Any],
                                mcp_tools: List,
                                openai_client: 'OpenAIClient') -> Dict[str, Any]:
        """å¤„ç†å¸¦æœ‰å·¥å…·è°ƒç”¨çš„OpenAIè¯·æ±‚"""
        try:
            # å¦‚æœæ²¡æœ‰å·¥å…·ï¼Œç›´æ¥è°ƒç”¨æ™®é€šAPI
            if not mcp_tools:
                return await openai_client.process_task(openai_request)
            
            logger.trace(f"ğŸ”§ [TOOL-PROCESS] å¼€å§‹å¤„ç†å¸¦å·¥å…·çš„è¯·æ±‚")
            logger.trace(f"   - å¯ç”¨å·¥å…·æ•°é‡: {len(mcp_tools)}")
            
            # è·å–å·¥å…·é…ç½®
            tool_config = {}
            if isinstance(agent, dict):
                tool_config = agent.get('tool_config', {})
            elif hasattr(agent, 'tool_config'):
                tool_config = getattr(agent, 'tool_config', {}) or {}
                
            max_tool_calls = tool_config.get('max_tool_calls', 5) if isinstance(tool_config, dict) else 5
            tool_timeout = tool_config.get('timeout', 30) if isinstance(tool_config, dict) else 30
            
            logger.trace(f"   - æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°: {max_tool_calls}")
            logger.trace(f"   - å·¥å…·è¶…æ—¶æ—¶é—´: {tool_timeout}ç§’")
            
            # åˆ›å»ºå·¥å…·æ˜ å°„è¡¨
            tool_map = {tool.name: tool for tool in mcp_tools}
            
            messages = openai_request['messages'].copy()
            tool_call_count = 0
            
            while tool_call_count < max_tool_calls:
                # è°ƒç”¨OpenAI API
                logger.trace(f"ğŸš€ [TOOL-PROCESS] è°ƒç”¨OpenAI API (è½®æ¬¡ {tool_call_count + 1})")
                response = await openai_client.process_task(openai_request)
                
                if not response['success']:
                    return response
                
                ai_response = response['result']
                assistant_message = ai_response.get('message', {})
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                tool_calls = assistant_message.get('tool_calls', [])
                
                if not tool_calls:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›æœ€ç»ˆç»“æœ
                    logger.trace(f"âœ… [TOOL-PROCESS] å¯¹è¯å®Œæˆï¼Œæ— å·¥å…·è°ƒç”¨")
                    return response
                
                logger.trace(f"ğŸ”§ [TOOL-PROCESS] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {len(tool_calls)} ä¸ª")
                
                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å¯¹è¯å†å²
                messages.append({
                    'role': 'assistant',
                    'content': assistant_message.get('content'),
                    'tool_calls': tool_calls
                })
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_responses = []
                for tool_call in tool_calls:
                    tool_call_id = tool_call.get('id')
                    function_call = tool_call.get('function', {})
                    tool_name = function_call.get('name')
                    
                    logger.trace(f"ğŸ”§ [TOOL-CALL] è°ƒç”¨å·¥å…·: {tool_name}")
                    
                    if tool_name in tool_map:
                        try:
                            tool = tool_map[tool_name]
                            arguments = json.loads(function_call.get('arguments', '{}'))
                            
                            # è°ƒç”¨MCPå·¥å…·
                            logger.trace(f"   - å‚æ•°: {arguments}")
                            logger.trace(f"ğŸ”§ [AGENT-TOOL-CALL] Agentè°ƒç”¨å·¥å…·")
                            logger.trace(f"   - Agentæƒé™å·²é€šè¿‡get_agent_toolséªŒè¯")
                            logger.trace(f"   - è·³è¿‡ç”¨æˆ·æƒé™éªŒè¯ï¼Œä½¿ç”¨ç³»ç»Ÿè°ƒç”¨")
                            
                            tool_result = await asyncio.wait_for(
                                mcp_service.call_tool(
                                    tool_name, 
                                    tool.server_name, 
                                    arguments
                                    # æ³¨æ„ï¼šä¸ä¼ é€’user_idï¼Œè®©ç³»ç»Ÿè¯†åˆ«ä¸ºAgentè°ƒç”¨
                                ),
                                timeout=tool_timeout
                            )
                            
                            if tool_result['success']:
                                logger.trace(f"   âœ… å·¥å…·è°ƒç”¨æˆåŠŸ")
                                # å·¥å…·ç»“æœå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å¯¹è±¡ï¼Œç»Ÿä¸€å¤„ç†
                                result_data = tool_result['result']
                                if isinstance(result_data, str):
                                    response_content = result_data
                                else:
                                    response_content = json.dumps(result_data)
                            else:
                                logger.warning(f"   âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {tool_result['error']}")
                                response_content = f"é”™è¯¯: {tool_result['error']}"
                            
                        except asyncio.TimeoutError:
                            logger.warning(f"   â° å·¥å…·è°ƒç”¨è¶…æ—¶: {tool_name}")
                            response_content = f"å·¥å…·è°ƒç”¨è¶…æ—¶ ({tool_timeout}ç§’)"
                        except Exception as e:
                            logger.error(f"   âŒ å·¥å…·è°ƒç”¨å¼‚å¸¸: {e}")
                            response_content = f"å·¥å…·è°ƒç”¨å¼‚å¸¸: {str(e)}"
                    else:
                        logger.warning(f"   âŒ æœªæ‰¾åˆ°å·¥å…·: {tool_name}")
                        response_content = f"æœªæ‰¾åˆ°å·¥å…·: {tool_name}"
                    
                    # æ·»åŠ å·¥å…·å“åº”
                    tool_responses.append({
                        'role': 'tool',
                        'content': response_content,
                        'tool_call_id': tool_call_id
                    })
                
                # å°†å·¥å…·å“åº”æ·»åŠ åˆ°æ¶ˆæ¯å†å²
                messages.extend(tool_responses)
                
                # æ›´æ–°è¯·æ±‚æ¶ˆæ¯
                openai_request['messages'] = messages
                tool_call_count += 1
                
                logger.trace(f"ğŸ”„ [TOOL-PROCESS] å·¥å…·è°ƒç”¨å®Œæˆï¼Œå‡†å¤‡ä¸‹ä¸€è½®å¯¹è¯")
            
            # è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°
            logger.warning(f"âš ï¸ [TOOL-PROCESS] è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°: {max_tool_calls}")
            
            # è¿›è¡Œæœ€åä¸€æ¬¡è°ƒç”¨è·å–æœ€ç»ˆç»“æœ
            final_response = await openai_client.process_task(openai_request)
            return final_response
            
        except Exception as e:
            logger.error(f"âŒ [TOOL-PROCESS] å·¥å…·è°ƒç”¨å¤„ç†å¤±è´¥: {e}")
            import traceback
            logger.error(f"   - é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {
                'success': False,
                'error': f'å·¥å…·è°ƒç”¨å¤„ç†å¤±è´¥: {str(e)}'
            }

    async def _process_task_attachments(self, task_id: uuid.UUID, agent: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†ä»»åŠ¡é™„ä»¶ï¼Œæ ¹æ®agentçš„èƒ½åŠ›æå–å†…å®¹
        æ”¯æŒå¤šæ¨¡æ€AIçš„å›¾ç‰‡base64ä¼ è¾“

        Args:
            task_id: ä»»åŠ¡å®ä¾‹ID
            agent: Agentä¿¡æ¯ï¼ŒåŒ…å«tagsç­‰èƒ½åŠ›æ ‡è¯†

        Returns:
            åŒ…å«æ–‡æœ¬å†…å®¹å’Œå›¾ç‰‡å†…å®¹çš„å­—å…¸
        """
        try:
            from .file_content_extractor import FileContentExtractor

            logger.debug(f"ğŸ“ [é™„ä»¶å¤„ç†] å¼€å§‹å¤„ç†ä»»åŠ¡é™„ä»¶: {task_id}")

            # æ£€æŸ¥agentæ˜¯å¦æ”¯æŒå¤šæ¨¡æ€
            agent_tags = agent.get('tags', [])
            if isinstance(agent_tags, str):
                import json
                try:
                    agent_tags = json.loads(agent_tags)
                except:
                    agent_tags = []

            supports_multimodal = 'multimodal' in agent_tags or 'vision' in agent_tags
            logger.debug(f"ğŸ” [é™„ä»¶å¤„ç†] Agentå¤šæ¨¡æ€æ”¯æŒ: {supports_multimodal}, æ ‡ç­¾: {agent_tags}")

            # ä½¿ç”¨æ”¯æŒèŠ‚ç‚¹çº§åˆ«é™„ä»¶ä¼ é€’çš„æå–å™¨
            extractor = FileContentExtractor()

            if supports_multimodal:
                # å¤šæ¨¡æ€æ¨¡å¼ï¼šåˆ†åˆ«å¤„ç†æ–‡æœ¬å’Œå›¾ç‰‡
                result = await self._extract_multimodal_attachments(extractor, task_id)
            else:
                # æ–‡æœ¬æ¨¡å¼ï¼šæ‰€æœ‰é™„ä»¶è½¬ä¸ºæ–‡æœ¬
                attachments_content = await extractor.extract_task_attachments(task_id)
                result = {
                    'has_content': bool(attachments_content),
                    'text_content': attachments_content,
                    'images': [],
                    'mode': 'text_only'
                }

            if result['has_content']:
                logger.debug(f"âœ… [é™„ä»¶å¤„ç†] æˆåŠŸå¤„ç†é™„ä»¶ï¼Œæ¨¡å¼: {result['mode']}")
                if result.get('images'):
                    logger.debug(f"ğŸ“· [é™„ä»¶å¤„ç†] åŒ…å« {len(result['images'])} ä¸ªå›¾ç‰‡")
            else:
                logger.debug(f"ğŸ“ [é™„ä»¶å¤„ç†] ä»»åŠ¡ {task_id} æ²¡æœ‰é™„ä»¶å†…å®¹")

            return result

        except Exception as e:
            logger.error(f"âŒ [é™„ä»¶å¤„ç†] å¤„ç†é™„ä»¶å¤±è´¥: {e}")
            import traceback
            logger.error(f"   é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {
                'has_content': False,
                'text_content': f"é™„ä»¶å¤„ç†å¤±è´¥: {str(e)}",
                'images': [],
                'mode': 'error'
            }

    async def _extract_multimodal_attachments(self, extractor: 'FileContentExtractor', task_id: uuid.UUID) -> Dict[str, Any]:
        """
        æå–å¤šæ¨¡æ€é™„ä»¶å†…å®¹

        Args:
            extractor: æ–‡ä»¶å†…å®¹æå–å™¨
            task_id: ä»»åŠ¡å®ä¾‹ID

        Returns:
            åŒ…å«æ–‡æœ¬å’Œå›¾ç‰‡çš„å¤šæ¨¡æ€å†…å®¹
        """
        try:
            # è·å–ä»»åŠ¡çš„æ‰€æœ‰é™„ä»¶æ–‡ä»¶
            from .file_association_service import FileAssociationService
            file_service = FileAssociationService()

            # 1. é¦–å…ˆæŸ¥è¯¢ç›´æ¥å…³è”çš„ä»»åŠ¡é™„ä»¶
            task_files = await file_service.get_task_instance_files(task_id)

            # 2. å¦‚æœæ²¡æœ‰ç›´æ¥ä»»åŠ¡é™„ä»¶ï¼ŒæŸ¥è¯¢èŠ‚ç‚¹çº§åˆ«çš„é™„ä»¶
            if not task_files:
                try:
                    from ..repositories.instance.task_instance_repository import TaskInstanceRepository
                    task_repo = TaskInstanceRepository()
                    task_info = await task_repo.get_task_by_id(task_id)

                    if task_info and task_info.get('node_instance_id'):
                        node_instance_id = task_info['node_instance_id']
                        task_files = await file_service.get_node_instance_files(uuid.UUID(str(node_instance_id)))

                except Exception as e:
                    logger.warning(f"âš ï¸ [å¤šæ¨¡æ€é™„ä»¶] æŸ¥è¯¢èŠ‚ç‚¹é™„ä»¶å¤±è´¥: {e}")

            if not task_files:
                return {
                    'has_content': False,
                    'text_content': '',
                    'images': [],
                    'mode': 'multimodal'
                }

            logger.debug(f"ğŸ“ [å¤šæ¨¡æ€é™„ä»¶] æ‰¾åˆ° {len(task_files)} ä¸ªæ–‡ä»¶")

            text_parts = []
            images = []

            # å¤„ç†æ¯ä¸ªæ–‡ä»¶
            for file_info in task_files:
                try:
                    file_path = file_info.get('file_path', '')
                    file_name = file_info.get('file_name', '') or file_info.get('original_filename', 'unknown')
                    content_type = file_info.get('content_type', '')

                    logger.debug(f"ğŸ“„ [å¤šæ¨¡æ€é™„ä»¶] å¤„ç†æ–‡ä»¶: {file_name}")

                    if not os.path.exists(file_path):
                        logger.warning(f"âš ï¸ [å¤šæ¨¡æ€é™„ä»¶] æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                        text_parts.append(f"## æ–‡ä»¶: {file_name}\n[æ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„æ— æ•ˆ]")
                        continue

                    # ä½¿ç”¨å¤šæ¨¡æ€æå–å™¨
                    result = await extractor.extract_content_for_multimodal(file_path, content_type)

                    if result['success']:
                        if result['is_image']:
                            # å›¾ç‰‡æ–‡ä»¶ï¼šæ·»åŠ åˆ°imagesåˆ—è¡¨
                            images.append({
                                'name': file_name,
                                'content_type': result['content_type'],
                                'base64_data': result['content'],
                                'metadata': result.get('metadata', {})
                            })
                            # åœ¨æ–‡æœ¬ä¸­ä¹Ÿæ·»åŠ å›¾ç‰‡å¼•ç”¨
                            text_parts.append(f"## å›¾ç‰‡: {file_name}\n[å›¾ç‰‡å·²ä»¥å¤šæ¨¡æ€æ–¹å¼å¤„ç†]")
                        else:
                            # æ–‡æœ¬æ–‡ä»¶ï¼šæ·»åŠ åˆ°æ–‡æœ¬å†…å®¹
                            text_parts.append(f"## æ–‡ä»¶: {file_name}\n{result['content']}")

                        logger.debug(f"âœ… [å¤šæ¨¡æ€é™„ä»¶] æ–‡ä»¶ {file_name} å¤„ç†æˆåŠŸ")
                    else:
                        logger.warning(f"âš ï¸ [å¤šæ¨¡æ€é™„ä»¶] æ–‡ä»¶ {file_name} å¤„ç†å¤±è´¥: {result.get('error', 'unknown')}")
                        text_parts.append(f"## æ–‡ä»¶: {file_name}\n[å¤„ç†å¤±è´¥: {result.get('error', 'unknown')}]")

                except Exception as e:
                    logger.error(f"âŒ [å¤šæ¨¡æ€é™„ä»¶] å¤„ç†å•ä¸ªæ–‡ä»¶å¤±è´¥: {e}")
                    text_parts.append(f"## æ–‡ä»¶: {file_name if 'file_name' in locals() else 'unknown'}\n[å¤„ç†å¼‚å¸¸: {str(e)}]")

            # æ•´åˆç»“æœ
            text_content = "\n\n".join(text_parts) if text_parts else ""
            has_content = bool(text_content or images)

            logger.info(f"ğŸ“Š [å¤šæ¨¡æ€é™„ä»¶] å¤„ç†å®Œæˆ - æ–‡æœ¬: {len(text_content)} å­—ç¬¦, å›¾ç‰‡: {len(images)} ä¸ª")

            return {
                'has_content': has_content,
                'text_content': text_content,
                'images': images,
                'mode': 'multimodal'
            }

        except Exception as e:
            logger.error(f"âŒ [å¤šæ¨¡æ€é™„ä»¶] æå–å¤±è´¥: {e}")
            import traceback
            logger.error(f"   é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {
                'has_content': False,
                'text_content': f"å¤šæ¨¡æ€é™„ä»¶æå–å¤±è´¥: {str(e)}",
                'images': [],
                'mode': 'error'
            }

    async def _process_ai_generated_images(self, task_id: uuid.UUID, ai_result: Dict[str, Any], agent: Dict[str, Any]) -> None:
        """
        å¤„ç†AIç”Ÿæˆçš„å›¾ç‰‡å†…å®¹ï¼Œä¿å­˜åˆ°æœ¬åœ°å¹¶å…³è”åˆ°ä»»åŠ¡å’ŒèŠ‚ç‚¹å®ä¾‹

        Args:
            task_id: ä»»åŠ¡å®ä¾‹ID
            ai_result: AIå“åº”ç»“æœ
            agent: Agentä¿¡æ¯
        """
        try:
            logger.info(f"ğŸ–¼ï¸ [AI-IMAGE-SAVE] å¼€å§‹å¤„ç†AIç”Ÿæˆçš„å›¾ç‰‡å†…å®¹")

            # æ£€æµ‹AIå“åº”ä¸­çš„å›¾ç‰‡å†…å®¹
            images_to_save = await self._extract_images_from_ai_response(ai_result)

            if not images_to_save:
                logger.debug(f"ğŸ“ [AI-IMAGE-SAVE] AIå“åº”ä¸­æ²¡æœ‰æ£€æµ‹åˆ°å›¾ç‰‡å†…å®¹")
                return

            logger.info(f"ğŸ–¼ï¸ [AI-IMAGE-SAVE] æ£€æµ‹åˆ° {len(images_to_save)} ä¸ªå›¾ç‰‡")

            # è·å–ä»»åŠ¡ä¿¡æ¯ä»¥ä¾¿å…³è”åˆ°èŠ‚ç‚¹å®ä¾‹
            task_info = await self.task_repo.get_task_by_id(task_id)
            node_instance_id = task_info.get('node_instance_id') if task_info else None

            # è·å–ç³»ç»Ÿç”¨æˆ·IDï¼ˆç”¨äºæ ‡è®°ä¸ºAIç”Ÿæˆï¼‰
            system_user_id = await self._get_system_user_id()

            # ä¿å­˜å’Œå…³è”æ¯ä¸ªå›¾ç‰‡
            for i, image_data in enumerate(images_to_save):
                try:
                    logger.info(f"ğŸ’¾ [AI-IMAGE-SAVE] å¤„ç†ç¬¬ {i+1} ä¸ªå›¾ç‰‡")

                    # ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
                    saved_file_info = await self._save_ai_generated_image(
                        image_data,
                        f"ai_generated_{i+1}",
                        system_user_id
                    )

                    if saved_file_info:
                        logger.info(f"âœ… [AI-IMAGE-SAVE] å›¾ç‰‡ä¿å­˜æˆåŠŸ: {saved_file_info['filename']}")

                        # åˆ›å»ºworkflow_fileè®°å½•
                        file_record = await self._create_workflow_file_record(saved_file_info)

                        if file_record:
                            file_id = uuid.UUID(file_record['file_id'])

                            # åªå…³è”åˆ°ä»»åŠ¡å®ä¾‹ - ç§»é™¤èŠ‚ç‚¹ç»‘å®š
                            await self._associate_image_to_task(task_id, file_id, system_user_id)

                            logger.info(f"ğŸ”— [AI-IMAGE-SAVE] å›¾ç‰‡å…³è”åˆ°ä»»åŠ¡å®Œæˆ: task={task_id}, file={file_id}")
                        else:
                            logger.error(f"âŒ [AI-IMAGE-SAVE] åˆ›å»ºæ–‡ä»¶è®°å½•å¤±è´¥")
                    else:
                        logger.error(f"âŒ [AI-IMAGE-SAVE] å›¾ç‰‡ä¿å­˜å¤±è´¥")

                except Exception as e:
                    logger.error(f"âŒ [AI-IMAGE-SAVE] å¤„ç†ç¬¬ {i+1} ä¸ªå›¾ç‰‡å¤±è´¥: {e}")
                    continue

            logger.info(f"ğŸ‰ [AI-IMAGE-SAVE] AIç”Ÿæˆå›¾ç‰‡å¤„ç†å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ [AI-IMAGE-SAVE] å¤„ç†AIç”Ÿæˆå›¾ç‰‡å¤±è´¥: {e}")
            import traceback
            logger.error(f"   é”™è¯¯å †æ ˆ: {traceback.format_exc()}")

    async def _extract_images_from_ai_response(self, ai_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        ä»AIå“åº”ä¸­æå–å›¾ç‰‡å†…å®¹

        Args:
            ai_result: AIå“åº”ç»“æœ

        Returns:
            å›¾ç‰‡æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«base64_dataã€content_typeç­‰ä¿¡æ¯
        """
        images = []

        try:
            # æ–¹æ¡ˆ1: æ£€æŸ¥ç»“æœæ–‡æœ¬ä¸­çš„base64å›¾ç‰‡
            result_text = ai_result.get('result', '') if isinstance(ai_result, dict) else str(ai_result)

            # æŸ¥æ‰¾base64å›¾ç‰‡æ ‡è¯†
            import re

            # åŒ¹é… data:image/xxx;base64,xxxx æ ¼å¼
            base64_pattern = r'data:image/([^;]+);base64,([A-Za-z0-9+/=]+)'
            matches = re.findall(base64_pattern, result_text)

            for i, (image_type, base64_data) in enumerate(matches):
                images.append({
                    'base64_data': base64_data,
                    'content_type': f'image/{image_type}',
                    'source': 'inline_base64',
                    'index': i
                })
                logger.debug(f"ğŸ“· [IMAGE-EXTRACT] æ‰¾åˆ°å†…è”base64å›¾ç‰‡: image/{image_type}")

            # æ–¹æ¡ˆ2: æ£€æŸ¥æ˜¯å¦æœ‰ä¸“é—¨çš„å›¾ç‰‡å­—æ®µï¼ˆæŸäº›AIå¯èƒ½ä¼šå•ç‹¬è¿”å›å›¾ç‰‡ï¼‰
            if isinstance(ai_result, dict):
                # æ£€æŸ¥å¸¸è§çš„å›¾ç‰‡å­—æ®µå
                image_fields = ['images', 'generated_images', 'image_outputs', 'pictures']
                for field in image_fields:
                    if field in ai_result and ai_result[field]:
                        field_images = ai_result[field]
                        if isinstance(field_images, list):
                            for i, img in enumerate(field_images):
                                if isinstance(img, dict):
                                    images.append({
                                        'base64_data': img.get('data', img.get('base64', '')),
                                        'content_type': img.get('content_type', img.get('format', 'image/png')),
                                        'source': f'field_{field}',
                                        'index': i
                                    })
                                    logger.debug(f"ğŸ“· [IMAGE-EXTRACT] æ‰¾åˆ°å­—æ®µå›¾ç‰‡: {field}[{i}]")

            # æ–¹æ¡ˆ3: æ£€æŸ¥OpenAIé£æ ¼çš„å·¥å…·è°ƒç”¨ç»“æœï¼ˆå¯èƒ½åŒ…å«å›¾ç‰‡ç”Ÿæˆï¼‰
            if isinstance(ai_result, dict) and 'message' in ai_result:
                message = ai_result['message']
                if isinstance(message, dict) and 'tool_calls' in message:
                    # è¿™é‡Œå¯ä»¥æ‰©å±•å¤„ç†ç‰¹å®šçš„å›¾ç‰‡ç”Ÿæˆå·¥å…·è°ƒç”¨ç»“æœ
                    pass

            logger.info(f"ğŸ” [IMAGE-EXTRACT] ä»AIå“åº”ä¸­æå–åˆ° {len(images)} ä¸ªå›¾ç‰‡")
            return images

        except Exception as e:
            logger.error(f"âŒ [IMAGE-EXTRACT] æå–AIå“åº”å›¾ç‰‡å¤±è´¥: {e}")
            return []

    async def _save_ai_generated_image(self, image_data: Dict[str, Any], base_filename: str,
                                     uploaded_by: uuid.UUID) -> Optional[Dict[str, Any]]:
        """
        ä¿å­˜AIç”Ÿæˆçš„å›¾ç‰‡åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ

        Args:
            image_data: å›¾ç‰‡æ•°æ®ï¼ŒåŒ…å«base64_dataã€content_typeç­‰
            base_filename: åŸºç¡€æ–‡ä»¶å
            uploaded_by: ä¸Šä¼ è€…ID

        Returns:
            ä¿å­˜çš„æ–‡ä»¶ä¿¡æ¯å­—å…¸
        """
        try:
            import base64
            import os
            from pathlib import Path
            import hashlib
            from datetime import datetime

            base64_data = image_data.get('base64_data', '')
            content_type = image_data.get('content_type', 'image/png')

            if not base64_data:
                logger.error(f"âŒ [AI-IMAGE-SAVE] å›¾ç‰‡æ•°æ®ä¸ºç©º")
                return None

            # ç¡®å®šæ–‡ä»¶æ‰©å±•å
            type_map = {
                'image/png': '.png',
                'image/jpeg': '.jpg',
                'image/jpg': '.jpg',
                'image/gif': '.gif',
                'image/webp': '.webp',
                'image/bmp': '.bmp'
            }
            file_ext = type_map.get(content_type, '.png')

            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            unique_id = str(uuid.uuid4())
            filename = f"{base_filename}_{unique_id}{file_ext}"

            # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
            from ..config.settings import get_settings
            settings = get_settings()
            upload_root = Path(settings.upload_root_dir if hasattr(settings, 'upload_root_dir') else "./uploads")

            now = datetime.now()
            date_path = upload_root / str(now.year) / f"{now.month:02d}" / f"{now.day:02d}"
            date_path.mkdir(parents=True, exist_ok=True)

            file_path = date_path / filename

            # è§£ç å¹¶ä¿å­˜å›¾ç‰‡
            try:
                image_bytes = base64.b64decode(base64_data)
            except Exception as e:
                logger.error(f"âŒ [AI-IMAGE-SAVE] Base64è§£ç å¤±è´¥: {e}")
                return None

            # å†™å…¥æ–‡ä»¶
            with open(file_path, 'wb') as f:
                f.write(image_bytes)

            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            hash_sha256 = hashlib.sha256()
            hash_sha256.update(image_bytes)
            file_hash = hash_sha256.hexdigest()

            file_size = len(image_bytes)

            logger.info(f"ğŸ’¾ [AI-IMAGE-SAVE] å›¾ç‰‡ä¿å­˜æˆåŠŸ: {filename} ({file_size} bytes)")

            return {
                'filename': filename,
                'original_filename': f"{base_filename}_ai_generated{file_ext}",
                'file_path': str(file_path),
                'file_size': file_size,
                'content_type': content_type,
                'file_hash': file_hash,
                'uploaded_by': uploaded_by
            }

        except Exception as e:
            logger.error(f"âŒ [AI-IMAGE-SAVE] ä¿å­˜AIå›¾ç‰‡å¤±è´¥: {e}")
            return None

    async def _create_workflow_file_record(self, file_info: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        åˆ›å»ºworkflow_fileæ•°æ®åº“è®°å½•

        Args:
            file_info: æ–‡ä»¶ä¿¡æ¯å­—å…¸

        Returns:
            åˆ›å»ºçš„æ–‡ä»¶è®°å½•
        """
        try:
            from .file_association_service import FileAssociationService
            from ..models.file_attachment import WorkflowFileCreate

            file_service = FileAssociationService()

            # åˆ›å»ºæ–‡ä»¶è®°å½•å¯¹è±¡
            file_create = WorkflowFileCreate(
                filename=file_info['filename'],
                original_filename=file_info['original_filename'],
                file_path=file_info['file_path'],
                file_size=file_info['file_size'],
                content_type=file_info['content_type'],
                file_hash=file_info['file_hash'],
                uploaded_by=file_info['uploaded_by']
            )

            # åˆ›å»ºæ•°æ®åº“è®°å½•
            file_record = await file_service.create_workflow_file(file_create)

            if file_record:
                logger.info(f"âœ… [AI-IMAGE-SAVE] æ–‡ä»¶è®°å½•åˆ›å»ºæˆåŠŸ: {file_record['file_id']}")
                return file_record
            else:
                logger.error(f"âŒ [AI-IMAGE-SAVE] æ–‡ä»¶è®°å½•åˆ›å»ºå¤±è´¥")
                return None

        except Exception as e:
            logger.error(f"âŒ [AI-IMAGE-SAVE] åˆ›å»ºæ–‡ä»¶è®°å½•å¤±è´¥: {e}")
            return None

    async def _associate_image_to_task(self, task_id: uuid.UUID, file_id: uuid.UUID,
                                     uploaded_by: uuid.UUID) -> bool:
        """
        å…³è”å›¾ç‰‡åˆ°ä»»åŠ¡å®ä¾‹

        Args:
            task_id: ä»»åŠ¡å®ä¾‹ID
            file_id: æ–‡ä»¶ID
            uploaded_by: ä¸Šä¼ è€…ID

        Returns:
            æ˜¯å¦æˆåŠŸå…³è”
        """
        try:
            from .file_association_service import FileAssociationService
            from ..models.file_attachment import AttachmentType

            file_service = FileAssociationService()

            # å…³è”ä¸ºè¾“å‡ºé™„ä»¶
            success = await file_service.associate_task_instance_file(
                task_id,
                file_id,
                uploaded_by,
                AttachmentType.OUTPUT
            )

            if success:
                logger.info(f"âœ… [AI-IMAGE-SAVE] å›¾ç‰‡å…³è”åˆ°ä»»åŠ¡æˆåŠŸ: task={task_id}, file={file_id}")
            else:
                logger.error(f"âŒ [AI-IMAGE-SAVE] å›¾ç‰‡å…³è”åˆ°ä»»åŠ¡å¤±è´¥: task={task_id}, file={file_id}")

            return success

        except Exception as e:
            logger.error(f"âŒ [AI-IMAGE-SAVE] å…³è”å›¾ç‰‡åˆ°ä»»åŠ¡å¤±è´¥: {e}")
            return False

    async def _associate_image_to_node_instance(self, node_instance_id: uuid.UUID,
                                              file_id: uuid.UUID) -> bool:
        """
        å…³è”å›¾ç‰‡åˆ°èŠ‚ç‚¹å®ä¾‹

        Args:
            node_instance_id: èŠ‚ç‚¹å®ä¾‹ID
            file_id: æ–‡ä»¶ID

        Returns:
            æ˜¯å¦æˆåŠŸå…³è”
        """
        try:
            from .file_association_service import FileAssociationService
            from ..models.file_attachment import AttachmentType

            file_service = FileAssociationService()

            # å…³è”ä¸ºè¾“å‡ºé™„ä»¶
            success = await file_service.associate_node_instance_file(
                node_instance_id,
                file_id,
                AttachmentType.OUTPUT
            )

            if success:
                logger.info(f"âœ… [AI-IMAGE-SAVE] å›¾ç‰‡å…³è”åˆ°èŠ‚ç‚¹å®ä¾‹æˆåŠŸ: node={node_instance_id}, file={file_id}")
            else:
                logger.error(f"âŒ [AI-IMAGE-SAVE] å›¾ç‰‡å…³è”åˆ°èŠ‚ç‚¹å®ä¾‹å¤±è´¥: node={node_instance_id}, file={file_id}")

            return success

        except Exception as e:
            logger.error(f"âŒ [AI-IMAGE-SAVE] å…³è”å›¾ç‰‡åˆ°èŠ‚ç‚¹å®ä¾‹å¤±è´¥: {e}")
            return False

    async def _get_system_user_id(self) -> uuid.UUID:
        """
        è·å–ç³»ç»Ÿç”¨æˆ·IDï¼Œç”¨äºæ ‡è®°AIç”Ÿæˆçš„æ–‡ä»¶

        Returns:
            ç³»ç»Ÿç”¨æˆ·ID
        """
        try:
            # æŸ¥è¯¢ç³»ç»Ÿç”¨æˆ·
            system_user_query = """
                SELECT user_id FROM user
                WHERE username = 'system' OR username = 'ai_agent'
                LIMIT 1
            """

            result = await self.task_repo.db.fetch_one(system_user_query)

            if result:
                return uuid.UUID(str(result['user_id']))
            else:
                # å¦‚æœæ²¡æœ‰ç³»ç»Ÿç”¨æˆ·ï¼Œåˆ›å»ºä¸€ä¸ª
                logger.warning(f"âš ï¸ [AI-IMAGE-SAVE] æœªæ‰¾åˆ°ç³»ç»Ÿç”¨æˆ·ï¼Œåˆ›å»ºé»˜è®¤ç³»ç»Ÿç”¨æˆ·")
                return await self._create_system_user()

        except Exception as e:
            logger.error(f"âŒ [AI-IMAGE-SAVE] è·å–ç³»ç»Ÿç”¨æˆ·IDå¤±è´¥: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„UUID
            return uuid.UUID('00000000-0000-0000-0000-000000000001')

    async def _create_system_user(self) -> uuid.UUID:
        """
        åˆ›å»ºç³»ç»Ÿç”¨æˆ·

        Returns:
            ç³»ç»Ÿç”¨æˆ·ID
        """
        try:
            system_user_id = uuid.uuid4()

            create_user_query = """
                INSERT INTO user (user_id, username, email, password_hash, status, created_at, updated_at)
                VALUES (%s, 'ai_agent', 'ai@system.local', 'system_generated', 1, NOW(), NOW())
                ON DUPLICATE KEY UPDATE user_id = user_id
            """

            await self.task_repo.db.execute(create_user_query, system_user_id)

            logger.info(f"âœ… [AI-IMAGE-SAVE] ç³»ç»Ÿç”¨æˆ·åˆ›å»ºæˆåŠŸ: {system_user_id}")
            return system_user_id

        except Exception as e:
            logger.error(f"âŒ [AI-IMAGE-SAVE] åˆ›å»ºç³»ç»Ÿç”¨æˆ·å¤±è´¥: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„UUID
            return uuid.UUID('00000000-0000-0000-0000-000000000001')

    def _is_image_generation_request(self, user_message: str) -> bool:
        """
        æ£€æµ‹ç”¨æˆ·æ¶ˆæ¯æ˜¯å¦ä¸ºå›¾åƒç”Ÿæˆè¯·æ±‚

        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯å†…å®¹

        Returns:
            æ˜¯å¦ä¸ºå›¾åƒç”Ÿæˆè¯·æ±‚
        """
        # å›¾åƒç”Ÿæˆå…³é”®è¯
        image_keywords = [
            'ç”Ÿæˆå›¾ç‰‡', 'ç”Ÿæˆå›¾åƒ', 'ç”»', 'ç”»ä¸€ä¸ª', 'ç”»ä¸€å¼ ', 'ç»˜åˆ¶', 'åˆ›å»ºå›¾ç‰‡', 'åˆ›å»ºå›¾åƒ',
            'generate image', 'generate picture', 'create image', 'draw', 'paint',
            'åˆ¶ä½œå›¾ç‰‡', 'ç”Ÿæˆ', 'å›¾ç‰‡', 'å›¾åƒ', 'picture', 'image'
        ]

        # è½¬æ¢ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
        message_lower = user_message.lower()

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾åƒç”Ÿæˆå…³é”®è¯
        for keyword in image_keywords:
            if keyword in message_lower:
                logger.debug(f"ğŸ” [IMAGE-DETECT] åŒ¹é…åˆ°å…³é”®è¯: {keyword}")
                return True

        return False

    async def _handle_image_generation(self, user_message: str, agent: Dict[str, Any],
                                     task_id: uuid.UUID = None, task_metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        å¤„ç†å›¾åƒç”Ÿæˆè¯·æ±‚

        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            agent: Agentä¿¡æ¯
            task_id: ä»»åŠ¡IDï¼ˆç”¨äºå…³è”ç”Ÿæˆçš„å›¾ç‰‡ï¼‰
            task_metadata: ä»»åŠ¡å…ƒæ•°æ®ï¼ˆåŒ…å«ä»»åŠ¡æ ‡é¢˜å’Œæè¿°ï¼‰

        Returns:
            å›¾åƒç”Ÿæˆç»“æœ
        """
        try:
            from ..utils.openai_client import openai_client

            logger.info(f"ğŸ¨ [IMAGE-GEN] å¼€å§‹å¤„ç†å›¾åƒç”Ÿæˆè¯·æ±‚")
            logger.info(f"ğŸ¨ [IMAGE-GEN] === PROMPTå¤„ç†æµç¨‹ ===")
            logger.info(f"ğŸ¨ [IMAGE-GEN] 1. åŸå§‹ç”¨æˆ·è¾“å…¥: {user_message}")
            logger.info(f"ğŸ¨ [IMAGE-GEN] 2. ä»»åŠ¡å…ƒæ•°æ®: {task_metadata}")

            # æå–å›¾åƒæè¿°æç¤º
            image_prompt = self._extract_image_prompt(user_message)
            logger.info(f"ğŸ¨ [IMAGE-GEN] 3. æå–åçš„åŸºç¡€æç¤º: {image_prompt}")

            # å¢å¼ºæç¤ºï¼šåŠ å…¥ä»»åŠ¡ä¸Šä¸‹æ–‡ä¿¡æ¯
            if task_metadata:
                task_title = task_metadata.get('task_title', '')
                task_description = task_metadata.get('task_description', '')

                logger.info(f"ğŸ¨ [IMAGE-GEN] 4. ä»»åŠ¡ä¸Šä¸‹æ–‡ä¿¡æ¯:")
                logger.info(f"   - ä»»åŠ¡æ ‡é¢˜: {task_title}")
                logger.info(f"   - ä»»åŠ¡æè¿°: {task_description}")

                if task_title or task_description:
                    context_parts = []
                    if task_title:
                        context_parts.append(f"ä»»åŠ¡ï¼š{task_title}")
                    if task_description:
                        context_parts.append(f"æè¿°ï¼š{task_description}")

                    context_info = "ï¼Œ".join(context_parts)
                    enhanced_prompt = f"{image_prompt}ã€‚ä»»åŠ¡èƒŒæ™¯ï¼š{context_info}"

                    logger.info(f"ğŸ¨ [IMAGE-GEN] 5. å¢å¼ºåçš„æœ€ç»ˆæç¤º: {enhanced_prompt}")
                    image_prompt = enhanced_prompt
                else:
                    logger.info(f"ğŸ¨ [IMAGE-GEN] 5. æ— ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨åŸºç¡€æç¤º: {image_prompt}")
            else:
                logger.info(f"ğŸ¨ [IMAGE-GEN] 4. æ— ä»»åŠ¡å…ƒæ•°æ®ï¼Œä½¿ç”¨åŸºç¡€æç¤º: {image_prompt}")
            logger.info(f"ğŸ¨ [IMAGE-GEN] === APIè°ƒç”¨å‡†å¤‡ ===")
            logger.info(f"ğŸ¨ [IMAGE-GEN] 6. å‘é€åˆ°å›¾åƒç”ŸæˆAPIçš„æœ€ç»ˆprompt: {image_prompt}")

            # è°ƒç”¨å›¾åƒç”ŸæˆAPI
            image_result = await openai_client.generate_image(
                prompt=image_prompt,
                model="black-forest-labs/FLUX.1-schnell",  # SiliconFlowæ”¯æŒçš„æ¨¡å‹
                size="1024x1024",
                quality="standard",
                n=1
            )

            if image_result['success']:
                logger.info(f"âœ… [IMAGE-GEN] å›¾åƒç”ŸæˆæˆåŠŸ")

                # ä¸‹è½½å¹¶ä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡
                saved_images = await self._download_and_save_images(
                    image_result.get('images', []),
                    task_id,
                    image_prompt
                )

                # æ„å»ºå“åº”æ¶ˆæ¯
                response_content = f"æˆ‘ä¸ºæ‚¨ç”Ÿæˆäº†å›¾åƒï¼š\n\næè¿°ï¼š{image_prompt}\n\n"

                if saved_images:
                    response_content += f"å·²ä¿å­˜ {len(saved_images)} å¼ å›¾ç‰‡åˆ°æœ¬åœ°ã€‚\n"
                    for i, saved_img in enumerate(saved_images):
                        response_content += f"å›¾ç‰‡ {i+1}: {saved_img['filename']}\n"
                else:
                    # å¦‚æœä¿å­˜å¤±è´¥ï¼Œä»æ˜¾ç¤ºåŸå§‹URLæˆ–Base64
                    if 'images' in image_result and image_result['images']:
                        first_image = image_result['images'][0]
                        if 'url' in first_image:
                            response_content += f"å›¾åƒé“¾æ¥ï¼š{first_image['url']}\n\n"
                            response_content += "æ³¨æ„ï¼šå›¾åƒé“¾æ¥æœ‰æ•ˆæœŸä¸º1å°æ—¶ï¼Œè¯·åŠæ—¶ä¿å­˜ã€‚"
                        elif 'b64_json' in first_image:
                            response_content += f"data:image/png;base64,{first_image['b64_json']}"

                return {
                    'success': True,
                    'content': response_content,
                    'image_data': image_result.get('images', []),
                    'saved_images': saved_images,
                    'prompt': image_prompt,
                    'model': image_result.get('model', 'unknown'),
                    'usage': {'total_tokens': 100}  # ä¼°ç®—
                }
            else:
                logger.error(f"âŒ [IMAGE-GEN] å›¾åƒç”Ÿæˆå¤±è´¥: {image_result.get('error')}")
                return {
                    'success': False,
                    'error': f"å›¾åƒç”Ÿæˆå¤±è´¥: {image_result.get('error')}",
                    'content': 'æŠ±æ­‰ï¼Œå›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°äº†é”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚'
                }

        except Exception as e:
            logger.error(f"âŒ [IMAGE-GEN] å¤„ç†å›¾åƒç”Ÿæˆè¯·æ±‚å¤±è´¥: {e}")
            import traceback
            logger.error(f"   é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {
                'success': False,
                'error': str(e),
                'content': 'æŠ±æ­‰ï¼Œå›¾åƒç”ŸæˆåŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚'
            }

    def _extract_image_prompt(self, user_message: str) -> str:
        """
        ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–å›¾åƒæè¿°æç¤º

        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯

        Returns:
            å›¾åƒæè¿°æç¤º
        """
        logger.info(f"ğŸ” [PROMPT-EXTRACT] === æç¤ºè¯æå–è¿‡ç¨‹ ===")
        logger.info(f"ğŸ” [PROMPT-EXTRACT] åŸå§‹è¾“å…¥: {user_message}")

        # ç§»é™¤å¸¸è§çš„æŒ‡ä»¤è¯
        prompt_text = user_message

        # ç§»é™¤æŒ‡ä»¤æ€§è¯æ±‡
        remove_patterns = [
            r'ç”Ÿæˆå›¾ç‰‡.*?[:ï¼š]\s*',
            r'ç”Ÿæˆå›¾åƒ.*?[:ï¼š]\s*',
            r'ç”».*?[:ï¼š]\s*',
            r'ç»˜åˆ¶.*?[:ï¼š]\s*',
            r'create\s+image.*?[:ï¼š]\s*',
            r'generate\s+image.*?[:ï¼š]\s*',
            r'è¯·.*?ç”»',
            r'è¯·.*?ç”Ÿæˆ',
            r'å¸®æˆ‘.*?ç”»',
            r'å¸®æˆ‘.*?ç”Ÿæˆ'
        ]

        import re
        for i, pattern in enumerate(remove_patterns):
            before = prompt_text
            prompt_text = re.sub(pattern, '', prompt_text, flags=re.IGNORECASE)
            if before != prompt_text:
                logger.info(f"ğŸ” [PROMPT-EXTRACT] è§„åˆ™ {i+1} åŒ¹é…: {pattern}")
                logger.info(f"   - å¤„ç†å‰: {before}")
                logger.info(f"   - å¤„ç†å: {prompt_text}")

        # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
        cleaned_prompt = prompt_text.strip()
        logger.info(f"ğŸ” [PROMPT-EXTRACT] æ¸…ç†ç©ºç™½å­—ç¬¦å: {cleaned_prompt}")

        # å¦‚æœæå–åä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤æç¤º
        if not cleaned_prompt:
            cleaned_prompt = "ç”Ÿæˆä¸€ä¸ªå›¾åƒ"
            logger.info(f"ğŸ” [PROMPT-EXTRACT] æå–ç»“æœä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤æç¤º: {cleaned_prompt}")

        logger.info(f"ğŸ” [PROMPT-EXTRACT] æœ€ç»ˆæå–ç»“æœ: {cleaned_prompt}")
        return cleaned_prompt

    async def _download_and_save_images(self, images: List[Dict[str, Any]],
                                      task_id: uuid.UUID = None,
                                      prompt: str = "") -> List[Dict[str, Any]]:
        """
        ä¸‹è½½å¹¶ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°ï¼Œæ”¯æŒURLå’ŒBase64æ ¼å¼

        Args:
            images: å›¾ç‰‡æ•°æ®åˆ—è¡¨
            task_id: ä»»åŠ¡ID
            prompt: å›¾ç‰‡ç”Ÿæˆæç¤º

        Returns:
            ä¿å­˜çš„å›¾ç‰‡ä¿¡æ¯åˆ—è¡¨
        """
        saved_images = []

        try:
            for i, image_data in enumerate(images):
                try:
                    logger.info(f"ğŸ“¥ [IMAGE-SAVE] å¤„ç†ç¬¬ {i+1} å¼ å›¾ç‰‡")

                    # ç¡®å®šå›¾ç‰‡æ¥æºå’Œæ•°æ®
                    image_bytes = None
                    original_url = None
                    content_type = 'image/png'  # é»˜è®¤æ ¼å¼

                    if 'url' in image_data:
                        # URLæ ¼å¼ - éœ€è¦ä¸‹è½½
                        original_url = image_data['url']
                        logger.info(f"ğŸŒ [IMAGE-SAVE] ä»URLä¸‹è½½å›¾ç‰‡: {original_url[:100]}...")
                        image_bytes = await self._download_image_from_url(original_url)
                        if not image_bytes:
                            logger.error(f"âŒ [IMAGE-SAVE] URLå›¾ç‰‡ä¸‹è½½å¤±è´¥")
                            continue

                    elif 'b64_json' in image_data:
                        # Base64æ ¼å¼
                        logger.info(f"ğŸ“„ [IMAGE-SAVE] å¤„ç†Base64å›¾ç‰‡æ•°æ®")
                        image_bytes = await self._decode_base64_image(image_data['b64_json'])
                        if not image_bytes:
                            logger.error(f"âŒ [IMAGE-SAVE] Base64å›¾ç‰‡è§£ç å¤±è´¥")
                            continue

                    else:
                        logger.warning(f"âš ï¸ [IMAGE-SAVE] å›¾ç‰‡æ•°æ®æ ¼å¼ä¸æ”¯æŒ: {list(image_data.keys())}")
                        continue

                    # æ£€æµ‹å›¾ç‰‡æ ¼å¼å¹¶è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                    image_format, processed_bytes = await self._process_image_format(image_bytes)
                    if not processed_bytes:
                        logger.error(f"âŒ [IMAGE-SAVE] å›¾ç‰‡æ ¼å¼å¤„ç†å¤±è´¥")
                        continue

                    # ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°
                    saved_info = await self._save_image_to_local(
                        processed_bytes,
                        image_format,
                        f"generated_{i+1}",
                        prompt
                    )

                    if saved_info:
                        # å…³è”åˆ°ä»»åŠ¡å’ŒèŠ‚ç‚¹
                        if task_id:
                            await self._associate_saved_image_to_task(saved_info, task_id)

                        saved_info['original_url'] = original_url
                        saved_info['index'] = i
                        saved_images.append(saved_info)
                        logger.info(f"âœ… [IMAGE-SAVE] å›¾ç‰‡ {i+1} ä¿å­˜æˆåŠŸ: {saved_info['filename']}")
                    else:
                        logger.error(f"âŒ [IMAGE-SAVE] å›¾ç‰‡ {i+1} ä¿å­˜å¤±è´¥")

                except Exception as e:
                    logger.error(f"âŒ [IMAGE-SAVE] å¤„ç†ç¬¬ {i+1} å¼ å›¾ç‰‡å¤±è´¥: {e}")
                    continue

            logger.info(f"ğŸ‰ [IMAGE-SAVE] å›¾ç‰‡ä¿å­˜å®Œæˆï¼ŒæˆåŠŸä¿å­˜ {len(saved_images)} å¼ ")
            return saved_images

        except Exception as e:
            logger.error(f"âŒ [IMAGE-SAVE] å›¾ç‰‡ä¿å­˜è¿‡ç¨‹å¤±è´¥: {e}")
            import traceback
            logger.error(f"   é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return []

    async def _download_image_from_url(self, url: str) -> Optional[bytes]:
        """
        ä»URLä¸‹è½½å›¾ç‰‡

        Args:
            url: å›¾ç‰‡URL

        Returns:
            å›¾ç‰‡å­—èŠ‚æ•°æ®
        """
        try:
            import aiohttp
            import asyncio

            logger.debug(f"ğŸŒ [URL-DOWNLOAD] å¼€å§‹ä¸‹è½½å›¾ç‰‡: {url}")

            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
                    if response.status == 200:
                        image_bytes = await response.read()
                        logger.info(f"âœ… [URL-DOWNLOAD] å›¾ç‰‡ä¸‹è½½æˆåŠŸï¼Œå¤§å°: {len(image_bytes)} bytes")
                        return image_bytes
                    else:
                        logger.error(f"âŒ [URL-DOWNLOAD] HTTPé”™è¯¯: {response.status}")
                        return None

        except Exception as e:
            logger.error(f"âŒ [URL-DOWNLOAD] ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
            return None

    async def _decode_base64_image(self, b64_data: str) -> Optional[bytes]:
        """
        è§£ç Base64å›¾ç‰‡æ•°æ®

        Args:
            b64_data: Base64ç¼–ç çš„å›¾ç‰‡æ•°æ®

        Returns:
            å›¾ç‰‡å­—èŠ‚æ•°æ®
        """
        try:
            import base64

            logger.debug(f"ğŸ“„ [BASE64-DECODE] å¼€å§‹è§£ç Base64æ•°æ®ï¼Œé•¿åº¦: {len(b64_data)}")

            # ç§»é™¤å¯èƒ½çš„data URLå‰ç¼€
            if b64_data.startswith('data:'):
                if ',' in b64_data:
                    b64_data = b64_data.split(',', 1)[1]

            image_bytes = base64.b64decode(b64_data)
            logger.info(f"âœ… [BASE64-DECODE] Base64è§£ç æˆåŠŸï¼Œå¤§å°: {len(image_bytes)} bytes")
            return image_bytes

        except Exception as e:
            logger.error(f"âŒ [BASE64-DECODE] Base64è§£ç å¤±è´¥: {e}")
            return None

    async def _process_image_format(self, image_bytes: bytes) -> tuple:
        """
        å¤„ç†å›¾ç‰‡æ ¼å¼ï¼Œè½¬æ¢ä¸ºJPGæˆ–PNG

        Args:
            image_bytes: åŸå§‹å›¾ç‰‡å­—èŠ‚

        Returns:
            (æ ¼å¼åç§°, å¤„ç†åçš„å­—èŠ‚æ•°æ®)
        """
        try:
            from PIL import Image
            import io

            logger.debug(f"ğŸ”„ [FORMAT-PROCESS] å¼€å§‹å¤„ç†å›¾ç‰‡æ ¼å¼")

            # åŠ è½½å›¾ç‰‡
            with Image.open(io.BytesIO(image_bytes)) as img:
                # æ£€æµ‹åŸå§‹æ ¼å¼
                original_format = img.format
                logger.debug(f"   - åŸå§‹æ ¼å¼: {original_format}")

                # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆå»é™¤é€æ˜åº¦ï¼‰
                if img.mode in ('RGBA', 'LA', 'P'):
                    # æœ‰é€æ˜åº¦ï¼Œä¿å­˜ä¸ºPNG
                    target_format = 'PNG'
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                else:
                    # æ— é€æ˜åº¦ï¼Œä¿å­˜ä¸ºJPGï¼ˆæ›´å°çš„æ–‡ä»¶ï¼‰
                    target_format = 'JPEG'
                    if img.mode != 'RGB':
                        img = img.convert('RGB')

                # ä¿å­˜å¤„ç†åçš„å›¾ç‰‡
                output_buffer = io.BytesIO()
                if target_format == 'JPEG':
                    img.save(output_buffer, format='JPEG', quality=95, optimize=True)
                    file_ext = 'jpg'
                else:
                    img.save(output_buffer, format='PNG', optimize=True)
                    file_ext = 'png'

                processed_bytes = output_buffer.getvalue()

                logger.info(f"âœ… [FORMAT-PROCESS] æ ¼å¼å¤„ç†å®Œæˆ: {original_format} -> {target_format}")
                logger.info(f"   - åŸå§‹å¤§å°: {len(image_bytes)} bytes")
                logger.info(f"   - å¤„ç†åå¤§å°: {len(processed_bytes)} bytes")

                return file_ext, processed_bytes

        except Exception as e:
            logger.error(f"âŒ [FORMAT-PROCESS] å›¾ç‰‡æ ¼å¼å¤„ç†å¤±è´¥: {e}")
            # å¦‚æœå¤„ç†å¤±è´¥ï¼Œè¿”å›åŸå§‹æ•°æ®å’Œé»˜è®¤æ ¼å¼
            return 'png', image_bytes

    async def _save_image_to_local(self, image_bytes: bytes, file_ext: str,
                                 base_name: str, prompt: str = "") -> Optional[Dict[str, Any]]:
        """
        ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ

        Args:
            image_bytes: å›¾ç‰‡å­—èŠ‚æ•°æ®
            file_ext: æ–‡ä»¶æ‰©å±•å
            base_name: åŸºç¡€æ–‡ä»¶å
            prompt: å›¾ç‰‡æè¿°

        Returns:
            ä¿å­˜çš„æ–‡ä»¶ä¿¡æ¯
        """
        try:
            import os
            from pathlib import Path
            import hashlib
            from datetime import datetime

            logger.debug(f"ğŸ’¾ [LOCAL-SAVE] å¼€å§‹ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°")

            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            unique_id = str(uuid.uuid4())
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{base_name}_{timestamp}_{unique_id[:8]}.{file_ext}"

            # åˆ›å»ºä¿å­˜ç›®å½•
            upload_root = Path("uploads")
            now = datetime.now()
            date_path = upload_root / str(now.year) / f"{now.month:02d}" / f"{now.day:02d}"
            date_path.mkdir(parents=True, exist_ok=True)

            file_path = date_path / filename

            # å†™å…¥æ–‡ä»¶
            with open(file_path, 'wb') as f:
                f.write(image_bytes)

            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            hash_sha256 = hashlib.sha256()
            hash_sha256.update(image_bytes)
            file_hash = hash_sha256.hexdigest()

            file_size = len(image_bytes)

            logger.info(f"ğŸ’¾ [LOCAL-SAVE] å›¾ç‰‡ä¿å­˜æˆåŠŸ: {filename} ({file_size} bytes)")

            # è·å–ç³»ç»Ÿç”¨æˆ·ID
            system_user_id = await self._get_system_user_id()

            return {
                'filename': filename,
                'original_filename': f"{base_name}_ai_generated.{file_ext}",
                'file_path': str(file_path),
                'content_type': f'image/{file_ext}',
                'file_size': file_size,
                'file_hash': file_hash,
                'uploaded_by': system_user_id,
                'description': prompt[:200] if prompt else f"AIç”Ÿæˆçš„å›¾ç‰‡: {base_name}",
                'tags': ['ai-generated', 'image-generation']
            }

        except Exception as e:
            logger.error(f"âŒ [LOCAL-SAVE] ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°å¤±è´¥: {e}")
            return None

    async def _associate_saved_image_to_task(self, image_info: Dict[str, Any],
                                           task_id: uuid.UUID) -> bool:
        """
        å…³è”ä¿å­˜çš„å›¾ç‰‡åˆ°ä»»åŠ¡å’ŒèŠ‚ç‚¹

        Args:
            image_info: å›¾ç‰‡ä¿¡æ¯
            task_id: ä»»åŠ¡ID

        Returns:
            æ˜¯å¦æˆåŠŸå…³è”
        """
        try:
            logger.info(f"ğŸ”— [IMAGE-ASSOC] å¼€å§‹å…³è”å›¾ç‰‡åˆ°ä»»åŠ¡: {task_id}")

            # åˆ›å»ºworkflow_fileè®°å½•
            file_record = await self._create_workflow_file_record(image_info)
            if not file_record:
                logger.error(f"âŒ [IMAGE-ASSOC] åˆ›å»ºæ–‡ä»¶è®°å½•å¤±è´¥")
                return False

            file_id = uuid.UUID(file_record['file_id'])
            system_user_id = image_info['uploaded_by']

            # å…³è”åˆ°ä»»åŠ¡å®ä¾‹
            task_success = await self._associate_image_to_task(task_id, file_id, system_user_id)

            # åªå…³è”åˆ°ä»»åŠ¡å®ä¾‹ - ç§»é™¤èŠ‚ç‚¹ç»‘å®š
            if task_success:
                logger.info(f"âœ… [IMAGE-ASSOC] å›¾ç‰‡å…³è”æˆåŠŸ: file={file_id}, task={task_id}")
            else:
                logger.error(f"âŒ [IMAGE-ASSOC] å›¾ç‰‡å…³è”å¤±è´¥")

            return task_success

        except Exception as e:
            logger.error(f"âŒ [IMAGE-ASSOC] å…³è”å›¾ç‰‡åˆ°ä»»åŠ¡å¤±è´¥: {e}")
            return False

# å…¨å±€Agentä»»åŠ¡æœåŠ¡å®ä¾‹
agent_task_service = AgentTaskService()