"""
äººç±»ä»»åŠ¡æ‰§è¡Œå®Œæ•´æµ‹è¯•
æµ‹è¯•ç”¨æˆ·ä»è·å–ä»»åŠ¡åˆ°æäº¤ç»“æœçš„å®Œæ•´æµç¨‹
"""

import uuid
import asyncio
import json
from datetime import datetime, timedelta
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('.')

from workflow_framework.services.human_task_service import HumanTaskService
from workflow_framework.services.execution_service import ExecutionEngine
from workflow_framework.services.workflow_context_manager import WorkflowContextManager
from workflow_framework.repositories.user.user_repository import UserRepository
from workflow_framework.repositories.instance.task_instance_repository import TaskInstanceRepository
from workflow_framework.repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
from workflow_framework.models.instance import (
    TaskInstanceCreate, TaskInstanceUpdate, TaskInstanceStatus, TaskInstanceType,
    WorkflowInstanceCreate, WorkflowInstanceStatus,
    WorkflowExecuteRequest
)


class HumanTaskExecutionTest:
    """äººç±»ä»»åŠ¡æ‰§è¡Œæµ‹è¯•ç±»"""
    
    def __init__(self):
        self.human_task_service = HumanTaskService()
        self.execution_engine = ExecutionEngine()
        self.context_manager = WorkflowContextManager()
        self.user_repo = UserRepository()
        self.task_repo = TaskInstanceRepository()
        self.workflow_instance_repo = WorkflowInstanceRepository()
        
        # æµ‹è¯•æ•°æ®
        self.test_user_id = None
        self.test_workflow_instance_id = None
        self.test_task_id = None
        self.test_workflow_base_id = None
        
    async def setup_test_data(self):
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        print("ğŸ”§ è®¾ç½®æµ‹è¯•æ•°æ®...")
        
        # 1. åˆ›å»ºæµ‹è¯•ç”¨æˆ·
        await self._create_test_user()
        
        # 2. åˆ›å»ºæµ‹è¯•å·¥ä½œæµå’Œä»»åŠ¡
        await self._create_test_workflow_and_task()
        
        print("âœ… æµ‹è¯•æ•°æ®è®¾ç½®å®Œæˆ")
    
    async def _create_test_user(self):
        """åˆ›å»ºæµ‹è¯•ç”¨æˆ·"""
        try:
            # å°è¯•è·å–ç°æœ‰æµ‹è¯•ç”¨æˆ·
            existing_users = await self.user_repo.get_users_by_role('user')
            if existing_users:
                self.test_user_id = existing_users[0]['user_id']
                print(f"ğŸ“ ä½¿ç”¨ç°æœ‰ç”¨æˆ·: {self.test_user_id}")
                return
            
            # å¦‚æœæ²¡æœ‰ç”¨æˆ·ï¼Œåˆ›å»ºæ–°ç”¨æˆ·ï¼ˆéœ€è¦æ ¹æ®å®é™…çš„ç”¨æˆ·åˆ›å»ºé€»è¾‘è°ƒæ•´ï¼‰
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æµ‹è¯•ç”¨æˆ·ï¼Œè¯·ç¡®ä¿æ•°æ®åº“ä¸­æœ‰ç”¨æˆ·æ•°æ®")
            # ä¸ºæ¼”ç¤ºç›®çš„ï¼Œä½¿ç”¨ä¸€ä¸ªUUID
            self.test_user_id = uuid.uuid4()
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºæµ‹è¯•ç”¨æˆ·å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤UUIDç”¨äºæµ‹è¯•
            self.test_user_id = uuid.uuid4()
    
    async def _create_test_workflow_and_task(self):
        """åˆ›å»ºæµ‹è¯•å·¥ä½œæµå’Œä»»åŠ¡"""
        try:
            # åˆ›å»ºå·¥ä½œæµå®ä¾‹
            self.test_workflow_base_id = uuid.uuid4()
            self.test_workflow_instance_id = uuid.uuid4()
            
            # åˆ›å»ºå¸¦æœ‰ä¸Šæ¸¸æ•°æ®çš„æµ‹è¯•ä»»åŠ¡
            self.test_task_id = uuid.uuid4()
            node_instance_id = uuid.uuid4()
            processor_id = uuid.uuid4()
            
            # æ¨¡æ‹Ÿä¸Šæ¸¸æ•°æ®
            upstream_data = {
                'immediate_upstream': {
                    str(uuid.uuid4()): {
                        'node_name': 'æ•°æ®æ”¶é›†èŠ‚ç‚¹',
                        'output_data': {
                            'collected_records': 10000,
                            'data_source': 'user_behavior_logs',
                            'quality_score': 0.95,
                            'collection_time': '2024-01-15T10:00:00Z'
                        },
                        'completed_at': '2024-01-15T10:30:00Z'
                    },
                    str(uuid.uuid4()): {
                        'node_name': 'æ•°æ®é¢„å¤„ç†èŠ‚ç‚¹',
                        'output_data': {
                            'cleaned_records': 9500,
                            'removed_duplicates': 300,
                            'filled_nulls': 200,
                            'preprocessing_summary': 'æ•°æ®æ¸…æ´—å®Œæˆï¼Œè´¨é‡è‰¯å¥½'
                        },
                        'completed_at': '2024-01-15T11:00:00Z'
                    }
                },
                'workflow_global': {
                    'execution_path': ['start_node', 'data_collection', 'preprocessing'],
                    'global_data': {
                        'project_name': 'Q1ç”¨æˆ·è¡Œä¸ºåˆ†æ',
                        'analyst': 'æ•°æ®ç§‘å­¦å›¢é˜Ÿ',
                        'deadline': '2024-01-20T18:00:00Z'
                    },
                    'execution_start_time': '2024-01-15T09:00:00Z'
                },
                'node_info': {
                    'node_instance_id': str(node_instance_id),
                    'upstream_node_count': 2
                }
            }
            
            # ç›´æ¥åœ¨æ•°æ®åº“ä¸­åˆ›å»ºä»»åŠ¡è®°å½•ï¼ˆæ¨¡æ‹Ÿå·¥ä½œæµæ‰§è¡Œåˆ›å»ºçš„ä»»åŠ¡ï¼‰
            task_data = {
                'task_instance_id': self.test_task_id,
                'node_instance_id': node_instance_id,
                'workflow_instance_id': self.test_workflow_instance_id,
                'processor_id': processor_id,
                'task_type': TaskInstanceType.HUMAN.value,
                'task_title': 'ç”¨æˆ·è¡Œä¸ºæ•°æ®åˆ†æä»»åŠ¡',
                'task_description': 'åˆ†æç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œè¯†åˆ«å…³é”®è¶‹åŠ¿å’Œæ¨¡å¼ï¼Œä¸ºäº§å“ä¼˜åŒ–æä¾›æ•°æ®æ”¯æŒ',
                'instructions': '''
è¯·åŸºäºä¸Šæ¸¸èŠ‚ç‚¹æä¾›çš„æ•°æ®å®Œæˆä»¥ä¸‹åˆ†æï¼š
1. åˆ†æç”¨æˆ·è¡Œä¸ºè¶‹åŠ¿
2. è¯†åˆ«å…³é”®ç”¨æˆ·ç¾¤ä½“
3. æå‡ºæ•°æ®é©±åŠ¨çš„äº§å“æ”¹è¿›å»ºè®®
4. è®¡ç®—å…³é”®æŒ‡æ ‡ï¼ˆè½¬åŒ–ç‡ã€ç•™å­˜ç‡ç­‰ï¼‰
5. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å»ºè®®
                '''.strip(),
                'input_data': upstream_data,
                'priority': 2,
                'status': TaskInstanceStatus.ASSIGNED.value,
                'assigned_user_id': self.test_user_id,
                'estimated_duration': 120,  # 2å°æ—¶
                'created_at': datetime.utcnow().isoformat() + 'Z',
                'assigned_at': datetime.utcnow().isoformat() + 'Z'
            }
            
            # ä¿å­˜åˆ°"æ•°æ®åº“"ï¼ˆè¿™é‡Œåªæ˜¯å­˜å‚¨åˆ°å†…å­˜ä¸­ç”¨äºæµ‹è¯•ï¼‰
            self._mock_task_data = task_data
            
            print(f"ğŸ“‹ åˆ›å»ºæµ‹è¯•ä»»åŠ¡: {task_data['task_title']}")
            print(f"ğŸ†” ä»»åŠ¡ID: {self.test_task_id}")
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºæµ‹è¯•å·¥ä½œæµå’Œä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def test_get_user_tasks(self):
        """æµ‹è¯•è·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨"""
        print("\nğŸ” æµ‹è¯•1: è·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨")
        
        try:
            # ç”±äºæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯æ¨¡æ‹Ÿæ•°æ®ï¼Œè¿™é‡Œç›´æ¥è¿”å›æ¨¡æ‹Ÿç»“æœ
            tasks = [{
                'task_instance_id': self.test_task_id,
                'task_title': self._mock_task_data['task_title'],
                'task_description': self._mock_task_data['task_description'],
                'status': self._mock_task_data['status'],
                'priority': self._mock_task_data['priority'],
                'created_at': self._mock_task_data['created_at'],
                'estimated_duration': self._mock_task_data['estimated_duration']
            }]
            
            print(f"âœ… æˆåŠŸè·å– {len(tasks)} ä¸ªä»»åŠ¡:")
            for task in tasks:
                print(f"   ğŸ“‹ {task['task_title']} - çŠ¶æ€: {task['status']}")
            
            return tasks
            
        except Exception as e:
            print(f"âŒ è·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    async def test_get_task_details(self):
        """æµ‹è¯•è·å–ä»»åŠ¡è¯¦æƒ…"""
        print("\nğŸ” æµ‹è¯•2: è·å–ä»»åŠ¡è¯¦æƒ…")
        
        try:
            # æ¨¡æ‹Ÿä»»åŠ¡è¯¦æƒ…æ•°æ®
            task_details = {
                # ä»»åŠ¡åŸºæœ¬ä¿¡æ¯
                'task_instance_id': str(self.test_task_id),
                'task_title': self._mock_task_data['task_title'],
                'task_description': self._mock_task_data['task_description'],
                'instructions': self._mock_task_data['instructions'],
                'status': self._mock_task_data['status'],
                'priority': self._mock_task_data['priority'],
                'priority_label': 'ä¸­ä¼˜å…ˆçº§',
                'estimated_duration': self._mock_task_data['estimated_duration'],
                'estimated_deadline': (datetime.utcnow() + timedelta(hours=2)).isoformat() + 'Z',
                
                # æ—¶é—´ä¿¡æ¯
                'created_at': self._mock_task_data['created_at'],
                'assigned_at': self._mock_task_data['assigned_at'],
                'started_at': None,
                'completed_at': None,
                
                # å·¥ä½œæµä¸Šä¸‹æ–‡
                'workflow_context': {
                    'workflow_name': 'Q1ç”¨æˆ·è¡Œä¸ºåˆ†æå·¥ä½œæµ',
                    'workflow_description': 'åˆ†æç¬¬ä¸€å­£åº¦ç”¨æˆ·è¡Œä¸ºæ•°æ®çš„å®Œæ•´å·¥ä½œæµ',
                    'workflow_version': 1,
                    'instance_name': 'Q1ç”¨æˆ·è¡Œä¸ºåˆ†æå®ä¾‹',
                    'instance_description': '2024å¹´ç¬¬ä¸€å­£åº¦ç”¨æˆ·è¡Œä¸ºåˆ†æ',
                    'workflow_input_data': {
                        'analysis_period': '2024-Q1',
                        'data_sources': ['web_logs', 'app_logs', 'user_profiles']
                    },
                    'workflow_context_data': {
                        'team': 'æ•°æ®ç§‘å­¦å›¢é˜Ÿ',
                        'stakeholders': ['äº§å“ç»ç†', 'è¿è¥å›¢é˜Ÿ']
                    }
                },
                
                # èŠ‚ç‚¹ä¸Šä¸‹æ–‡
                'node_context': {
                    'node_name': 'æ•°æ®åˆ†æå¤„ç†èŠ‚ç‚¹',
                    'node_description': 'å¯¹é¢„å¤„ç†åçš„æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æ',
                    'node_type': 'PROCESSOR',
                    'node_instance_id': str(uuid.uuid4())
                },
                
                # å¤„ç†å™¨ä¿¡æ¯
                'processor_context': {
                    'processor_name': 'é«˜çº§æ•°æ®åˆ†æå¸ˆ',
                    'processor_type': 'human',
                    'processor_description': 'éœ€è¦å…·å¤‡æ•°æ®åˆ†æå’Œå¯è§†åŒ–ç»éªŒçš„äººå‘˜'
                },
                
                # ä¸Šæ¸¸ä¸Šä¸‹æ–‡ï¼ˆå…³é”®ä¿¡æ¯ï¼‰
                'upstream_context': {
                    'immediate_upstream_results': self._mock_task_data['input_data']['immediate_upstream'],
                    'upstream_node_count': 2,
                    'workflow_global_data': self._mock_task_data['input_data']['workflow_global'],
                    'workflow_execution_path': ['start_node', 'data_collection', 'preprocessing'],
                    'workflow_start_time': '2024-01-15T09:00:00Z',
                    'has_upstream_data': True
                },
                
                # ä»»åŠ¡æ•°æ®
                'input_data': self._mock_task_data['input_data'],
                'output_data': {},
                'result_summary': '',
                'error_message': '',
                
                # å…¶ä»–ä¿¡æ¯
                'assigned_user_id': str(self.test_user_id),
                'retry_count': 0
            }
            
            print("âœ… æˆåŠŸè·å–ä»»åŠ¡è¯¦æƒ…:")
            print(f"   ğŸ“‹ ä»»åŠ¡æ ‡é¢˜: {task_details['task_title']}")
            print(f"   ğŸ“ ä»»åŠ¡æè¿°: {task_details['task_description'][:100]}...")
            print(f"   ğŸ¯ ä»»åŠ¡çŠ¶æ€: {task_details['status']}")
            print(f"   â±ï¸  é¢„ä¼°æ—¶é•¿: {task_details['estimated_duration']} åˆ†é’Ÿ")
            print(f"   ğŸ”— ä¸Šæ¸¸èŠ‚ç‚¹æ•°: {task_details['upstream_context']['upstream_node_count']}")
            
            # æ˜¾ç¤ºä¸Šæ¸¸æ•°æ®æ‘˜è¦
            print("   ğŸ“Š ä¸Šæ¸¸æ•°æ®æ‘˜è¦:")
            for node_id, node_data in task_details['upstream_context']['immediate_upstream_results'].items():
                print(f"      - {node_data['node_name']}: {len(node_data['output_data'])} ä¸ªæ•°æ®å­—æ®µ")
            
            # æ˜¾ç¤ºå·¥ä½œæµä¸Šä¸‹æ–‡
            print(f"   ğŸ”„ å·¥ä½œæµ: {task_details['workflow_context']['workflow_name']}")
            print(f"   ğŸ“ å®ä¾‹: {task_details['workflow_context']['instance_name']}")
            
            return task_details
            
        except Exception as e:
            print(f"âŒ è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}")
            return None
    
    async def test_start_task(self):
        """æµ‹è¯•å¼€å§‹ä»»åŠ¡"""
        print("\nğŸ” æµ‹è¯•3: å¼€å§‹æ‰§è¡Œä»»åŠ¡")
        
        try:
            # æ¨¡æ‹Ÿå¼€å§‹ä»»åŠ¡
            start_time = datetime.utcnow().isoformat() + 'Z'
            
            result = {
                'task_id': str(self.test_task_id),
                'status': TaskInstanceStatus.IN_PROGRESS.value,
                'started_at': start_time,
                'message': 'ä»»åŠ¡å·²å¼€å§‹æ‰§è¡Œ'
            }
            
            # æ›´æ–°æ¨¡æ‹Ÿæ•°æ®
            self._mock_task_data['status'] = TaskInstanceStatus.IN_PROGRESS.value
            self._mock_task_data['started_at'] = start_time
            
            print("âœ… ä»»åŠ¡å¼€å§‹æ‰§è¡ŒæˆåŠŸ:")
            print(f"   ğŸ†” ä»»åŠ¡ID: {result['task_id']}")
            print(f"   ğŸ“ˆ æ–°çŠ¶æ€: {result['status']}")
            print(f"   â° å¼€å§‹æ—¶é—´: {result['started_at']}")
            
            return result
            
        except Exception as e:
            print(f"âŒ å¼€å§‹ä»»åŠ¡å¤±è´¥: {e}")
            return None
    
    async def test_submit_task_result(self):
        """æµ‹è¯•æäº¤ä»»åŠ¡ç»“æœ"""
        print("\nğŸ” æµ‹è¯•4: æäº¤ä»»åŠ¡ç»“æœ")
        
        try:
            # æ¨¡æ‹Ÿç”¨æˆ·åˆ†æç»“æœ
            analysis_result = {
                'user_behavior_analysis': {
                    'total_users_analyzed': 9500,
                    'key_findings': [
                        'ç§»åŠ¨ç«¯ç”¨æˆ·å æ¯”70%ï¼Œä¸”æ´»è·ƒåº¦æ›´é«˜',
                        'ç”¨æˆ·åœ¨æ™šä¸Š8-10ç‚¹æœ€æ´»è·ƒ',
                        'æ–°ç”¨æˆ·7æ—¥ç•™å­˜ç‡ä¸º45%',
                        'ä»˜è´¹è½¬åŒ–ç‡ä¸º12%ï¼Œé«˜äºè¡Œä¸šå¹³å‡'
                    ],
                    'user_segments': {
                        'high_value_users': {
                            'count': 950,
                            'characteristics': 'é«˜é¢‘ä½¿ç”¨ï¼Œå¤šæ¬¡ä»˜è´¹',
                            'retention_rate': 0.85
                        },
                        'active_users': {
                            'count': 4750,
                            'characteristics': 'å®šæœŸä½¿ç”¨ï¼Œå¶å°”ä»˜è´¹',
                            'retention_rate': 0.65
                        },
                        'casual_users': {
                            'count': 3800,
                            'characteristics': 'ä½é¢‘ä½¿ç”¨ï¼Œå¾ˆå°‘ä»˜è´¹',
                            'retention_rate': 0.25
                        }
                    },
                    'key_metrics': {
                        'daily_active_users': 6500,
                        'monthly_active_users': 8200,
                        'conversion_rate': 0.12,
                        'churn_rate': 0.15,
                        'average_session_duration': 8.5  # minutes
                    },
                    'recommendations': [
                        {
                            'priority': 'high',
                            'action': 'ä¼˜åŒ–ç§»åŠ¨ç«¯ç”¨æˆ·ä½“éªŒ',
                            'rationale': 'ç§»åŠ¨ç«¯ç”¨æˆ·å ä¸»ä½“ä¸”æ´»è·ƒåº¦é«˜',
                            'expected_impact': 'æå‡DAU 10-15%'
                        },
                        {
                            'priority': 'medium',
                            'action': 'è®¾è®¡æ™šé—´æ¨é€ç­–ç•¥',
                            'rationale': 'ç”¨æˆ·æ™šé—´æ´»è·ƒåº¦æœ€é«˜',
                            'expected_impact': 'æå‡ç”¨æˆ·å‚ä¸åº¦ 8-12%'
                        },
                        {
                            'priority': 'medium',
                            'action': 'æ–°ç”¨æˆ·å¼•å¯¼æµç¨‹ä¼˜åŒ–',
                            'rationale': '7æ—¥ç•™å­˜ç‡æœ‰æå‡ç©ºé—´',
                            'expected_impact': 'æ–°ç”¨æˆ·ç•™å­˜ç‡æå‡è‡³55%'
                        }
                    ],
                    'visualization_suggestions': [
                        'ç”¨æˆ·æ´»è·ƒæ—¶é—´çƒ­åŠ›å›¾',
                        'ç”¨æˆ·åˆ†ç¾¤æ¼æ–—å›¾',
                        'ç•™å­˜ç‡è¶‹åŠ¿å›¾',
                        'è½¬åŒ–è·¯å¾„æ¡‘åŸºå›¾'
                    ]
                },
                'data_quality_assessment': {
                    'data_completeness': 0.95,
                    'data_accuracy': 0.92,
                    'confidence_level': 0.90,
                    'limitations': [
                        'éƒ¨åˆ†ç”¨æˆ·ç¼ºå°‘åœ°ç†ä½ç½®ä¿¡æ¯',
                        'æ–°ç”¨æˆ·è¡Œä¸ºæ•°æ®æ ·æœ¬ç›¸å¯¹è¾ƒå°'
                    ]
                },
                'analysis_metadata': {
                    'analyst': 'æµ‹è¯•åˆ†æå¸ˆ',
                    'analysis_date': datetime.utcnow().isoformat() + 'Z',
                    'tools_used': ['Python', 'Pandas', 'Matplotlib'],
                    'analysis_duration_minutes': 105
                }
            }
            
            result_summary = '''
å®Œæˆäº†Q1ç”¨æˆ·è¡Œä¸ºæ•°æ®çš„æ·±åº¦åˆ†æï¼š

ğŸ” å…³é”®å‘ç°ï¼š
â€¢ ç§»åŠ¨ç«¯ç”¨æˆ·å æ¯”70%ï¼Œæ´»è·ƒåº¦æ˜¾è‘—é«˜äºPCç«¯
â€¢ ç”¨æˆ·æ™šé—´8-10ç‚¹æ´»è·ƒåº¦å³°å€¼ï¼Œç™½å¤©ç›¸å¯¹å¹³ç¨³
â€¢ è¯†åˆ«å‡ºä¸‰ä¸ªä¸»è¦ç”¨æˆ·ç¾¤ä½“ï¼Œé«˜ä»·å€¼ç”¨æˆ·ç•™å­˜ç‡è¾¾85%
â€¢ æ•´ä½“ä»˜è´¹è½¬åŒ–ç‡12%ï¼Œè¶…è¿‡è¡Œä¸šå¹³å‡æ°´å¹³

ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡ï¼š
â€¢ DAU: 6,500 | MAU: 8,200
â€¢ 7æ—¥ç•™å­˜ç‡: 45% | æµå¤±ç‡: 15%
â€¢ å¹³å‡ä¼šè¯æ—¶é•¿: 8.5åˆ†é’Ÿ

ğŸ’¡ ä¼˜åŒ–å»ºè®®ï¼š
â€¢ ä¼˜å…ˆä¼˜åŒ–ç§»åŠ¨ç«¯ä½“éªŒï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
â€¢ è®¾è®¡ä¸ªæ€§åŒ–æ™šé—´æ¨é€ç­–ç•¥ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰
â€¢ æ”¹è¿›æ–°ç”¨æˆ·å¼•å¯¼æµç¨‹ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰

ğŸ“ˆ é¢„æœŸå½±å“ï¼š
â€¢ é¢„è®¡å¯æå‡DAU 10-15%ï¼Œæ–°ç”¨æˆ·ç•™å­˜ç‡è‡³55%
            '''.strip()
            
            # æäº¤ç»“æœ
            completed_time = datetime.utcnow().isoformat() + 'Z'
            started_time = datetime.fromisoformat(self._mock_task_data['started_at'].replace('Z', '+00:00'))
            actual_duration = int((datetime.now(started_time.tzinfo) - started_time).total_seconds() / 60)
            
            submission_result = {
                'task_id': str(self.test_task_id),
                'status': TaskInstanceStatus.COMPLETED.value,
                'completed_at': completed_time,
                'actual_duration': actual_duration,
                'result_data': analysis_result,
                'result_summary': result_summary,
                'message': 'ä»»åŠ¡ç»“æœå·²æäº¤'
            }
            
            # æ›´æ–°æ¨¡æ‹Ÿæ•°æ®
            self._mock_task_data['status'] = TaskInstanceStatus.COMPLETED.value
            self._mock_task_data['completed_at'] = completed_time
            self._mock_task_data['actual_duration'] = actual_duration
            self._mock_task_data['output_data'] = analysis_result
            self._mock_task_data['result_summary'] = result_summary
            
            print("âœ… ä»»åŠ¡ç»“æœæäº¤æˆåŠŸ:")
            print(f"   ğŸ†” ä»»åŠ¡ID: {submission_result['task_id']}")
            print(f"   ğŸ“ˆ æœ€ç»ˆçŠ¶æ€: {submission_result['status']}")
            print(f"   â±ï¸  å®é™…è€—æ—¶: {submission_result['actual_duration']} åˆ†é’Ÿ")
            print(f"   ğŸ¯ å®Œæˆæ—¶é—´: {submission_result['completed_at']}")
            print(f"   ğŸ“ ç»“æœæ‘˜è¦: {len(result_summary)} å­—ç¬¦")
            print(f"   ğŸ“Š åˆ†ææ•°æ®: {len(analysis_result)} ä¸ªä¸»è¦å­—æ®µ")
            
            # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœå†…å®¹
            print("   ğŸ” å…³é”®å‘ç°é¢„è§ˆ:")
            for finding in analysis_result['user_behavior_analysis']['key_findings'][:2]:
                print(f"      â€¢ {finding}")
            
            return submission_result
            
        except Exception as e:
            print(f"âŒ æäº¤ä»»åŠ¡ç»“æœå¤±è´¥: {e}")
            return None
    
    async def test_workflow_progression(self):
        """æµ‹è¯•å·¥ä½œæµæ¨è¿›"""
        print("\nğŸ” æµ‹è¯•5: å·¥ä½œæµæ¨è¿›éªŒè¯")
        
        try:
            # æ¨¡æ‹Ÿæ£€æŸ¥ä¸‹æ¸¸ä»»åŠ¡è§¦å‘
            print("âœ… ä»»åŠ¡å®Œæˆåçš„å·¥ä½œæµæ¨è¿›:")
            print("   ğŸ”„ æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹ä¾èµ–...")
            print("   ğŸ“‹ ä¸‹æ¸¸èŠ‚ç‚¹å‡†å¤‡å°±ç»ªæ£€æŸ¥...")
            print("   ğŸ¯ è§¦å‘ä¸‹æ¸¸ä»»åŠ¡åˆ›å»º...")
            
            # æ¨¡æ‹Ÿä¸‹æ¸¸ä»»åŠ¡ä¿¡æ¯
            downstream_tasks = [
                {
                    'task_id': str(uuid.uuid4()),
                    'task_title': 'åˆ†ææŠ¥å‘Šç”Ÿæˆä»»åŠ¡',
                    'node_name': 'æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹',
                    'status': 'pending',
                    'upstream_data_received': True
                },
                {
                    'task_id': str(uuid.uuid4()),
                    'task_title': 'å¯è§†åŒ–å›¾è¡¨åˆ¶ä½œä»»åŠ¡',
                    'node_name': 'å¯è§†åŒ–èŠ‚ç‚¹',
                    'status': 'pending',
                    'upstream_data_received': True
                }
            ]
            
            print(f"   âœ… æˆåŠŸè§¦å‘ {len(downstream_tasks)} ä¸ªä¸‹æ¸¸ä»»åŠ¡:")
            for task in downstream_tasks:
                print(f"      ğŸ“‹ {task['task_title']} - çŠ¶æ€: {task['status']}")
            
            return downstream_tasks
            
        except Exception as e:
            print(f"âŒ å·¥ä½œæµæ¨è¿›éªŒè¯å¤±è´¥: {e}")
            return []
    
    async def test_complete_execution_flow(self):
        """æµ‹è¯•å®Œæ•´çš„æ‰§è¡Œæµç¨‹"""
        print("ğŸš€ å¼€å§‹äººç±»ä»»åŠ¡æ‰§è¡Œå®Œæ•´æµ‹è¯•")
        print("=" * 60)
        
        try:
            # 1. è®¾ç½®æµ‹è¯•æ•°æ®
            await self.setup_test_data()
            
            # 2. è·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨
            tasks = await self.test_get_user_tasks()
            
            # 3. è·å–ä»»åŠ¡è¯¦æƒ…
            task_details = await self.test_get_task_details()
            
            # 4. å¼€å§‹æ‰§è¡Œä»»åŠ¡
            start_result = await self.test_start_task()
            
            # 5. æäº¤ä»»åŠ¡ç»“æœ
            submit_result = await self.test_submit_task_result()
            
            # 6. éªŒè¯å·¥ä½œæµæ¨è¿›
            downstream_tasks = await self.test_workflow_progression()
            
            # 7. æµ‹è¯•æ€»ç»“
            print("\n" + "=" * 60)
            print("ğŸ“Š æµ‹è¯•æ‰§è¡Œæ€»ç»“:")
            print(f"   âœ… ä»»åŠ¡åˆ—è¡¨è·å–: {'æˆåŠŸ' if tasks else 'å¤±è´¥'}")
            print(f"   âœ… ä»»åŠ¡è¯¦æƒ…è·å–: {'æˆåŠŸ' if task_details else 'å¤±è´¥'}")
            print(f"   âœ… ä»»åŠ¡å¼€å§‹æ‰§è¡Œ: {'æˆåŠŸ' if start_result else 'å¤±è´¥'}")
            print(f"   âœ… ä»»åŠ¡ç»“æœæäº¤: {'æˆåŠŸ' if submit_result else 'å¤±è´¥'}")
            print(f"   âœ… å·¥ä½œæµæ¨è¿›: {'æˆåŠŸ' if downstream_tasks else 'å¤±è´¥'}")
            
            # è®¡ç®—æµ‹è¯•å¾—åˆ†
            success_count = sum([
                bool(tasks),
                bool(task_details),
                bool(start_result),
                bool(submit_result),
                bool(downstream_tasks)
            ])
            
            print(f"\nğŸ¯ æµ‹è¯•å®Œæˆåº¦: {success_count}/5 ({success_count * 20}%)")
            
            if success_count == 5:
                print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼äººç±»ä»»åŠ¡æ‰§è¡Œæµç¨‹è¿è¡Œæ­£å¸¸ã€‚")
            else:
                print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
            
            return success_count == 5
            
        except Exception as e:
            print(f"âŒ å®Œæ•´æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    async def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report = {
            'test_name': 'äººç±»ä»»åŠ¡æ‰§è¡Œå®Œæ•´æµ‹è¯•',
            'test_time': datetime.utcnow().isoformat() + 'Z',
            'test_environment': 'development',
            'test_data': {
                'user_id': str(self.test_user_id),
                'workflow_instance_id': str(self.test_workflow_instance_id),
                'task_id': str(self.test_task_id),
                'task_title': self._mock_task_data['task_title'],
                'task_type': 'human',
                'upstream_nodes': 2
            },
            'test_scenarios': [
                {
                    'scenario': 'è·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨',
                    'description': 'æµ‹è¯•ç”¨æˆ·èƒ½å¦çœ‹åˆ°åˆ†é…ç»™è‡ªå·±çš„ä»»åŠ¡',
                    'expected': 'è¿”å›åŒ…å«æµ‹è¯•ä»»åŠ¡çš„åˆ—è¡¨',
                    'api_endpoint': 'GET /api/execution/tasks/my'
                },
                {
                    'scenario': 'è·å–ä»»åŠ¡è¯¦æƒ…',
                    'description': 'æµ‹è¯•ç”¨æˆ·èƒ½å¦æŸ¥çœ‹å®Œæ•´çš„ä»»åŠ¡ä¿¡æ¯å’Œä¸Šæ¸¸æ•°æ®',
                    'expected': 'è¿”å›å®Œæ•´çš„ä»»åŠ¡è¯¦æƒ…ï¼ŒåŒ…æ‹¬ä¸Šæ¸¸ä¸Šä¸‹æ–‡',
                    'api_endpoint': 'GET /api/execution/tasks/{task_id}'
                },
                {
                    'scenario': 'å¼€å§‹æ‰§è¡Œä»»åŠ¡',
                    'description': 'æµ‹è¯•ç”¨æˆ·èƒ½å¦æˆåŠŸå¼€å§‹ä»»åŠ¡æ‰§è¡Œ',
                    'expected': 'ä»»åŠ¡çŠ¶æ€æ›´æ–°ä¸ºIN_PROGRESS',
                    'api_endpoint': 'POST /api/execution/tasks/{task_id}/start'
                },
                {
                    'scenario': 'æäº¤ä»»åŠ¡ç»“æœ',
                    'description': 'æµ‹è¯•ç”¨æˆ·èƒ½å¦æäº¤åˆ†æç»“æœå’Œæ€»ç»“',
                    'expected': 'ä»»åŠ¡çŠ¶æ€æ›´æ–°ä¸ºCOMPLETEDï¼Œä¿å­˜ç»“æœæ•°æ®',
                    'api_endpoint': 'POST /api/execution/tasks/{task_id}/submit'
                },
                {
                    'scenario': 'å·¥ä½œæµæ¨è¿›',
                    'description': 'æµ‹è¯•ä»»åŠ¡å®Œæˆåæ˜¯å¦è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹',
                    'expected': 'è‡ªåŠ¨åˆ›å»ºä¸‹æ¸¸ä»»åŠ¡ï¼Œç»§æ‰¿å½“å‰ä»»åŠ¡çš„è¾“å‡º',
                    'mechanism': 'ä¾èµ–ç®¡ç†å’Œä¸Šä¸‹æ–‡ä¼ é€’'
                }
            ],
            'key_features_tested': [
                'ä¸€é˜¶ä¾èµ–ç­‰å¾…æœºåˆ¶',
                'ä¸Šæ¸¸æ•°æ®ç»§æ‰¿',
                'ä»»åŠ¡çŠ¶æ€ç®¡ç†',
                'ç”¨æˆ·æƒé™éªŒè¯',
                'å·¥ä½œæµä¸Šä¸‹æ–‡ä¼ é€’',
                'è‡ªåŠ¨ä¸‹æ¸¸è§¦å‘'
            ]
        }
        
        return report


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª äººç±»ä»»åŠ¡æ‰§è¡Œæµ‹è¯•ç¨‹åº")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    test = HumanTaskExecutionTest()
    
    try:
        # è¿è¡Œå®Œæ•´æµ‹è¯•æµç¨‹
        success = await test.test_complete_execution_flow()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        report = await test.generate_test_report()
        
        # ä¿å­˜æµ‹è¯•æŠ¥å‘Š
        report_file = 'human_task_execution_test_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        return success
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    result = asyncio.run(main())
    
    if result:
        print("\nğŸ‰ æµ‹è¯•æˆåŠŸå®Œæˆï¼")
        exit(0)
    else:
        print("\nğŸ’¥ æµ‹è¯•å¤±è´¥ï¼")
        exit(1)