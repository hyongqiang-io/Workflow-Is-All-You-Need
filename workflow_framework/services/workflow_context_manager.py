"""
å·¥ä½œæµä¸Šä¸‹æ–‡ç®¡ç†å™¨
ç»Ÿä¸€ç®¡ç†æ•´ä¸ªå·¥ä½œæµçš„æ‰§è¡Œä¸Šä¸‹æ–‡å’Œæ•°æ®æµ
"""

import uuid
from datetime import datetime
from typing import Dict, List, Any, Set, Optional
import asyncio
import logging
from loguru import logger

# å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
from ..models.instance import WorkflowInstanceStatus, WorkflowInstanceUpdate


class WorkflowContextManager:
    """å®è§‚å·¥ä½œæµä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self):
        # å·¥ä½œæµçº§åˆ«çš„å…¨å±€ä¸Šä¸‹æ–‡
        self.workflow_contexts: Dict[uuid.UUID, Dict[str, Any]] = {}
        
        # èŠ‚ç‚¹ä¾èµ–å…³ç³»ç®¡ç†
        self.node_dependencies: Dict[uuid.UUID, Dict[str, Any]] = {}
        
        # èŠ‚ç‚¹å®ŒæˆçŠ¶æ€è¿½è¸ª
        self.node_completion_status: Dict[uuid.UUID, str] = {}
        
        # å¾…è§¦å‘çš„èŠ‚ç‚¹é˜Ÿåˆ—
        self.pending_triggers: Dict[uuid.UUID, Set[uuid.UUID]] = {}
        
        # å›è°ƒå‡½æ•°æ³¨å†Œ
        self.completion_callbacks: List[callable] = []
    
    async def initialize_workflow_context(self, workflow_instance_id: uuid.UUID):
        """åˆå§‹åŒ–å·¥ä½œæµä¸Šä¸‹æ–‡"""
        self.workflow_contexts[workflow_instance_id] = {
            'global_data': {},
            'node_outputs': {},  # node_base_id -> output_data
            'execution_path': [],  # å·²æ‰§è¡Œçš„èŠ‚ç‚¹è·¯å¾„
            'execution_start_time': datetime.utcnow(),
            'current_executing_nodes': set(),
            'completed_nodes': set(),
            'failed_nodes': set()
        }
        
        # åˆå§‹åŒ–å·¥ä½œæµçš„å¾…è§¦å‘é˜Ÿåˆ—
        self.pending_triggers[workflow_instance_id] = set()
        
        logger.info(f"Initialized workflow context for {workflow_instance_id}")
    
    async def register_node_dependencies(self, 
                                       node_instance_id: uuid.UUID,
                                       node_base_id: uuid.UUID,
                                       workflow_instance_id: uuid.UUID, 
                                       upstream_nodes: List[uuid.UUID]):
        """æ³¨å†ŒèŠ‚ç‚¹çš„ä¸€é˜¶ä¾èµ–å…³ç³»"""
        self.node_dependencies[node_instance_id] = {
            'node_base_id': node_base_id,
            'workflow_instance_id': workflow_instance_id,
            'upstream_nodes': upstream_nodes,
            'completed_upstream': set(),
            'ready_to_execute': len(upstream_nodes) == 0,  # STARTèŠ‚ç‚¹æ— ä¾èµ–
            'dependency_count': len(upstream_nodes)
        }
        
        # åˆå§‹åŒ–èŠ‚ç‚¹çŠ¶æ€
        self.node_completion_status[node_instance_id] = 'PENDING'
        
        logger.debug(f"Registered dependencies for node {node_instance_id}: {len(upstream_nodes)} upstream nodes")
    
    async def mark_node_completed(self, 
                                workflow_instance_id: uuid.UUID,
                                node_base_id: uuid.UUID, 
                                node_instance_id: uuid.UUID,
                                output_data: Dict[str, Any]):
        """æ ‡è®°èŠ‚ç‚¹å®Œæˆå¹¶æ›´æ–°ä¸Šä¸‹æ–‡"""
        if workflow_instance_id not in self.workflow_contexts:
            logger.error(f"Workflow context not found for {workflow_instance_id}")
            return
        
        # æ›´æ–°å·¥ä½œæµä¸Šä¸‹æ–‡
        context = self.workflow_contexts[workflow_instance_id]
        context['node_outputs'][node_base_id] = output_data
        context['execution_path'].append(node_base_id)
        context['completed_nodes'].add(node_base_id)
        
        # ä»æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹ä¸­ç§»é™¤
        if node_base_id in context['current_executing_nodes']:
            context['current_executing_nodes'].remove(node_base_id)
        
        # æ›´æ–°å®ŒæˆçŠ¶æ€
        self.node_completion_status[node_instance_id] = 'COMPLETED'
        
        logger.info(f"Node {node_base_id} completed in workflow {workflow_instance_id}")
        
        # æ£€æŸ¥å¹¶è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹
        await self._check_and_trigger_downstream_nodes(
            workflow_instance_id, node_base_id
        )
        
        # æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å…¨éƒ¨å®Œæˆ
        await self._check_workflow_completion(workflow_instance_id)
    
    async def mark_node_failed(self,
                             workflow_instance_id: uuid.UUID,
                             node_base_id: uuid.UUID,
                             node_instance_id: uuid.UUID,
                             error_info: Dict[str, Any]):
        """æ ‡è®°èŠ‚ç‚¹å¤±è´¥"""
        if workflow_instance_id not in self.workflow_contexts:
            return
        
        context = self.workflow_contexts[workflow_instance_id]
        context['failed_nodes'].add(node_base_id)
        
        # ä»æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹ä¸­ç§»é™¤
        if node_base_id in context['current_executing_nodes']:
            context['current_executing_nodes'].remove(node_base_id)
        
        # æ›´æ–°å¤±è´¥çŠ¶æ€
        self.node_completion_status[node_instance_id] = 'FAILED'
        
        logger.error(f"Node {node_base_id} failed in workflow {workflow_instance_id}: {error_info}")
    
    async def mark_node_executing(self,
                                workflow_instance_id: uuid.UUID,
                                node_base_id: uuid.UUID,
                                node_instance_id: uuid.UUID):
        """æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ"""
        if workflow_instance_id not in self.workflow_contexts:
            return
        
        context = self.workflow_contexts[workflow_instance_id]
        context['current_executing_nodes'].add(node_base_id)
        
        self.node_completion_status[node_instance_id] = 'EXECUTING'
        
        logger.info(f"Node {node_base_id} started executing in workflow {workflow_instance_id}")
    
    async def _check_and_trigger_downstream_nodes(self, 
                                                workflow_instance_id: uuid.UUID,
                                                completed_node_id: uuid.UUID):
        """æ£€æŸ¥å¹¶è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹"""
        triggered_nodes = []
        
        # éå†æ‰€æœ‰èŠ‚ç‚¹ä¾èµ–ï¼Œæ‰¾åˆ°ä»¥å½“å‰èŠ‚ç‚¹ä¸ºä¸Šæ¸¸çš„èŠ‚ç‚¹
        for node_instance_id, deps in self.node_dependencies.items():
            if (deps['workflow_instance_id'] == workflow_instance_id and 
                completed_node_id in deps['upstream_nodes']):
                
                # æ ‡è®°è¯¥ä¸Šæ¸¸èŠ‚ç‚¹å·²å®Œæˆ
                deps['completed_upstream'].add(completed_node_id)
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä¸Šæ¸¸èŠ‚ç‚¹éƒ½å·²å®Œæˆ
                if len(deps['completed_upstream']) == len(deps['upstream_nodes']):
                    deps['ready_to_execute'] = True
                    
                    # æ·»åŠ åˆ°å¾…è§¦å‘é˜Ÿåˆ—
                    self.pending_triggers[workflow_instance_id].add(node_instance_id)
                    triggered_nodes.append(node_instance_id)
                    
                    logger.info(f"Node {deps['node_base_id']} ready to execute - all upstream completed")
        
        # é€šçŸ¥å›è°ƒå‡½æ•°æœ‰æ–°çš„èŠ‚ç‚¹å‡†å¤‡æ‰§è¡Œ
        if triggered_nodes:
            await self._notify_completion_callbacks(workflow_instance_id, triggered_nodes)
    
    async def get_ready_nodes(self, workflow_instance_id: uuid.UUID) -> List[uuid.UUID]:
        """è·å–å‡†å¤‡æ‰§è¡Œçš„èŠ‚ç‚¹å®ä¾‹IDåˆ—è¡¨"""
        if workflow_instance_id not in self.pending_triggers:
            return []
        
        ready_nodes = list(self.pending_triggers[workflow_instance_id])
        # æ¸…ç©ºå¾…è§¦å‘é˜Ÿåˆ—
        self.pending_triggers[workflow_instance_id].clear()
        
        return ready_nodes
    
    async def get_node_upstream_context(self, 
                                      workflow_instance_id: uuid.UUID,
                                      node_instance_id: uuid.UUID) -> Dict[str, Any]:
        """è·å–èŠ‚ç‚¹çš„ä¸€é˜¶ä¸Šæ¸¸ä¸Šä¸‹æ–‡æ•°æ®"""
        if node_instance_id not in self.node_dependencies:
            return {'immediate_upstream_results': {}, 'upstream_node_count': 0}
        
        deps = self.node_dependencies[node_instance_id]
        upstream_nodes = deps['upstream_nodes']
        
        # è·å–å·¥ä½œæµä¸Šä¸‹æ–‡
        workflow_context = self.workflow_contexts.get(workflow_instance_id, {})
        node_outputs = workflow_context.get('node_outputs', {})
        
        # æ”¶é›†ä¸€é˜¶ä¸Šæ¸¸èŠ‚ç‚¹çš„è¾“å‡ºæ•°æ®
        upstream_results = {}
        for upstream_node_id in upstream_nodes:
            if upstream_node_id in node_outputs:
                upstream_results[str(upstream_node_id)] = node_outputs[upstream_node_id]
        
        return {
            'immediate_upstream_results': upstream_results,
            'upstream_node_count': len(upstream_nodes),
            'workflow_global': {
                'execution_path': workflow_context.get('execution_path', []),
                'global_data': workflow_context.get('global_data', {}),
                'execution_start_time': workflow_context.get('execution_start_time')
            }
        }
    
    async def get_workflow_status(self, workflow_instance_id: uuid.UUID) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµæ•´ä½“çŠ¶æ€"""
        if workflow_instance_id not in self.workflow_contexts:
            return {'status': 'NOT_FOUND'}
        
        context = self.workflow_contexts[workflow_instance_id]
        
        # ç»Ÿè®¡èŠ‚ç‚¹çŠ¶æ€
        total_nodes = len(self.node_dependencies)
        completed_nodes = len(context['completed_nodes'])
        failed_nodes = len(context['failed_nodes'])
        executing_nodes = len(context['current_executing_nodes'])
        pending_nodes = total_nodes - completed_nodes - failed_nodes - executing_nodes
        
        # åˆ¤æ–­å·¥ä½œæµæ•´ä½“çŠ¶æ€
        if failed_nodes > 0:
            overall_status = 'FAILED'
        elif completed_nodes == total_nodes:
            overall_status = 'COMPLETED'
        elif executing_nodes > 0 or pending_nodes > 0:
            overall_status = 'RUNNING'
        else:
            overall_status = 'UNKNOWN'
        
        return {
            'status': overall_status,
            'total_nodes': total_nodes,
            'completed_nodes': completed_nodes,
            'failed_nodes': failed_nodes,
            'executing_nodes': executing_nodes,
            'pending_nodes': pending_nodes,
            'execution_path': context['execution_path'],
            'execution_start_time': context['execution_start_time']
        }
    
    def register_completion_callback(self, callback: callable):
        """æ³¨å†ŒèŠ‚ç‚¹å®Œæˆå›è°ƒå‡½æ•°"""
        self.completion_callbacks.append(callback)
    
    async def _notify_completion_callbacks(self, 
                                         workflow_instance_id: uuid.UUID,
                                         triggered_nodes: List[uuid.UUID]):
        """é€šçŸ¥å›è°ƒå‡½æ•°æœ‰æ–°èŠ‚ç‚¹å‡†å¤‡æ‰§è¡Œ"""
        for callback in self.completion_callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(workflow_instance_id, triggered_nodes)
                else:
                    callback(workflow_instance_id, triggered_nodes)
            except Exception as e:
                logger.error(f"Error in completion callback: {e}")
    
    async def cleanup_workflow_context(self, workflow_instance_id: uuid.UUID):
        """æ¸…ç†å·¥ä½œæµä¸Šä¸‹æ–‡ï¼ˆå·¥ä½œæµå®Œæˆåè°ƒç”¨ï¼‰"""
        if workflow_instance_id in self.workflow_contexts:
            del self.workflow_contexts[workflow_instance_id]
        
        if workflow_instance_id in self.pending_triggers:
            del self.pending_triggers[workflow_instance_id]
        
        # æ¸…ç†ç›¸å…³çš„èŠ‚ç‚¹ä¾èµ–
        to_remove = []
        for node_instance_id, deps in self.node_dependencies.items():
            if deps['workflow_instance_id'] == workflow_instance_id:
                to_remove.append(node_instance_id)
        
        for node_instance_id in to_remove:
            del self.node_dependencies[node_instance_id]
            if node_instance_id in self.node_completion_status:
                del self.node_completion_status[node_instance_id]
        
        logger.info(f"Cleaned up workflow context for {workflow_instance_id}")
    
    def get_node_dependency_info(self, node_instance_id: uuid.UUID) -> Optional[Dict[str, Any]]:
        """è·å–èŠ‚ç‚¹çš„ä¾èµ–ä¿¡æ¯"""
        return self.node_dependencies.get(node_instance_id)
    
    def is_node_ready_to_execute(self, node_instance_id: uuid.UUID) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å‡†å¤‡å¥½æ‰§è¡Œ"""
        deps = self.node_dependencies.get(node_instance_id)
        return deps is not None and deps.get('ready_to_execute', False)
    
    async def _check_workflow_completion(self, workflow_instance_id: uuid.UUID):
        """æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å®Œæˆå¹¶æ›´æ–°æ•°æ®åº“çŠ¶æ€"""
        try:
            if workflow_instance_id not in self.workflow_contexts:
                return
            
            # è·å–å·¥ä½œæµçŠ¶æ€
            status_info = await self.get_workflow_status(workflow_instance_id)
            current_status = status_info.get('status')
            
            logger.info(f"ğŸ” [å·¥ä½œæµçŠ¶æ€æ£€æŸ¥] å·¥ä½œæµ {workflow_instance_id}:")
            logger.info(f"   - å½“å‰çŠ¶æ€: {current_status}")
            logger.info(f"   - æ€»èŠ‚ç‚¹æ•°: {status_info.get('total_nodes', 0)}")
            logger.info(f"   - å·²å®ŒæˆèŠ‚ç‚¹: {status_info.get('completed_nodes', 0)}")
            logger.info(f"   - å¤±è´¥èŠ‚ç‚¹: {status_info.get('failed_nodes', 0)}")
            logger.info(f"   - æ‰§è¡Œä¸­èŠ‚ç‚¹: {status_info.get('executing_nodes', 0)}")
            
            # å¦‚æœå·¥ä½œæµå·²å®Œæˆæˆ–å¤±è´¥ï¼Œæ›´æ–°æ•°æ®åº“çŠ¶æ€
            if current_status in ['COMPLETED', 'FAILED']:
                logger.info(f"ğŸ¯ [å·¥ä½œæµçŠ¶æ€æ£€æŸ¥] å·¥ä½œæµ {workflow_instance_id} éœ€è¦æ›´æ–°çŠ¶æ€ä¸º: {current_status}")
                
                # å»¶è¿Ÿå¯¼å…¥å·¥ä½œæµå®ä¾‹ä»“åº“é¿å…å¾ªç¯ä¾èµ–
                from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
                workflow_repo = WorkflowInstanceRepository()
                
                # å‡†å¤‡è¾“å‡ºæ•°æ®
                context = self.workflow_contexts[workflow_instance_id]
                output_data = {
                    'completion_time': datetime.utcnow().isoformat(),
                    'node_outputs': context.get('node_outputs', {}),
                    'execution_path': context.get('execution_path', []),
                    'total_nodes': status_info.get('total_nodes', 0),
                    'completed_nodes': status_info.get('completed_nodes', 0),
                    'failed_nodes': status_info.get('failed_nodes', 0)
                }
                
                # æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€
                if current_status == 'COMPLETED':
                    update_data = WorkflowInstanceUpdate(
                        status=WorkflowInstanceStatus.COMPLETED,
                        output_data=output_data
                    )
                    logger.info(f"âœ… [å·¥ä½œæµçŠ¶æ€æ£€æŸ¥] æ ‡è®°å·¥ä½œæµ {workflow_instance_id} ä¸ºå·²å®Œæˆ")
                else:  # FAILED
                    update_data = WorkflowInstanceUpdate(
                        status=WorkflowInstanceStatus.FAILED,
                        output_data=output_data,
                        error_message="å·¥ä½œæµä¸­æœ‰èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥"
                    )
                    logger.error(f"âŒ [å·¥ä½œæµçŠ¶æ€æ£€æŸ¥] æ ‡è®°å·¥ä½œæµ {workflow_instance_id} ä¸ºå¤±è´¥")
                
                # æ›´æ–°æ•°æ®åº“
                await workflow_repo.update_instance(workflow_instance_id, update_data)
                
                # æ¸…ç†å·¥ä½œæµä¸Šä¸‹æ–‡
                await self.cleanup_workflow_context(workflow_instance_id)
                
            else:
                logger.info(f"â³ [å·¥ä½œæµçŠ¶æ€æ£€æŸ¥] å·¥ä½œæµ {workflow_instance_id} ä»åœ¨è¿è¡Œä¸­")
                
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")