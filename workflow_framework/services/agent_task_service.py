"""
Agentä»»åŠ¡å¤„ç†æœåŠ¡
Agent Task Processing Service
"""

import uuid
import json
import sys
import asyncio
from typing import Optional, Dict, Any, List
from datetime import datetime
from loguru import logger
logger.remove()
logger.add(sys.stderr, level="DEBUG", enqueue=True)  # ä¿®å¤Windows GBKç¼–ç é—®é¢˜

from ..repositories.instance.task_instance_repository import TaskInstanceRepository
from ..repositories.agent.agent_repository import AgentRepository
from ..models.instance import (
    TaskInstanceUpdate, TaskInstanceStatus, TaskInstanceType
)
from ..utils.helpers import now_utc
from ..utils.openai_client import openai_client
from .mcp_service import mcp_service


class AgentTaskService:
    """Agentä»»åŠ¡å¤„ç†æœåŠ¡"""
    
    def __init__(self):
        self.task_repo = TaskInstanceRepository()
        self.agent_repo = AgentRepository()
        
        # Agentä»»åŠ¡å¤„ç†é˜Ÿåˆ—
        self.processing_queue = asyncio.Queue()
        self.is_running = False
        self.max_concurrent_tasks = 5
        
        # ä»»åŠ¡å®Œæˆå›è°ƒåˆ—è¡¨
        self.completion_callbacks = []
    
    def register_completion_callback(self, callback):
        """æ³¨å†Œä»»åŠ¡å®Œæˆå›è°ƒ"""
        self.completion_callbacks.append(callback)
        logger.trace(f"æ³¨å†Œä»»åŠ¡å®Œæˆå›è°ƒ: {callback}")
    
    async def _notify_task_completion(self, task_id: uuid.UUID, result: Dict[str, Any]):
        """é€šçŸ¥ä»»åŠ¡å®Œæˆ"""
        try:
            for callback in self.completion_callbacks:
                try:
                    await callback.on_task_completed(task_id, result)
                except Exception as e:
                    logger.error(f"å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"é€šçŸ¥ä»»åŠ¡å®Œæˆå¤±è´¥: {e}")
    
    async def _notify_task_failure(self, task_id: uuid.UUID, error_message: str):
        """é€šçŸ¥ä»»åŠ¡å¤±è´¥"""
        try:
            for callback in self.completion_callbacks:
                try:
                    await callback.on_task_failed(task_id, error_message)
                except Exception as e:
                    logger.error(f"å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"é€šçŸ¥ä»»åŠ¡å¤±è´¥å¤±è´¥: {e}")
    
    async def start_service(self):
        """å¯åŠ¨Agentä»»åŠ¡å¤„ç†æœåŠ¡"""
        if self.is_running:
            logger.warning("Agentä»»åŠ¡å¤„ç†æœåŠ¡å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.is_running = True
        logger.trace("Agentä»»åŠ¡å¤„ç†æœåŠ¡å¯åŠ¨")
        
        # å¯åŠ¨ä»»åŠ¡å¤„ç†åç¨‹
        for i in range(self.max_concurrent_tasks):
            asyncio.create_task(self._process_agent_tasks())
        
        # å¯åŠ¨ä»»åŠ¡ç›‘æ§åç¨‹
        asyncio.create_task(self._monitor_pending_tasks())
    
    async def stop_service(self):
        """åœæ­¢Agentä»»åŠ¡å¤„ç†æœåŠ¡"""
        self.is_running = False
        logger.trace("Agentä»»åŠ¡å¤„ç†æœåŠ¡åœæ­¢")
    
    async def _has_active_workflows(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒçš„å·¥ä½œæµ"""
        try:
            from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
            workflow_repo = WorkflowInstanceRepository()
            
            # æŸ¥è¯¢è¿è¡Œä¸­çš„å·¥ä½œæµ
            active_workflows = await workflow_repo.db.fetch_all("""
                SELECT workflow_instance_id, status 
                FROM workflow_instance 
                WHERE status IN ('RUNNING', 'PENDING') 
                AND is_deleted = FALSE
                LIMIT 1
            """)
            
            return len(active_workflows) > 0
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ´»è·ƒå·¥ä½œæµå¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶å‡è®¾æœ‰æ´»è·ƒå·¥ä½œæµï¼Œç»§ç»­ç›‘æ§
    
    async def get_pending_agent_tasks(self, agent_id: Optional[uuid.UUID] = None, 
                                    limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–å¾…å¤„ç†çš„Agentä»»åŠ¡"""
        try:
            logger.trace(f"ğŸ” [AGENT-SERVICE] å¼€å§‹è·å–å¾…å¤„ç†Agentä»»åŠ¡")
            logger.trace(f"   - Agent ID: {agent_id if agent_id else 'æ‰€æœ‰Agent'}")  
            logger.trace(f"   - é™åˆ¶æ•°é‡: {limit}")
            
            tasks = await self.task_repo.get_agent_tasks_for_processing(agent_id, limit)
            
            logger.trace(f"ğŸ“‹ [AGENT-SERVICE] è·å–å¾…å¤„ç†Agentä»»åŠ¡å®Œæˆ")
            logger.trace(f"   - æ‰¾åˆ°ä»»åŠ¡æ•°é‡: {len(tasks)}")
            
            if tasks:
                logger.trace(f"   - ä»»åŠ¡è¯¦æƒ…:")
                for i, task in enumerate(tasks[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªä»»åŠ¡
                    task_id = task.get('task_instance_id', 'unknown')
                    task_title = task.get('task_title', 'unknown')
                    task_status = task.get('status', 'unknown')
                    logger.trace(f"     {i+1}. {task_title} (ID: {task_id}, çŠ¶æ€: {task_status})")
                if len(tasks) > 3:
                    logger.trace(f"     ... è¿˜æœ‰ {len(tasks) - 3} ä¸ªä»»åŠ¡")
            else:
                # å‡å°‘æ—¥å¿—é¢‘ç‡ï¼Œé¿å…åˆ·å±
                pass  # åœ¨ç›‘æ§å™¨ä¸­ä¼šç»Ÿä¸€å¤„ç†ç©ºæ£€æŸ¥çš„æ—¥å¿—
                
            return tasks
            
        except Exception as e:
            logger.error(f"âŒ [AGENT-SERVICE] è·å–å¾…å¤„ç†Agentä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            logger.error(f"   - é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def submit_task_to_agent(self, task_id: uuid.UUID) -> Dict[str, Any]:
        """å°†ä»»åŠ¡æäº¤ç»™Agentå¤„ç†"""
        try:
            # è·å–ä»»åŠ¡ä¿¡æ¯
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            # éªŒè¯ä»»åŠ¡ç±»å‹å’ŒçŠ¶æ€
            if task['task_type'] not in [TaskInstanceType.AGENT.value, TaskInstanceType.MIXED.value]:
                raise ValueError("ä»»åŠ¡ç±»å‹ä¸æ”¯æŒAgentå¤„ç†")
            
            if task['status'] != TaskInstanceStatus.PENDING.value:
                raise ValueError(f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æäº¤ç»™Agentï¼Œå½“å‰çŠ¶æ€: {task['status']}")
            
            # å°†ä»»åŠ¡åŠ å…¥å¤„ç†é˜Ÿåˆ—
            queue_item = {
                'task_id': task_id,
                'submitted_at': now_utc()
            }
            
            await self.processing_queue.put(queue_item)
            
            logger.trace(f"ä»»åŠ¡ {task_id} å·²æäº¤ç»™Agentå¤„ç†é˜Ÿåˆ—")
            return {
                'task_id': task_id,
                'status': 'queued',
                'message': 'ä»»åŠ¡å·²åŠ å…¥Agentå¤„ç†é˜Ÿåˆ—'
            }
            
        except Exception as e:
            logger.error(f"æäº¤ä»»åŠ¡ç»™Agentå¤±è´¥: {e}")
            raise
    
    async def process_agent_task(self, task_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªAgentä»»åŠ¡"""
        try:
            logger.trace(f"ğŸš€ [AGENT-PROCESS] å¼€å§‹å¤„ç†Agentä»»åŠ¡: {task_id}")
            
            # è·å–ä»»åŠ¡è¯¦æƒ…
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                logger.error(f"âŒ [AGENT-PROCESS] ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            logger.trace(f"ğŸ“‹ [AGENT-PROCESS] ä»»åŠ¡è¯¦æƒ…è·å–æˆåŠŸ:")
            logger.trace(f"   - ä»»åŠ¡æ ‡é¢˜: {task['task_title']}")
            logger.trace(f"   - ä»»åŠ¡ç±»å‹: {task.get('task_type', 'unknown')}")
            logger.trace(f"   - å½“å‰çŠ¶æ€: {task.get('status', 'unknown')}")
            logger.trace(f"   - å¤„ç†å™¨ID: {task.get('processor_id', 'none')}")
            logger.trace(f"   - åˆ†é…Agent ID: {task.get('assigned_agent_id', 'none')}")
            logger.trace(f"   - ä¼˜å…ˆçº§: {task.get('priority', 0)}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿›è¡Œä¸­
            logger.trace(f"â³ [AGENT-PROCESS] æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºIN_PROGRESS")
            update_data = TaskInstanceUpdate(status=TaskInstanceStatus.IN_PROGRESS)
            await self.task_repo.update_task(task_id, update_data)
            logger.trace(f"âœ… [AGENT-PROCESS] ä»»åŠ¡çŠ¶æ€æ›´æ–°æˆåŠŸ")
            
            start_time = datetime.now()
            logger.trace(f"â° [AGENT-PROCESS] ä»»åŠ¡å¼€å§‹æ—¶é—´: {start_time.isoformat()}")
            
            # è·å–Agentä¿¡æ¯
            agent_id = task.get('assigned_agent_id')
            logger.trace(f"ğŸ” [AGENT-PROCESS] æ£€æŸ¥Agentåˆ†é…: {agent_id}")
            
            # å¦‚æœä»»åŠ¡æ²¡æœ‰ç›´æ¥åˆ†é…Agentï¼Œå°è¯•ä»processorè·å–
            if not agent_id:
                processor_id = task.get('processor_id')
                logger.warning(f"âš ï¸ [AGENT-PROCESS] ä»»åŠ¡æœªç›´æ¥åˆ†é…Agentï¼Œå°è¯•ä»processorè·å–: {processor_id}")
                
                if processor_id:
                    # ä»processorè·å–å…³è”çš„agent
                    from ..repositories.processor.processor_repository import ProcessorRepository
                    processor_repo = ProcessorRepository()
                    processor = await processor_repo.get_processor_with_details(processor_id)
                    if processor and processor.get('agent_id'):
                        agent_id = processor['agent_id']
                        logger.trace(f"âœ… [AGENT-PROCESS] ä»processorè·å–åˆ°Agent ID: {agent_id}")
                    else:
                        logger.error(f"âŒ [AGENT-PROCESS] Processoræœªå…³è”Agent: {processor_id}")
                        raise ValueError(f"Processor {processor_id} æœªå…³è”Agent")
                else:
                    logger.error(f"âŒ [AGENT-PROCESS] ä»»åŠ¡æ—¢æ²¡æœ‰assigned_agent_idä¹Ÿæ²¡æœ‰processor_id")
                    raise ValueError("ä»»åŠ¡æœªåˆ†é…Agent")
            
            logger.trace(f"ğŸ¤– [AGENT-PROCESS] è·å–Agentè¯¦æƒ…: {agent_id}")
            agent = await self.agent_repo.get_agent_by_id(agent_id)
            if not agent:
                logger.error(f"âŒ [AGENT-PROCESS] Agentä¸å­˜åœ¨: {agent_id}")
                raise ValueError(f"Agentä¸å­˜åœ¨: {agent_id}")
            
            logger.trace(f"âœ… [AGENT-PROCESS] Agentè¯¦æƒ…è·å–æˆåŠŸ:")
            logger.trace(f"   - Agentåç§°: {agent.get('agent_name', 'unknown')}")
            logger.trace(f"   - æ¨¡å‹: {agent.get('model_name', 'unknown')}")
            logger.trace(f"   - Base URL: {agent.get('base_url', 'none')}")
            logger.trace(f"   - API Keyå­˜åœ¨: {'æ˜¯' if agent.get('api_key') else 'å¦'}")

            # è¯¦ç»†è°ƒè¯•ä»»åŠ¡æ•°æ®å­—æ®µ
            logger.trace(f"ğŸ” [AGENT-PROCESS] è¯¦ç»†è°ƒè¯•ä»»åŠ¡æ•°æ®å­—æ®µ:")
            logger.trace(f"   - ä»»åŠ¡å­—å…¸æ‰€æœ‰é”®: {list(task.keys())}")
            for key, value in task.items():
                if key in ['input_data', 'context_data', 'output_data']:
                    logger.trace(f"   - {key}: ç±»å‹={type(value)}, é•¿åº¦={len(str(value)) if value else 0}, å€¼='{str(value)[:100]}{'...' if value and len(str(value)) > 100 else ''}'")
                elif key in ['task_title', 'task_description', 'status']:
                    logger.trace(f"   - {key}: '{value}'")
            
            # å‡†å¤‡AIä»»åŠ¡æ•°æ® - å¤šæ•°æ®æºæ™ºèƒ½é€‰æ‹©
            logger.trace(f"full task:{task}")
            task_input_data = task.get('input_data', '')
            task_context_data = task.get('context_data', '')
            
            # å°è¯•ä»èŠ‚ç‚¹å®ä¾‹è·å–æ•°æ®ï¼ˆè¿™æ˜¯UIæ˜¾ç¤ºçš„æ•°æ®æºï¼‰
            node_input_data = ""
            node_instance_id = task.get('node_instance_id')
            if node_instance_id:
                try:
                    from ..repositories.instance.node_instance_repository import NodeInstanceRepository
                    node_repo = NodeInstanceRepository()
                    node_instance = await node_repo.get_instance_by_id(node_instance_id)
                    if node_instance and node_instance.get('input_data'):
                        node_input_data = node_instance['input_data']
                        logger.trace(f"   - ä»èŠ‚ç‚¹å®ä¾‹è·å–è¾“å…¥æ•°æ®: {len(node_input_data)} å­—ç¬¦")
                except Exception as e:
                    logger.warning(f"   - è·å–èŠ‚ç‚¹å®ä¾‹æ•°æ®å¤±è´¥: {e}")
            
            # æ•´åˆæ‰€æœ‰å¯ç”¨æ•°æ®æº
            data_sources = [
                ("node_input_data", node_input_data),
                ("task_context_data", task_context_data), 
                ("task_input_data", task_input_data)
            ]
            
            logger.trace(f"ğŸ“Š [AGENT-PROCESS] å¤šæ•°æ®æºåˆ†æ:")
            for source_name, source_data in data_sources:
                data_str = str(source_data) if source_data is not None else ""
                logger.trace(f"   - {source_name}: å¤§å°={len(data_str)} å­—ç¬¦, ç±»å‹={type(source_data)}")
                if data_str and len(data_str) > 0:
                    logger.trace(f"     é¢„è§ˆ: {data_str[:100]}{'...' if len(data_str) > 100 else ''}")
            
            # æ™ºèƒ½é€‰æ‹©æœ€ä½³æ•°æ®æºï¼šä¼˜å…ˆé€‰æ‹©å†…å®¹æœ€ä¸°å¯Œçš„
            actual_data = ""
            data_source = "none"
            
            for source_name, source_data in data_sources:
                # å°†æ•°æ®è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¿›è¡Œå¤„ç†
                data_str = str(source_data) if source_data is not None else ""
                if data_str and data_str.strip() and data_str.strip() != '{}' and data_str.strip() != 'None':
                    actual_data = data_str
                    data_source = source_name
                    logger.trace(f"   âœ… é€‰æ‹©{source_name}ä½œä¸ºæ•°æ®æº")
                    break
            
            if not actual_data:
                logger.warning(f"   âŒ æ‰€æœ‰æ•°æ®æºéƒ½ä¸ºç©º")
                
            logger.trace(f"   - å®é™…ä½¿ç”¨æ•°æ®æº: {data_source}")
            logger.trace(f"   - å®é™…æ•°æ®å¤§å°: {len(actual_data)} å­—ç¬¦")
            if actual_data and len(actual_data) > 0:
                logger.trace(f"   - å®é™…æ•°æ®é¢„è§ˆ: {actual_data[:200]}...")
            
            # æ„å»ºç³»ç»Ÿ Promptï¼ˆä½¿ç”¨ä»»åŠ¡çš„è¯¦ç»†æè¿°ï¼‰
            logger.trace(f"ğŸ”¨ [AGENT-PROCESS] æ„å»ºç³»ç»ŸPrompt")
            system_prompt = self._build_system_prompt(task)
            logger.trace(f"   - ç³»ç»ŸPrompté•¿åº¦: {len(system_prompt)} å­—ç¬¦")
            logger.trace(f"   - ç³»ç»ŸPrompté¢„è§ˆ: {system_prompt[:200]}...")
            
            # é¢„å¤„ç†ä¸Šæ¸¸ä¸Šä¸‹æ–‡ï¼ˆæ•´ç†æˆè¡¥å……ä¿¡æ¯ï¼‰
            logger.trace(f"ğŸ”„ [AGENT-PROCESS] é¢„å¤„ç†ä¸Šæ¸¸ä¸Šä¸‹æ–‡")
            logger.trace(f"   - ä¼ å…¥é¢„å¤„ç†çš„actual_data: {actual_data[:500] if actual_data else 'None'}...")
            context_info = self._preprocess_upstream_context(actual_data)
            logger.trace(f"   - ä¸Šä¸‹æ–‡ä¿¡æ¯é•¿åº¦: {len(context_info)} å­—ç¬¦")
            logger.trace(f"   - ä¸Šä¸‹æ–‡ä¿¡æ¯é¢„è§ˆ: {context_info[:200]}...")
            logger.trace(f"   - ä¸Šä¸‹æ–‡ä¿¡æ¯å®Œæ•´å†…å®¹: '{context_info}'")
            
            # æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼ˆä½œä¸ºä»»åŠ¡è¾“å…¥ï¼‰
            logger.trace(f"âœ‰ï¸ [AGENT-PROCESS] æ„å»ºç”¨æˆ·æ¶ˆæ¯")
            user_message = self._build_user_message(task, context_info)
            logger.trace(f"   - ç”¨æˆ·æ¶ˆæ¯é•¿åº¦: {len(user_message)} å­—ç¬¦")
            logger.trace(f"   - ç”¨æˆ·æ¶ˆæ¯é¢„è§ˆ: {user_message[:200]}...")
        
            # æ•´ç†æˆAI Clientå¯æ¥æ”¶çš„æ•°æ®ç»“æ„
            ai_client_data = {
                'task_id': str(task_id),
                'system_prompt': system_prompt,
                'user_message': user_message,
                'task_metadata': {
                    'task_title': task['task_title'],
                    'estimated_duration': task.get('estimated_duration', 30)
                }
            }
            
            logger.trace(f"ğŸ“¦ [AGENT-PROCESS] AI Clientæ•°æ®å‡†å¤‡å®Œæˆ:")
            logger.trace(f"   - ä»»åŠ¡ID: {ai_client_data['task_id']}")
            logger.trace(f"   - ç³»ç»ŸPrompt: {len(ai_client_data['system_prompt'])} å­—ç¬¦")
            logger.trace(f"   - ç”¨æˆ·æ¶ˆæ¯: {len(ai_client_data['user_message'])} å­—ç¬¦")
            logger.trace(f"   - å…ƒæ•°æ®: {ai_client_data['task_metadata']}")
            
            # è°ƒç”¨Agentå¤„ç†
            logger.trace(f"ğŸš€ [AGENT-PROCESS] å¼€å§‹è°ƒç”¨Agent API")
            result = await self._call_agent_api(agent, ai_client_data)
            logger.trace(f"âœ… [AGENT-PROCESS] Agent APIè°ƒç”¨æˆåŠŸ")
            logger.trace(f"   - ç»“æœç±»å‹: {type(result)}")
            logger.trace(f"   - ç»“æœé”®: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
            
            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            end_time = datetime.now()
            actual_duration = int((end_time - start_time).total_seconds() / 60)
            
            logger.trace(f"â° [AGENT-PROCESS] ä»»åŠ¡æ‰§è¡Œå®Œæˆ:")
            logger.trace(f"   - å¼€å§‹æ—¶é—´: {start_time.isoformat()}")
            logger.trace(f"   - ç»“æŸæ—¶é—´: {end_time.isoformat()}")
            logger.trace(f"   - å®é™…ç”¨æ—¶: {actual_duration} åˆ†é’Ÿ")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å®Œæˆï¼ˆå°†ç»“æœè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼ï¼‰
            logger.trace(f"ğŸ’¾ [AGENT-PROCESS] æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºCOMPLETED")
            
            # å°†ç»“æœè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼å­˜å‚¨
            output_text = result['result'] if isinstance(result, dict) and 'result' in result else str(result)
            result_summary = output_text[:500] + '...' if len(output_text) > 500 else output_text  # æ‘˜è¦ä¸ºå‰500å­—ç¬¦
            
            complete_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.COMPLETED,
                output_data=output_text,
                result_summary=result_summary,
                actual_duration=actual_duration
            )
            
            updated_task = await self.task_repo.update_task(task_id, complete_update)
            logger.trace(f"âœ… [AGENT-PROCESS] ä»»åŠ¡çŠ¶æ€æ›´æ–°ä¸ºCOMPLETEDæˆåŠŸ")
            
            if updated_task:
                logger.trace(f"ğŸ“‹ [AGENT-PROCESS] æ›´æ–°åä»»åŠ¡çŠ¶æ€: {updated_task.get('status', 'unknown')}")
            else:
                logger.warning(f"âš ï¸ [AGENT-PROCESS] ä»»åŠ¡æ›´æ–°è¿”å›ç©ºç»“æœ")
            
            # æ˜¾ç¤ºAgentè¾“å‡ºç»“æœ
            logger.trace(f"ğŸ¯ [AGENT-PROCESS] === AGENTè¾“å‡ºç»“æœ ===")
            logger.trace(f"   ğŸ“ ä»»åŠ¡æ ‡é¢˜: {task['task_title']}")
            logger.trace(f"   â±ï¸  å¤„ç†æ—¶é•¿: {actual_duration}åˆ†é’Ÿ")
            logger.trace(f"   ğŸ“Š ç»“æœå†…å®¹:")
            
            # æ˜¾ç¤ºæ–‡æœ¬ç»“æœ
            logger.trace(f"      ğŸ“„ è¾“å‡ºå†…å®¹: {output_text[:300]}{'...' if len(output_text) > 300 else ''}")
            
            # æ˜¾ç¤ºæ¨¡å‹ä½¿ç”¨ä¿¡æ¯
            if isinstance(result, dict):
                model_used = result.get('model_used', 'N/A')
                if model_used and model_used != 'N/A':
                    logger.trace(f"      ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_used}")
                
                token_usage = result.get('token_usage', {})
                if token_usage:
                    logger.trace(f"      ğŸ’° Tokenä½¿ç”¨: {token_usage}")
            
            logger.trace(f"ğŸ‰ [AGENT-PROCESS] Agentä»»åŠ¡å¤„ç†å®Œæˆ: {task['task_title']}")
            
            # é€šçŸ¥ä»»åŠ¡å®Œæˆå›è°ƒ
            completion_result = {
                'task_id': task_id,
                'status': TaskInstanceStatus.COMPLETED.value,
                'result': output_text,  # ä½¿ç”¨æ–‡æœ¬æ ¼å¼çš„ç»“æœ
                'duration': actual_duration,
                'message': 'Agentä»»åŠ¡å¤„ç†å®Œæˆ'
            }
            await self._notify_task_completion(task_id, completion_result)
            
            return completion_result
            
        except Exception as e:
            logger.error(f"å¤„ç†Agentä»»åŠ¡å¤±è´¥: {e}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            fail_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.FAILED,
                error_message=str(e)
            )
            await self.task_repo.update_task(task_id, fail_update)
            
            # é€šçŸ¥ä»»åŠ¡å¤±è´¥å›è°ƒ
            await self._notify_task_failure(task_id, str(e))
            
            raise
    
    async def _call_agent_api(self, agent: Dict[str, Any], 
                            ai_client_data: Dict[str, Any]) -> Dict[str, Any]:
        """è°ƒç”¨Agent APIå¤„ç†ä»»åŠ¡ï¼ˆä»…ä½¿ç”¨OpenAIè§„èŒƒï¼‰"""
        try:
            logger.trace(f"ğŸ”Œ [AGENT-API] å¼€å§‹è°ƒç”¨Agent API")
            
            # å…¼å®¹ä¸åŒAgentå¯¹è±¡æ ¼å¼
            agent_name = 'unknown'
            model_name = 'unknown'  
            base_url = 'none'
            
            if isinstance(agent, dict):
                agent_name = agent.get('agent_name', 'unknown')
                model_name = agent.get('model_name', 'unknown')
                base_url = agent.get('base_url', 'none')
            elif hasattr(agent, 'agent_name'):
                agent_name = getattr(agent, 'agent_name', 'unknown')
                model_name = getattr(agent, 'model_name', 'unknown')
                base_url = getattr(agent, 'base_url', 'none')
            
            logger.trace(f"   - Agent: {agent_name}")
            logger.trace(f"   - æ¨¡å‹: {model_name}")
            logger.trace(f"   - Base URL: {base_url}")
            logger.trace(f"   - ä»»åŠ¡ID: {ai_client_data.get('task_id', 'unknown')}")
            
            # ç»Ÿä¸€ä½¿ç”¨OpenAIè§„èŒƒæ ¼å¼å¤„ç†æ‰€æœ‰AIä»»åŠ¡
            result = await self._process_with_openai_format(agent, ai_client_data)
            
            logger.trace(f"âœ… [AGENT-API] Agent APIè°ƒç”¨æˆåŠŸ")
            logger.trace(f"   - è¿”å›ç»“æœç±»å‹: {type(result)}")
            if isinstance(result, dict):
                logger.trace(f"   - ç»“æœåŒ…å«çš„é”®: {list(result.keys())}")
                logger.trace(f"   - ç½®ä¿¡åº¦: {result.get('confidence_score', 'N/A')}")
                
            return result
                
        except Exception as e:
            logger.error(f"âŒ [AGENT-API] è°ƒç”¨Agent APIå¤±è´¥: {e}")
            import traceback
            logger.error(f"   - é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def _process_with_openai_format(self, agent: Dict[str, Any], 
                                        ai_client_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨OpenAIè§„èŒƒæ ¼å¼å¤„ç†ä»»åŠ¡"""
        try:
            task_title = ai_client_data['task_metadata']['task_title']
            logger.trace(f"ğŸš€ [OPENAI-FORMAT] ä½¿ç”¨OpenAIè§„èŒƒå¤„ç†ä»»åŠ¡: {task_title}")
            
            # æ„å»ºç¬¦åˆOpenAI APIè§„èŒƒçš„è¯·æ±‚æ•°æ®
            logger.trace(f"ğŸ› ï¸ [OPENAI-FORMAT] æ„å»º OpenAI API è¯·æ±‚æ•°æ®")
            
            # ä» agent çš„ parameters ä¸­è·å–å‚æ•°
            if isinstance(agent, dict):
                agent_params = agent.get('parameters') or {}
                model_name = agent.get('model_name', 'gpt-3.5-turbo')
            elif hasattr(agent, 'parameters'):
                agent_params = agent.parameters or {}
                model_name = getattr(agent, 'model_name', 'gpt-3.5-turbo')
            else:
                logger.warning(f"âš ï¸ [OPENAI-FORMAT] æ— æ³•è·å–Agentå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                agent_params = {}
                model_name = 'gpt-3.5-turbo'
                
            temperature = agent_params.get('temperature', 0.7) if isinstance(agent_params, dict) else 0.7
            max_tokens = agent_params.get('max_tokens', 2000) if isinstance(agent_params, dict) else 2000
            
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            logger.trace(f"ğŸ”§ [OPENAI-FORMAT] Agentå‚æ•°:")
            logger.trace(f"   - model_name: {model_name}")
            logger.trace(f"   - agent_params: {agent_params}")
            logger.trace(f"   - temperature: {temperature}")
            logger.trace(f"   - max_tokens: {max_tokens}")
            
            # è·å–Agentçš„MCPå·¥å…·
            agent_id = None
            if isinstance(agent, dict):
                agent_id = agent.get('agent_id')
            elif hasattr(agent, 'agent_id'):
                agent_id = agent.agent_id
            else:
                logger.warning(f"âš ï¸ [MCP-TOOLS] Agentå¯¹è±¡ç±»å‹æ— æ³•è¯†åˆ«: {type(agent)}, è·³è¿‡å·¥å…·è·å–")
                
            mcp_tools = []
            if agent_id:
                try:
                    logger.trace(f"ğŸ”§ [MCP-TOOLS] è·å–Agentçš„MCPå·¥å…·: {agent_id}")
                    logger.trace(f"   - Agentå¯¹è±¡ç±»å‹: {type(agent)}")
                    logger.trace(f"   - Agentæ˜¯å¦ä¸ºå­—å…¸: {isinstance(agent, dict)}")
                    if isinstance(agent, dict):
                        logger.trace(f"   - Agentå­—å…¸é”®: {list(agent.keys())}")
                    
                    mcp_tools = await mcp_service.get_agent_tools(agent_id)
                    logger.trace(f"   - æ‰¾åˆ°MCPå·¥å…·æ•°é‡: {len(mcp_tools)}")
                    
                    # æ£€æŸ¥å·¥å…·é€‰æ‹©æ¨¡å¼
                    tool_config = {}
                    if isinstance(agent, dict):
                        tool_config = agent.get('tool_config', {}) or {}
                    elif hasattr(agent, 'tool_config'):
                        tool_config = getattr(agent, 'tool_config', {}) or {}
                    
                    # ç¡®ä¿tool_configæ˜¯å­—å…¸ç±»å‹
                    if not isinstance(tool_config, dict):
                        logger.warning(f"âš ï¸ [MCP-TOOLS] tool_configä¸æ˜¯å­—å…¸ç±»å‹: {type(tool_config)}, ä½¿ç”¨é»˜è®¤é…ç½®")
                        tool_config = {}
                        
                    tool_selection = tool_config.get('tool_selection', 'auto')
                    
                    logger.trace(f"   - å·¥å…·é€‰æ‹©æ¨¡å¼: {tool_selection}")
                    
                    if tool_selection == 'disabled':
                        logger.trace(f"   - å·¥å…·è°ƒç”¨å·²ç¦ç”¨ï¼Œæ¸…ç©ºå·¥å…·åˆ—è¡¨")
                        mcp_tools = []
                    elif tool_selection == 'manual':
                        # åº”ç”¨å·¥å…·è¿‡æ»¤
                        allowed_tools = tool_config.get('allowed_tools', [])
                        blocked_tools = tool_config.get('blocked_tools', [])
                        
                        if allowed_tools:
                            mcp_tools = [tool for tool in mcp_tools if tool.name in allowed_tools]
                            logger.trace(f"   - åº”ç”¨å…è®¸åˆ—è¡¨åå·¥å…·æ•°é‡: {len(mcp_tools)}")
                        
                        if blocked_tools:
                            mcp_tools = [tool for tool in mcp_tools if tool.name not in blocked_tools]
                            logger.trace(f"   - åº”ç”¨ç¦ç”¨åˆ—è¡¨åå·¥å…·æ•°é‡: {len(mcp_tools)}")
                    
                    # æ˜¾ç¤ºæœ€ç»ˆå·¥å…·åˆ—è¡¨
                    if mcp_tools:
                        logger.trace(f"   - å¯ç”¨å·¥å…·:")
                        for i, tool in enumerate(mcp_tools[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
                            logger.trace(f"     {i+1}. {tool.name} ({tool.server_name})")
                        if len(mcp_tools) > 5:
                            logger.trace(f"     ... è¿˜æœ‰ {len(mcp_tools) - 5} ä¸ªå·¥å…·")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ [MCP-TOOLS] è·å–MCPå·¥å…·å¤±è´¥: {e}")
                    mcp_tools = []
            
            openai_request = {
                'messages': [
                    {
                        'role': 'system',
                        'content': ai_client_data['system_prompt']
                    },
                    {
                        'role': 'user', 
                        'content': ai_client_data['user_message']
                    }
                ],
                'model': model_name,
                'temperature': temperature,
                'max_tokens': max_tokens
            }
            
            # å¦‚æœæœ‰MCPå·¥å…·ï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­
            if mcp_tools:
                openai_tools = [tool.to_openai_format() for tool in mcp_tools]
                openai_request['tools'] = openai_tools
                openai_request['tool_choice'] = 'auto'
                logger.trace(f"ğŸ”§ [MCP-TOOLS] æ·»åŠ å·¥å…·åˆ°OpenAIè¯·æ±‚: {len(openai_tools)} ä¸ªå·¥å…·")
            
            logger.trace(f"   - æ¨¡å‹: {model_name}")
            logger.trace(f"   - æ¸©åº¦: {temperature}")
            logger.trace(f"   - æœ€å¤§token: {max_tokens}")
            logger.trace(f"   - æ¶ˆæ¯æ•°é‡: {len(openai_request['messages'])}")
            logger.trace(f"   - å·¥å…·æ•°é‡: {len(openai_request.get('tools', []))}")
            logger.trace(f"   - ç³»ç»Ÿæ¶ˆæ¯é•¿åº¦: {len(openai_request['messages'][0]['content'])}")
            logger.trace(f"   - ç”¨æˆ·æ¶ˆæ¯é•¿åº¦: {len(openai_request['messages'][1]['content'])}")
            
            # è°ƒç”¨OpenAIå®¢æˆ·ç«¯å¤„ç†ä»»åŠ¡ï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
            logger.trace(f"ğŸ”„ [OPENAI-FORMAT] è°ƒç”¨OpenAIå®¢æˆ·ç«¯")
            logger.trace(f"   - ä½¿ç”¨æ¨¡å‹: {openai_request['model']}")
            
            # è·å–Base URLå’ŒAPI Keyï¼ˆå…¼å®¹å­—å…¸å’Œå¯¹è±¡ï¼‰
            base_url = 'default'
            has_api_key = False
            if isinstance(agent, dict):
                base_url = agent.get('base_url', 'default')
                has_api_key = bool(agent.get('api_key'))
            elif hasattr(agent, 'base_url'):
                base_url = getattr(agent, 'base_url', 'default')
                has_api_key = bool(getattr(agent, 'api_key', None))
                
            logger.trace(f"   - Base URL: {base_url}")
            logger.trace(f"   - API Keyå­˜åœ¨: {'æ˜¯' if has_api_key else 'å¦'}")
            logger.trace(f" ç³»ç»Ÿæ¶ˆæ¯ï¼š{openai_request['messages'][0]['content']}")
            logger.trace(f" ç”¨æˆ·æ¶ˆæ¯ï¼š{openai_request['messages'][1]['content']}")
            
            # è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆé˜²æ­¢å¡æ­»ï¼‰
            try:
                openai_result = await asyncio.wait_for(
                    self._process_with_tools(agent, openai_request, mcp_tools),
                    timeout=600  # 10åˆ†é’Ÿè¶…æ—¶ï¼ˆå·¥å…·è°ƒç”¨å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
                )
                logger.trace(f"âœ… [OPENAI-FORMAT] OpenAIå®¢æˆ·ç«¯è°ƒç”¨æˆåŠŸ")
            except asyncio.TimeoutError:
                logger.error(f"â° [OPENAI-FORMAT] OpenAI APIè°ƒç”¨è¶…æ—¶ï¼ˆ10åˆ†é’Ÿï¼‰")
                raise RuntimeError("OpenAI APIè°ƒç”¨è¶…æ—¶")
            except Exception as api_e:
                logger.error(f"âŒ [OPENAI-FORMAT] OpenAI APIè°ƒç”¨å¼‚å¸¸: {api_e}")
                raise
            
            if openai_result['success']:
                # ä»OpenAIæ ¼å¼çš„å›å¤ä¸­æå–æ–‡æœ¬ç»“æœ
                ai_response = openai_result['result']
                response_content = ai_response.get('content', '')
                
                # ç›´æ¥è¿”å›æ–‡æœ¬ç»“æœï¼Œä¸è¦æ±‚ç‰¹å®šæ ¼å¼
                model_used = openai_result.get('model', model_name)  # ä½¿ç”¨ä¹‹å‰è·å–çš„model_name
                result = {
                    'result': response_content,  # Agentçš„åŸå§‹è¾“å‡º
                    'model_used': model_used,
                    'token_usage': openai_result.get('usage', {})
                }
                
                logger.trace(f"OpenAIè§„èŒƒå¤„ç†å®Œæˆï¼Œè¿”å›æ–‡æœ¬ç»“æœ")
                return result
            else:
                # å¤„ç†å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                error_msg = openai_result.get('error', 'AIå¤„ç†å¤±è´¥')
                raise RuntimeError(f"AIå¤„ç†å¤±è´¥: {error_msg}")
            
        except Exception as e:
            logger.error(f"OpenAIè§„èŒƒå¤„ç†å¤±è´¥: {e}")
            raise
    
    
    
    async def _process_agent_tasks(self):
        """å¤„ç†Agentä»»åŠ¡çš„å·¥ä½œåç¨‹"""
        while self.is_running:
            try:
                # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
                queue_item = await asyncio.wait_for(
                    self.processing_queue.get(), timeout=5.0
                )
                
                task_id = queue_item['task_id']
                logger.trace(f"ä»é˜Ÿåˆ—å–å‡ºAgentä»»åŠ¡: {task_id}")
                
                # å¤„ç†ä»»åŠ¡
                await self.process_agent_task(task_id)
                
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"å¤„ç†Agentä»»åŠ¡åç¨‹å‡ºé”™: {e}")
                await asyncio.sleep(1)
    
    async def _monitor_pending_tasks(self):
        """ç›‘æ§å¾…å¤„ç†ä»»åŠ¡çš„åç¨‹ï¼ˆæ™ºèƒ½è°ƒåº¦ç‰ˆæœ¬ï¼‰"""
        consecutive_empty_checks = 0
        base_sleep_interval = 15  # åŸºç¡€æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰- ä¼˜åŒ–ä¸ºæ›´é¢‘ç¹
        max_sleep_interval = 120  # æœ€å¤§æ£€æŸ¥é—´éš”ï¼ˆ2åˆ†é’Ÿï¼‰- å‡å°‘æœ€å¤§å»¶è¿Ÿ
        
        while self.is_running:
            try:
                # åŠ¨æ€è°ƒæ•´æ£€æŸ¥é—´éš”
                if consecutive_empty_checks == 0:
                    sleep_interval = base_sleep_interval
                elif consecutive_empty_checks <= 3:
                    sleep_interval = base_sleep_interval * 2  # 60ç§’
                elif consecutive_empty_checks <= 6:
                    sleep_interval = base_sleep_interval * 4  # 120ç§’
                else:
                    sleep_interval = max_sleep_interval  # 300ç§’
                
                await asyncio.sleep(sleep_interval)
                
                # è·å–å¾…å¤„ç†çš„Agentä»»åŠ¡
                pending_tasks = await self.get_pending_agent_tasks(limit=10)
                
                if pending_tasks:
                    # æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œé‡ç½®è®¡æ•°å™¨
                    consecutive_empty_checks = 0
                    
                    # å°†å¾…å¤„ç†ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—
                    for task in pending_tasks:
                        if task['status'] == TaskInstanceStatus.PENDING.value:
                            queue_item = {
                                'task_id': task['task_instance_id'],
                                'submitted_at': now_utc()
                            }
                            await self.processing_queue.put(queue_item)
                            
                            logger.trace(f"è‡ªåŠ¨åŠ å…¥Agentä»»åŠ¡åˆ°å¤„ç†é˜Ÿåˆ—: {task['task_instance_id']}")
                else:
                    # æ²¡æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼Œå¢åŠ ç©ºæ£€æŸ¥è®¡æ•°
                    consecutive_empty_checks += 1
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒçš„å·¥ä½œæµ
                    has_active_workflows = await self._has_active_workflows()
                    
                    # å¦‚æœæ²¡æœ‰æ´»è·ƒå·¥ä½œæµï¼Œè¿›ä¸€æ­¥å»¶é•¿æ£€æŸ¥é—´éš”
                    if not has_active_workflows and consecutive_empty_checks > 10:
                        sleep_interval = min(sleep_interval * 2, 600)  # æœ€é•¿10åˆ†é’Ÿ
                    
                    # æ¯éš”ä¸€å®šæ¬¡æ•°æ‰è¾“å‡ºä¸€æ¬¡è­¦å‘Šï¼Œé¿å…æ—¥å¿—åˆ·å±
                    if consecutive_empty_checks in [1, 5, 10, 20] or consecutive_empty_checks % 50 == 0:
                        status_msg = "æ— æ´»è·ƒå·¥ä½œæµ" if not has_active_workflows else "æœ‰æ´»è·ƒå·¥ä½œæµ"
                        logger.trace(f"ğŸ” [AGENT-MONITOR] è¿ç»­ {consecutive_empty_checks} æ¬¡æœªæ‰¾åˆ°å¾…å¤„ç†ä»»åŠ¡ï¼Œ{status_msg}ï¼Œæ£€æŸ¥é—´éš”å·²è°ƒæ•´ä¸º {sleep_interval} ç§’")
                
            except Exception as e:
                logger.error(f"ç›‘æ§å¾…å¤„ç†ä»»åŠ¡å¤±è´¥: {e}")
                await asyncio.sleep(10)
                consecutive_empty_checks = 0  # é‡ç½®è®¡æ•°å™¨
    
    async def get_agent_task_statistics(self, agent_id: Optional[uuid.UUID] = None) -> Dict[str, Any]:
        """è·å–Agentä»»åŠ¡ç»Ÿè®¡"""
        try:
            # è·å–Agentçš„æ‰€æœ‰ä»»åŠ¡
            all_tasks = await self.task_repo.get_agent_tasks_for_processing(agent_id, 1000)
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = {
                'total_tasks': len(all_tasks),
                'pending_tasks': 0,
                'in_progress_tasks': 0,
                'completed_tasks': 0,
                'failed_tasks': 0,
                'average_processing_time': 0,
                'success_rate': 0,
                'queue_size': self.processing_queue.qsize()
            }
            
            total_duration = 0
            completed_count = 0
            
            for task in all_tasks:
                status = task['status']
                if status == TaskInstanceStatus.PENDING.value:
                    stats['pending_tasks'] += 1
                elif status == TaskInstanceStatus.IN_PROGRESS.value:
                    stats['in_progress_tasks'] += 1
                elif status == TaskInstanceStatus.COMPLETED.value:
                    stats['completed_tasks'] += 1
                    completed_count += 1
                    if task.get('actual_duration'):
                        total_duration += task['actual_duration']
                elif status == TaskInstanceStatus.FAILED.value:
                    stats['failed_tasks'] += 1
            
            # è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´å’ŒæˆåŠŸç‡
            if completed_count > 0:
                stats['average_processing_time'] = total_duration / completed_count
            
            if len(all_tasks) > 0:
                stats['success_rate'] = (completed_count / len(all_tasks)) * 100
            
            logger.trace(f"ç”ŸæˆAgentä»»åŠ¡ç»Ÿè®¡ï¼ŒæˆåŠŸç‡: {stats['success_rate']:.1f}%")
            return stats
            
        except Exception as e:
            logger.error(f"è·å–Agentä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {e}")
            raise
    
    async def retry_failed_task(self, task_id: uuid.UUID) -> Dict[str, Any]:
        """é‡è¯•å¤±è´¥çš„ä»»åŠ¡"""
        try:
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task['status'] != TaskInstanceStatus.FAILED.value:
                raise ValueError("åªèƒ½é‡è¯•å¤±è´¥çš„ä»»åŠ¡")
            
            # é‡ç½®ä»»åŠ¡çŠ¶æ€ä¸ºå¾…å¤„ç†
            reset_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.PENDING,
                error_message=None
            )
            await self.task_repo.update_task(task_id, reset_update)
            
            # é‡æ–°æäº¤åˆ°å¤„ç†é˜Ÿåˆ—
            await self.submit_task_to_agent(task_id)
            
            logger.trace(f"é‡è¯•å¤±è´¥ä»»åŠ¡: {task_id}")
            return {
                'task_id': task_id,
                'status': 'retry_queued',
                'message': 'å¤±è´¥ä»»åŠ¡å·²é‡æ–°åŠ å…¥å¤„ç†é˜Ÿåˆ—'
            }
            
        except Exception as e:
            logger.error(f"é‡è¯•å¤±è´¥ä»»åŠ¡å‡ºé”™: {e}")
            raise
    
    async def cancel_agent_task(self, task_id: uuid.UUID) -> Dict[str, Any]:
        """å–æ¶ˆAgentä»»åŠ¡"""
        try:
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task['status'] in [TaskInstanceStatus.COMPLETED.value, TaskInstanceStatus.CANCELLED.value]:
                raise ValueError("ä»»åŠ¡å·²å®Œæˆæˆ–å·²å–æ¶ˆï¼Œæ— æ³•å–æ¶ˆ")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å–æ¶ˆ
            cancel_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.CANCELLED,
                error_message="ä»»åŠ¡è¢«æ‰‹åŠ¨å–æ¶ˆ"
            )
            await self.task_repo.update_task(task_id, cancel_update)
            
            logger.trace(f"å–æ¶ˆAgentä»»åŠ¡: {task_id}")
            return {
                'task_id': task_id,
                'status': TaskInstanceStatus.CANCELLED.value,
                'message': 'ä»»åŠ¡å·²å–æ¶ˆ'
            }
            
        except Exception as e:
            logger.error(f"å–æ¶ˆAgentä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    def _build_system_prompt(self, task: Dict[str, Any]) -> str:
        """æ„å»ºç³»ç»ŸPromptï¼ˆä»…åŒ…å«ä»»åŠ¡æè¿°ï¼‰"""
        try:
            task_description = task.get('task_description', 'æ— ä»»åŠ¡æè¿°')
            
            # ç®€åŒ–çš„ç³»ç»Ÿpromptï¼Œåªæä¾›ä»»åŠ¡æè¿°
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

{task_description}

è¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»¥è‡ªç„¶ã€å‡†ç¡®çš„æ–¹å¼å®Œæˆä»»åŠ¡ã€‚"""

            return system_prompt.strip()
            
        except Exception as e:
            logger.error(f"æ„å»ºç³»ç»Ÿpromptå¤±è´¥: {e}")
            return "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·å¸®åŠ©å®Œæˆåˆ†é…çš„ä»»åŠ¡ã€‚"
    
    def _preprocess_upstream_context(self, input_data: str) -> str:
        """é¢„å¤„ç†ä¸Šæ¸¸ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆä»…åŒ…å«å·¥ä½œæµæè¿°ã€èŠ‚ç‚¹åç§°ã€ä»»åŠ¡titleã€èŠ‚ç‚¹è¾“å‡ºå†…å®¹ï¼‰"""
        try:
            logger.debug(f"ğŸ” [ä¸Šä¸‹æ–‡é¢„å¤„ç†] ===== å¼€å§‹é¢„å¤„ç†ä¸Šæ¸¸ä¸Šä¸‹æ–‡ =====")
            logger.debug(f"  - è¾“å…¥æ•°æ®ç±»å‹: {type(input_data)}")
            
            # å®‰å…¨åœ°è®¡ç®—é•¿åº¦å’Œé¢„è§ˆ
            input_str = str(input_data) if input_data is not None else ""
            logger.debug(f"  - è¾“å…¥æ•°æ®é•¿åº¦: {len(input_str)}")
            logger.debug(f"  - è¾“å…¥æ•°æ®æ˜¯å¦ä¸ºç©º: {not input_data}")
            logger.debug(f"  - è¾“å…¥æ•°æ®é¢„è§ˆ: {input_str[:200]}{'...' if len(input_str) > 200 else ''}")
            logger.debug(f"  - è¾“å…¥æ•°æ®å®Œæ•´å†…å®¹: '{input_data}'")
            
            context_parts = []
            
            # æ™ºèƒ½å¤„ç†è¾“å…¥æ•°æ®ï¼šæ”¯æŒå­—å…¸ã€JSONå­—ç¬¦ä¸²å’Œæ™®é€šå­—ç¬¦ä¸²
            data_dict = {}
            try:
                if input_data:
                    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯å­—å…¸ç±»å‹
                    if isinstance(input_data, dict):
                        data_dict = input_data
                        logger.debug(f"  - è¾“å…¥æ•°æ®å·²æ˜¯å­—å…¸ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨")
                        logger.debug(f"  - å­—å…¸é¡¶çº§é”®: {list(data_dict.keys())}")
                    elif isinstance(input_data, str) and input_data.strip():
                        # å°è¯•è§£æJSONå­—ç¬¦ä¸²
                        try:
                            data_dict = json.loads(input_data)
                            logger.debug(f"  - JSONè§£ææˆåŠŸï¼Œæ•°æ®ç±»å‹: {type(data_dict)}")
                            logger.debug(f"  - JSONè§£æåé¡¶çº§é”®: {list(data_dict.keys()) if isinstance(data_dict, dict) else 'Not a dict'}")
                        except json.JSONDecodeError:
                            # å¦‚æœä¸æ˜¯æœ‰æ•ˆJSONï¼Œå°†æ•´ä¸ªå­—ç¬¦ä¸²ä½œä¸ºç®€å•ä¸Šä¸‹æ–‡
                            logger.debug(f"  - è¾“å…¥ä¸æ˜¯æœ‰æ•ˆJSONï¼Œä½œä¸ºæ™®é€šæ–‡æœ¬å¤„ç†")
                            context_parts.append(f"ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{input_data}")
                            return "\n".join(context_parts)
                    else:
                        # å…¶ä»–ç±»å‹è½¬ä¸ºå­—ç¬¦ä¸²å¤„ç†
                        input_str = str(input_data)
                        logger.debug(f"  - å…¶ä»–ç±»å‹æ•°æ®è½¬ä¸ºå­—ç¬¦ä¸²: {input_str[:100]}...")
                        context_parts.append(f"ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{input_str}")
                        return "\n".join(context_parts)
                else:
                    data_dict = {}
                    logger.debug(f"  - è¾“å…¥æ•°æ®ä¸ºç©ºï¼Œä½¿ç”¨ç©ºå­—å…¸")
            except Exception as e:
                logger.error(f"å¤„ç†è¾“å…¥æ•°æ®å¤±è´¥: {e}")
                return "ä¸Šä¸‹æ–‡ä¿¡æ¯å¤„ç†å¤±è´¥ï¼Œè¯·åŸºäºä»»åŠ¡æè¿°è¿›è¡Œå¤„ç†ã€‚"
            
            # 1. å·¥ä½œæµæè¿°
            workflow_global = data_dict.get('workflow_global', {})
            if workflow_global:
                workflow_description = workflow_global.get('workflow_description', '')
                if workflow_description:
                    context_parts.append(f"å·¥ä½œæµæè¿°ï¼š{workflow_description}")
            
            # 2. ä¸Šæ¸¸èŠ‚ç‚¹ä¿¡æ¯ï¼ˆèŠ‚ç‚¹åç§°ã€ä»»åŠ¡titleã€èŠ‚ç‚¹è¾“å‡ºå†…å®¹ï¼‰
            logger.debug(f"ğŸ” [ä¸Šä¸‹æ–‡é¢„å¤„ç†] è¾“å…¥æ•°æ®ç»“æ„: {data_dict}")
            
            # å…¼å®¹ä¸åŒçš„ä¸Šæ¸¸æ•°æ®å­—æ®µå
            immediate_upstream = data_dict.get('immediate_upstream', {})
            upstream_outputs = data_dict.get('upstream_outputs', [])
            
            logger.debug(f"ğŸ” [ä¸Šä¸‹æ–‡é¢„å¤„ç†] immediate_upstreamç±»å‹: {type(immediate_upstream)}, å†…å®¹: {immediate_upstream}")
            logger.debug(f"ğŸ” [ä¸Šä¸‹æ–‡é¢„å¤„ç†] upstream_outputsç±»å‹: {type(upstream_outputs)}, å†…å®¹: {upstream_outputs}")
            
            # å¤„ç†immediate_upstreamæ ¼å¼ï¼ˆæ—§æ ¼å¼ï¼‰
            if immediate_upstream:
                context_parts.append("\nä¸Šæ¸¸èŠ‚ç‚¹ä¿¡æ¯ï¼š")
                
                for node_id, node_data in immediate_upstream.items():
                    logger.trace(f"ğŸ“‹ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] å¤„ç†èŠ‚ç‚¹ {node_id[:8]}...")
                    logger.trace(f"  - åŸå§‹æ•°æ®ç±»å‹: {type(node_data)}")
                    logger.trace(f"  - åŸå§‹æ•°æ®å†…å®¹: {node_data}")
                    
                    # æ£€æŸ¥node_dataæ˜¯å¦å·²ç»æ˜¯å­—å…¸ç±»å‹
                    if isinstance(node_data, str):
                        try:
                            node_data = json.loads(node_data)
                            logger.trace(f"  - è§£æåæ•°æ®: {node_data}")
                        except json.JSONDecodeError:
                            logger.warning(f"  âŒ æ— æ³•è§£æèŠ‚ç‚¹æ•°æ®: {node_data[:100]}...")
                            continue
                    elif not isinstance(node_data, dict):
                        logger.warning(f"  âŒ èŠ‚ç‚¹æ•°æ®ç±»å‹ä¸æ­£ç¡®: {type(node_data)}")
                        continue
                    
                    node_name = node_data.get('node_name', f'èŠ‚ç‚¹_{node_id[:8]}')
                    
                    # æ£€æŸ¥å¤šç§å¯èƒ½çš„è¾“å‡ºå­—æ®µ - ä¿®å¤é€»è¾‘ï¼Œç¡®ä¿æ­£ç¡®æå–æ•°æ®
                    output_data = None
                    if 'task_result' in node_data:
                        output_data = node_data['task_result']
                    elif 'output_data' in node_data:
                        output_data = node_data['output_data']
                    elif 'result' in node_data:
                        output_data = node_data['result']
                    elif 'task_description' in node_data:
                        output_data = node_data['task_description']
                    
                    logger.trace(f"  - èŠ‚ç‚¹åç§°: {node_name}")
                    logger.trace(f"  - è¾“å‡ºæ•°æ®: {output_data}")
                    logger.trace(f"  - è¾“å‡ºæ•°æ®ç±»å‹: {type(output_data)}")
                    logger.trace(f"  - èŠ‚ç‚¹å®Œæ•´æ•°æ®: {node_data}")
                    
                    context_parts.append(f"\nèŠ‚ç‚¹ï¼š{node_name}")
                   
                    # è¾“å‡ºå†…å®¹ï¼ˆç®€åŒ–å±•ç¤ºï¼‰
                    if output_data is not None:
                        if isinstance(output_data, dict):
                            # å¯¹äºå­—å…¸ç±»å‹ï¼Œå°è¯•æå–æœ€é‡è¦çš„æ•°æ®
                            context_parts.append("è¾“å‡ºæ•°æ®ï¼š")
                            for key, value in output_data.items():
                                formatted_value = self._format_simple_output(value)
                                context_parts.append(f"- {key}: {formatted_value}")
                                logger.trace(f"  - æ·»åŠ å­—æ®µ {key}: {formatted_value[:100]}...")
                        else:
                            # å¯¹äºç®€å•ç±»å‹ï¼Œç›´æ¥æ˜¾ç¤º
                            formatted_output = self._format_simple_output(output_data)
                            context_parts.append(f"è¾“å‡ºæ•°æ®ï¼š{formatted_output}")
                            logger.trace(f"  - æ·»åŠ è¾“å‡º: {formatted_output}")
                            
                            # å¦‚æœæ˜¯æ•°å­—ï¼Œé¢å¤–æç¤º
                            try:
                                num_value = float(output_data)
                                context_parts.append(f"ï¼ˆè¿™æ˜¯ä¸€ä¸ªæ•°å€¼ï¼š{num_value}ï¼‰")
                                logger.trace(f"  - è¯†åˆ«ä¸ºæ•°å€¼: {num_value}")
                            except (ValueError, TypeError):
                                logger.trace(f"  - éæ•°å€¼ç±»å‹: {type(output_data)}")
                                pass
                    else:
                        context_parts.append("- æ— è¾“å‡ºå†…å®¹")
                        logger.trace(f"  - è¯¥èŠ‚ç‚¹æ— è¾“å‡ºå†…å®¹")
            
            # å¤„ç†upstream_outputsæ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼‰
            elif upstream_outputs and isinstance(upstream_outputs, list):
                context_parts.append("\nä¸Šæ¸¸èŠ‚ç‚¹ä¿¡æ¯ï¼š")
                
                for i, upstream_node in enumerate(upstream_outputs):
                    logger.trace(f"ğŸ“‹ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] å¤„ç†ä¸Šæ¸¸èŠ‚ç‚¹ {i+1}...")
                    logger.trace(f"  - èŠ‚ç‚¹æ•°æ®: {upstream_node}")
                    
                    if isinstance(upstream_node, dict):
                        node_name = upstream_node.get('node_name', f'ä¸Šæ¸¸èŠ‚ç‚¹_{i+1}')
                        output_data = upstream_node.get('output_data', '')
                        
                        context_parts.append(f"\nèŠ‚ç‚¹ï¼š{node_name}")
                        
                        if output_data:
                            formatted_output = self._format_simple_output(output_data)
                            context_parts.append(f"è¾“å‡ºæ•°æ®ï¼š{formatted_output}")
                            logger.trace(f"  - æ·»åŠ è¾“å‡º: {formatted_output[:100]}...")
                        else:
                            context_parts.append("- æ— è¾“å‡ºå†…å®¹")
                            logger.trace(f"  - è¯¥èŠ‚ç‚¹æ— è¾“å‡ºå†…å®¹")
                    else:
                        logger.warning(f"  âŒ ä¸Šæ¸¸èŠ‚ç‚¹æ•°æ®æ ¼å¼ä¸æ­£ç¡®: {upstream_node}")
            else:
                logger.debug(f"ğŸ” [ä¸Šä¸‹æ–‡é¢„å¤„ç†] æ²¡æœ‰æ‰¾åˆ°ä¸Šæ¸¸èŠ‚ç‚¹ä¿¡æ¯")
            
            final_context = "\n".join(context_parts) if context_parts else "æ— ä¸Šæ¸¸ä¸Šä¸‹æ–‡æ•°æ®ã€‚"
            logger.trace(f"ğŸ¯ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] context_partsé•¿åº¦: {len(context_parts)}")
            logger.trace(f"ğŸ¯ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] context_partså†…å®¹: {context_parts}")
            logger.trace(f"ğŸ¯ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] æœ€ç»ˆç”Ÿæˆçš„ä¸Šä¸‹æ–‡é•¿åº¦: {len(final_context)}")
            logger.trace(f"ğŸ¯ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] æœ€ç»ˆç”Ÿæˆçš„ä¸Šä¸‹æ–‡: {final_context}")
            return final_context
            
        except Exception as e:
            logger.error(f"âŒ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] é¢„å¤„ç†ä¸Šæ¸¸ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            import traceback
            logger.error(f"âŒ [ä¸Šä¸‹æ–‡é¢„å¤„ç†] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return "ä¸Šä¸‹æ–‡ä¿¡æ¯å¤„ç†å¤±è´¥ï¼Œè¯·åŸºäºä»»åŠ¡æè¿°è¿›è¡Œå¤„ç†ã€‚"
    
    def _format_simple_output(self, data) -> str:
        """æ ¼å¼åŒ–è¾“å‡ºæ•°æ®ä¸ºç®€å•æ–‡æœ¬å½¢å¼"""
        try:
            if isinstance(data, dict):
                # å¯¹äºå­—å…¸ï¼Œå°è¯•æ‰¾åˆ°æœ€é‡è¦çš„å­—æ®µ
                if 'result' in data:
                    return str(data['result'])
                elif 'content' in data:
                    return str(data['content'])
                elif 'value' in data:
                    return str(data['value'])
                elif len(data) == 1:
                    # å¦‚æœåªæœ‰ä¸€ä¸ªé”®å€¼å¯¹ï¼Œç›´æ¥è¿”å›å€¼
                    return str(list(data.values())[0])
                else:
                    # è¿”å›ç®€åŒ–çš„å­—å…¸è¡¨ç¤º
                    return str(data)
            elif isinstance(data, list):
                if len(data) <= 3:
                    return str(data)
                else:
                    return f"åŒ…å«{len(data)}ä¸ªé¡¹ç›®çš„åˆ—è¡¨"
            else:
                return str(data)
        except:
            return "æ•°æ®"
    
    def _build_user_message(self, task: Dict[str, Any], context_info: str) -> str:
        """æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼ˆåŒ…å«ä»»åŠ¡æ ‡é¢˜å’Œä¸Šæ¸¸èŠ‚ç‚¹ä¿¡æ¯ï¼‰"""
        try:
            message_parts = []
            
            # ä»»åŠ¡æ ‡é¢˜
            logger.trace(f"ä¸Šä¸‹æ–‡ä¿¡æ¯: {context_info}")
            task_title = task.get('task_title', 'æœªå‘½åä»»åŠ¡')
            message_parts.append(f"ä»»åŠ¡ï¼š{task_title}")
            
            # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆä¸Šæ¸¸èŠ‚ç‚¹ä¿¡æ¯ï¼‰
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            invalid_context_messages = [
                "æ— ä¸Šæ¸¸ä¸Šä¸‹æ–‡æ•°æ®ã€‚",
                "ä¸Šä¸‹æ–‡ä¿¡æ¯å¤„ç†å¤±è´¥ï¼Œè¯·åŸºäºä»»åŠ¡æè¿°è¿›è¡Œå¤„ç†ã€‚",
                "ä¸Šä¸‹æ–‡ä¿¡æ¯æ ¼å¼é”™è¯¯ï¼Œè¯·åŸºäºä»»åŠ¡æè¿°è¿›è¡Œå¤„ç†ã€‚"
            ]
            
            logger.debug(f"ğŸ” [æ¶ˆæ¯æ„å»º] æ£€æŸ¥ä¸Šä¸‹æ–‡ä¿¡æ¯æœ‰æ•ˆæ€§...")
            logger.debug(f"  - context_infoå­˜åœ¨: {bool(context_info)}")
            logger.debug(f"  - context_infoé•¿åº¦: {len(context_info) if context_info else 0}")
            logger.debug(f"  - context_infoå†…å®¹: '{context_info}'")
            logger.debug(f"  - context_info.strip(): '{context_info.strip() if context_info else ''}'")
            logger.debug(f"  - æ˜¯å¦åœ¨æ— æ•ˆæ¶ˆæ¯åˆ—è¡¨ä¸­: {context_info.strip() in invalid_context_messages if context_info else False}")
            
            if context_info and context_info.strip() and context_info.strip() not in invalid_context_messages:
                message_parts.append("\nä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š")
                message_parts.append(context_info)
                logger.debug(f"âœ… [æ¶ˆæ¯æ„å»º] æ·»åŠ äº†æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œé•¿åº¦: {len(context_info)}")
            else:
                message_parts.append("\nå½“å‰æ²¡æœ‰ä¸Šæ¸¸èŠ‚ç‚¹æ•°æ®ã€‚")
                logger.warning(f"âš ï¸ [æ¶ˆæ¯æ„å»º] ä¸Šä¸‹æ–‡ä¿¡æ¯æ— æ•ˆæˆ–ä¸ºç©º: '{context_info}'")
            
            return "\n".join(message_parts)
            
        except Exception as e:
            logger.error(f"æ„å»ºç”¨æˆ·æ¶ˆæ¯å¤±è´¥: {e}")
            return f"ä»»åŠ¡ï¼š{task.get('task_title', 'æœªçŸ¥ä»»åŠ¡')}"
    
    async def _process_with_tools(self, agent: Dict[str, Any], 
                                openai_request: Dict[str, Any], 
                                mcp_tools: List) -> Dict[str, Any]:
        """å¤„ç†å¸¦æœ‰å·¥å…·è°ƒç”¨çš„OpenAIè¯·æ±‚"""
        try:
            # å¦‚æœæ²¡æœ‰å·¥å…·ï¼Œç›´æ¥è°ƒç”¨æ™®é€šAPI
            if not mcp_tools:
                return await openai_client.process_task(openai_request)
            
            logger.trace(f"ğŸ”§ [TOOL-PROCESS] å¼€å§‹å¤„ç†å¸¦å·¥å…·çš„è¯·æ±‚")
            logger.trace(f"   - å¯ç”¨å·¥å…·æ•°é‡: {len(mcp_tools)}")
            
            # è·å–å·¥å…·é…ç½®
            tool_config = {}
            if isinstance(agent, dict):
                tool_config = agent.get('tool_config', {})
            elif hasattr(agent, 'tool_config'):
                tool_config = getattr(agent, 'tool_config', {}) or {}
                
            max_tool_calls = tool_config.get('max_tool_calls', 5) if isinstance(tool_config, dict) else 5
            tool_timeout = tool_config.get('timeout', 30) if isinstance(tool_config, dict) else 30
            
            logger.trace(f"   - æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°: {max_tool_calls}")
            logger.trace(f"   - å·¥å…·è¶…æ—¶æ—¶é—´: {tool_timeout}ç§’")
            
            # åˆ›å»ºå·¥å…·æ˜ å°„è¡¨
            tool_map = {tool.name: tool for tool in mcp_tools}
            
            messages = openai_request['messages'].copy()
            tool_call_count = 0
            
            while tool_call_count < max_tool_calls:
                # è°ƒç”¨OpenAI API
                logger.trace(f"ğŸš€ [TOOL-PROCESS] è°ƒç”¨OpenAI API (è½®æ¬¡ {tool_call_count + 1})")
                response = await openai_client.process_task(openai_request)
                
                if not response['success']:
                    return response
                
                ai_response = response['result']
                assistant_message = ai_response.get('message', {})
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                tool_calls = assistant_message.get('tool_calls', [])
                
                if not tool_calls:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›æœ€ç»ˆç»“æœ
                    logger.trace(f"âœ… [TOOL-PROCESS] å¯¹è¯å®Œæˆï¼Œæ— å·¥å…·è°ƒç”¨")
                    return response
                
                logger.trace(f"ğŸ”§ [TOOL-PROCESS] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {len(tool_calls)} ä¸ª")
                
                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å¯¹è¯å†å²
                messages.append({
                    'role': 'assistant',
                    'content': assistant_message.get('content'),
                    'tool_calls': tool_calls
                })
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_responses = []
                for tool_call in tool_calls:
                    tool_call_id = tool_call.get('id')
                    function_call = tool_call.get('function', {})
                    tool_name = function_call.get('name')
                    
                    logger.trace(f"ğŸ”§ [TOOL-CALL] è°ƒç”¨å·¥å…·: {tool_name}")
                    
                    if tool_name in tool_map:
                        try:
                            tool = tool_map[tool_name]
                            arguments = json.loads(function_call.get('arguments', '{}'))
                            
                            # è°ƒç”¨MCPå·¥å…·
                            logger.trace(f"   - å‚æ•°: {arguments}")
                            tool_result = await asyncio.wait_for(
                                mcp_service.call_tool(tool_name, tool.server_name, arguments),
                                timeout=tool_timeout
                            )
                            
                            if tool_result['success']:
                                logger.trace(f"   âœ… å·¥å…·è°ƒç”¨æˆåŠŸ")
                                # å·¥å…·ç»“æœå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å¯¹è±¡ï¼Œç»Ÿä¸€å¤„ç†
                                result_data = tool_result['result']
                                if isinstance(result_data, str):
                                    response_content = result_data
                                else:
                                    response_content = json.dumps(result_data)
                            else:
                                logger.warning(f"   âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {tool_result['error']}")
                                response_content = f"é”™è¯¯: {tool_result['error']}"
                            
                        except asyncio.TimeoutError:
                            logger.warning(f"   â° å·¥å…·è°ƒç”¨è¶…æ—¶: {tool_name}")
                            response_content = f"å·¥å…·è°ƒç”¨è¶…æ—¶ ({tool_timeout}ç§’)"
                        except Exception as e:
                            logger.error(f"   âŒ å·¥å…·è°ƒç”¨å¼‚å¸¸: {e}")
                            response_content = f"å·¥å…·è°ƒç”¨å¼‚å¸¸: {str(e)}"
                    else:
                        logger.warning(f"   âŒ æœªæ‰¾åˆ°å·¥å…·: {tool_name}")
                        response_content = f"æœªæ‰¾åˆ°å·¥å…·: {tool_name}"
                    
                    # æ·»åŠ å·¥å…·å“åº”
                    tool_responses.append({
                        'role': 'tool',
                        'content': response_content,
                        'tool_call_id': tool_call_id
                    })
                
                # å°†å·¥å…·å“åº”æ·»åŠ åˆ°æ¶ˆæ¯å†å²
                messages.extend(tool_responses)
                
                # æ›´æ–°è¯·æ±‚æ¶ˆæ¯
                openai_request['messages'] = messages
                tool_call_count += 1
                
                logger.trace(f"ğŸ”„ [TOOL-PROCESS] å·¥å…·è°ƒç”¨å®Œæˆï¼Œå‡†å¤‡ä¸‹ä¸€è½®å¯¹è¯")
            
            # è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°
            logger.warning(f"âš ï¸ [TOOL-PROCESS] è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°: {max_tool_calls}")
            
            # è¿›è¡Œæœ€åä¸€æ¬¡è°ƒç”¨è·å–æœ€ç»ˆç»“æœ
            final_response = await openai_client.process_task(openai_request)
            return final_response
            
        except Exception as e:
            logger.error(f"âŒ [TOOL-PROCESS] å·¥å…·è°ƒç”¨å¤„ç†å¤±è´¥: {e}")
            import traceback
            logger.error(f"   - é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {
                'success': False,
                'error': f'å·¥å…·è°ƒç”¨å¤„ç†å¤±è´¥: {str(e)}'
            }


# å…¨å±€Agentä»»åŠ¡æœåŠ¡å®ä¾‹
agent_task_service = AgentTaskService()