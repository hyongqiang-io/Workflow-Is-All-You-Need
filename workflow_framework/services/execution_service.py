"""
å·¥ä½œæµæ‰§è¡Œå¼•æ“æœåŠ¡
Workflow Execution Engine Service
"""

import uuid
import json
import asyncio
from typing import Optional, Dict, Any, List
from datetime import datetime
import sys
from loguru import logger
logger.remove()
logger.add(sys.stderr,level="WARNING")

from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
from ..repositories.instance.task_instance_repository import TaskInstanceRepository
from ..repositories.workflow.workflow_repository import WorkflowRepository
from ..repositories.node.node_repository import NodeRepository
from ..repositories.processor.processor_repository import ProcessorRepository
from ..repositories.user.user_repository import UserRepository
from ..repositories.agent.agent_repository import AgentRepository
from ..models.instance import (
    WorkflowInstanceCreate, WorkflowInstanceUpdate, WorkflowInstanceStatus,
    TaskInstanceCreate, TaskInstanceUpdate, TaskInstanceStatus, TaskInstanceType,
    WorkflowExecuteRequest
)
from ..models.node import NodeType
from ..utils.helpers import now_utc
from .agent_task_service import agent_task_service
from .workflow_instance_manager import get_instance_manager
from .resource_cleanup_manager import ResourceCleanupManager
from .node_dependency_tracker import NodeDependencyTracker
# ä¿æŒå‘ä¸‹å…¼å®¹
from .workflow_context_manager import WorkflowContextManager
from .node_dependency_manager import NodeDependencyManager


def _json_serializer(obj):
    """è‡ªå®šä¹‰JSONåºåˆ—åŒ–å‡½æ•°ï¼Œå¤„ç†datetimeå¯¹è±¡"""
    if isinstance(obj, datetime):
        return obj.isoformat()
    raise TypeError(f"Object of type {obj.__class__.__name__} is not JSON serializable")


class ExecutionEngine:
    """å·¥ä½œæµæ‰§è¡Œå¼•æ“ - é‡æ„ç‰ˆæœ¬"""
    
    def __init__(self):
        # æ•°æ®è®¿é—®å±‚
        self.workflow_instance_repo = WorkflowInstanceRepository()
        self.task_instance_repo = TaskInstanceRepository()
        self.workflow_repo = WorkflowRepository()
        self.node_repo = NodeRepository()
        self.processor_repo = ProcessorRepository()
        self.user_repo = UserRepository()
        self.agent_repo = AgentRepository()
        
        # æ‰§è¡Œé˜Ÿåˆ—å’ŒçŠ¶æ€è·Ÿè¸ª
        self.execution_queue = asyncio.Queue()
        self.is_running = False
        
        # ä»»åŠ¡å®Œæˆå›è°ƒæ˜ å°„
        self.task_callbacks = {}
        
        # æ–°æ¶æ„ç»„ä»¶
        self.instance_manager = None  # å°†åœ¨start_engineä¸­åˆå§‹åŒ–
        self.resource_cleanup_manager = ResourceCleanupManager()
        self.dependency_tracker = NodeDependencyTracker()
        
        # ç›‘å¬å™¨è·Ÿè¸ªï¼Œé˜²æ­¢é‡å¤å¯åŠ¨
        self.active_monitors = set()
        
        # å‘ä¸‹å…¼å®¹ - ä¿ç•™æ—§æ¥å£
        self.context_manager = None  # å…¼å®¹æ€§å±æ€§
        self.dependency_manager = None  # å…¼å®¹æ€§å±æ€§
        self.running_instances = {}  # å…¼å®¹æ€§å±æ€§
    
    async def start_engine(self):
        """å¯åŠ¨æ‰§è¡Œå¼•æ“"""
        if self.is_running:
            logger.warning("æ‰§è¡Œå¼•æ“å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.is_running = True
        logger.trace("å·¥ä½œæµæ‰§è¡Œå¼•æ“å¯åŠ¨")
        
        # åˆå§‹åŒ–æ–°æ¶æ„ç»„ä»¶
        self.instance_manager = await get_instance_manager()
        await self.resource_cleanup_manager.start_manager()
        logger.trace("æ–°æ¶æ„ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
        
        # å‘ä¸‹å…¼å®¹ - åˆå§‹åŒ–æ—§ç»„ä»¶
        if self.context_manager is None:
            from .workflow_context_manager import WorkflowContextManager
            self.context_manager = WorkflowContextManager()
        
        # åˆå§‹åŒ–ä¾èµ–ç®¡ç†å™¨
        self.dependency_manager = NodeDependencyManager("node_instance")
        
        # æ³¨å†Œä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„å›è°ƒ
        self.context_manager.register_completion_callback(self._on_nodes_ready_to_execute)
        
        # æ³¨å†Œä¸ºAgentTaskServiceçš„å›è°ƒç›‘å¬å™¨
        agent_task_service.register_completion_callback(self)
        logger.trace("å·²æ³¨å†Œå›è°ƒç›‘å¬å™¨")
        
        # å¯åŠ¨ä»»åŠ¡å¤„ç†åç¨‹
        asyncio.create_task(self._process_execution_queue())
        asyncio.create_task(self._monitor_running_instances())
    
    async def stop_engine(self):
        """åœæ­¢æ‰§è¡Œå¼•æ“"""
        self.is_running = False
        
        # åœæ­¢æ–°æ¶æ„ç»„ä»¶
        if self.resource_cleanup_manager:
            await self.resource_cleanup_manager.stop_manager()
        
        # æ¸…ç†å®ä¾‹ç®¡ç†å™¨
        if self.instance_manager:
            from .workflow_instance_manager import cleanup_instance_manager
            await cleanup_instance_manager()
        
        logger.trace("å·¥ä½œæµæ‰§è¡Œå¼•æ“åœæ­¢")
    
    async def execute_workflow(self, request: WorkflowExecuteRequest, 
                             executor_id: uuid.UUID) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥ä½œæµ"""
        try:
            logger.trace(f"å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {request.workflow_base_id}, æ‰§è¡Œè€…: {executor_id}")
            # 1. éªŒè¯å·¥ä½œæµæ˜¯å¦å­˜åœ¨ä¸”å¯æ‰§è¡Œ
            logger.trace(f"æ­¥éª¤1: æŸ¥è¯¢å·¥ä½œæµ {request.workflow_base_id}")
            workflow = await self.workflow_repo.get_workflow_by_base_id(request.workflow_base_id)
            if not workflow:
                logger.error(f"å·¥ä½œæµä¸å­˜åœ¨: {request.workflow_base_id}")
                raise ValueError("å·¥ä½œæµä¸å­˜åœ¨")
            
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å…·ä½“çš„workflow_idè€Œä¸æ˜¯base_id
            workflow_id = workflow['workflow_id']
            logger.trace(f"âœ… å·¥ä½œæµæŸ¥è¯¢æˆåŠŸ: {workflow.get('name', 'Unknown')} (ç‰ˆæœ¬ID: {workflow_id})")
            
            # 1.5. æ£€æŸ¥æ˜¯å¦å·²æœ‰æ­£åœ¨è¿è¡Œçš„å®ä¾‹
            logger.trace(f"æ­¥éª¤1.5: æ£€æŸ¥æ˜¯å¦å·²æœ‰æ­£åœ¨è¿è¡Œçš„å·¥ä½œæµå®ä¾‹")
            existing_instances = await self._check_running_instances(request.workflow_base_id, executor_id)
            if existing_instances:
                logger.trace(f"âœ… å‘ç°å·²æœ‰æ­£åœ¨è¿è¡Œçš„å®ä¾‹: {len(existing_instances)} ä¸ª")
                latest_instance = existing_instances[0]  # è·å–æœ€æ–°çš„å®ä¾‹
                logger.trace(f"è¿”å›ç°æœ‰å®ä¾‹: {latest_instance['workflow_instance_name']} (ID: {latest_instance['workflow_instance_id']})")
                return {
                    'instance_id': latest_instance['workflow_instance_id'],
                    'status': latest_instance['status'],
                    'message': 'å·¥ä½œæµå·²åœ¨è¿è¡Œä¸­ï¼Œè¿”å›ç°æœ‰å®ä¾‹'
                }
            
            # 2. åˆ›å»ºå·¥ä½œæµå®ä¾‹
            logger.trace(f"æ­¥éª¤2: åˆ›å»ºå·¥ä½œæµå®ä¾‹ '{request.instance_name}'")
            instance_data = WorkflowInstanceCreate(
                workflow_base_id=request.workflow_base_id,
                executor_id=executor_id,
                instance_name=request.instance_name,
                input_data=request.input_data,
                context_data=request.context_data
            )
            
            instance = await self.workflow_instance_repo.create_instance(instance_data)
            if not instance:
                logger.error("åˆ›å»ºå·¥ä½œæµå®ä¾‹å¤±è´¥")
                raise RuntimeError("åˆ›å»ºå·¥ä½œæµå®ä¾‹å¤±è´¥")
            
            instance_id = instance['workflow_instance_id']
            logger.trace(f"âœ… å·¥ä½œæµå®ä¾‹åˆ›å»ºæˆåŠŸ: {request.instance_name} (ID: {instance_id})")
            
            # 3. è·å–å·¥ä½œæµçš„æ‰€æœ‰èŠ‚ç‚¹ï¼ˆä½¿ç”¨å…·ä½“ç‰ˆæœ¬IDï¼‰
            logger.trace(f"æ­¥éª¤3: æŸ¥è¯¢å·¥ä½œæµç‰ˆæœ¬ {workflow_id} çš„æ‰€æœ‰èŠ‚ç‚¹")
            nodes = await self._get_workflow_nodes_by_version_id(workflow_id)
            
            if not nodes:
                logger.error(f"å·¥ä½œæµæ²¡æœ‰èŠ‚ç‚¹: {workflow_id}")
                raise ValueError("å·¥ä½œæµæ²¡æœ‰èŠ‚ç‚¹")
            
            logger.trace(f"âœ… æ‰¾åˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹:")
            for i, node in enumerate(nodes, 1):
                logger.trace(f"   èŠ‚ç‚¹{i}: {node['name']} (ç±»å‹: {node['type']}, å…·ä½“ID: {node['node_id']})")
            
            # 4. è·å–èŠ‚ç‚¹è¿æ¥å…³ç³»
            logger.trace(f"æ­¥éª¤4: æŸ¥è¯¢å·¥ä½œæµèŠ‚ç‚¹è¿æ¥å…³ç³»")
            connections = []
            try:
                if hasattr(self.node_repo, 'get_workflow_connections'):
                    connections = await self.node_repo.get_workflow_connections(request.workflow_base_id)
                    logger.trace(f"âœ… æ‰¾åˆ° {len(connections)} ä¸ªè¿æ¥:")
                    for i, conn in enumerate(connections, 1):
                        logger.trace(f"   è¿æ¥{i}: {conn.get('from_node_name', 'Unknown')} -> {conn.get('to_node_name', 'Unknown')}")
                else:
                    logger.warning("èŠ‚ç‚¹ä»“åº“ä¸æ”¯æŒè·å–è¿æ¥å…³ç³»")
            except Exception as e:
                logger.warning(f"è·å–å·¥ä½œæµè¿æ¥å¤±è´¥: {e}")
                connections = []
            
            # 5. åˆå§‹åŒ–å·¥ä½œæµä¸Šä¸‹æ–‡
            logger.trace(f"æ­¥éª¤5: åˆå§‹åŒ–å·¥ä½œæµä¸Šä¸‹æ–‡")
            try:
                await self.context_manager.initialize_workflow_context(instance_id)
                logger.trace(f"âœ… å·¥ä½œæµä¸Šä¸‹æ–‡åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"å·¥ä½œæµä¸Šä¸‹æ–‡åˆå§‹åŒ–å¤±è´¥: {e}")
                raise
            
            # 6. åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å’Œæ³¨å†Œä¾èµ–å…³ç³»ï¼ˆä¸åˆ›å»ºä»»åŠ¡å®ä¾‹ï¼‰
            logger.trace(f"æ­¥éª¤6: åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å’Œä¾èµ–å…³ç³»")
            try:
                await self._create_node_instances_with_dependencies(instance_id, workflow_id, nodes)
                logger.trace(f"âœ… èŠ‚ç‚¹å®ä¾‹å’Œä¾èµ–å…³ç³»åˆ›å»ºå®Œæˆ")
            except Exception as e:
                logger.error(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å’Œä¾èµ–å…³ç³»å¤±è´¥: {e}")
                raise
            
            # 7. å¯åŠ¨æ‰§è¡Œï¼ˆåªå¯åŠ¨STARTèŠ‚ç‚¹ï¼‰
            logger.trace(f"æ­¥éª¤7: å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ")
            try:
                await self._start_workflow_execution_with_dependencies(instance_id, workflow_id)
                logger.trace(f"âœ… å·¥ä½œæµæ‰§è¡Œå¯åŠ¨å®Œæˆ")
                
                # è¾“å‡ºæ‰§è¡Œå¯åŠ¨çš„å®Œæ•´çŠ¶æ€
                print(f"\nğŸš€ ã€å·¥ä½œæµå¯åŠ¨æˆåŠŸã€‘")
                print(f"å·¥ä½œæµ: {workflow.get('name', 'Unknown')}")
                print(f"å®ä¾‹åç§°: {request.instance_name}")
                print(f"å®ä¾‹ID: {instance_id} - æ–°æ¶æ„")
                print(f"æ‰§è¡Œè€…: {executor_id}")
                print(f"èŠ‚ç‚¹æ•°é‡: {len(nodes)}")
                print(f"çŠ¶æ€: RUNNING")
                print(f"æ¶æ„: æ–°ä¸€ä»£ä¸Šä¸‹æ–‡ç®¡ç†")
                print(f"å¯åŠ¨æ—¶é—´: {now_utc().strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"è¯·å…³æ³¨åç»­çš„ä»»åŠ¡åˆ†é…æ—¥å¿—...")
                print("=" * 60)
                
                # ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œæ‘˜è¦ï¼ˆå»¶è¿Ÿä¸€ç‚¹ï¼Œè®©ä»»åŠ¡åˆ›å»ºå®Œæˆï¼‰
                try:
                    import asyncio
                    await asyncio.sleep(1)  # ç­‰å¾…1ç§’è®©ä»»åŠ¡åˆ›å»ºå®Œæˆ
                    await self._log_workflow_execution_summary(instance_id)
                except Exception as e:
                    logger.warning(f"ç”Ÿæˆæ‰§è¡Œæ‘˜è¦å¤±è´¥: {e}")
                
            except Exception as e:
                logger.error(f"å¯åŠ¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
                raise
            
            return {
                'instance_id': instance_id,
                'status': WorkflowInstanceStatus.RUNNING.value,
                'message': 'å·¥ä½œæµå¼€å§‹æ‰§è¡Œ'
            }
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œå·¥ä½œæµå¤±è´¥: {e}")
            raise
    
    async def _get_workflow_nodes_by_version_id(self, workflow_id: uuid.UUID) -> List[Dict[str, Any]]:
        """é€šè¿‡å·¥ä½œæµç‰ˆæœ¬IDè·å–æ‰€æœ‰èŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰"""
        try:
            query = """
                SELECT 
                    n.*,
                    np.processor_id
                FROM "node" n
                LEFT JOIN node_processor np ON np.node_id = n.node_id
                WHERE n.workflow_id = $1 
                AND n.is_deleted = false
                ORDER BY n.created_at ASC
            """
            results = await self.node_repo.db.fetch_all(query, workflow_id)
            logger.trace(f"âœ… é€šè¿‡ç‰ˆæœ¬ID {workflow_id} è·å–åˆ° {len(results)} ä¸ªèŠ‚ç‚¹")
            return results
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµèŠ‚ç‚¹åˆ—è¡¨å¤±è´¥: {e}")
            raise
    
    async def _check_running_instances(self, workflow_base_id: uuid.UUID, executor_id: uuid.UUID) -> List[Dict]:
        """æ£€æŸ¥æ˜¯å¦å·²æœ‰æ­£åœ¨è¿è¡Œçš„å·¥ä½œæµå®ä¾‹"""
        try:
            from ..models.instance import WorkflowInstanceStatus
            
            # æŸ¥è¯¢æ­£åœ¨è¿è¡Œçš„å·¥ä½œæµå®ä¾‹
            query = """
            SELECT wi.*
            FROM workflow_instance wi
            WHERE wi.workflow_base_id = $1
            AND wi.executor_id = $2
            AND wi.status IN ('RUNNING', 'PAUSED')
            AND wi.is_deleted = FALSE
            ORDER BY wi.created_at DESC
            """
            
            running_instances = await self.workflow_instance_repo.db.fetch_all(
                query, workflow_base_id, executor_id
            )
            
            logger.trace(f"æ‰¾åˆ° {len(running_instances)} ä¸ªæ­£åœ¨è¿è¡Œçš„å·¥ä½œæµå®ä¾‹")
            return running_instances
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥è¿è¡Œå®ä¾‹å¤±è´¥: {e}")
            return []
    
    async def _create_node_instances(self, workflow_instance_id: uuid.UUID, nodes: List[Dict[str, Any]]):
        """åˆ›å»ºèŠ‚ç‚¹å®ä¾‹"""
        try:
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceCreate, NodeInstanceStatus
            
            node_instance_repo = NodeInstanceRepository()
            
            for node in nodes:
                # 1. å…ˆåˆ›å»ºèŠ‚ç‚¹å®ä¾‹
                node_instance_data = NodeInstanceCreate(
                    workflow_instance_id=workflow_instance_id,
                    node_id=node['node_id'],
                    node_base_id=node['node_base_id'],  # æ·»åŠ ç¼ºå¤±çš„node_base_id
                    node_instance_name=f"{node['name']}_instance",
                    task_description=node.get('task_description', ''),
                    status=NodeInstanceStatus.PENDING,
                    input_data={},
                    output_data={},
                    error_message=None,
                    retry_count=0
                )
                
                node_instance = await node_instance_repo.create_node_instance(node_instance_data)
                if not node_instance:
                    logger.error(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¤±è´¥: {node['name']}")
                    continue
                
                node_instance_id = node_instance['node_instance_id']
                logger.trace(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹: {node['name']} (ID: {node_instance_id})")
                
                # 2. ä¸ºå¤„ç†å™¨èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹
                if node['type'] == NodeType.PROCESSOR.value:
                    # è·å–èŠ‚ç‚¹çš„å¤„ç†å™¨ï¼ˆä¿®å¤ï¼šä½¿ç”¨node_idï¼‰
                    processors = await self._get_node_processors(node['node_id'])
                    
                    for processor in processors:
                        # æ ¹æ®å¤„ç†å™¨ç±»å‹ç¡®å®šä»»åŠ¡ç±»å‹å’Œåˆ†é…
                        processor_type = processor.get('processor_type', processor.get('type', 'HUMAN'))
                        task_type = self._determine_task_type(processor_type)
                        assigned_user_id = processor.get('user_id')
                        assigned_agent_id = processor.get('agent_id')
                        
                        # åˆ›å»ºä»»åŠ¡å®ä¾‹
                        task_title = node['name']
                        task_description = node.get('task_description') or node.get('description') or f"æ‰§è¡ŒèŠ‚ç‚¹ {node['name']} çš„ä»»åŠ¡"
                        
                        # æ”¶é›†ä»»åŠ¡ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆä½¿ç”¨WorkflowContextManagerï¼‰
                        context_data = await self.context_manager.get_task_context_data(workflow_instance_id, node_instance_id)
                        
                        # å°†ä¸Šä¸‹æ–‡æ•°æ®è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
                        context_text = json.dumps(context_data, ensure_ascii=False, indent=2, default=_json_serializer) if context_data else ""
                        input_text = json.dumps(node.get('input_data', {}), ensure_ascii=False, indent=2, default=_json_serializer)
                        
                        task_data = TaskInstanceCreate(
                            node_instance_id=node_instance_id,  # ä½¿ç”¨çœŸå®çš„èŠ‚ç‚¹å®ä¾‹ID
                            workflow_instance_id=workflow_instance_id,
                            processor_id=processor['processor_id'],
                            task_type=task_type,
                            task_title=task_title,
                            task_description=task_description,
                            input_data=input_text,
                            context_data=context_text,
                            assigned_user_id=assigned_user_id,
                            assigned_agent_id=assigned_agent_id,
                            estimated_duration=30
                        )
                        
                        task = await self.task_instance_repo.create_task(task_data)
                        if task:
                            logger.trace(f"åˆ›å»ºä»»åŠ¡å®ä¾‹: {task['task_title']} (ID: {task['task_instance_id']})")
                        
        except Exception as e:
            logger.error(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¤±è´¥: {e}")
            raise
    
    async def _get_node_processors(self, node_id: uuid.UUID):
        """è·å–èŠ‚ç‚¹çš„å¤„ç†å™¨åˆ—è¡¨ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼šä½¿ç”¨å…·ä½“node_idï¼‰"""
        try:
            query = """
                SELECT np.*, p.name as processor_name, p.type as processor_type,
                       u.username, a.agent_name, p.user_id, p.agent_id
                FROM node_processor np
                JOIN processor p ON p.processor_id = np.processor_id AND p.is_deleted = FALSE
                LEFT JOIN "user" u ON u.user_id = p.user_id AND u.is_deleted = FALSE
                LEFT JOIN agent a ON a.agent_id = p.agent_id AND a.is_deleted = FALSE
                WHERE np.node_id = $1
                ORDER BY np.created_at ASC
            """
            results = await self.processor_repo.db.fetch_all(query, node_id)
            return results
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹å¤„ç†å™¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    async def _get_next_nodes(self, node_id: uuid.UUID):
        """è·å–èŠ‚ç‚¹çš„ä¸‹æ¸¸èŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼šä½¿ç”¨å…·ä½“node_idï¼‰"""
        try:
            query = """
                SELECT tn.node_id as to_node_id
                FROM node_connection nc
                JOIN node tn ON tn.node_id = nc.to_node_id
                WHERE nc.from_node_id = $1
                ORDER BY nc.created_at ASC
            """
            results = await self.node_repo.db.fetch_all(query, node_id)
            return [result['to_node_id'] for result in results]
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            return []
    
    def _determine_task_type(self, processor_type: str) -> TaskInstanceType:
        """æ ¹æ®å¤„ç†å™¨ç±»å‹ç¡®å®šä»»åŠ¡ç±»å‹"""
        processor_type_upper = processor_type.upper() if processor_type else ""
        
        if processor_type_upper == "HUMAN":
            return TaskInstanceType.HUMAN
        elif processor_type_upper == "AGENT":
            return TaskInstanceType.AGENT
        elif processor_type_upper == "MIX" or processor_type_upper == "MIXED":
            return TaskInstanceType.MIXED
        else:
            # è®°å½•è°ƒè¯•ä¿¡æ¯
            logger.warning(f"æœªçŸ¥çš„å¤„ç†å™¨ç±»å‹: '{processor_type}' (è½¬æ¢å: '{processor_type_upper}')ï¼Œé»˜è®¤ä¸ºäººå·¥ä»»åŠ¡")
            return TaskInstanceType.HUMAN  # é»˜è®¤ä¸ºäººå·¥ä»»åŠ¡
    
    def _determine_task_priority(self, task_type: TaskInstanceType, node_data: Dict[str, Any]) -> int:
        """ç¡®å®šä»»åŠ¡ä¼˜å…ˆçº§ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™æ–¹æ³•é¿å…è°ƒç”¨é”™è¯¯ï¼‰"""
        try:
            # ä¼˜å…ˆçº§å­—æ®µå·²åºŸå¼ƒï¼Œè¿”å›é»˜è®¤å€¼
            return 1
                
        except Exception as e:
            logger.warning(f"ç¡®å®šä»»åŠ¡ä¼˜å…ˆçº§å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            return 1
    
    def _determine_task_duration(self, task_type: TaskInstanceType, node_data: Dict[str, Any]) -> int:
        """æ ¹æ®ä»»åŠ¡ç±»å‹å’ŒèŠ‚ç‚¹é…ç½®ç¡®å®šé¢„ä¼°æ‰§è¡Œæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"""
        try:
            # ä»èŠ‚ç‚¹æ•°æ®ä¸­è·å–é¢„ä¼°æ—¶é—´é…ç½®
            node_duration = node_data.get('estimated_duration', None)
            if node_duration is not None:
                return max(5, min(480, int(node_duration)))  # é™åˆ¶åœ¨5åˆ†é’Ÿåˆ°8å°æ—¶ä¹‹é—´
            
            # æ ¹æ®ä»»åŠ¡ç±»å‹è®¾ç½®é»˜è®¤é¢„ä¼°æ—¶é—´
            if task_type == TaskInstanceType.HUMAN:
                return 60  # äººå·¥ä»»åŠ¡é»˜è®¤1å°æ—¶
            elif task_type == TaskInstanceType.AGENT:
                return 15  # Agentä»»åŠ¡é»˜è®¤15åˆ†é’Ÿ
            elif task_type == TaskInstanceType.MIXED:
                return 45  # æ··åˆä»»åŠ¡é»˜è®¤45åˆ†é’Ÿ
            else:
                return 30  # é»˜è®¤30åˆ†é’Ÿ
                
        except Exception as e:
            logger.warning(f"ç¡®å®šä»»åŠ¡é¢„ä¼°æ—¶é—´å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            return 30
    
    async def _start_workflow_execution(self, instance_id: uuid.UUID, workflow_id: uuid.UUID):
        """å¯åŠ¨å·¥ä½œæµæ‰§è¡Œï¼ˆä¿®å¤ç‰ˆæœ¬ï¼šä½¿ç”¨å…·ä½“ç‰ˆæœ¬IDï¼‰"""
        try:
            # æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.RUNNING)
            await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            # æŸ¥æ‰¾å¼€å§‹èŠ‚ç‚¹ï¼ˆä½¿ç”¨å…·ä½“ç‰ˆæœ¬IDï¼‰
            nodes = await self._get_workflow_nodes_by_version_id(workflow_id)
            start_nodes = [node for node in nodes if node['type'] == NodeType.START.value]
            
            if not start_nodes:
                raise ValueError("å·¥ä½œæµæ²¡æœ‰å¼€å§‹èŠ‚ç‚¹")
            
            # å°†å·¥ä½œæµå®ä¾‹åŠ å…¥æ‰§è¡Œé˜Ÿåˆ—ï¼ˆä½¿ç”¨å…·ä½“node_idï¼‰
            execution_item = {
                'instance_id': instance_id,
                'workflow_id': workflow_id,
                'current_nodes': [node['node_id'] for node in start_nodes],
                'context_data': {}
            }
            
            await self.execution_queue.put(execution_item)
            self.running_instances[instance_id] = execution_item
            
            logger.trace(f"å·¥ä½œæµå®ä¾‹ {instance_id} å¼€å§‹æ‰§è¡Œ")
            
        except Exception as e:
            logger.error(f"å¯åŠ¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    async def _process_execution_queue(self):
        """å¤„ç†æ‰§è¡Œé˜Ÿåˆ—"""
        while self.is_running:
            try:
                # ä»é˜Ÿåˆ—è·å–æ‰§è¡Œé¡¹ç›®
                execution_item = await asyncio.wait_for(
                    self.execution_queue.get(), timeout=1.0
                )
                
                # å¤„ç†æ‰§è¡Œé¡¹ç›®
                await self._process_workflow_step(execution_item)
                
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"å¤„ç†æ‰§è¡Œé˜Ÿåˆ—å¤±è´¥: {e}")
                await asyncio.sleep(1)
    
    async def _process_workflow_step(self, execution_item: Dict[str, Any]):
        """å¤„ç†å·¥ä½œæµæ­¥éª¤"""
        try:
            instance_id = execution_item['instance_id']
            workflow_id = execution_item['workflow_id']
            current_nodes = execution_item['current_nodes']
            
            logger.trace(f"å¤„ç†å·¥ä½œæµå®ä¾‹ {instance_id} çš„èŠ‚ç‚¹: {current_nodes}")
            
            # å¤„ç†å½“å‰èŠ‚ç‚¹
            next_nodes = []
            for node_id in current_nodes:
                node_result = await self._process_node(instance_id, workflow_id, node_id)
                if node_result.get('next_nodes'):
                    next_nodes.extend(node_result['next_nodes'])
            
            # å¦‚æœæœ‰ä¸‹ä¸€æ­¥èŠ‚ç‚¹ï¼Œç»§ç»­æ‰§è¡Œ
            if next_nodes:
                execution_item['current_nodes'] = next_nodes
                await self.execution_queue.put(execution_item)
            else:
                # å·¥ä½œæµå®Œæˆ
                await self._complete_workflow(instance_id)
                
        except Exception as e:
            logger.error(f"å¤„ç†å·¥ä½œæµæ­¥éª¤å¤±è´¥: {e}")
            await self._fail_workflow(execution_item['instance_id'], str(e))
    
    async def _process_node(self, instance_id: uuid.UUID, workflow_id: uuid.UUID, 
                          node_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªèŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼šä½¿ç”¨å…·ä½“çš„node_idï¼‰"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šç›´æ¥é€šè¿‡node_idè·å–èŠ‚ç‚¹ä¿¡æ¯
            node = await self.node_repo.get_node_by_id(node_id)
            if not node:
                raise ValueError(f"èŠ‚ç‚¹ {node_id} ä¸å­˜åœ¨")
            
            node_type = node['type']
            logger.trace(f"å¤„ç†èŠ‚ç‚¹: {node['name']} (ç±»å‹: {node_type}, ID: {node_id})")
            
            if node_type == NodeType.START.value:
                # å¼€å§‹èŠ‚ç‚¹ç›´æ¥å®Œæˆ
                return await self._handle_start_node(instance_id, workflow_id, node_id)
            elif node_type == NodeType.END.value:
                # ç»“æŸèŠ‚ç‚¹
                return await self._handle_end_node(instance_id, workflow_id, node_id)
            elif node_type == NodeType.PROCESSOR.value:
                # å¤„ç†å™¨èŠ‚ç‚¹
                return await self._handle_processor_node(instance_id, workflow_id, node_id)
            else:
                logger.warning(f"æœªçŸ¥èŠ‚ç‚¹ç±»å‹: {node_type}")
                return {'next_nodes': []}
                
        except Exception as e:
            logger.error(f"å¤„ç†èŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _handle_start_node(self, instance_id: uuid.UUID, workflow_id: uuid.UUID, 
                                node_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†å¼€å§‹èŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰"""
        try:
            # è·å–ä¸‹æ¸¸èŠ‚ç‚¹
            next_nodes = await self._get_next_nodes(node_id)
            
            logger.trace(f"å¼€å§‹èŠ‚ç‚¹å¤„ç†å®Œæˆï¼Œä¸‹ä¸€æ­¥èŠ‚ç‚¹: {next_nodes}")
            return {'next_nodes': next_nodes}
            
        except Exception as e:
            logger.error(f"å¤„ç†å¼€å§‹èŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _handle_end_node(self, instance_id: uuid.UUID, workflow_id: uuid.UUID, 
                              node_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†ç»“æŸèŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰"""
        try:
            logger.trace(f"åˆ°è¾¾ç»“æŸèŠ‚ç‚¹ï¼Œå·¥ä½œæµå®ä¾‹ {instance_id} å³å°†å®Œæˆ")
            return {'next_nodes': []}  # æ²¡æœ‰ä¸‹ä¸€æ­¥èŠ‚ç‚¹
            
        except Exception as e:
            logger.error(f"å¤„ç†ç»“æŸèŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _handle_processor_node(self, instance_id: uuid.UUID, workflow_id: uuid.UUID, 
                                   node_id: uuid.UUID) -> Dict[str, Any]:
        """å¤„ç†å¤„ç†å™¨èŠ‚ç‚¹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šé€šè¿‡node_idæŸ¥æ‰¾ä»»åŠ¡å®ä¾‹
            tasks = await self.task_instance_repo.get_tasks_by_workflow_instance(instance_id)
            node_tasks = [task for task in tasks if task.get('node_instance', {}).get('node_id') == node_id]
            
            if not node_tasks:
                logger.warning(f"èŠ‚ç‚¹ {node_id} æ²¡æœ‰ä»»åŠ¡å®ä¾‹")
                return {'next_nodes': []}
            
            # å¯åŠ¨ä»»åŠ¡æ‰§è¡Œ
            for task in node_tasks:
                await self._execute_task(task)
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥å¼‚æ­¥ç­‰å¾…ï¼‰
            await asyncio.sleep(1)  # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œæ—¶é—´
            
            # è·å–ä¸‹æ¸¸èŠ‚ç‚¹
            next_nodes = await self._get_next_nodes(node_id)
            
            logger.trace(f"å¤„ç†å™¨èŠ‚ç‚¹å¤„ç†å®Œæˆï¼Œä¸‹ä¸€æ­¥èŠ‚ç‚¹: {next_nodes}")
            return {'next_nodes': next_nodes}
            
        except Exception as e:
            logger.error(f"å¤„ç†å¤„ç†å™¨èŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _execute_task(self, task: Dict[str, Any]):
        """æ‰§è¡Œå•ä¸ªä»»åŠ¡"""
        try:
            task_id = task['task_instance_id']
            task_type = task['task_type']
            
            logger.trace(f"æ‰§è¡Œä»»åŠ¡: {task['task_title']} (ç±»å‹: {task_type})")
            
            if task_type == TaskInstanceType.HUMAN.value:
                # äººå·¥ä»»åŠ¡ï¼šæ›´æ–°çŠ¶æ€ä¸ºå·²åˆ†é…ï¼Œç­‰å¾…äººå·¥å¤„ç†
                logger.trace(f"ğŸ‘¤ å¤„ç†äººå·¥ä»»åŠ¡: {task['task_title']}")
                logger.trace(f"   - ä»»åŠ¡ID: {task_id}")
                logger.trace(f"   - åˆ†é…ç›®æ ‡ç”¨æˆ·: {task.get('assigned_user_id')}")
                
                # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æœ‰åˆ†é…çš„ç”¨æˆ·
                assigned_user_id = task.get('assigned_user_id')
                if not assigned_user_id:
                    logger.warning(f"âš ï¸  äººå·¥ä»»åŠ¡æ²¡æœ‰åˆ†é…ç”¨æˆ·ï¼Œä»»åŠ¡å°†ä¿æŒPENDINGçŠ¶æ€")
                    logger.warning(f"   - ä»»åŠ¡ID: {task_id}")
                    logger.warning(f"   - ä»»åŠ¡æ ‡é¢˜: {task['task_title']}")
                    logger.warning(f"   - å»ºè®®: è¯·ä¸ºè¯¥ä»»åŠ¡çš„å¤„ç†å™¨é…ç½®ç”¨æˆ·")
                    return
                
                # ä»»åŠ¡åˆ›å»ºæ—¶å·²ç»è®¾ç½®äº†æ­£ç¡®çš„çŠ¶æ€ï¼Œè¿™é‡Œä¸éœ€è¦å†æ›´æ–°
                # ï¼ˆä»»åŠ¡åˆ›å»ºæ—¶å¦‚æœæœ‰assigned_user_idï¼ŒçŠ¶æ€å°±æ˜¯ASSIGNEDï¼‰
                logger.trace(f"   âœ… ä»»åŠ¡å·²å¤„äºæ­£ç¡®çŠ¶æ€ï¼Œæ— éœ€æ›´æ–°")
                
                # è·å–ä»»åŠ¡è¯¦ç»†ä¿¡æ¯ç”¨äºé€šçŸ¥
                task_title = task.get('task_title', 'æœªå‘½åä»»åŠ¡')
                workflow_name = task.get('workflow_name', 'æœªå‘½åå·¥ä½œæµ')
                estimated_duration = task.get('estimated_duration', 30)
                
                logger.trace(f"ğŸ“‹ äººå·¥ä»»åŠ¡åˆ†é…è¯¦æƒ…:")
                logger.trace(f"   - ä»»åŠ¡æ ‡é¢˜: {task_title}")
                logger.trace(f"   - å·¥ä½œæµ: {workflow_name}")
                logger.trace(f"   - åˆ†é…ç»™ç”¨æˆ·: {assigned_user_id}")
                logger.trace(f"   - é¢„ä¼°æ—¶é•¿: {estimated_duration}åˆ†é’Ÿ")
                logger.trace(f"   - ä»»åŠ¡æè¿°: {task.get('task_description', 'æ— æè¿°')[:100]}...")
                
                # å®æ—¶é€šçŸ¥ç”¨æˆ·æœ‰æ–°ä»»åŠ¡ - é‡è¦æ”¹è¿›ï¼
                try:
                    await self._notify_user_new_task(assigned_user_id, task_id, task_title)
                    logger.trace(f"   ğŸ“¬ ç”¨æˆ·é€šçŸ¥å·²å‘é€")
                except Exception as e:
                    logger.error(f"   âŒ å‘é€ç”¨æˆ·é€šçŸ¥å¤±è´¥: {e}")
                
                # è®°å½•ä»»åŠ¡åˆ†é…äº‹ä»¶ï¼ˆç”¨äºåç»­åˆ†æå’Œç›‘æ§ï¼‰
                await self._log_task_assignment_event(task_id, assigned_user_id, task_title)
                
                # è®°å½•åˆ°æ§åˆ¶å°ç”¨äºè°ƒè¯•
                print(f"\nğŸ¯ ã€ä»»åŠ¡æ¨é€ã€‘ æ–°çš„äººå·¥ä»»åŠ¡å·²åˆ†é…:")
                print(f"   ç”¨æˆ·ID: {assigned_user_id}")
                print(f"   ä»»åŠ¡ID: {task_id}")
                print(f"   ä»»åŠ¡æ ‡é¢˜: {task_title}")
                print(f"   å·¥ä½œæµ: {workflow_name}")
                print(f"   æ—¶é—´: {now_utc().strftime('%Y-%m-%d %H:%M:%S')}")
                print("=" * 60)
                
            elif task_type == TaskInstanceType.AGENT.value:
                # Agentä»»åŠ¡ï¼šè°ƒç”¨AIå¤„ç†
                await self._process_agent_task(task)
                
            elif task_type == TaskInstanceType.MIXED.value:
                # æ··åˆä»»åŠ¡ï¼šåŒæ—¶æäº¤ç»™äººå·¥å’ŒAgentå¤„ç†
                await self._process_mixed_task(task)
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _process_agent_task(self, task: Dict[str, Any]):
        """å¤„ç†Agentä»»åŠ¡ - é›†æˆAgentTaskService"""
        try:
            task_id = task['task_instance_id']
            logger.trace(f"é›†æˆAgentä»»åŠ¡æœåŠ¡å¤„ç†ä»»åŠ¡: {task['task_title']}")
            
            # æ³¨å†Œä»»åŠ¡å®Œæˆå›è°ƒ
            callback_future = asyncio.Future()
            self.task_callbacks[task_id] = callback_future
            
            # æäº¤ä»»åŠ¡åˆ°AgentTaskServiceè¿›è¡Œå¤„ç†
            result = await agent_task_service.submit_task_to_agent(task_id)
            
            if result['status'] == 'queued':
                logger.trace(f"Agentä»»åŠ¡ {task_id} å·²æäº¤åˆ°æœåŠ¡é˜Ÿåˆ—")
                
                # ç­‰å¾…ä»»åŠ¡å¤„ç†å®Œæˆï¼ˆé€šè¿‡å›è°ƒæœºåˆ¶ï¼‰
                try:
                    await asyncio.wait_for(callback_future, timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                    logger.trace(f"Agentä»»åŠ¡ {task_id} é€šè¿‡å›è°ƒæœºåˆ¶å®Œæˆ")
                except asyncio.TimeoutError:
                    logger.error(f"Agentä»»åŠ¡ {task_id} å¤„ç†è¶…æ—¶")
                    raise TimeoutError("Agentä»»åŠ¡å¤„ç†è¶…æ—¶")
                finally:
                    # æ¸…ç†å›è°ƒ
                    self.task_callbacks.pop(task_id, None)
                
            else:
                logger.warning(f"Agentä»»åŠ¡æäº¤å¤±è´¥: {result}")
                # æ¸…ç†å›è°ƒ
                self.task_callbacks.pop(task_id, None)
                raise RuntimeError(f"Agentä»»åŠ¡æäº¤å¤±è´¥: {result}")
            
        except Exception as e:
            logger.error(f"å¤„ç†Agentä»»åŠ¡å¤±è´¥: {e}")
            # æ¸…ç†å›è°ƒ
            self.task_callbacks.pop(task.get('task_instance_id'), None)
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            fail_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.FAILED,
                error_message=str(e)
            )
            await self.task_instance_repo.update_task(task['task_instance_id'], fail_update)
            raise
    
    async def on_task_completed(self, task_id: uuid.UUID, result: Dict[str, Any]):
        """ä»»åŠ¡å®Œæˆå›è°ƒå¤„ç†"""
        try:
            logger.trace(f"æ”¶åˆ°ä»»åŠ¡å®Œæˆå›è°ƒ: {task_id}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…çš„å›è°ƒ
            if task_id in self.task_callbacks:
                callback_future = self.task_callbacks[task_id]
                if not callback_future.done():
                    callback_future.set_result(result)
                    logger.trace(f"ä»»åŠ¡ {task_id} å›è°ƒå·²è§¦å‘")
            else:
                # è¿™æ˜¯æ­£å¸¸æƒ…å†µï¼šä»»åŠ¡å®Œæˆæ—¶ç­‰å¾…çš„Futureå¯èƒ½å·²ç»è¢«å¤„ç†å¹¶æ¸…ç†
                logger.debug(f"ä»»åŠ¡ {task_id} å®Œæˆï¼Œä½†å›è°ƒå·²è¢«å¤„ç†ï¼ˆæ­£å¸¸æƒ…å†µï¼‰")
            
            # è·å–ä»»åŠ¡ä¿¡æ¯ä»¥ä¾¿æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
            task_info = await self.task_instance_repo.get_task_by_id(task_id)
            if task_info:
                workflow_instance_id = task_info['workflow_instance_id']
                node_instance_id = task_info['node_instance_id']
                
                logger.trace(f"ğŸ¯ Agentä»»åŠ¡å®Œæˆï¼Œæ›´æ–°èŠ‚ç‚¹çŠ¶æ€: workflow={workflow_instance_id}, node_instance={node_instance_id}")
                
                # è·å–èŠ‚ç‚¹ä¿¡æ¯
                node_query = """
                SELECT n.node_id, n.name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.node_instance_id = $1
                """
                node_info = await self.task_instance_repo.db.fetch_one(node_query, node_instance_id)
                
                if node_info:
                    # ä½¿ç”¨WorkflowContextManageræ ‡è®°èŠ‚ç‚¹å®Œæˆ
                    output_data = {
                        'task_result': result.get('result', ''),
                        'task_summary': result.get('message', ''),
                        'execution_time': result.get('duration', 0),
                        'completion_time': datetime.utcnow().isoformat()
                    }
                    
                    await self.context_manager.mark_node_completed(
                        workflow_instance_id=workflow_instance_id,
                        node_id=node_info['node_id'],
                        node_instance_id=node_instance_id,
                        output_data=output_data
                    )
                    
                    logger.trace(f"âœ… Agentä»»åŠ¡å®ŒæˆåèŠ‚ç‚¹çŠ¶æ€æ›´æ–°å®Œæˆ")
                else:
                    logger.error(f"æ— æ³•è·å–èŠ‚ç‚¹ä¿¡æ¯: node_instance_id={node_instance_id}")
            else:
                logger.error(f"æ— æ³•è·å–ä»»åŠ¡ä¿¡æ¯: task_id={task_id}")
                
        except Exception as e:
            logger.error(f"å¤„ç†ä»»åŠ¡å®Œæˆå›è°ƒå¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def on_task_failed(self, task_id: uuid.UUID, error_message: str):
        """ä»»åŠ¡å¤±è´¥å›è°ƒå¤„ç†"""
        try:
            logger.trace(f"æ”¶åˆ°ä»»åŠ¡å¤±è´¥å›è°ƒ: {task_id} - {error_message}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…çš„å›è°ƒ
            if task_id in self.task_callbacks:
                callback_future = self.task_callbacks[task_id]
                if not callback_future.done():
                    callback_future.set_exception(RuntimeError(error_message))
                    logger.trace(f"ä»»åŠ¡ {task_id} å¤±è´¥å›è°ƒå·²è§¦å‘")
            else:
                # è¿™æ˜¯æ­£å¸¸æƒ…å†µï¼šä»»åŠ¡å¤±è´¥æ—¶ç­‰å¾…çš„Futureå¯èƒ½å·²ç»è¢«å¤„ç†å¹¶æ¸…ç†
                logger.debug(f"ä»»åŠ¡ {task_id} å¤±è´¥ï¼Œä½†å›è°ƒå·²è¢«å¤„ç†ï¼ˆæ­£å¸¸æƒ…å†µï¼‰")
            
            # è·å–ä»»åŠ¡ä¿¡æ¯ä»¥ä¾¿æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå¤±è´¥
            task_info = await self.task_instance_repo.get_task_by_id(task_id)
            if task_info:
                workflow_instance_id = task_info['workflow_instance_id']
                node_instance_id = task_info['node_instance_id']
                
                logger.trace(f"âŒ Agentä»»åŠ¡å¤±è´¥ï¼Œæ ‡è®°èŠ‚ç‚¹å¤±è´¥: workflow={workflow_instance_id}, node_instance={node_instance_id}")
                
                # è·å–èŠ‚ç‚¹ä¿¡æ¯
                node_query = """
                SELECT n.node_id, n.name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.node_instance_id = $1
                """
                node_info = await self.task_instance_repo.db.fetch_one(node_query, node_instance_id)
                
                if node_info:
                    # ä½¿ç”¨WorkflowContextManageræ ‡è®°èŠ‚ç‚¹å¤±è´¥
                    await self.context_manager.mark_node_failed(
                        workflow_instance_id=workflow_instance_id,
                        node_id=node_info['node_id'],
                        node_instance_id=node_instance_id,
                        error_info={'error': error_message}
                    )
                    
                    logger.trace(f"âŒ Agentä»»åŠ¡å¤±è´¥åèŠ‚ç‚¹çŠ¶æ€æ›´æ–°å®Œæˆ")
                else:
                    logger.error(f"æ— æ³•è·å–èŠ‚ç‚¹ä¿¡æ¯: node_instance_id={node_instance_id}")
            else:
                logger.error(f"æ— æ³•è·å–ä»»åŠ¡ä¿¡æ¯: task_id={task_id}")
                
        except Exception as e:
            logger.error(f"å¤„ç†ä»»åŠ¡å¤±è´¥å›è°ƒå¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _process_mixed_task(self, task: Dict[str, Any]):
        """å¤„ç†æ··åˆä»»åŠ¡ - äººæœºåä½œ"""
        try:
            task_id = task['task_instance_id']
            logger.trace(f"å¤„ç†æ··åˆä»»åŠ¡: {task['task_title']}")
            
            # 1. é¦–å…ˆåˆ†é…ç»™äººå·¥ç”¨æˆ·å¤„ç†
            human_update = TaskInstanceUpdate(status=TaskInstanceStatus.ASSIGNED)
            await self.task_instance_repo.update_task(task_id, human_update)
            logger.trace(f"æ··åˆä»»åŠ¡ {task_id} å·²åˆ†é…ç»™äººå·¥ç”¨æˆ·")
            
            # 2. åŒæ—¶æäº¤ç»™AgentæœåŠ¡è·å–AIå»ºè®®ï¼ˆä¸é˜»å¡ï¼‰
            try:
                # åˆ›å»ºAIå»ºè®®ä»»åŠ¡çš„å‰¯æœ¬æ•°æ®
                ai_suggestion_task = task.copy()
                ai_suggestion_task['task_title'] = f"[AIå»ºè®®] {task['task_title']}"
                ai_suggestion_task['task_description'] = f"ä¸ºäººå·¥ä»»åŠ¡æä¾›AIå»ºè®®: {task['task_description']}"
                
                # å¼‚æ­¥æäº¤åˆ°AgentæœåŠ¡è·å–å»ºè®®
                asyncio.create_task(self._provide_ai_assistance(task_id, ai_suggestion_task))
                logger.trace(f"ä¸ºæ··åˆä»»åŠ¡ {task_id} å¯åŠ¨AIååŠ©")
                
            except Exception as e:
                logger.warning(f"å¯åŠ¨AIååŠ©å¤±è´¥ï¼Œç»§ç»­äººå·¥å¤„ç†: {e}")
            
            # 3. æ··åˆä»»åŠ¡ä¸»è¦ç­‰å¾…äººå·¥å®Œæˆï¼ŒAIå»ºè®®ä½œä¸ºè¾…åŠ©
            logger.trace(f"æ··åˆä»»åŠ¡ {task_id} è¿›å…¥äººæœºåä½œæ¨¡å¼")
            
        except Exception as e:
            logger.error(f"å¤„ç†æ··åˆä»»åŠ¡å¤±è´¥: {e}")
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            fail_update = TaskInstanceUpdate(
                status=TaskInstanceStatus.FAILED,
                error_message=str(e)
            )
            await self.task_instance_repo.update_task(task['task_instance_id'], fail_update)
            raise
    
    async def _provide_ai_assistance(self, original_task_id: uuid.UUID, ai_task: Dict[str, Any]):
        """ä¸ºäººå·¥ä»»åŠ¡æä¾›AIååŠ©å»ºè®®"""
        try:
            logger.trace(f"ä¸ºä»»åŠ¡ {original_task_id} ç”ŸæˆAIå»ºè®®")
            
            # è°ƒç”¨AgentTaskServiceç”ŸæˆAIå»ºè®®
            ai_result = await agent_task_service.process_agent_task(original_task_id)
            
            # å°†AIå»ºè®®å­˜å‚¨åˆ°åŸä»»åŠ¡çš„ä¸Šä¸‹æ–‡ä¸­
            if ai_result['status'] == TaskInstanceStatus.COMPLETED.value:
                ai_suggestions = {
                    'ai_analysis': ai_result['result'],
                    'suggestions_generated_at': now_utc().isoformat(),
                    'confidence_score': ai_result['result'].get('confidence_score', 0.8),
                    'ai_recommendations': ai_result['result'].get('recommendations', [])
                }
                
                # æ›´æ–°åŸä»»åŠ¡ï¼Œæ·»åŠ AIå»ºè®®åˆ°ä¸Šä¸‹æ–‡
                update_data = TaskInstanceUpdate(
                    context_data={'ai_assistance': ai_suggestions}
                )
                await self.task_instance_repo.update_task(original_task_id, update_data)
                
                logger.trace(f"AIå»ºè®®å·²æ·»åŠ åˆ°ä»»åŠ¡ {original_task_id} çš„ä¸Šä¸‹æ–‡ä¸­")
            
        except Exception as e:
            logger.warning(f"ç”ŸæˆAIååŠ©å»ºè®®å¤±è´¥: {e}")
            # AIååŠ©å¤±è´¥ä¸å½±å“ä¸»ä»»åŠ¡
    
    async def _complete_workflow(self, instance_id: uuid.UUID):
        """å®Œæˆå·¥ä½œæµ"""
        try:
            logger.trace(f"ğŸ å¼€å§‹å®Œæˆå·¥ä½œæµ: {instance_id}")
            
            # 1. ç”Ÿæˆæ ‡å‡†åŒ–è¾“å‡ºæ‘˜è¦
            logger.trace(f"ğŸ“Š ç”Ÿæˆå·¥ä½œæµè¾“å‡ºæ‘˜è¦")
            try:
                from .output_data_processor import OutputDataProcessor
                output_processor = OutputDataProcessor()
                
                # ç”Ÿæˆè¾“å‡ºæ‘˜è¦
                output_summary = await output_processor.generate_workflow_output_summary(instance_id)
                if output_summary:
                    logger.trace(f"âœ… å·¥ä½œæµè¾“å‡ºæ‘˜è¦ç”ŸæˆæˆåŠŸ")
                    
                    # å‡†å¤‡ç»“æ„åŒ–è¾“å‡ºæ•°æ®
                    summary_dict = output_summary.dict()
                    execution_summary = {
                        "execution_result": summary_dict.get("execution_result"),
                        "execution_stats": summary_dict.get("execution_stats")
                    }
                    quality_metrics = summary_dict.get("quality_metrics")
                    data_lineage = summary_dict.get("data_lineage")
                    
                    # è®¾ç½®åŸºç¡€è¾“å‡ºæ•°æ®
                    basic_output_data = {
                        'message': 'å·¥ä½œæµæ‰§è¡Œå®Œæˆ',
                        'completion_time': datetime.utcnow().isoformat(),
                        'result_type': summary_dict.get("execution_result", {}).get("result_type", "success")
                    }
                    
                    # å¦‚æœæœ‰å…·ä½“çš„ä¸šåŠ¡è¾“å‡ºæ•°æ®ï¼Œæ·»åŠ åˆ°åŸºç¡€è¾“å‡ºä¸­
                    if summary_dict.get("execution_result", {}).get("data_output"):
                        basic_output_data['workflow_results'] = summary_dict["execution_result"]["data_output"]
                    
                    logger.trace(f"ğŸ’¾ æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€å’Œè¾“å‡ºæ•°æ®")
                    
                    # 2. æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºå·²å®Œæˆï¼ŒåŒ…å«ç»“æ„åŒ–è¾“å‡º
                    update_data = WorkflowInstanceUpdate(
                        status=WorkflowInstanceStatus.COMPLETED,
                        output_data=basic_output_data,
                        execution_summary=execution_summary,
                        quality_metrics=quality_metrics,
                        data_lineage=data_lineage,
                        output_summary=output_summary
                    )
                    
                else:
                    logger.warning(f"âš ï¸ å·¥ä½œæµè¾“å‡ºæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€è¾“å‡ºæ•°æ®")
                    # ä½¿ç”¨åŸºç¡€è¾“å‡ºæ•°æ®
                    update_data = WorkflowInstanceUpdate(
                        status=WorkflowInstanceStatus.COMPLETED,
                        output_data={
                            'message': 'å·¥ä½œæµæ‰§è¡Œå®Œæˆ',
                            'completion_time': datetime.utcnow().isoformat(),
                            'result_type': 'success'
                        }
                    )
                    
            except Exception as output_error:
                logger.error(f"âŒ ç”Ÿæˆè¾“å‡ºæ‘˜è¦å¼‚å¸¸: {output_error}")
                import traceback
                logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                
                # å³ä½¿è¾“å‡ºæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä¹Ÿè¦å®Œæˆå·¥ä½œæµ
                update_data = WorkflowInstanceUpdate(
                    status=WorkflowInstanceStatus.COMPLETED,
                    output_data={
                        'message': 'å·¥ä½œæµæ‰§è¡Œå®Œæˆ',
                        'completion_time': datetime.utcnow().isoformat(),
                        'result_type': 'success',
                        'note': 'è¾“å‡ºæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½†å·¥ä½œæµæ­£å¸¸å®Œæˆ'
                    }
                )
            
            # 3. æ›´æ–°æ•°æ®åº“
            await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            # 4. ä»è¿è¡Œå®ä¾‹ä¸­ç§»é™¤
            self.running_instances.pop(instance_id, None)
            
            logger.trace(f"âœ… å·¥ä½œæµå®ä¾‹ {instance_id} æ‰§è¡Œå®Œæˆ")
            logger.trace(f"ğŸ“‹ å·¥ä½œæµå®Œæˆç»Ÿè®¡:")
            logger.trace(f"   - å®ä¾‹ID: {instance_id}")
            logger.trace(f"   - å®Œæˆæ—¶é—´: {datetime.utcnow().isoformat()}")
            logger.trace(f"   - è¾“å‡ºæ‘˜è¦: {'å·²ç”Ÿæˆ' if 'output_summary' in locals() and output_summary else 'ç”Ÿæˆå¤±è´¥'}")
            
        except Exception as e:
            logger.error(f"âŒ å®Œæˆå·¥ä½œæµå¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def _fail_workflow(self, instance_id: uuid.UUID, error_message: str):
        """å·¥ä½œæµæ‰§è¡Œå¤±è´¥"""
        try:
            # æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºå¤±è´¥
            update_data = WorkflowInstanceUpdate(
                status=WorkflowInstanceStatus.FAILED,
                error_message=error_message
            )
            await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            # ä»è¿è¡Œå®ä¾‹ä¸­ç§»é™¤
            self.running_instances.pop(instance_id, None)
            
            logger.error(f"å·¥ä½œæµå®ä¾‹ {instance_id} æ‰§è¡Œå¤±è´¥: {error_message}")
            
        except Exception as e:
            logger.error(f"æ ‡è®°å·¥ä½œæµå¤±è´¥çŠ¶æ€å¤±è´¥: {e}")
    
    async def _monitor_running_instances(self):
        """ç›‘æ§è¿è¡Œä¸­çš„å®ä¾‹"""
        while self.is_running:
            try:
                # æ£€æŸ¥è¶…æ—¶çš„å®ä¾‹
                for instance_id, execution_item in list(self.running_instances.items()):
                    # è¿™é‡Œå¯ä»¥æ·»åŠ è¶…æ—¶æ£€æŸ¥é€»è¾‘
                    pass
                
                await asyncio.sleep(15)  # æ¯15ç§’æ£€æŸ¥ä¸€æ¬¡ - ä¼˜åŒ–ä¸ºæ›´é¢‘ç¹
                
            except Exception as e:
                logger.error(f"ç›‘æ§è¿è¡Œå®ä¾‹å¤±è´¥: {e}")
                await asyncio.sleep(10)
    
    async def pause_workflow(self, instance_id: uuid.UUID) -> bool:
        """æš‚åœå·¥ä½œæµ"""
        try:
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.PAUSED)
            result = await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            if result:
                logger.trace(f"å·¥ä½œæµå®ä¾‹ {instance_id} å·²æš‚åœ")
                return True
            return False
            
        except Exception as e:
            logger.error(f"æš‚åœå·¥ä½œæµå¤±è´¥: {e}")
            return False
    
    async def resume_workflow(self, instance_id: uuid.UUID) -> bool:
        """æ¢å¤å·¥ä½œæµ"""
        try:
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.RUNNING)
            result = await self.workflow_instance_repo.update_instance(instance_id, update_data)
            
            if result:
                logger.trace(f"å·¥ä½œæµå®ä¾‹ {instance_id} å·²æ¢å¤")
                return True
            return False
            
        except Exception as e:
            logger.error(f"æ¢å¤å·¥ä½œæµå¤±è´¥: {e}")
            return False
    
    async def cancel_workflow(self, instance_id: uuid.UUID) -> bool:
        """å–æ¶ˆå·¥ä½œæµ"""
        try:
            logger.trace(f"ğŸš« å¼€å§‹å–æ¶ˆå·¥ä½œæµå®ä¾‹: {instance_id}")
            
            # é¦–å…ˆæ£€æŸ¥å·¥ä½œæµå®ä¾‹æ˜¯å¦å­˜åœ¨
            instance = await self.workflow_instance_repo.get_instance_by_id(instance_id)
            if not instance:
                logger.error(f"âŒ å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨: {instance_id}")
                return False
                
            logger.trace(f"ğŸ“‹ æ‰¾åˆ°å·¥ä½œæµå®ä¾‹: {instance.get('instance_name', 'æœªå‘½å')}")
            logger.trace(f"   - å½“å‰çŠ¶æ€: {instance.get('status')}")
            logger.trace(f"   - æ‰§è¡Œè€…: {instance.get('executor_id')}")
            logger.trace(f"   - åˆ›å»ºæ—¶é—´: {instance.get('created_at')}")
            
            # 1. å–æ¶ˆæ­£åœ¨è¿è¡Œçš„å¼‚æ­¥ä»»åŠ¡
            logger.trace(f"ğŸ¯ æ­¥éª¤1: å–æ¶ˆæ­£åœ¨è¿è¡Œçš„å¼‚æ­¥ä»»åŠ¡")
            try:
                await self._cancel_running_tasks(instance_id)
                logger.trace(f"âœ… å¼‚æ­¥ä»»åŠ¡å–æ¶ˆå®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ å–æ¶ˆå¼‚æ­¥ä»»åŠ¡å¤±è´¥: {e}")
            
            # 2. ä½¿ç”¨æ–°æ¶æ„æ¸…ç†å®ä¾‹ä¸Šä¸‹æ–‡
            logger.trace(f"ğŸ¯ æ­¥éª¤2: æ¸…ç†å®ä¾‹ä¸Šä¸‹æ–‡")
            if self.instance_manager:
                logger.trace(f"   - å®ä¾‹ç®¡ç†å™¨å­˜åœ¨ï¼Œå¼€å§‹æ¸…ç†")
                try:
                    context = await self.instance_manager.get_instance(instance_id)
                    if context:
                        logger.trace(f"   - æ‰¾åˆ°å®ä¾‹ä¸Šä¸‹æ–‡ï¼Œå¼€å§‹æ¸…ç†ä»»åŠ¡")
                        # å–æ¶ˆå®ä¾‹ä¸­çš„æ‰€æœ‰æ‰§è¡Œä»»åŠ¡
                        await self._cancel_instance_context_tasks(context)
                        # ä»å®ä¾‹ç®¡ç†å™¨ä¸­ç§»é™¤
                        await self.instance_manager.remove_instance(instance_id)
                        logger.trace(f"âœ… å·²ä»æ–°æ¶æ„å®ä¾‹ç®¡ç†å™¨ä¸­ç§»é™¤å·¥ä½œæµ: {instance_id}")
                    else:
                        logger.trace(f"   - å®ä¾‹ä¸Šä¸‹æ–‡ä¸å­˜åœ¨æˆ–å·²æ¸…ç†")
                except Exception as e:
                    logger.error(f"âŒ æ¸…ç†å®ä¾‹ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            else:
                logger.warning(f"   - å®ä¾‹ç®¡ç†å™¨ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¸Šä¸‹æ–‡æ¸…ç†")
            
            # 3. æ›´æ–°æ•°æ®åº“çŠ¶æ€
            logger.trace(f"ğŸ¯ æ­¥éª¤3: æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸ºCANCELLED")
            try:
                update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.CANCELLED)
                logger.trace(f"   - å‡†å¤‡æ›´æ–°æ•°æ®: {update_data}")
                result = await self.workflow_instance_repo.update_instance(instance_id, update_data)
                logger.trace(f"   - æ•°æ®åº“æ›´æ–°ç»“æœ: {result}")
                
                if result:
                    logger.trace(f"âœ… æ•°æ®åº“çŠ¶æ€æ›´æ–°æˆåŠŸ")
                    
                    # 4. ä»è¿è¡Œå®ä¾‹ä¸­ç§»é™¤ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰
                    logger.trace(f"ğŸ¯ æ­¥éª¤4: ä»è¿è¡Œå®ä¾‹åˆ—è¡¨ä¸­ç§»é™¤")
                    if instance_id in self.running_instances:
                        self.running_instances.pop(instance_id, None)
                        logger.trace(f"   - å·²ä»è¿è¡Œå®ä¾‹åˆ—è¡¨ä¸­ç§»é™¤")
                    else:
                        logger.trace(f"   - å®ä¾‹ä¸åœ¨è¿è¡Œåˆ—è¡¨ä¸­")
                    
                    # 5. é€šçŸ¥ç›¸å…³æœåŠ¡
                    logger.trace(f"ğŸ¯ æ­¥éª¤5: é€šçŸ¥ç›¸å…³æœåŠ¡")
                    try:
                        await self._notify_services_workflow_cancelled(instance_id)
                        logger.trace(f"âœ… æœåŠ¡é€šçŸ¥å®Œæˆ")
                    except Exception as e:
                        logger.error(f"âŒ é€šçŸ¥æœåŠ¡å¤±è´¥: {e}")
                    
                    logger.trace(f"âœ… å·¥ä½œæµå®ä¾‹ {instance_id} å·²æˆåŠŸå–æ¶ˆ (æ‰€æœ‰æ­¥éª¤å®Œæˆ)")
                    return True
                else:
                    logger.error(f"âŒ æ›´æ–°å·¥ä½œæµçŠ¶æ€å¤±è´¥: {instance_id}")
                    return False
            except Exception as e:
                logger.error(f"âŒ æ•°æ®åº“æ›´æ–°å¼‚å¸¸: {e}")
                import traceback
                logger.error(f"   - æ›´æ–°å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                return False
            
        except Exception as e:
            logger.error(f"âŒ å–æ¶ˆå·¥ä½œæµå¤±è´¥: {e}")
            import traceback
            logger.error(f"   - å®Œæ•´å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            return False
    
    async def get_workflow_status(self, instance_id: uuid.UUID) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        try:
            instance = await self.workflow_instance_repo.get_instance_by_id(instance_id)
            if not instance:
                return None
            
            # è·å–æ‰§è¡Œç»Ÿè®¡
            stats = await self.workflow_instance_repo.get_execution_statistics(instance_id)
            
            return {
                'instance': instance,
                'statistics': stats,
                'is_running': instance_id in self.running_instances
            }
            
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµçŠ¶æ€å¤±è´¥: {e}")
            return None
    
    # =============================================================================
    # æ–°å¢ï¼šä¾èµ–ç­‰å¾…å’Œä¸Šä¸‹æ–‡ç®¡ç†æ–¹æ³•
    # =============================================================================
    
    async def _create_node_instances_with_dependencies(self, 
                                                     workflow_instance_id: uuid.UUID,
                                                     workflow_base_id: uuid.UUID,
                                                     nodes: List[Dict[str, Any]]):
        """åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¹¶æ³¨å†Œä¾èµ–å…³ç³»"""
        try:
            logger.trace(f"å¼€å§‹åˆ›å»ºèŠ‚ç‚¹å®ä¾‹: å·¥ä½œæµå®ä¾‹ ID={workflow_instance_id}, èŠ‚ç‚¹æ•°é‡={len(nodes)}")
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceCreate, NodeInstanceStatus
            
            node_instance_repo = NodeInstanceRepository()
            created_nodes = []
            
            # 1. å…ˆåˆ›å»ºæ‰€æœ‰èŠ‚ç‚¹å®ä¾‹
            logger.trace(f"é˜¶æ®µ1: åˆ›å»º {len(nodes)} ä¸ªèŠ‚ç‚¹å®ä¾‹")
            for i, node in enumerate(nodes, 1):
                logger.trace(f"  æ­£åœ¨åˆ›å»ºèŠ‚ç‚¹å®ä¾‹ {i}/{len(nodes)}: {node['name']} (ç±»å‹: {node['type']})")
                
                # è®¾ç½®åˆå§‹çŠ¶æ€ï¼šSTARTèŠ‚ç‚¹ä¸ºPENDINGï¼Œå…¶ä»–èŠ‚ç‚¹ä¹Ÿä¸ºPENDINGï¼ˆç­‰å¾…å‰ç½®æ¡ä»¶æ»¡è¶³ï¼‰
                initial_status = NodeInstanceStatus.PENDING
                logger.trace(f"    åˆå§‹çŠ¶æ€: {initial_status.value}")
                
                node_instance_data = NodeInstanceCreate(
                    workflow_instance_id=workflow_instance_id,
                    node_id=node['node_id'],
                    node_base_id=node['node_base_id'],
                    node_instance_name=f"{node['name']}_instance",
                    task_description=node.get('task_description') or '',
                    status=initial_status,
                    input_data={},
                    output_data={},
                    error_message=None,
                    retry_count=0
                )
                
                node_instance = await node_instance_repo.create_node_instance(node_instance_data)
                if node_instance:
                    created_nodes.append({
                        'node_instance_id': node_instance['node_instance_id'],
                        'node_base_id': node['node_base_id'],
                        'node_type': node['type'],
                        'node_data': node
                    })
                    logger.trace(f"  âœ… èŠ‚ç‚¹å®ä¾‹åˆ›å»ºæˆåŠŸ: {node['name']} (ID: {node_instance['node_instance_id']})")
                else:
                    logger.error(f"  âŒ èŠ‚ç‚¹å®ä¾‹åˆ›å»ºå¤±è´¥: {node['name']}")
            
            # 2. ä¸ºæ¯ä¸ªèŠ‚ç‚¹æ³¨å†Œä¾èµ–å…³ç³»
            logger.trace(f"é˜¶æ®µ2: æ³¨å†Œ {len(created_nodes)} ä¸ªèŠ‚ç‚¹çš„ä¾èµ–å…³ç³»")
            for i, created_node in enumerate(created_nodes, 1):
                logger.trace(f"  æ­£åœ¨æ³¨å†ŒèŠ‚ç‚¹ {i}/{len(created_nodes)} çš„ä¾èµ–: {created_node['node_data']['name']}")
                try:
                    # ç›´æ¥ä»æ•°æ®åº“æŸ¥è¯¢è¿æ¥å…³ç³»ï¼Œä½¿ç”¨æ­£ç¡®çš„workflow_id
                    from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
                    workflow_instance_repo = WorkflowInstanceRepository()
                    workflow_instance = await workflow_instance_repo.get_instance_by_id(workflow_instance_id)
                    current_workflow_id = workflow_instance['workflow_id'] if workflow_instance else None
                    
                    logger.trace(f"    ğŸ” æŸ¥è¯¢èŠ‚ç‚¹ {created_node['node_data']['name']} çš„ä¾èµ–å…³ç³»:")
                    logger.trace(f"      - node_id: {created_node['node_data']['node_id']}")
                    logger.trace(f"      - workflow_id: {current_workflow_id}")
                    
                    # æŸ¥è¯¢ä¸Šæ¸¸è¿æ¥å…³ç³»
                    upstream_query = """
                    SELECT DISTINCT 
                        nc.from_node_id as upstream_node_id,
                        n.name as upstream_node_name,
                        n.type as upstream_node_type
                    FROM node_connection nc
                    JOIN node n ON nc.from_node_id = n.node_id
                    WHERE nc.to_node_id = $1 
                    AND nc.workflow_id = $2
                    ORDER BY n.name
                    """
                    
                    upstream_connections = await self.dependency_manager.db.fetch_all(
                        upstream_query, 
                        created_node['node_data']['node_id'],  # ä½¿ç”¨node_idæŸ¥è¯¢
                        current_workflow_id  # ä½¿ç”¨workflow_idæŸ¥è¯¢
                    )
                    
                    logger.trace(f"    ğŸ” æŸ¥è¯¢åˆ° {len(upstream_connections)} ä¸ªä¸Šæ¸¸èŠ‚ç‚¹è¿æ¥:")
                    upstream_node_ids = []
                    for upstream in upstream_connections:
                        upstream_node_id = upstream['upstream_node_id']
                        upstream_node_ids.append(upstream_node_id)
                        logger.trace(f"      - ä¸Šæ¸¸èŠ‚ç‚¹: {upstream.get('upstream_node_name', 'Unknown')} (node_id: {upstream_node_id})")
                    
                    logger.trace(f"    ğŸ“‹ æœ€ç»ˆä¾èµ–åˆ—è¡¨ (node_id): {upstream_node_ids}")
                    
                    await self.context_manager.register_node_dependencies(
                        created_node['node_instance_id'],
                        created_node['node_data']['node_id'],  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
                        workflow_instance_id,
                        upstream_node_ids  # ä¸Šæ¸¸èŠ‚ç‚¹çš„node_idåˆ—è¡¨
                    )
                    
                    logger.trace(f"  âœ… èŠ‚ç‚¹ä¾èµ–æ³¨å†ŒæˆåŠŸ: {len(upstream_node_ids)} ä¸ªä¸Šæ¸¸èŠ‚ç‚¹ (ä½¿ç”¨node_id)")
                except Exception as e:
                    logger.error(f"  âŒ èŠ‚ç‚¹ä¾èµ–æ³¨å†Œå¤±è´¥: {e}")
                    import traceback
                    logger.error(f"    å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            
            # 3. ä¸å†ä¸ºæ‰€æœ‰å¤„ç†å™¨èŠ‚ç‚¹ç«‹å³åˆ›å»ºä»»åŠ¡ - æ”¹ä¸ºå»¶è¿Ÿåˆ›å»ºæœºåˆ¶
            logger.trace(f"é˜¶æ®µ3: å¯ç”¨å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶ï¼Œåªä¸ºSTARTèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡")
            try:
                # åªä¸ºSTARTèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡ï¼ˆå¦‚æœSTARTèŠ‚ç‚¹æ˜¯PROCESSORç±»å‹ï¼‰
                start_nodes = [n for n in created_nodes if n['node_data']['type'] == NodeType.START.value]
                if start_nodes:
                    await self._create_tasks_for_nodes(start_nodes, workflow_instance_id)
                    logger.trace(f"âœ… STARTèŠ‚ç‚¹ä»»åŠ¡åˆ›å»ºå®Œæˆ")
                
                # æ£€æŸ¥æ‰€æœ‰å°±ç»ªèŠ‚ç‚¹ï¼Œä¸ºæ»¡è¶³æ¡ä»¶çš„èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
                await self._check_downstream_nodes_for_task_creation(workflow_instance_id)
                logger.trace(f"âœ… å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶å¯åŠ¨å®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶å¯åŠ¨å¤±è´¥: {e}")
            
            logger.trace(f"âœ… èŠ‚ç‚¹å®ä¾‹å’Œä¾èµ–å…³ç³»åˆ›å»ºå®Œæˆ: {len(created_nodes)} ä¸ªèŠ‚ç‚¹")
            
            # æ‰“å°ä¾èµ–å…³ç³»æ€»ç»“
            logger.trace(f"ğŸ“Š [ä¾èµ–æ€»ç»“] æ‰“å°å·¥ä½œæµ {workflow_instance_id} çš„å®Œæ•´ä¾èµ–å…³ç³»:")
            self.context_manager.print_dependency_summary(workflow_instance_id)
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºå¸¦ä¾èµ–çš„èŠ‚ç‚¹å®ä¾‹å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def _create_tasks_for_nodes(self, created_nodes: List[Dict], workflow_instance_id: uuid.UUID):
        """ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹"""
        logger.trace(f"ğŸ”§ å¼€å§‹ä¸º {len(created_nodes)} ä¸ªèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹")
        
        task_creation_count = 0
        for i, created_node in enumerate(created_nodes, 1):
            logger.trace(f"ğŸ“‹ å¤„ç†èŠ‚ç‚¹ {i}/{len(created_nodes)}: {created_node.get('node_data', {}).get('name', 'æœªçŸ¥èŠ‚ç‚¹')}")
            logger.trace(f"   èŠ‚ç‚¹ç±»å‹: {created_node['node_type']}")
            logger.trace(f"   èŠ‚ç‚¹å®ä¾‹ID: {created_node['node_instance_id']}")
            
            if created_node['node_type'] == NodeType.PROCESSOR.value:
                node_data = created_node['node_data']
                
                logger.trace(f"   ğŸ” æŸ¥è¯¢èŠ‚ç‚¹å¤„ç†å™¨...")
                # è·å–èŠ‚ç‚¹çš„å¤„ç†å™¨ï¼ˆä¿®å¤ï¼šä½¿ç”¨node_idï¼‰
                processors = await self._get_node_processors(
                    created_node['node_data']['node_id']
                )
                
                if not processors:
                    logger.warning(f"   âš ï¸  èŠ‚ç‚¹ {node_data['name']} æ²¡æœ‰é…ç½®å¤„ç†å™¨ï¼Œè·³è¿‡ä»»åŠ¡åˆ›å»º")
                    continue
                
                logger.trace(f"   âœ… æ‰¾åˆ° {len(processors)} ä¸ªå¤„ç†å™¨")
                
                for j, processor in enumerate(processors, 1):
                    logger.trace(f"   ğŸ¯ å¤„ç†å¤„ç†å™¨ {j}/{len(processors)}: {processor.get('processor_name', processor.get('name', 'Unknown'))}")
                    
                    processor_type = processor.get('processor_type', processor.get('type', 'HUMAN'))
                    task_type = self._determine_task_type(processor_type)
                    
                    logger.trace(f"      å¤„ç†å™¨ç±»å‹: {processor_type}")
                    logger.trace(f"      ä»»åŠ¡ç±»å‹: {task_type.value}")
                    
                    # æ ¹æ®ä»»åŠ¡ç±»å‹å’ŒèŠ‚ç‚¹é…ç½®ç¡®å®šè¶…æ—¶è®¾ç½®
                    estimated_duration = self._determine_task_duration(task_type, node_data)
                    
                    logger.trace(f"      é¢„ä¼°æŒç»­æ—¶é—´: {estimated_duration}åˆ†é’Ÿ")
                    
                    # ç¡®å®šä»»åŠ¡åˆ†é…
                    assigned_user_id = processor.get('user_id')
                    assigned_agent_id = processor.get('agent_id')
                    
                    if assigned_user_id:
                        logger.trace(f"      ğŸ‘¤ ä»»åŠ¡å°†åˆ†é…ç»™ç”¨æˆ·: {assigned_user_id}")
                    elif assigned_agent_id:
                        logger.trace(f"      ğŸ¤– ä»»åŠ¡å°†åˆ†é…ç»™ä»£ç†: {assigned_agent_id}")
                    else:
                        logger.trace(f"      â³ ä»»åŠ¡æš‚æœªåˆ†é…ï¼Œå°†ä¿æŒPENDINGçŠ¶æ€")
                    
                    # åˆ›å»ºä»»åŠ¡å®ä¾‹ï¼Œä½†æš‚æ—¶ä¸åˆ†é…ä¸Šä¸‹æ–‡æ•°æ®
                    task_title = node_data['name']
                    
                    # ç¡®ä¿task_descriptionæœ‰å€¼
                    task_description = node_data.get('task_description') or node_data.get('description') or f"æ‰§è¡ŒèŠ‚ç‚¹ {node_data['name']} çš„ä»»åŠ¡"
                    
                    logger.trace(f"      ğŸ“ ä»»åŠ¡æè¿°: {task_description[:50]}{'...' if len(task_description) > 50 else ''}")
                    
                    # æ”¶é›†ä»»åŠ¡ä¸Šä¸‹æ–‡æ•°æ®
                    logger.trace(f"      ğŸ” æ”¶é›†ä»»åŠ¡ä¸Šä¸‹æ–‡æ•°æ®...")
                    context_data = await self.context_manager.get_task_context_data(workflow_instance_id, created_node['node_instance_id'])
                    
                    # å°†ä¸Šä¸‹æ–‡æ•°æ®è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
                    context_text = json.dumps(context_data, ensure_ascii=False, indent=2, default=_json_serializer) if context_data else ""
                    input_text = json.dumps(node_data.get('input_data', {}), ensure_ascii=False, indent=2, default=_json_serializer)
                    
                    task_data = TaskInstanceCreate(
                        node_instance_id=created_node['node_instance_id'],
                        workflow_instance_id=workflow_instance_id,
                        processor_id=processor['processor_id'],
                        task_type=task_type,
                        task_title=task_title,
                        task_description=task_description,
                        input_data=input_text,
                        context_data=context_text,
                        assigned_user_id=assigned_user_id,
                        assigned_agent_id=assigned_agent_id,
                        estimated_duration=estimated_duration
                    )
                    
                    logger.trace(f"      ğŸ“ æ­£åœ¨åˆ›å»ºä»»åŠ¡å®ä¾‹...")
                    try:
                        task = await self.task_instance_repo.create_task(task_data)
                        if task:
                            task_creation_count += 1
                            logger.trace(f"      âœ… ä»»åŠ¡å®ä¾‹åˆ›å»ºæˆåŠŸ!")
                            logger.trace(f"         ä»»åŠ¡ID: {task['task_instance_id']}")
                            logger.trace(f"         ä»»åŠ¡æ ‡é¢˜: {task['task_title']}")
                        else:
                            logger.error(f"      âŒ ä»»åŠ¡å®ä¾‹åˆ›å»ºå¤±è´¥: è¿”å›ç©ºç»“æœ")
                    except Exception as e:
                        logger.error(f"      âŒ ä»»åŠ¡å®ä¾‹åˆ›å»ºå¼‚å¸¸: {e}")
                        import traceback
                        logger.error(f"      å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            else:
                logger.trace(f"   â­ï¸  èŠ‚ç‚¹ç±»å‹ä¸æ˜¯PROCESSORï¼Œè·³è¿‡ä»»åŠ¡åˆ›å»º")
        
        logger.trace(f"ğŸ‰ ä»»åŠ¡åˆ›å»ºå®Œæˆ! æ€»å…±åˆ›å»ºäº† {task_creation_count} ä¸ªä»»åŠ¡å®ä¾‹")
    
    async def _start_workflow_execution_with_dependencies(self, 
                                                        workflow_instance_id: uuid.UUID,
                                                        workflow_base_id: uuid.UUID):
        """å¯åŠ¨å·¥ä½œæµæ‰§è¡Œï¼ˆåªå¯åŠ¨STARTèŠ‚ç‚¹ï¼‰"""
        try:
            logger.trace(f"å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ: {workflow_instance_id}")
            logger.trace(f"è°ƒç”¨_get_start_nodesï¼Œå·¥ä½œæµå®ä¾‹ID: {workflow_instance_id}")
            
            # é¦–å…ˆæ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.RUNNING)
            await self.workflow_instance_repo.update_instance(workflow_instance_id, update_data)
            
            # è·å–STARTèŠ‚ç‚¹
            logger.trace(f"æ­¥éª¤A: æŸ¥æ‰¾STARTèŠ‚ç‚¹")
            start_nodes = await self._get_start_nodes(workflow_instance_id)
            logger.trace(f"âœ… STARTèŠ‚ç‚¹æŸ¥è¯¢ç»“æœ: æ‰¾åˆ° {len(start_nodes)} ä¸ªSTARTèŠ‚ç‚¹")
            
            if not start_nodes:
                logger.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°pendingçŠ¶æ€çš„STARTèŠ‚ç‚¹ï¼Œå¯èƒ½å·¥ä½œæµå·²åœ¨è¿è¡Œä¸­")
                # æ£€æŸ¥æ˜¯å¦æœ‰å·²å®Œæˆçš„STARTèŠ‚ç‚¹ï¼Œå¦‚æœæœ‰åˆ™è¯´æ˜å·¥ä½œæµå·²å¯åŠ¨
                logger.trace(f"æ£€æŸ¥å·¥ä½œæµå½“å‰çŠ¶æ€å¹¶å°è¯•æ¢å¤æ‰§è¡Œ")
                await self._resume_workflow_execution(workflow_instance_id)
                return
            
            # æ˜¾ç¤ºæ‰¾åˆ°çš„STARTèŠ‚ç‚¹è¯¦æƒ…
            for i, start_node in enumerate(start_nodes, 1):
                logger.trace(f"  STARTèŠ‚ç‚¹{i}: {start_node.get('node_name', '\u672a\u77e5')} (ID: {start_node['node_instance_id']})")
            
            # æ‰§è¡ŒSTARTèŠ‚ç‚¹
            logger.trace(f"æ­¥éª¤B: å¼€å§‹æ‰§è¡Œ {len(start_nodes)} ä¸ªSTARTèŠ‚ç‚¹")
            for i, start_node in enumerate(start_nodes, 1):
                node_name = start_node.get('node_name', '\u672a\u77e5')
                logger.trace(f"  æ­£åœ¨æ‰§è¡ŒSTARTèŠ‚ç‚¹ {i}/{len(start_nodes)}: {node_name} (ID: {start_node['node_instance_id']})")
                try:
                    await self._execute_start_node_directly(workflow_instance_id, start_node)
                    logger.trace(f"  âœ… STARTèŠ‚ç‚¹æ‰§è¡ŒæˆåŠŸ: {node_name}")
                except Exception as e:
                    logger.error(f"  âŒ STARTèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {node_name} - {e}")
                    raise
            
            logger.trace(f"âœ… å·¥ä½œæµ {workflow_instance_id} æ‰€æœ‰STARTèŠ‚ç‚¹æ‰§è¡Œå®Œæˆï¼Œå·¥ä½œæµå·²å¼€å§‹è¿è¡Œ")
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆè¯¦æƒ…: {traceback.format_exc()}")
            raise
    
    async def _get_start_nodes(self, workflow_instance_id: uuid.UUID) -> List[Dict]:
        """è·å–STARTèŠ‚ç‚¹"""
        try:
            logger.trace(f"ğŸ” å¼€å§‹æŸ¥è¯¢STARTèŠ‚ç‚¹: workflow_instance_id={workflow_instance_id}")
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_instance_repo = NodeInstanceRepository()
            
            query = """
            SELECT ni.*, n.type as node_type, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1
            AND LOWER(n.type) = 'start'
            AND ni.status IN ('pending', 'PENDING')
            AND ni.is_deleted = FALSE
            AND n.is_deleted = FALSE
            ORDER BY ni.created_at ASC
            """
            
            # ä½¿ç”¨æ•°æ®åº“ç®¡ç†å™¨ç›´æ¥æ‰§è¡ŒæŸ¥è¯¢
            start_nodes = await node_instance_repo.db.fetch_all(query, workflow_instance_id)
            logger.trace(f"æ‰¾åˆ° {len(start_nodes)} ä¸ªSTARTèŠ‚ç‚¹å®ä¾‹ï¼Œå·¥ä½œæµå®ä¾‹ID: {workflow_instance_id}")
            
            # æ€»æ˜¯æŸ¥æ‰¾æ‰€æœ‰èŠ‚ç‚¹ä»¥è¿›è¡Œè°ƒè¯•
            logger.trace("è°ƒè¯•: æŸ¥æ‰¾æ‰€æœ‰èŠ‚ç‚¹ç±»å‹")
            debug_query = """
            SELECT ni.*, n.type as node_type, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1
            AND ni.is_deleted = FALSE
            AND n.is_deleted = FALSE
            ORDER BY n.type, ni.created_at ASC
            """
            all_nodes = await node_instance_repo.db.fetch_all(debug_query, workflow_instance_id)
            logger.trace(f"å·¥ä½œæµå®ä¾‹ {workflow_instance_id} çš„æ‰€æœ‰èŠ‚ç‚¹ ({len(all_nodes)} ä¸ª):")
            for node in all_nodes:
                logger.trace(f"  - èŠ‚ç‚¹: {node.get('node_name', 'Unknown')} (ç±»å‹: '{node.get('node_type', 'Unknown')}', çŠ¶æ€: {node.get('status', 'Unknown')})")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°pendingçŠ¶æ€çš„STARTèŠ‚ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å·²å®Œæˆçš„STARTèŠ‚ç‚¹
            if not start_nodes and all_nodes:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°pendingçŠ¶æ€çš„STARTèŠ‚ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å·²å®Œæˆçš„STARTèŠ‚ç‚¹")
                completed_start_query = """
                SELECT ni.*, n.type as node_type, n.name as node_name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.workflow_instance_id = $1
                AND LOWER(n.type) = 'start'
                AND ni.status IN ('completed', 'COMPLETED')
                AND ni.is_deleted = FALSE
                AND n.is_deleted = FALSE
                ORDER BY ni.created_at ASC
                """
                completed_start_nodes = await node_instance_repo.db.fetch_all(completed_start_query, workflow_instance_id)
                logger.trace(f"æ‰¾åˆ° {len(completed_start_nodes)} ä¸ªå·²å®Œæˆçš„STARTèŠ‚ç‚¹")
                
                if completed_start_nodes:
                    logger.trace("STARTèŠ‚ç‚¹å·²ç»æ‰§è¡Œå®Œæˆï¼Œå·¥ä½œæµå·²åœ¨è¿è¡Œä¸­")
                    # è¿”å›ç©ºåˆ—è¡¨ï¼Œè¡¨ç¤ºä¸éœ€è¦é‡æ–°å¯åŠ¨STARTèŠ‚ç‚¹
                    return []
                
                # å°è¯•ä¸åŒçš„æŸ¥è¯¢æ–¹å¼
                alt_query = """
                SELECT ni.*, n.type as node_type, n.name as node_name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.workflow_instance_id = $1
                AND n.type IN ('start', 'START')
                AND ni.status IN ('pending', 'PENDING')
                AND ni.is_deleted = FALSE
                AND n.is_deleted = FALSE
                ORDER BY ni.created_at ASC
                """
                alt_start_nodes = await node_instance_repo.db.fetch_all(alt_query, workflow_instance_id)
                logger.trace(f"å¤‡ç”¨æŸ¥è¯¢æ‰¾åˆ° {len(alt_start_nodes)} ä¸ªSTARTèŠ‚ç‚¹")
                if alt_start_nodes:
                    start_nodes = alt_start_nodes
            
            return start_nodes
            
        except Exception as e:
            logger.error(f"è·å–STARTèŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            return []
    
    async def _resume_workflow_execution(self, workflow_instance_id: uuid.UUID):
        """æ¢å¤å·¥ä½œæµæ‰§è¡Œï¼Œæ£€æŸ¥å¹¶è§¦å‘å‡†å¤‡å¥½çš„èŠ‚ç‚¹"""
        try:
            logger.trace(f"ğŸ”„ å¼€å§‹æ¢å¤å·¥ä½œæµæ‰§è¡Œ: {workflow_instance_id}")
            
            # æŸ¥æ‰¾æ‰€æœ‰pendingçŠ¶æ€çš„èŠ‚ç‚¹
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_instance_repo = NodeInstanceRepository()
            
            pending_query = """
            SELECT ni.*, n.type as node_type, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1
            AND ni.status IN ('pending', 'PENDING')
            AND ni.is_deleted = FALSE
            AND n.is_deleted = FALSE
            ORDER BY ni.created_at ASC
            """
            
            pending_nodes = await node_instance_repo.db.fetch_all(pending_query, workflow_instance_id)
            logger.trace(f"æ‰¾åˆ° {len(pending_nodes)} ä¸ªpendingçŠ¶æ€çš„èŠ‚ç‚¹")
            
            if pending_nodes:
                for node in pending_nodes:
                    node_name = node.get('node_name', 'æœªçŸ¥')
                    node_type = node.get('node_type', 'æœªçŸ¥')
                    logger.trace(f"  - PendingèŠ‚ç‚¹: {node_name} (ç±»å‹: {node_type})")
                
                # ç¡®ä¿å·²å®Œæˆçš„STARTèŠ‚ç‚¹å·²é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
                await self._ensure_completed_start_nodes_notified(workflow_instance_id)
                
                # æ£€æŸ¥è¿™äº›èŠ‚ç‚¹çš„ä¾èµ–æ˜¯å¦å·²æ»¡è¶³ï¼Œå¦‚æœæ»¡è¶³åˆ™è§¦å‘æ‰§è¡Œ
                logger.trace(f"æ£€æŸ¥pendingèŠ‚ç‚¹çš„ä¾èµ–å…³ç³»")
                await self._check_and_trigger_ready_nodes(workflow_instance_id, pending_nodes)
            else:
                logger.trace(f"æ²¡æœ‰æ‰¾åˆ°pendingçŠ¶æ€çš„èŠ‚ç‚¹ï¼Œå·¥ä½œæµå¯èƒ½å·²å®Œæˆæˆ–å‡ºç°å¼‚å¸¸")
                
        except Exception as e:
            logger.error(f"æ¢å¤å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
    
    async def _ensure_completed_start_nodes_notified(self, workflow_instance_id: uuid.UUID):
        """ç¡®ä¿å·²å®Œæˆçš„STARTèŠ‚ç‚¹å·²é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        try:
            logger.trace(f"ğŸ” [STARTèŠ‚ç‚¹ä¿®å¤] æ£€æŸ¥å·²å®Œæˆçš„STARTèŠ‚ç‚¹æ˜¯å¦å·²é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
            
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_instance_repo = NodeInstanceRepository()
            
            # æŸ¥æ‰¾å·²å®Œæˆçš„STARTèŠ‚ç‚¹
            completed_start_query = """
            SELECT ni.*, n.type as node_type, n.name as node_name, n.node_id
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1
            AND LOWER(n.type) = 'start'
            AND ni.status IN ('completed', 'COMPLETED')
            AND ni.is_deleted = FALSE
            AND n.is_deleted = FALSE
            ORDER BY ni.completed_at ASC
            """
            
            completed_start_nodes = await node_instance_repo.db.fetch_all(completed_start_query, workflow_instance_id)
            logger.trace(f"  - æ‰¾åˆ° {len(completed_start_nodes)} ä¸ªå·²å®Œæˆçš„STARTèŠ‚ç‚¹")
            
            # ååºåˆ—åŒ–JSONå­—æ®µ
            for i, node in enumerate(completed_start_nodes):
                completed_start_nodes[i] = node_instance_repo._deserialize_json_fields(dict(node))
            
            if not completed_start_nodes:
                logger.trace(f"  âŒ æ²¡æœ‰æ‰¾åˆ°å·²å®Œæˆçš„STARTèŠ‚ç‚¹")
                return
            
            for start_node in completed_start_nodes:
                node_instance_id = start_node['node_instance_id']
                node_id = start_node['node_id']
                node_name = start_node.get('node_name', 'æœªçŸ¥')
                output_data = start_node.get('output_data', {})
                
                logger.trace(f"  ğŸ“‹ å¤„ç†STARTèŠ‚ç‚¹: {node_name}")
                logger.trace(f"    - node_instance_id: {node_instance_id}")
                logger.trace(f"    - node_id: {node_id}")
                
                # æ£€æŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­æ˜¯å¦å·²ç»è®°å½•äº†è¿™ä¸ªèŠ‚ç‚¹çš„å®ŒæˆçŠ¶æ€
                dependency_info = self.context_manager.get_node_dependency_info(node_instance_id)
                if dependency_info:
                    logger.trace(f"    - èŠ‚ç‚¹ä¾èµ–ä¿¡æ¯å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦å·²åœ¨completed_nodesä¸­")
                    workflow_context = self.context_manager.workflow_contexts.get(workflow_instance_id, {})
                    completed_nodes = workflow_context.get('completed_nodes', set())
                    
                    if node_id not in completed_nodes:
                        logger.trace(f"  ğŸ”§ [STARTèŠ‚ç‚¹ä¿®å¤] STARTèŠ‚ç‚¹ {node_name} å·²å®Œæˆä½†æœªé€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œæ­£åœ¨ä¿®å¤...")
                        
                        # ç¡®ä¿output_dataåŒ…å«task_description
                        if isinstance(output_data, dict) and 'task_description' not in output_data:
                            # ä»èŠ‚ç‚¹å®šä¹‰ä¸­è·å–task_description
                            task_description = start_node.get('task_description', '')
                            if not task_description:
                                from ..repositories.node.node_repository import NodeRepository
                                node_repo = NodeRepository()
                                node_data = await node_repo.get_node_by_id(node_id)
                                if node_data:
                                    task_description = node_data.get('task_description', '')
                            
                            # ç¡®ä¿output_dataæ˜¯å­—å…¸ç±»å‹ï¼Œå¹¶æ·»åŠ task_description
                            if not isinstance(output_data, dict):
                                output_data = {}
                            output_data['task_description'] = task_description
                            logger.trace(f"    - è¡¥å……task_description: {task_description[:50]}...")
                        
                        # æ‰‹åŠ¨é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
                        await self.context_manager.mark_node_completed(
                            workflow_instance_id, 
                            node_id, 
                            node_instance_id, 
                            output_data
                        )
                        
                        logger.trace(f"  âœ… [STARTèŠ‚ç‚¹ä¿®å¤] å·²é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨STARTèŠ‚ç‚¹ {node_name} çš„å®ŒæˆçŠ¶æ€")
                    else:
                        logger.trace(f"  âœ… STARTèŠ‚ç‚¹ {node_name} å·²åœ¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­æ ‡è®°ä¸ºå®Œæˆ")
                else:
                    logger.warning(f"  âš ï¸ STARTèŠ‚ç‚¹ {node_name} çš„ä¾èµ–ä¿¡æ¯ä¸å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦é‡æ–°æ³¨å†Œ")
            
            logger.trace(f"âœ… [STARTèŠ‚ç‚¹ä¿®å¤] å·²å®Œæˆçš„STARTèŠ‚ç‚¹é€šçŸ¥æ£€æŸ¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ [STARTèŠ‚ç‚¹ä¿®å¤] ç¡®ä¿STARTèŠ‚ç‚¹é€šçŸ¥å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
    
    async def _check_and_trigger_ready_nodes(self, workflow_instance_id: uuid.UUID, pending_nodes: List[Dict]):
        """æ£€æŸ¥å¹¶è§¦å‘å‡†å¤‡å¥½çš„èŠ‚ç‚¹"""
        try:
            logger.trace(f"æ£€æŸ¥ {len(pending_nodes)} ä¸ªpendingèŠ‚ç‚¹çš„ä¾èµ–å…³ç³»")
            
            for node in pending_nodes:
                node_instance_id = node['node_instance_id']
                node_name = node.get('node_name', 'æœªçŸ¥')
                
                # æ£€æŸ¥èŠ‚ç‚¹ä¾èµ–æ˜¯å¦æ»¡è¶³
                if await self._check_node_dependencies_satisfied(workflow_instance_id, node_instance_id):
                    logger.trace(f"âœ… èŠ‚ç‚¹ {node_name} çš„ä¾èµ–å·²æ»¡è¶³ï¼Œè§¦å‘æ‰§è¡Œ")
                    await self._execute_node_when_ready(workflow_instance_id, node_instance_id)
                else:
                    logger.trace(f"â³ èŠ‚ç‚¹ {node_name} çš„ä¾èµ–å°šæœªæ»¡è¶³ï¼Œç­‰å¾…ä¸­")
                    
        except Exception as e:
            logger.error(f"æ£€æŸ¥å’Œè§¦å‘å‡†å¤‡å¥½çš„èŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
    
    # _collect_task_context_data æ–¹æ³•å·²è¢« WorkflowContextManager.get_task_context_data æ›¿æ¢

    async def _check_node_dependencies_satisfied(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹çš„ä¾èµ–æ˜¯å¦å·²æ»¡è¶³"""
        try:
            # è·å–èŠ‚ç‚¹çš„ä¸Šæ¸¸ä¾èµ–
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_instance_repo = NodeInstanceRepository()
            
            # ä½¿ç”¨ node_connection è¡¨æŸ¥è¯¢ä¸Šæ¸¸èŠ‚ç‚¹çš„çŠ¶æ€  
            dependency_query = """
            SELECT COUNT(*) as total_dependencies,
                   COUNT(CASE WHEN upstream_ni.status = 'completed' THEN 1 END) as completed_dependencies
            FROM node_connection nc
            JOIN node_instance ni ON nc.to_node_id = ni.node_id
            JOIN node_instance upstream_ni ON nc.from_node_id = upstream_ni.node_id
            WHERE ni.node_instance_id = $1
            AND ni.workflow_instance_id = $2
            AND upstream_ni.workflow_instance_id = $2
            AND ni.is_deleted = FALSE
            AND upstream_ni.is_deleted = FALSE
            """
            
            result = await node_instance_repo.db.fetch_one(dependency_query, node_instance_id, workflow_instance_id)
            
            if result:
                total_deps = result.get('total_dependencies', 0)
                completed_deps = result.get('completed_dependencies', 0)
                
                logger.trace(f"èŠ‚ç‚¹ {node_instance_id} ä¾èµ–æ£€æŸ¥: {completed_deps}/{total_deps} ä¸ªä¾èµ–å·²å®Œæˆ")
                
                # å¦‚æœæ²¡æœ‰ä¾èµ–æˆ–æ‰€æœ‰ä¾èµ–éƒ½å·²å®Œæˆï¼Œåˆ™èŠ‚ç‚¹å‡†å¤‡å¥½æ‰§è¡Œ
                return total_deps == 0 or completed_deps == total_deps
            else:
                # å¦‚æœæŸ¥è¯¢æ— ç»“æœï¼Œå‡è®¾æ²¡æœ‰ä¾èµ–ï¼ˆå¦‚èµ·å§‹èŠ‚ç‚¹ï¼‰
                logger.trace(f"èŠ‚ç‚¹ {node_instance_id} æ²¡æœ‰æ‰¾åˆ°ä¾èµ–ä¿¡æ¯ï¼Œå‡è®¾æ— ä¾èµ–")
                return True
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥èŠ‚ç‚¹ä¾èµ–å¤±è´¥: {e}")
            return False
    
    async def _execute_start_node_directly(self, workflow_instance_id: uuid.UUID, start_node: Dict[str, Any]):
        """ç›´æ¥æ‰§è¡ŒSTARTèŠ‚ç‚¹"""
        try:
            node_instance_id = start_node['node_instance_id']
            node_name = start_node.get('node_name', 'æœªçŸ¥')
            logger.trace(f"â–¶ï¸ å¼€å§‹ç›´æ¥æ‰§è¡ŒSTARTèŠ‚ç‚¹: {node_name} (ID: {node_instance_id})")
            
            # æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
            logger.trace(f"  æ­¥éª¤1: æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€ä¸º RUNNING")
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceUpdate, NodeInstanceStatus
            
            node_instance_repo = NodeInstanceRepository()
            
            # æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
            update_data = NodeInstanceUpdate(
                status=NodeInstanceStatus.RUNNING
            )
            await node_instance_repo.update_node_instance(node_instance_id, update_data)
            logger.trace(f"  âœ… èŠ‚ç‚¹çŠ¶æ€æ›´æ–°ä¸º RUNNING æˆåŠŸ")
            
            # STARTèŠ‚ç‚¹æ²¡æœ‰å®é™…ä»»åŠ¡ï¼Œç›´æ¥å®Œæˆï¼Œä½†è¦åŒ…å«task_descriptionä¾›ä¸‹æ¸¸ä½¿ç”¨
            logger.trace(f"  æ­¥éª¤2: STARTèŠ‚ç‚¹æ— å®é™…ä»»åŠ¡ï¼Œç›´æ¥æ ‡è®°ä¸º COMPLETED")
            
            # è·å–èŠ‚ç‚¹çš„task_description
            task_description = start_node.get('task_description', '')
            if not task_description:
                # å¦‚æœèŠ‚ç‚¹å®ä¾‹æ²¡æœ‰task_descriptionï¼Œä»èŠ‚ç‚¹å®šä¹‰ä¸­è·å–
                from ..repositories.node.node_repository import NodeRepository
                node_repo = NodeRepository()
                node_data = await node_repo.get_node_by_id(start_node['node_id'])
                if node_data:
                    task_description = node_data.get('task_description', '')
            
            completed_data = NodeInstanceUpdate(
                status=NodeInstanceStatus.COMPLETED,
                output_data={
                    'message': 'STARTèŠ‚ç‚¹è‡ªåŠ¨å®Œæˆ',
                    'task_description': task_description,  # æ·»åŠ task_descriptionä¾›ä¸‹æ¸¸èŠ‚ç‚¹ä½¿ç”¨
                    'completed_at': datetime.utcnow().isoformat()
                }
            )
            await node_instance_repo.update_node_instance(node_instance_id, completed_data)
            logger.trace(f"  âœ… èŠ‚ç‚¹çŠ¶æ€æ›´æ–°ä¸º COMPLETED æˆåŠŸ")
            
            # æ­¥éª¤3: é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨èŠ‚ç‚¹å®Œæˆ
            logger.trace(f"  æ­¥éª¤3: é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨STARTèŠ‚ç‚¹å®Œæˆ")
            node_instance_data = await node_instance_repo.get_instance_by_id(node_instance_id)
            if node_instance_data and self.context_manager:
                node_id = node_instance_data['node_id']
                output_data = completed_data.output_data
                
                logger.trace(f"    - é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨: node_id={node_id}")
                logger.trace(f"    - ä¼ é€’çš„output_dataç±»å‹: {type(output_data)}")
                logger.trace(f"    - ä¼ é€’çš„output_dataå†…å®¹: {output_data}")
                await self.context_manager.mark_node_completed(
                    workflow_instance_id, node_id, node_instance_id, output_data
                )
                logger.trace(f"    âœ… ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€šçŸ¥å®Œæˆ")
            else:
                logger.warning(f"    âš ï¸ æ— æ³•é€šçŸ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨: node_instance_data={node_instance_data is not None}, context_manager={self.context_manager is not None}")
            
            # è·å–ä¸‹æ¸¸èŠ‚ç‚¹å¹¶å¯åŠ¨æ‰§è¡Œï¼ˆè¿™ä¸ªæ–¹æ³•å¯èƒ½æ˜¯é‡å¤çš„ï¼Œä¸Šä¸‹æ–‡ç®¡ç†å™¨å·²ç»å¤„ç†äº†ï¼‰
            logger.trace(f"  æ­¥éª¤4: è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹æ‰§è¡Œï¼ˆé€šè¿‡_trigger_downstream_nodesï¼‰")
            await self._trigger_downstream_nodes(workflow_instance_id, start_node)
            logger.trace(f"  âœ… ä¸‹æ¸¸èŠ‚ç‚¹è§¦å‘å®Œæˆ")
            
            logger.trace(f"  âœ… STARTèŠ‚ç‚¹æ‰§è¡Œå®Œæˆ: {node_name} (ID: {node_instance_id})")
            
        except Exception as e:
            node_name = start_node.get('node_name', 'æœªçŸ¥')
            logger.error(f"âŒ æ‰§è¡ŒSTARTèŠ‚ç‚¹å¤±è´¥ {node_name}: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆè¯¦æƒ…: {traceback.format_exc()}")
            raise
    
    async def _trigger_downstream_nodes(self, workflow_instance_id: uuid.UUID, completed_node: Dict[str, Any]):
        """è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹æ‰§è¡Œ"""
        try:
            logger.trace(f"è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹æ‰§è¡Œï¼Œå·²å®ŒæˆèŠ‚ç‚¹: {completed_node.get('node_base_id')}")
            
            # 1. è·å–å·¥ä½œæµå®ä¾‹ä¸Šä¸‹æ–‡
            if self.instance_manager:
                context = await self.instance_manager.get_instance(workflow_instance_id)
                if context:
                    # ä½¿ç”¨æ–°æ¶æ„çš„ä¾èµ–ç®¡ç†
                    await self._trigger_downstream_nodes_new_architecture(workflow_instance_id, completed_node, context)
                else:
                    logger.warning(f"æœªæ‰¾åˆ°å·¥ä½œæµå®ä¾‹ä¸Šä¸‹æ–‡: {workflow_instance_id}")
            
            # 2. ä½¿ç”¨æ—§æ¶æ„çš„ä¾èµ–ç®¡ç†ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰
            # await self._trigger_downstream_nodes_legacy(workflow_instance_id, completed_node)
            
        except Exception as e:
            logger.error(f"è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    async def _execute_node_when_ready(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """å½“èŠ‚ç‚¹å‡†å¤‡å¥½æ—¶æ‰§è¡ŒèŠ‚ç‚¹"""
        try:
            logger.trace(f"ğŸš€ [èŠ‚ç‚¹æ‰§è¡Œ] å¼€å§‹æ‰§è¡ŒèŠ‚ç‚¹: {node_instance_id}")
            logger.trace(f"  - å·¥ä½œæµå®ä¾‹: {workflow_instance_id}")
            
            # é¦–å…ˆæ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å·²ç»å®Œæˆæˆ–æ­£åœ¨æ‰§è¡Œï¼Œé˜²æ­¢é‡å¤æ‰§è¡Œ
            node_status = self.context_manager.node_completion_status.get(node_instance_id)
            if node_status in ['COMPLETED', 'EXECUTING']:
                logger.warning(f"ğŸ”„ [èŠ‚ç‚¹æ‰§è¡Œ-é˜²é‡å¤] èŠ‚ç‚¹ {node_instance_id} çŠ¶æ€ä¸º {node_status}ï¼Œè·³è¿‡é‡å¤æ‰§è¡Œ")
                return
            
            # æ ‡è®°èŠ‚ç‚¹ä¸ºæ‰§è¡Œä¸­çŠ¶æ€
            self.context_manager.node_completion_status[node_instance_id] = 'EXECUTING'
            logger.trace(f"  - èŠ‚ç‚¹çŠ¶æ€å·²æ ‡è®°ä¸º: EXECUTING")
            
            # é¦–å…ˆæ£€æŸ¥å·¥ä½œæµä¸Šä¸‹æ–‡æ˜¯å¦ä»ç„¶å­˜åœ¨
            if workflow_instance_id not in self.context_manager.workflow_contexts:
                logger.warning(f"âŒ [èŠ‚ç‚¹æ‰§è¡Œ] å·¥ä½œæµä¸Šä¸‹æ–‡ {workflow_instance_id} å·²è¢«æ¸…ç†ï¼ŒèŠ‚ç‚¹æ‰§è¡Œå–æ¶ˆ")
                # æ¢å¤çŠ¶æ€ä¸ºPENDING
                self.context_manager.node_completion_status[node_instance_id] = 'PENDING'
                return
            
            # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å‡†å¤‡å¥½æ‰§è¡Œ
            is_ready = self.context_manager.is_node_ready_to_execute(node_instance_id)
            logger.trace(f"  - èŠ‚ç‚¹å°±ç»ªçŠ¶æ€æ£€æŸ¥: {is_ready}")
            
            if not is_ready:
                logger.warning(f"âŒ [èŠ‚ç‚¹æ‰§è¡Œ] èŠ‚ç‚¹ {node_instance_id} å°šæœªå‡†å¤‡å¥½æ‰§è¡Œ")
                # æ¢å¤çŠ¶æ€ä¸ºPENDING
                self.context_manager.node_completion_status[node_instance_id] = 'PENDING'
                return
            
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            dep_info = self.context_manager.get_node_dependency_info(node_instance_id)
            logger.trace(f"  - ä¾èµ–ä¿¡æ¯è·å–: {'æˆåŠŸ' if dep_info else 'å¤±è´¥'}")
            
            if not dep_info:
                logger.error(f"âŒ [èŠ‚ç‚¹æ‰§è¡Œ] æ— æ³•è·å–èŠ‚ç‚¹ {node_instance_id} çš„ä¾èµ–ä¿¡æ¯")
                return
            
            node_id = dep_info.get('node_id')  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
            logger.trace(f"  - èŠ‚ç‚¹ID: {node_id}")
            logger.trace(f"  - ä¾èµ–æ•°é‡: {dep_info.get('dependency_count', 0)}")
            logger.trace(f"  - å·²å®Œæˆä¸Šæ¸¸: {len(dep_info.get('completed_upstream', set()))}")
            
            # æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
            logger.trace(f"ğŸ“ [èŠ‚ç‚¹æ‰§è¡Œ] æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ...")
            await self.context_manager.mark_node_executing(
                workflow_instance_id, node_id, node_instance_id  # ä½¿ç”¨node_id
            )
            
            # è·å–èŠ‚ç‚¹çš„ä¸Šæ¸¸ä¸Šä¸‹æ–‡
            logger.trace(f"ğŸ” [èŠ‚ç‚¹æ‰§è¡Œ] æ”¶é›†ä¸Šæ¸¸ä¸Šä¸‹æ–‡æ•°æ®...")
            upstream_context = await self.context_manager.get_node_upstream_context(
                workflow_instance_id, node_instance_id
            )
            logger.trace(f"  - ä¸Šæ¸¸ç»“æœæ•°é‡: {len(upstream_context.get('immediate_upstream_results', {}))}")
            
            # æ›´æ–°èŠ‚ç‚¹çš„ä»»åŠ¡å®ä¾‹ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡æ•°æ®
            logger.trace(f"ğŸ“ [èŠ‚ç‚¹æ‰§è¡Œ] æ›´æ–°ä»»åŠ¡ä¸Šä¸‹æ–‡æ•°æ®...")
            await self._update_node_tasks_with_context(node_instance_id, upstream_context)
            
            # æ‰§è¡ŒèŠ‚ç‚¹çš„ä»»åŠ¡
            logger.trace(f"âš¡ [èŠ‚ç‚¹æ‰§è¡Œ] å¼€å§‹æ‰§è¡ŒèŠ‚ç‚¹ä»»åŠ¡...")
            await self._execute_node_tasks(workflow_instance_id, node_instance_id)
            
            logger.trace(f"âœ… [èŠ‚ç‚¹æ‰§è¡Œ] èŠ‚ç‚¹ {node_instance_id} æ‰§è¡Œæµç¨‹å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ [èŠ‚ç‚¹æ‰§è¡Œ] æ‰§è¡ŒèŠ‚ç‚¹ {node_instance_id} å¤±è´¥: {e}")
            import traceback
            logger.error(f"  å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            
            # æ ‡è®°èŠ‚ç‚¹å¤±è´¥
            dep_info = self.context_manager.get_node_dependency_info(node_instance_id)
            if dep_info:
                node_id = dep_info.get('node_id', dep_info.get('node_base_id'))  # å…¼å®¹å¤„ç†
                await self.context_manager.mark_node_failed(
                    workflow_instance_id, 
                    node_id, 
                    node_instance_id,
                    {'error': str(e)}
                )
    
    async def _update_node_tasks_with_context(self, node_instance_id: uuid.UUID, upstream_context: Dict[str, Any]):
        """æ›´æ–°èŠ‚ç‚¹ä»»åŠ¡çš„ä¸Šä¸‹æ–‡æ•°æ®ï¼Œå¹¶åŒæ­¥æ›´æ–°èŠ‚ç‚¹çš„è¾“å…¥æ•°æ®"""
        try:
            # æ„å»ºå®Œæ•´çš„ä»»åŠ¡ä¸Šä¸‹æ–‡ - ä¿®å¤æ•°æ®æ ¼å¼è½¬æ¢é—®é¢˜
            immediate_upstream_results = upstream_context.get('immediate_upstream_results', {})
            logger.trace(f"ğŸ”„ [æ•°æ®æ ¼å¼è½¬æ¢] åŸå§‹ä¸Šæ¸¸ç»“æœ: {immediate_upstream_results}")
            
            task_context = {
                'immediate_upstream': immediate_upstream_results,  # ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨immediate_upstream_results
                'workflow_global': upstream_context.get('workflow_global', {}),
                'node_info': {
                    'node_instance_id': str(node_instance_id),
                    'upstream_node_count': upstream_context.get('upstream_node_count', 0)
                }
            }
            
            logger.trace(f"ğŸ”„ [æ•°æ®æ ¼å¼è½¬æ¢] æœ€ç»ˆä»»åŠ¡ä¸Šä¸‹æ–‡åŒ…å« {len(immediate_upstream_results)} ä¸ªä¸Šæ¸¸èŠ‚ç‚¹æ•°æ®")
            
            # é¦–å…ˆæ›´æ–°èŠ‚ç‚¹å®ä¾‹çš„è¾“å…¥æ•°æ®ï¼ˆç”¨äºå‰ç«¯æ˜¾ç¤ºï¼‰
            logger.trace(f"ğŸ“ [èŠ‚ç‚¹ä¸Šä¸‹æ–‡] æ›´æ–°èŠ‚ç‚¹ {node_instance_id} çš„è¾“å…¥æ•°æ®")
            logger.trace(f"   - ä¸Šæ¸¸ç»“æœæ•°é‡: {len(task_context.get('immediate_upstream', {}))}")
            logger.trace(f"   - å·¥ä½œæµå…¨å±€æ•°æ®: {len(task_context.get('workflow_global', {}).get('global_data', {}))}")
            
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceUpdate
            node_instance_repo = NodeInstanceRepository()
            
            node_update = NodeInstanceUpdate(input_data=task_context)
            await node_instance_repo.update_node_instance(node_instance_id, node_update)
            logger.trace(f"   âœ… èŠ‚ç‚¹è¾“å…¥æ•°æ®å·²æ›´æ–°ï¼šåŒ…å« {len(task_context)} ä¸ªé¡¶çº§å­—æ®µ")
            
            # ç„¶åè·å–èŠ‚ç‚¹çš„æ‰€æœ‰ä»»åŠ¡å¹¶æ›´æ–°å®ƒä»¬çš„ä¸Šä¸‹æ–‡
            tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
            
            for task in tasks:
                
                # å°†ä¸Šä¸‹æ–‡è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²ï¼ˆæ•°æ®åº“input_dataå­—æ®µæ˜¯TEXTç±»å‹ï¼‰
                from ..utils.helpers import safe_json_dumps
                task_context_json = safe_json_dumps(task_context)
                
                # æ›´æ–°ä»»åŠ¡çš„è¾“å…¥æ•°æ®ï¼ˆä½†ä¸æ”¹å˜å·²å®Œæˆæˆ–å¤±è´¥ä»»åŠ¡çš„çŠ¶æ€ï¼‰
                current_status = task.get('status', 'PENDING')
                
                # åªæœ‰PENDINGçŠ¶æ€çš„ä»»åŠ¡æ‰éœ€è¦æ›´æ–°çŠ¶æ€
                if current_status == 'PENDING':
                    new_status = TaskInstanceStatus.ASSIGNED if task.get('assigned_user_id') or task.get('assigned_agent_id') else TaskInstanceStatus.PENDING
                    update_data = TaskInstanceUpdate(
                        input_data=task_context_json,
                        status=new_status
                    )
                    logger.warning(f"ä»»åŠ¡ {task['task_instance_id']} çŠ¶æ€æ›´æ–°: {current_status} â†’ {new_status.value}")
                    logger.warning(f"ä»»åŠ¡ {task['task_instance_id']} ä¸Šä¸‹æ–‡æ•°æ®: {len(task_context_json)} å­—ç¬¦")
                else:
                    # å·²å®Œæˆ/å¤±è´¥/è¿›è¡Œä¸­çš„ä»»åŠ¡åªæ›´æ–°ä¸Šä¸‹æ–‡ï¼Œä¸æ”¹å˜çŠ¶æ€
                    update_data = TaskInstanceUpdate(
                        input_data=task_context_json
                    )
                    logger.warning(f"ä»»åŠ¡ {task['task_instance_id']} çŠ¶æ€ä¿æŒ: {current_status}ï¼ˆä»…æ›´æ–°ä¸Šä¸‹æ–‡ï¼‰")
                    logger.warning(f"ä»»åŠ¡ {task['task_instance_id']} ä¸Šä¸‹æ–‡æ•°æ®: {len(task_context_json)} å­—ç¬¦")
                
                await self.task_instance_repo.update_task(task['task_instance_id'], update_data)
                logger.warning(f"æ›´æ–°ä»»åŠ¡ {task['task_instance_id']} çš„ä¸Šä¸‹æ–‡æ•°æ®")
                
        except Exception as e:
            logger.error(f"æ›´æ–°èŠ‚ç‚¹ä»»åŠ¡ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            raise
    
    async def _execute_node_tasks(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """æ‰§è¡ŒèŠ‚ç‚¹çš„ä»»åŠ¡"""
        try:
            # è·å–èŠ‚ç‚¹çš„æ‰€æœ‰ä»»åŠ¡
            tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
            
            if not tasks:
                # è·å–èŠ‚ç‚¹ä¿¡æ¯åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ›å»ºä»»åŠ¡
                from ..repositories.instance.node_instance_repository import NodeInstanceRepository
                node_repo = NodeInstanceRepository()
                node_instance_data = await node_repo.get_instance_by_id(node_instance_id)
                
                if not node_instance_data:
                    logger.error(f"æ— æ³•è·å–èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯: {node_instance_id}")
                    return
                
                # è·å–èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
                node_query = """
                SELECT n.*, ni.workflow_instance_id
                FROM node n 
                JOIN node_instance ni ON n.node_id = ni.node_id
                WHERE ni.node_instance_id = $1
                """
                node_info = await self.task_instance_repo.db.fetch_one(node_query, node_instance_id)
                
                if not node_info:
                    logger.error(f"æ— æ³•è·å–èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯: {node_instance_id}")
                    return
                
                # å¦‚æœæ˜¯PROCESSORèŠ‚ç‚¹ä½†æ²¡æœ‰ä»»åŠ¡ï¼Œéœ€è¦å…ˆåˆ›å»ºä»»åŠ¡ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                if node_info['type'].upper() == 'PROCESSOR':
                    logger.trace(f"ğŸ”§ PROCESSORèŠ‚ç‚¹ {node_info['name']} æ²¡æœ‰ä»»åŠ¡ï¼Œå¼€å§‹åˆ›å»ºä»»åŠ¡...")
                    
                    # æ„é€ èŠ‚ç‚¹æ•°æ®ç”¨äºä»»åŠ¡åˆ›å»º
                    created_node = {
                        'node_instance_id': node_instance_id,
                        'node_type': node_info['type'],
                        'node_data': {
                            'node_id': node_info['node_id'],
                            'name': node_info['name'],
                            'description': node_info.get('description', ''),
                            'task_description': node_info.get('task_description', ''),
                            'input_data': {}
                        }
                    }
                    
                    logger.trace(f"ğŸ“‹ å¼€å§‹ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡ï¼ŒèŠ‚ç‚¹æ•°æ®: {created_node}")
                    
                    try:
                        # ä¸ºè¿™ä¸ªèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
                        await self._create_tasks_for_nodes([created_node], workflow_instance_id)
                        logger.trace(f"âœ… èŠ‚ç‚¹ {node_info['name']} ä»»åŠ¡åˆ›å»ºå®Œæˆ")
                    except Exception as task_creation_error:
                        logger.error(f"âŒ èŠ‚ç‚¹ {node_info['name']} ä»»åŠ¡åˆ›å»ºå¤±è´¥: {task_creation_error}")
                        import traceback
                        logger.error(f"ä»»åŠ¡åˆ›å»ºé”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                        # ç»§ç»­æ‰§è¡Œï¼Œä½†å¯èƒ½æ— æ³•æ‰¾åˆ°ä»»åŠ¡
                    
                    # é‡æ–°è·å–ä»»åŠ¡
                    tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
                    
                    if not tasks:
                        logger.error(f"âŒ PROCESSORèŠ‚ç‚¹ {node_info['name']} ä»»åŠ¡åˆ›å»ºå¤±è´¥ï¼Œæ²¡æœ‰é…ç½®å¤„ç†å™¨")
                        await self._complete_node_without_tasks(workflow_instance_id, node_instance_id)
                        return
                else:
                    # å¦‚æœæ˜¯STARTæˆ–ENDèŠ‚ç‚¹ç­‰éPROCESSORèŠ‚ç‚¹ï¼Œç›´æ¥æ ‡è®°å®Œæˆ
                    logger.trace(f"â­ï¸ éPROCESSORèŠ‚ç‚¹ {node_info.get('name', 'Unknown')} æ²¡æœ‰ä»»åŠ¡ï¼Œç›´æ¥æ ‡è®°å®Œæˆ")
                    await self._complete_node_without_tasks(workflow_instance_id, node_instance_id)
                    return
            
            # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            for task in tasks:
                if task['task_type'] == TaskInstanceType.AGENT.value:
                    # Agentä»»åŠ¡ï¼šæäº¤ç»™AgentTaskServiceå¤„ç†
                    await self._execute_agent_task(task)
                elif task['task_type'] == TaskInstanceType.HUMAN.value:
                    # Humanä»»åŠ¡ï¼šè°ƒç”¨_execute_taskæ–¹æ³•å¤„ç†ï¼ˆåŒ…å«ç”¨æˆ·é€šçŸ¥ï¼‰
                    await self._execute_task(task)
                    logger.trace(f"Humanä»»åŠ¡ {task['task_instance_id']} å·²åˆ†é…å¹¶é€šçŸ¥ç”¨æˆ·")
                elif task['task_type'] == TaskInstanceType.MIXED.value:
                    # Mixedä»»åŠ¡ï¼šå…ˆåˆ†é…ç»™ç”¨æˆ·ï¼ŒåŒæ—¶æä¾›AIè¾…åŠ©
                    await self._execute_mixed_task(task)
            
            # æ³¨å†Œä»»åŠ¡å®Œæˆç›‘å¬
            await self._register_node_completion_monitor(workflow_instance_id, node_instance_id)
            
        except Exception as e:
            logger.error(f"æ‰§è¡ŒèŠ‚ç‚¹ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _complete_node_without_tasks(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """å®Œæˆæ²¡æœ‰ä»»åŠ¡çš„èŠ‚ç‚¹ï¼ˆå¦‚STARTã€ENDèŠ‚ç‚¹ï¼‰"""
        try:
            from datetime import datetime as dt
            from ..models.instance import NodeInstanceStatus, NodeInstanceUpdate
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            
            # è·å–node_idç”¨äºæ ‡è®°å®Œæˆ
            node_repo = NodeInstanceRepository()
            node_instance_data = await node_repo.get_instance_by_id(node_instance_id)
            if not node_instance_data:
                logger.error(f"æ— æ³•æ‰¾åˆ°èŠ‚ç‚¹å®ä¾‹: {node_instance_id}")
                return
            
            node_id = node_instance_data['node_id']
            
            # æ ‡è®°èŠ‚ç‚¹å®Œæˆ
            output_data = {
                'completed_at': dt.utcnow().isoformat(),
                'node_type': 'system',
                'message': 'ç³»ç»ŸèŠ‚ç‚¹è‡ªåŠ¨å®Œæˆ'
            }
            
            await self.context_manager.mark_node_completed(
                workflow_instance_id, node_id, node_instance_id, output_data
            )
            
            # åŒæ—¶æ›´æ–°æ•°æ®åº“ä¸­çš„èŠ‚ç‚¹å®ä¾‹çŠ¶æ€
            try:
                node_repo = NodeInstanceRepository()
                node_update = NodeInstanceUpdate(
                    status=NodeInstanceStatus.COMPLETED,
                    output_data=output_data,
                    completed_at=dt.utcnow()
                )
                await node_repo.update_node_instance(node_instance_id, node_update)
                logger.trace(f"ğŸ’¾ [ç³»ç»ŸèŠ‚ç‚¹] èŠ‚ç‚¹å®ä¾‹ {node_instance_id} æ•°æ®åº“çŠ¶æ€å·²æ›´æ–°ä¸ºCOMPLETED")
            except Exception as e:
                logger.error(f"âŒ [ç³»ç»ŸèŠ‚ç‚¹] æ›´æ–°èŠ‚ç‚¹å®ä¾‹æ•°æ®åº“çŠ¶æ€å¤±è´¥: {e}")
            
            logger.trace(f"âœ… ç³»ç»ŸèŠ‚ç‚¹ {node_id} è‡ªåŠ¨å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å®Œæˆç³»ç»ŸèŠ‚ç‚¹å¤±è´¥: {e}")
            raise
    
    async def _execute_agent_task(self, task: Dict[str, Any]):
        """æ‰§è¡ŒAgentä»»åŠ¡"""
        try:
            task_id = task['task_instance_id']
            logger.trace(f"ğŸš€ [EXECUTION-ENGINE] å¼€å§‹æ‰§è¡ŒAgentä»»åŠ¡: {task_id}")
            logger.trace(f"   - ä»»åŠ¡æ ‡é¢˜: {task.get('task_title', 'unknown')}")
            logger.trace(f"   - ä»»åŠ¡ç±»å‹: {task.get('task_type', 'unknown')}")
            logger.trace(f"   - å½“å‰çŠ¶æ€: {task.get('status', 'unknown')}")
            logger.trace(f"   - åˆ†é…Agent: {task.get('assigned_agent_id', 'none')}")
            logger.trace(f"   - å¤„ç†å™¨ID: {task.get('processor_id', 'none')}")
            
            # è°ƒç”¨AgentTaskServiceå¤„ç†ä»»åŠ¡
            logger.trace(f"ğŸ”„ [EXECUTION-ENGINE] è°ƒç”¨AgentTaskServiceå¤„ç†ä»»åŠ¡")
            await agent_task_service.process_agent_task(task_id)
            
            logger.trace(f"âœ… [EXECUTION-ENGINE] Agentä»»åŠ¡æ‰§è¡Œå®Œæˆ: {task_id}")
            
        except Exception as e:
            logger.error(f"âŒ [EXECUTION-ENGINE] æ‰§è¡ŒAgentä»»åŠ¡ {task['task_instance_id']} å¤±è´¥: {e}")
            import traceback
            logger.error(f"   - é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def _execute_mixed_task(self, task: Dict[str, Any]):
        """æ‰§è¡ŒMixedä»»åŠ¡ï¼ˆäººæœºåä½œï¼‰"""
        try:
            # Mixedä»»åŠ¡åˆ†é…ç»™ç”¨æˆ·ï¼ŒåŒæ—¶å¯åŠ¨AIè¾…åŠ©
            task_id = task['task_instance_id']
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºASSIGNEDï¼ˆåˆ†é…ç»™ç”¨æˆ·ï¼‰
            update_data = TaskInstanceUpdate(status=TaskInstanceStatus.ASSIGNED)
            await self.task_instance_repo.update_task(task_id, update_data)
            
            # å¯åŠ¨AIè¾…åŠ©ï¼ˆå¯é€‰ï¼‰
            asyncio.create_task(self._provide_ai_assistance(task))
            
            logger.trace(f"Mixedä»»åŠ¡ {task_id} å·²åˆ†é…ç»™ç”¨æˆ·ï¼ŒAIè¾…åŠ©å·²å¯åŠ¨")
            
        except Exception as e:
            logger.error(f"æ‰§è¡ŒMixedä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _provide_ai_assistance(self, task: Dict[str, Any]):
        """ä¸ºMixedä»»åŠ¡æä¾›AIè¾…åŠ©"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°AIè¾…åŠ©é€»è¾‘
            # ä¾‹å¦‚ï¼šåˆ†æä»»åŠ¡å†…å®¹ï¼Œæä¾›å»ºè®®ç­‰
            logger.trace(f"ä¸ºä»»åŠ¡ {task['task_instance_id']} æä¾›AIè¾…åŠ©")
            
        except Exception as e:
            logger.error(f"æä¾›AIè¾…åŠ©å¤±è´¥: {e}")
    
    async def _register_node_completion_monitor(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """æ³¨å†ŒèŠ‚ç‚¹å®Œæˆç›‘å¬å™¨ï¼ˆé˜²é‡å¤ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ´»è·ƒçš„ç›‘å¬å™¨
            if node_instance_id in self.active_monitors:
                logger.warning(f"ğŸ”„ [ç›‘å¬å™¨æ³¨å†Œ-é˜²é‡å¤] èŠ‚ç‚¹ {node_instance_id} å·²æœ‰æ´»è·ƒç›‘å¬å™¨ï¼Œè·³è¿‡é‡å¤æ³¨å†Œ")
                return
            
            logger.trace(f"ğŸ“‹ [ç›‘å¬å™¨æ³¨å†Œ] ä¸ºèŠ‚ç‚¹ {node_instance_id} æ³¨å†Œå®Œæˆç›‘å¬å™¨")
            logger.trace(f"   - å·¥ä½œæµå®ä¾‹: {workflow_instance_id}")
            
            # æ·»åŠ åˆ°æ´»è·ƒç›‘å¬å™¨é›†åˆ
            self.active_monitors.add(node_instance_id)
            
            # å¯åŠ¨èŠ‚ç‚¹å®Œæˆç›‘å¬åç¨‹
            task = asyncio.create_task(self._monitor_node_completion(workflow_instance_id, node_instance_id))
            logger.trace(f"âœ… [ç›‘å¬å™¨æ³¨å†Œ] èŠ‚ç‚¹ {node_instance_id} ç›‘å¬åç¨‹å·²å¯åŠ¨")
            
        except Exception as e:
            logger.error(f"âŒ [ç›‘å¬å™¨æ³¨å†Œ] æ³¨å†ŒèŠ‚ç‚¹å®Œæˆç›‘å¬å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _monitor_node_completion(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """ç›‘å¬èŠ‚ç‚¹å®Œæˆ"""
        try:
            logger.trace(f"ğŸ” [èŠ‚ç‚¹ç›‘å¬] å¼€å§‹ç›‘å¬èŠ‚ç‚¹å®Œæˆ: {node_instance_id}")
            
            while True:
                # æ£€æŸ¥èŠ‚ç‚¹çš„æ‰€æœ‰ä»»åŠ¡æ˜¯å¦å®Œæˆ
                tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
                
                if not tasks:
                    logger.trace(f"âš ï¸ [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} æ²¡æœ‰ä»»åŠ¡ï¼Œåœæ­¢ç›‘å¬")
                    break
                
                completed_tasks = [t for t in tasks if t['status'] == TaskInstanceStatus.COMPLETED.value]
                failed_tasks = [t for t in tasks if t['status'] == TaskInstanceStatus.FAILED.value]
                
                logger.trace(f"ğŸ“Š [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} ä»»åŠ¡çŠ¶æ€:")
                logger.trace(f"   - æ€»ä»»åŠ¡æ•°: {len(tasks)}")
                logger.trace(f"   - å·²å®Œæˆ: {len(completed_tasks)}")
                logger.trace(f"   - å¤±è´¥: {len(failed_tasks)}")
                
                # æ˜¾ç¤ºæ¯ä¸ªä»»åŠ¡çš„è¯¦ç»†çŠ¶æ€
                for i, task in enumerate(tasks):
                    task_id = task.get('task_instance_id', 'unknown')
                    task_status = task.get('status', 'unknown')
                    task_title = task.get('task_title', 'unknown')
                    logger.trace(f"   - ä»»åŠ¡{i+1}: {task_title} (ID: {task_id}) - çŠ¶æ€: {task_status}")
                
                if len(completed_tasks) == len(tasks):
                    # æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œæ ‡è®°èŠ‚ç‚¹å®Œæˆ
                    logger.trace(f"ğŸ‰ [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œå¼€å§‹æ ‡è®°èŠ‚ç‚¹å®Œæˆ")
                    output_data = await self._aggregate_node_output(completed_tasks)
                    
                    # æ£€æŸ¥context manageræ˜¯å¦å¯ç”¨
                    if self.context_manager is None:
                        logger.error(f"âŒ [èŠ‚ç‚¹ç›‘å¬] context_manager ä¸º Noneï¼Œæ— æ³•æ ‡è®°èŠ‚ç‚¹å®Œæˆ")
                        break
                    
                    # è·å–node_idç”¨äºä¾èµ–åŒ¹é…ï¼Œå› ä¸ºä¾èµ–å…³ç³»æ˜¯åŸºäºnode_idæ³¨å†Œçš„
                    from ..repositories.instance.node_instance_repository import NodeInstanceRepository
                    node_repo = NodeInstanceRepository()
                    node_instance_data = await node_repo.get_instance_by_id(node_instance_id)
                    node_id = node_instance_data['node_id'] if node_instance_data else None
                    
                    if node_id:
                        logger.trace(f"ğŸ¯ [èŠ‚ç‚¹ç›‘å¬] æ ‡è®°èŠ‚ç‚¹å®Œæˆ: node_id={node_id}")
                        await self.context_manager.mark_node_completed(
                            workflow_instance_id, node_id, node_instance_id, output_data
                        )
                    else:
                        logger.error(f"âŒ [èŠ‚ç‚¹ç›‘å¬] æ— æ³•è·å–node_idï¼Œæ— æ³•æ ‡è®°èŠ‚ç‚¹å®Œæˆ")
                        break
                    
                    # åŒæ—¶æ›´æ–°æ•°æ®åº“ä¸­çš„èŠ‚ç‚¹å®ä¾‹çŠ¶æ€
                    try:
                        from datetime import datetime
                        from ..models.instance import NodeInstanceStatus, NodeInstanceUpdate
                        from ..repositories.instance.node_instance_repository import NodeInstanceRepository
                        
                        node_repo = NodeInstanceRepository()
                        node_update = NodeInstanceUpdate(
                            status=NodeInstanceStatus.COMPLETED,
                            output_data=output_data,
                            completed_at=datetime.utcnow()
                        )
                        await node_repo.update_node_instance(node_instance_id, node_update)
                        logger.trace(f"ğŸ’¾ [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹å®ä¾‹ {node_instance_id} æ•°æ®åº“çŠ¶æ€å·²æ›´æ–°ä¸ºCOMPLETED")
                    except Exception as e:
                        logger.error(f"âŒ [èŠ‚ç‚¹ç›‘å¬] æ›´æ–°èŠ‚ç‚¹å®ä¾‹æ•°æ®åº“çŠ¶æ€å¤±è´¥: {e}")
                    
                    logger.trace(f"âœ… [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} å·²æ ‡è®°ä¸ºå®Œæˆï¼Œåœæ­¢ç›‘å¬")
                    # ä»æ´»è·ƒç›‘å¬å™¨é›†åˆä¸­ç§»é™¤
                    self.active_monitors.discard(node_instance_id)
                    break
                elif len(failed_tasks) > 0:
                    # æœ‰ä»»åŠ¡å¤±è´¥ï¼Œæ ‡è®°èŠ‚ç‚¹å¤±è´¥
                    logger.error(f"âŒ [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} æœ‰ä»»åŠ¡å¤±è´¥ï¼Œæ ‡è®°èŠ‚ç‚¹å¤±è´¥")
                    error_info = {'failed_tasks': [str(t['task_instance_id']) for t in failed_tasks]}
                    
                    # è·å–node_idç”¨äºæ ‡è®°å¤±è´¥
                    from ..repositories.instance.node_instance_repository import NodeInstanceRepository
                    node_repo = NodeInstanceRepository()
                    node_instance_data = await node_repo.get_instance_by_id(node_instance_id)
                    node_id = node_instance_data['node_id'] if node_instance_data else None
                    
                    if node_id:
                        await self.context_manager.mark_node_failed(
                            workflow_instance_id, node_id, node_instance_id, error_info
                        )
                    else:
                        logger.error(f"âŒ [èŠ‚ç‚¹ç›‘å¬] æ— æ³•è·å–node_idï¼Œæ— æ³•æ ‡è®°èŠ‚ç‚¹å¤±è´¥")
                    # ä»æ´»è·ƒç›‘å¬å™¨é›†åˆä¸­ç§»é™¤
                    self.active_monitors.discard(node_instance_id)
                    break
                
                # ç­‰å¾…5ç§’åå†æ¬¡æ£€æŸ¥
                logger.trace(f"â³ [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} ä»æœ‰ä»»åŠ¡æœªå®Œæˆï¼Œ5ç§’åå†æ¬¡æ£€æŸ¥")
                await asyncio.sleep(5)
                
        except Exception as e:
            logger.error(f"ç›‘å¬èŠ‚ç‚¹å®Œæˆå¤±è´¥: {e}")
            # å¼‚å¸¸æ—¶ä¹Ÿè¦ä»æ´»è·ƒç›‘å¬å™¨é›†åˆä¸­ç§»é™¤
            self.active_monitors.discard(node_instance_id)
        finally:
            # ç¡®ä¿ç›‘å¬å™¨è¢«æ¸…ç†
            self.active_monitors.discard(node_instance_id)
            logger.trace(f"ğŸ§¹ [èŠ‚ç‚¹ç›‘å¬] èŠ‚ç‚¹ {node_instance_id} ç›‘å¬å™¨å·²æ¸…ç†")
    
    def _make_json_serializable(self, obj):
        """å°†å¯¹è±¡è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–çš„å½¢å¼"""
        if isinstance(obj, uuid.UUID):
            return str(obj)
        elif isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, dict):
            return {k: self._make_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        else:
            return obj

    async def _aggregate_node_output(self, completed_tasks: List[Dict]) -> Dict[str, Any]:
        """èšåˆèŠ‚ç‚¹çš„è¾“å‡ºæ•°æ®"""
        try:
            aggregated = {
                'task_count': len(completed_tasks),
                'completed_at': datetime.utcnow().isoformat(),
                'task_results': []
            }
            
            combined_output = {}
            
            for task_index, task in enumerate(completed_tasks):
                task_result = {
                    'task_id': str(task['task_instance_id']),  # è½¬æ¢UUIDä¸ºå­—ç¬¦ä¸²
                    'task_title': task.get('task_title', ''),
                    'output_data': task.get('output_data', ''),  # ç°åœ¨æ˜¯æ–‡æœ¬æ ¼å¼
                    'result_summary': task.get('result_summary', '')
                }
                aggregated['task_results'].append(task_result)
                
                # åˆå¹¶ä»»åŠ¡è¾“å‡ºæ•°æ®ï¼ˆç°åœ¨æ˜¯æ–‡æœ¬æ ¼å¼ï¼‰
                if task.get('output_data'):
                    output_data = task['output_data']
                    # ä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºä¸€ä¸ªé”®å€¼å¯¹
                    task_key = f"task_{task_index + 1}_output"
                    combined_output[task_key] = str(output_data)
            
            aggregated['combined_output'] = combined_output
            
            return self._make_json_serializable(aggregated)
            
        except Exception as e:
            logger.error(f"èšåˆèŠ‚ç‚¹è¾“å‡ºå¤±è´¥: {e}")
            return {'error': str(e)}
    
    async def _on_nodes_ready_to_execute(self, workflow_instance_id: uuid.UUID, ready_node_instance_ids: List[uuid.UUID]):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å›è°ƒï¼šæœ‰èŠ‚ç‚¹å‡†å¤‡æ‰§è¡Œ"""
        try:
            logger.trace(f"å·¥ä½œæµ {workflow_instance_id} ä¸­æœ‰ {len(ready_node_instance_ids)} ä¸ªèŠ‚ç‚¹å‡†å¤‡æ‰§è¡Œ")
            
            # æ‰§è¡Œå‡†å¤‡å¥½çš„èŠ‚ç‚¹
            for node_instance_id in ready_node_instance_ids:
                await self._execute_node_when_ready(workflow_instance_id, node_instance_id)
                
        except Exception as e:
            logger.error(f"æ‰§è¡Œå‡†å¤‡å¥½çš„èŠ‚ç‚¹å¤±è´¥: {e}")
    
    async def _log_task_assignment_event(self, task_id: uuid.UUID, assigned_user_id: Optional[uuid.UUID], task_title: str):
        """è®°å½•ä»»åŠ¡åˆ†é…äº‹ä»¶"""
        try:
            event_data = {
                'event_type': 'task_assigned',
                'task_id': str(task_id),
                'assigned_user_id': str(assigned_user_id) if assigned_user_id else None,
                'task_title': task_title,
                'timestamp': now_utc().isoformat(),
                'status': 'success'
            }
            
            # è¿™é‡Œå¯ä»¥è®°å½•åˆ°äº‹ä»¶æ—¥å¿—è¡¨æˆ–å‘é€åˆ°æ¶ˆæ¯é˜Ÿåˆ—
            logger.trace(f"ğŸ“ ä»»åŠ¡åˆ†é…äº‹ä»¶è®°å½•: {event_data}")
            
            # è®°å½•åˆ°ä¸“é—¨çš„äº‹ä»¶æ—¥å¿—æ–‡ä»¶
            try:
                event_log_entry = f"{event_data['timestamp']}|{event_data['event_type']}|{event_data['task_id']}|{event_data['assigned_user_id']}|{task_title[:50]}"
                with open("task_events.log", "a", encoding="utf-8") as f:
                    f.write(event_log_entry + "\n")
                logger.warning(f"   äº‹ä»¶å·²è®°å½•åˆ°æ–‡ä»¶")
            except Exception as e:
                logger.warning(f"   äº‹ä»¶æ–‡ä»¶è®°å½•å¤±è´¥: {e}")
            
            # TODO: å¯ä»¥åœ¨è¿™é‡Œé›†æˆæ¶ˆæ¯é˜Ÿåˆ—ç³»ç»Ÿï¼Œå¦‚Redisã€RabbitMQç­‰
            # await self.message_queue.publish('task_assignments', event_data)
            
        except Exception as e:
            logger.error(f"è®°å½•ä»»åŠ¡åˆ†é…äº‹ä»¶å¤±è´¥: {e}")
    
    async def _log_workflow_execution_summary(self, workflow_instance_id: uuid.UUID):
        """è®°å½•å·¥ä½œæµæ‰§è¡Œæ‘˜è¦"""
        try:
            logger.trace(f"ğŸ“Š ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œæ‘˜è¦: {workflow_instance_id}")
            
            # è·å–å·¥ä½œæµå®ä¾‹ä¿¡æ¯
            instance = await self.workflow_instance_repo.get_instance_by_id(workflow_instance_id)
            if not instance:
                logger.warning(f"   å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨: {workflow_instance_id}")
                return
            
            # è·å–æ‰€æœ‰ä»»åŠ¡
            tasks = await self.task_instance_repo.get_tasks_by_workflow_instance(workflow_instance_id)
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_tasks = len(tasks)
            human_tasks = len([t for t in tasks if t['task_type'] == TaskInstanceType.HUMAN.value])
            agent_tasks = len([t for t in tasks if t['task_type'] == TaskInstanceType.AGENT.value])
            assigned_tasks = len([t for t in tasks if t['status'] in ['ASSIGNED', 'IN_PROGRESS', 'COMPLETED']])
            pending_tasks = len([t for t in tasks if t['status'] == 'PENDING'])
            
            # è¾“å‡ºæ‘˜è¦
            print(f"\nğŸ“Š ã€å·¥ä½œæµæ‰§è¡Œæ‘˜è¦ã€‘")
            print(f"å·¥ä½œæµå®ä¾‹: {instance.get('workflow_instance_name', 'Unknown')}")
            print(f"å®ä¾‹ID: {workflow_instance_id}")
            print(f"çŠ¶æ€: {instance.get('status', 'Unknown')}")
            print(f"æ€»ä»»åŠ¡æ•°: {total_tasks}")
            print(f"  - äººå·¥ä»»åŠ¡: {human_tasks}")
            print(f"  - Agentä»»åŠ¡: {agent_tasks}")
            print(f"  - å·²åˆ†é…: {assigned_tasks}")
            print(f"  - ç­‰å¾…ä¸­: {pending_tasks}")
            print(f"åˆ›å»ºæ—¶é—´: {instance.get('created_at', 'Unknown')}")
            print("=" * 50)
            
            # åˆ—å‡ºæ‰€æœ‰å·²åˆ†é…çš„äººå·¥ä»»åŠ¡
            human_assigned_tasks = [t for t in tasks if t['task_type'] == TaskInstanceType.HUMAN.value and t.get('assigned_user_id')]
            if human_assigned_tasks:
                print(f"ğŸ“‹ å·²åˆ†é…çš„äººå·¥ä»»åŠ¡:")
                for i, task in enumerate(human_assigned_tasks, 1):
                    print(f"  {i}. {task['task_title']}")
                    print(f"     ç”¨æˆ·: {task.get('assigned_user_id')}")
                    print(f"     çŠ¶æ€: {task['status']}")
                print("=" * 50)
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œæ‘˜è¦å¤±è´¥: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
    
    async def _notify_user_new_task(self, user_id: uuid.UUID, task_id: uuid.UUID, task_title: str):
        """é€šçŸ¥ç”¨æˆ·æœ‰æ–°ä»»åŠ¡åˆ†é…"""
        try:
            logger.trace(f"ğŸ”” å¼€å§‹å‘é€ä»»åŠ¡é€šçŸ¥ç»™ç”¨æˆ·: {user_id}")
            
            # è·å–ç”¨æˆ·ä¿¡æ¯ç”¨äºé€šçŸ¥
            user_info = await self.user_repo.get_by_id(user_id, id_column="user_id")
            username = user_info.get('username', 'Unknown') if user_info else 'Unknown'
            
            notification_data = {
                'user_id': str(user_id),
                'username': username,
                'task_id': str(task_id),
                'task_title': task_title,
                'notification_type': 'new_task_assigned',
                'timestamp': now_utc().isoformat(),
                'message': f'æ‚¨æœ‰æ–°çš„ä»»åŠ¡: {task_title}',
                'action_url': f'/tasks/{task_id}'
            }
            
            logger.trace(f"ğŸ“¨ é€šçŸ¥æ•°æ®å‡†å¤‡å®Œæˆ:")
            logger.trace(f"   - ç”¨æˆ·: {username} ({user_id})")
            logger.trace(f"   - ä»»åŠ¡: {task_title}")
            logger.trace(f"   - æ—¶é—´: {notification_data['timestamp']}")
            
            # æ–¹å¼1: æ§åˆ¶å°é€šçŸ¥ï¼ˆç”¨äºå¼€å‘è°ƒè¯•ï¼‰
            print(f"\nğŸ”” ã€ç”¨æˆ·é€šçŸ¥ã€‘")
            print(f"ç”¨æˆ·: {username} ({user_id})")
            print(f"æ¶ˆæ¯: æ‚¨æœ‰æ–°çš„ä»»åŠ¡åˆ†é…")
            print(f"ä»»åŠ¡: {task_title}")
            print(f"ä»»åŠ¡ID: {task_id}")
            print(f"æ—¶é—´: {notification_data['timestamp']}")
            print(f"æ“ä½œ: è¯·ç™»å½•ç³»ç»ŸæŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…")
            print("=" * 50)
            
            # æ–¹å¼2: è®°å½•åˆ°æ•°æ®åº“ï¼ˆç”¨æˆ·é€šçŸ¥å†å²ï¼‰
            try:
                await self._store_user_notification(notification_data)
                logger.trace(f"   âœ… é€šçŸ¥å·²å­˜å‚¨åˆ°æ•°æ®åº“")
            except Exception as e:
                logger.warning(f"   âš ï¸  å­˜å‚¨é€šçŸ¥å¤±è´¥: {e}")
            
            # æ–¹å¼3: æ–‡ä»¶æ—¥å¿—è®°å½•ï¼ˆå¯ç”¨äºå…¶ä»–ç³»ç»Ÿè¯»å–ï¼‰
            try:
                notification_log_entry = f"{now_utc().isoformat()}|TASK_ASSIGNED|{user_id}|{username}|{task_id}|{task_title}"
                with open("user_notifications.log", "a", encoding="utf-8") as f:
                    f.write(notification_log_entry + "\n")
                logger.trace(f"   âœ… é€šçŸ¥å·²è®°å½•åˆ°æ–‡ä»¶")
            except Exception as e:
                logger.warning(f"   âš ï¸  æ–‡ä»¶è®°å½•å¤±è´¥: {e}")
            
            # TODO: æ–¹å¼4: å®æ—¶æ¨é€ï¼ˆæœªæ¥å®ç°ï¼‰
            # å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€å®ç°ï¼š
            # 1. WebSocket æ¨é€: await self.websocket_manager.send_to_user(user_id, notification_data)
            # 2. Server-Sent Events (SSE): await self.sse_manager.send_event(user_id, notification_data)
            # 3. æ¶ˆæ¯é˜Ÿåˆ—: await self.message_queue.publish(f"user.{user_id}.notifications", notification_data)
            # 4. é‚®ä»¶é€šçŸ¥: await self.email_service.send_task_notification(user_info.get('email'), notification_data)
            
            logger.trace(f"   ğŸ‰ ç”¨æˆ·é€šçŸ¥å¤„ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å‘é€ç”¨æˆ·é€šçŸ¥å¤±è´¥: {e}")
            import traceback
            logger.error(f"   å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
    
    async def _store_user_notification(self, notification_data: dict):
        """å­˜å‚¨ç”¨æˆ·é€šçŸ¥åˆ°æ•°æ®åº“ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰"""
        try:
            # è¿™é‡Œå¯ä»¥å­˜å‚¨åˆ°ä¸“é—¨çš„é€šçŸ¥è¡¨ä¸­
            # å¦‚æœæ²¡æœ‰é€šçŸ¥è¡¨ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªç®€å•çš„è®°å½•è¡¨
            logger.warning(f"å­˜å‚¨é€šçŸ¥æ•°æ®: {notification_data}")
            # æš‚æ—¶è·³è¿‡æ•°æ®åº“å­˜å‚¨ï¼Œé¿å…è¡¨ç»“æ„ä¾èµ–
        except Exception as e:
            logger.warning(f"å­˜å‚¨ç”¨æˆ·é€šçŸ¥å¤±è´¥: {e}")
    
    # ================================================================================
    # å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶ - æ ¸å¿ƒæ–¹æ³•
    # ================================================================================
    
    async def _check_node_prerequisites(self, workflow_instance_id: uuid.UUID, 
                                      node_instance_id: uuid.UUID) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹çš„å‰ç½®æ¡ä»¶æ˜¯å¦æ»¡è¶³"""
        try:
            logger.trace(f"ğŸ” æ£€æŸ¥èŠ‚ç‚¹å‰ç½®æ¡ä»¶: {node_instance_id}")
            
            # ä»æ•°æ®åº“æŸ¥è¯¢èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_repo = NodeInstanceRepository()
            node_instance = await node_repo.get_instance_by_id(node_instance_id)
            
            if not node_instance:
                logger.error(f"âŒ èŠ‚ç‚¹å®ä¾‹ä¸å­˜åœ¨: {node_instance_id}")
                return False
            
            node_id = node_instance['node_id']
            logger.trace(f"  èŠ‚ç‚¹ID: {node_id}")
            
            # æŸ¥è¯¢è¯¥èŠ‚ç‚¹çš„å‰ç½®èŠ‚ç‚¹
            prerequisite_query = '''
            SELECT source_n.node_id as prerequisite_node_id, source_n.name as prerequisite_name,
                   source_ni.node_instance_id as prerequisite_instance_id, source_ni.status as prerequisite_status
            FROM node_connection c
            JOIN node source_n ON c.from_node_id = source_n.node_id  
            JOIN node target_n ON c.to_node_id = target_n.node_id
            JOIN node_instance source_ni ON source_n.node_id = source_ni.node_id
            WHERE target_n.node_id = $1 
              AND source_ni.workflow_instance_id = $2
              AND source_ni.is_deleted = FALSE
            '''
            
            prerequisites = await self.workflow_instance_repo.db.fetch_all(
                prerequisite_query, node_id, workflow_instance_id
            )
            
            logger.trace(f"  æ‰¾åˆ° {len(prerequisites)} ä¸ªå‰ç½®èŠ‚ç‚¹")
            
            # å¦‚æœæ²¡æœ‰å‰ç½®èŠ‚ç‚¹ï¼ˆå¦‚STARTèŠ‚ç‚¹ï¼‰ï¼Œç›´æ¥è¿”å›True
            if not prerequisites:
                logger.trace(f"  âœ… æ— å‰ç½®èŠ‚ç‚¹ï¼Œæ»¡è¶³æ¡ä»¶")
                return True
            
            # æ£€æŸ¥æ‰€æœ‰å‰ç½®èŠ‚ç‚¹æ˜¯å¦éƒ½å·²å®Œæˆ
            all_completed = True
            for prerequisite in prerequisites:
                status = prerequisite['prerequisite_status']
                name = prerequisite['prerequisite_name']
                logger.trace(f"    å‰ç½®èŠ‚ç‚¹ {name}: {status}")
                
                if status != 'completed':
                    all_completed = False
                    logger.trace(f"    âŒ å‰ç½®èŠ‚ç‚¹ {name} æœªå®Œæˆ: {status}")
            
            if all_completed:
                logger.trace(f"  âœ… æ‰€æœ‰å‰ç½®èŠ‚ç‚¹å·²å®Œæˆï¼Œæ»¡è¶³ä»»åŠ¡åˆ›å»ºæ¡ä»¶")
            else:
                logger.trace(f"  â³ å‰ç½®èŠ‚ç‚¹æœªå…¨éƒ¨å®Œæˆï¼Œç­‰å¾…ä¸­")
            
            return all_completed
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥èŠ‚ç‚¹å‰ç½®æ¡ä»¶å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return False
    
    async def _create_tasks_when_ready(self, workflow_instance_id: uuid.UUID, 
                                     node_instance_id: uuid.UUID) -> bool:
        """å½“èŠ‚ç‚¹æ»¡è¶³å‰ç½®æ¡ä»¶æ—¶åˆ›å»ºä»»åŠ¡"""
        try:
            logger.trace(f"ğŸ¯ å°è¯•ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡: {node_instance_id}")
            
            # æ£€æŸ¥å‰ç½®æ¡ä»¶
            prerequisites_met = await self._check_node_prerequisites(workflow_instance_id, node_instance_id)
            if not prerequisites_met:
                logger.trace(f"  â³ å‰ç½®æ¡ä»¶æœªæ»¡è¶³ï¼Œæš‚ä¸åˆ›å»ºä»»åŠ¡")
                return False
            
            # è·å–èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_repo = NodeInstanceRepository()
            node_instance = await node_repo.get_instance_by_id(node_instance_id)
            
            if not node_instance:
                logger.error(f"âŒ èŠ‚ç‚¹å®ä¾‹ä¸å­˜åœ¨: {node_instance_id}")
                return False
            
            # è·å–èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
            node = await self.node_repo.get_node_by_id(node_instance['node_id'])
            if not node:
                logger.error(f"âŒ èŠ‚ç‚¹ä¸å­˜åœ¨: {node_instance['node_id']}")
                return False
            
            # åªä¸ºPROCESSORèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
            if node['type'] != NodeType.PROCESSOR.value:
                logger.trace(f"  â­ï¸ èŠ‚ç‚¹ç±»å‹ä¸æ˜¯PROCESSOR ({node['type']})ï¼Œè‡ªåŠ¨å®Œæˆ")
                
                # å¯¹äºéPROCESSORèŠ‚ç‚¹ï¼ˆå¦‚ENDèŠ‚ç‚¹ï¼‰ï¼Œç›´æ¥æ ‡è®°ä¸ºå®Œæˆ
                if node['type'] == NodeType.END.value:
                    await self._execute_end_node(workflow_instance_id, node_instance_id)
                elif node['type'] == NodeType.START.value:
                    from ..models.instance import NodeInstanceUpdate, NodeInstanceStatus
                    update_data = NodeInstanceUpdate(status=NodeInstanceStatus.COMPLETED)
                    await node_repo.update_node_instance(node_instance_id, update_data)
                    
                    # ä¿®å¤ï¼šSTARTèŠ‚ç‚¹å®Œæˆæ—¶ä¹Ÿéœ€è¦è°ƒç”¨mark_node_completedå­˜å‚¨è¾“å‡ºæ•°æ®
                    logger.trace(f"ğŸš€ STARTèŠ‚ç‚¹å®Œæˆï¼Œå­˜å‚¨è¾“å‡ºæ•°æ®åˆ°WorkflowContextManager")
                    task_description = node.get('task_description', 'å¼€å§‹èŠ‚ç‚¹å·²å®Œæˆ')
                    start_output_data = {
                        'task_result': task_description,  # å°†task_descriptionä½œä¸ºè¾“å‡ºç»“æœä¼ é€’ç»™ä¸‹æ¸¸
                        'task_summary': 'STARTèŠ‚ç‚¹å¤„ç†å®Œæˆ',
                        'execution_time': 0,
                        'completion_time': datetime.utcnow().isoformat()
                    }
                    logger.trace(f"  - STARTèŠ‚ç‚¹è¾“å‡ºæ•°æ®: {start_output_data}")
                    
                    await self.context_manager.mark_node_completed(
                        workflow_instance_id=workflow_instance_id,
                        node_id=node['node_id'],
                        node_instance_id=node_instance_id,
                        output_data=start_output_data
                    )
                else:
                    logger.error(f"error node type:{node['type']}")

                # ç»§ç»­æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹
                await self._check_downstream_nodes_for_task_creation(workflow_instance_id)
                return True
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»åˆ›å»ºè¿‡ä»»åŠ¡
            existing_tasks_query = '''
            SELECT task_instance_id FROM task_instance 
            WHERE node_instance_id = $1 AND is_deleted = FALSE
            '''
            existing_tasks = await self.task_instance_repo.db.fetch_all(existing_tasks_query, node_instance_id)
            
            if existing_tasks:
                logger.trace(f"  âœ… ä»»åŠ¡å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤åˆ›å»º")
                return True
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå‡†å¤‡ä¸­
            from ..models.instance import NodeInstanceUpdate, NodeInstanceStatus
            update_data = NodeInstanceUpdate(status=NodeInstanceStatus.PENDING)
            await node_repo.update_node_instance(node_instance_id, update_data)
            
            # ä¸ºè¯¥èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
            created_node = {
                'node_instance_id': node_instance_id,
                'node_id': node['node_id'],  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
                'node_type': node['type'],
                'node_data': node
            }
            
            await self._create_tasks_for_nodes([created_node], workflow_instance_id)
            
            logger.trace(f"  âœ… èŠ‚ç‚¹ä»»åŠ¡åˆ›å»ºå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºèŠ‚ç‚¹ä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return False
    
    async def _check_downstream_nodes_for_task_creation(self, workflow_instance_id: uuid.UUID):
        """æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹æ˜¯å¦å¯ä»¥åˆ›å»ºä»»åŠ¡"""
        try:
            logger.trace(f"ğŸ”„ æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹ä»»åŠ¡åˆ›å»ºæœºä¼š")
            
            # æŸ¥è¯¢å·¥ä½œæµä¸­æ‰€æœ‰ç­‰å¾…çŠ¶æ€çš„èŠ‚ç‚¹
            waiting_nodes_query = '''
            SELECT ni.node_instance_id, ni.node_id, n.name, n.type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 
              AND ni.status = 'pending'
              AND ni.is_deleted = FALSE
            '''
            
            waiting_nodes = await self.workflow_instance_repo.db.fetch_all(
                waiting_nodes_query, workflow_instance_id
            )
            
            logger.trace(f"  æ‰¾åˆ° {len(waiting_nodes)} ä¸ªç­‰å¾…ä¸­çš„èŠ‚ç‚¹")
            
            # ä¸ºæ¯ä¸ªç­‰å¾…èŠ‚ç‚¹æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆ›å»ºä»»åŠ¡
            for node in waiting_nodes:
                node_instance_id = node['node_instance_id']
                node_name = node['name']
                
                logger.trace(f"  æ£€æŸ¥èŠ‚ç‚¹: {node_name} ({node_instance_id})")
                
                # å°è¯•åˆ›å»ºä»»åŠ¡
                created = await self._create_tasks_when_ready(workflow_instance_id, node_instance_id)
                if created:
                    logger.trace(f"    âœ… èŠ‚ç‚¹ {node_name} ä»»åŠ¡åˆ›å»ºæˆåŠŸ")
                else:
                    logger.trace(f"    â³ èŠ‚ç‚¹ {node_name} æ¡ä»¶æœªæ»¡è¶³")
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _execute_end_node(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID):
        """æ‰§è¡Œç»“æŸèŠ‚ç‚¹"""
        try:
            logger.trace(f"ğŸ æ‰§è¡Œç»“æŸèŠ‚ç‚¹: {node_instance_id}")
            
            # æ£€æŸ¥ä¾èµ–ä¿¡æ¯æ˜¯å¦å­˜åœ¨
            is_ready = self.context_manager.is_node_ready_to_execute(node_instance_id)
            if not is_ready:
                logger.error(f"âŒ [ENDèŠ‚ç‚¹] èŠ‚ç‚¹ {node_instance_id} ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•æ‰§è¡Œ")
                return
            
            logger.trace(f"âœ… [ENDèŠ‚ç‚¹] ä¾èµ–æ£€æŸ¥é€šè¿‡ï¼Œå¼€å§‹æ‰§è¡Œ")
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceUpdate, NodeInstanceStatus
            
            node_repo = NodeInstanceRepository()
            update_data = NodeInstanceUpdate(status=NodeInstanceStatus.RUNNING)
            await node_repo.update_node_instance(node_instance_id, update_data)
            
            # æ”¶é›†å®Œæ•´çš„å·¥ä½œæµä¸Šä¸‹æ–‡
            context_data = await self._collect_workflow_context(workflow_instance_id)
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå®Œæˆï¼Œå¹¶ä¿å­˜ä¸Šä¸‹æ–‡æ•°æ®
            final_update = NodeInstanceUpdate(
                status=NodeInstanceStatus.COMPLETED,
                output_data=context_data
            )
            await node_repo.update_node_instance(node_instance_id, final_update)
            
            logger.trace(f"âœ… ç»“æŸèŠ‚ç‚¹æ‰§è¡Œå®Œæˆ")
            
            # æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å¯ä»¥å®Œæˆ
            await self._check_workflow_completion(workflow_instance_id)
            
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œç»“æŸèŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _collect_workflow_context(self, workflow_instance_id: uuid.UUID) -> Dict[str, Any]:
        """æ”¶é›†å·¥ä½œæµçš„å®Œæ•´ä¸Šä¸‹æ–‡"""
        try:
            logger.trace(f"ğŸ“‹ æ”¶é›†å·¥ä½œæµä¸Šä¸‹æ–‡: {workflow_instance_id}")
            
            # è·å–æ‰€æœ‰å·²å®Œæˆçš„èŠ‚ç‚¹å®ä¾‹åŠå…¶è¾“å‡º
            context_query = '''
            SELECT ni.node_instance_id, ni.output_data, n.name as node_name, n.type as node_type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 
              AND ni.status = 'completed'
              AND ni.is_deleted = FALSE
            ORDER BY ni.created_at
            '''
            
            completed_nodes = await self.workflow_instance_repo.db.fetch_all(
                context_query, workflow_instance_id
            )
            
            # è·å–æ‰€æœ‰å·²å®Œæˆçš„ä»»åŠ¡å®ä¾‹åŠå…¶è¾“å‡º  
            task_context_query = '''
            SELECT ti.task_instance_id, ti.output_data, ti.task_title, ti.result_summary,
                   n.name as node_name, n.type as node_type
            FROM task_instance ti
            JOIN node_instance ni ON ti.node_instance_id = ni.node_instance_id
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 
              AND ti.status = 'completed'
              AND ti.is_deleted = FALSE
            ORDER BY ti.completed_at
            '''
            
            completed_tasks = await self.task_instance_repo.db.fetch_all(
                task_context_query, workflow_instance_id
            )
            
            # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
            context_data = {
                'workflow_instance_id': str(workflow_instance_id),
                'completed_at': now_utc().isoformat(),
                'nodes_context': {},
                'tasks_context': {},
                'execution_summary': {
                    'total_nodes': len(completed_nodes),
                    'total_tasks': len(completed_tasks)
                }
            }
            
            # æ·»åŠ èŠ‚ç‚¹ä¸Šä¸‹æ–‡
            for node in completed_nodes:
                node_id = str(node['node_instance_id'])
                context_data['nodes_context'][node_id] = {
                    'node_name': node['node_name'],
                    'node_type': node['node_type'],
                    'output_data': node['output_data'] or {}
                }
            
            # æ·»åŠ ä»»åŠ¡ä¸Šä¸‹æ–‡
            for task in completed_tasks:
                task_id = str(task['task_instance_id'])
                context_data['tasks_context'][task_id] = {
                    'task_title': task['task_title'],
                    'node_name': task['node_name'],
                    'node_type': task['node_type'],
                    'output_data': task['output_data'] or {},
                    'result_summary': task['result_summary']
                }
            
            logger.trace(f"âœ… ä¸Šä¸‹æ–‡æ”¶é›†å®Œæˆ: {len(completed_nodes)} ä¸ªèŠ‚ç‚¹, {len(completed_tasks)} ä¸ªä»»åŠ¡")
            return context_data
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†å·¥ä½œæµä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {}
    
    async def _check_workflow_completion(self, workflow_instance_id: uuid.UUID):
        """æ£€æŸ¥å·¥ä½œæµæ˜¯å¦å¯ä»¥å®Œæˆ"""
        try:
            logger.trace(f"ğŸ æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€: {workflow_instance_id}")
            
            # æŸ¥è¯¢æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹çš„çŠ¶æ€
            nodes_status_query = '''
            SELECT ni.node_instance_id, ni.status, n.name, n.type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 AND ni.is_deleted = FALSE
            '''
            
            all_nodes = await self.workflow_instance_repo.db.fetch_all(
                nodes_status_query, workflow_instance_id
            )
            
            logger.trace(f"  å·¥ä½œæµæ€»èŠ‚ç‚¹æ•°: {len(all_nodes)}")
            
            # æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹æ˜¯å¦éƒ½å·²å®Œæˆ
            completed_nodes = [n for n in all_nodes if n['status'] == 'completed']
            failed_nodes = [n for n in all_nodes if n['status'] == 'failed']
            
            logger.trace(f"  å·²å®ŒæˆèŠ‚ç‚¹: {len(completed_nodes)}")
            logger.trace(f"  å¤±è´¥èŠ‚ç‚¹: {len(failed_nodes)}")
            
            # å¦‚æœæœ‰å¤±è´¥èŠ‚ç‚¹ï¼Œæ ‡è®°å·¥ä½œæµä¸ºå¤±è´¥
            if failed_nodes:
                from ..models.instance import WorkflowInstanceUpdate, WorkflowInstanceStatus
                update_data = WorkflowInstanceUpdate(
                    status=WorkflowInstanceStatus.FAILED,
                    error_message=f"å·¥ä½œæµåŒ…å« {len(failed_nodes)} ä¸ªå¤±è´¥èŠ‚ç‚¹"
                )
                await self.workflow_instance_repo.update_instance(workflow_instance_id, update_data)
                logger.trace(f"âŒ å·¥ä½œæµæ ‡è®°ä¸ºå¤±è´¥")
                return
            
            # å¦‚æœæ‰€æœ‰èŠ‚ç‚¹éƒ½å·²å®Œæˆï¼Œæ ‡è®°å·¥ä½œæµä¸ºå®Œæˆ
            if len(completed_nodes) == len(all_nodes):
                from ..models.instance import WorkflowInstanceUpdate, WorkflowInstanceStatus
                update_data = WorkflowInstanceUpdate(status=WorkflowInstanceStatus.COMPLETED)
                await self.workflow_instance_repo.update_instance(workflow_instance_id, update_data)
                logger.trace(f"âœ… å·¥ä½œæµæ ‡è®°ä¸ºå®Œæˆ")
            else:
                logger.trace(f"â³ å·¥ä½œæµä»åœ¨è¿›è¡Œä¸­: {len(completed_nodes)}/{len(all_nodes)} èŠ‚ç‚¹å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")

    # =============================================================================
    # æ–°æ¶æ„æ–¹æ³• - æ”¯æŒWorkflowInstanceContext
    # =============================================================================
    
    async def _create_node_instances_with_new_context(self, 
                                                    workflow_context, 
                                                    workflow_instance_id: uuid.UUID, 
                                                    workflow_base_id: uuid.UUID,
                                                    nodes: List[Dict[str, Any]]):
        """ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡ç®¡ç†å™¨åˆ›å»ºèŠ‚ç‚¹å®ä¾‹"""
        try:
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            from ..models.instance import NodeInstanceCreate, NodeInstanceStatus
            
            node_instance_repo = NodeInstanceRepository()
            
            for node in nodes:
                # 1. åˆ›å»ºèŠ‚ç‚¹å®ä¾‹
                node_instance_data = NodeInstanceCreate(
                    workflow_instance_id=workflow_instance_id,
                    node_id=node['node_id'],
                    node_base_id=node['node_base_id'],
                    node_instance_name=f"{node['name']}_instance",
                    task_description=node.get('task_description', ''),
                    status=NodeInstanceStatus.PENDING,
                    input_data={},
                    output_data={},
                    error_message=None,
                    retry_count=0
                )
                
                node_instance = await node_instance_repo.create_node_instance(node_instance_data)
                if not node_instance:
                    logger.error(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¤±è´¥: {node['name']}")
                    continue
                
                node_instance_id = node_instance['node_instance_id']
                logger.trace(f"åˆ›å»ºèŠ‚ç‚¹å®ä¾‹: {node['name']} (ID: {node_instance_id})")
                
                # 2. è·å–ä¸Šæ¸¸ä¾èµ– - æš‚æ—¶ä½¿ç”¨ç©ºåˆ—è¡¨
                upstream_node_ids = []
                
                # 3. åœ¨æ–°ä¸Šä¸‹æ–‡ä¸­æ³¨å†Œä¾èµ–
                await workflow_context.register_node_dependencies(
                    node_instance_id,
                    node['node_id'],  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
                    upstream_node_ids
                )
                
                # 4. ä¸ºå¤„ç†å™¨èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹
                if node['type'] == NodeType.PROCESSOR.value:
                    await self._create_tasks_for_node_new_context(node, node_instance_id, workflow_instance_id)
                
            logger.trace(f"âœ… ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡åˆ›å»ºäº† {len(nodes)} ä¸ªèŠ‚ç‚¹å®ä¾‹")
            
        except Exception as e:
            logger.error(f"ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡åˆ›å»ºèŠ‚ç‚¹å®ä¾‹å¤±èµ…: {e}")
            raise
    
    async def _create_tasks_for_node_new_context(self, node: Dict[str, Any], 
                                               node_instance_id: uuid.UUID,
                                               workflow_instance_id: uuid.UUID):
        """ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹ï¼ˆæ–°æ¶æ„ï¼‰"""
        try:
            # è·å–èŠ‚ç‚¹çš„å¤„ç†å™¨ï¼ˆä¿®å¤ï¼šä½¿ç”¨node_idï¼‰  
            processors = await self._get_node_processors(node['node_id'])
            
            for processor in processors:
                # æ ¹æ®å¤„ç†å™¨ç±»å‹ç¡®å®šä»»åŠ¡ç±»å‹å’Œåˆ†é…
                processor_type = processor.get('processor_type', processor.get('type', 'HUMAN'))
                task_type = self._determine_task_type(processor_type)
                assigned_user_id = processor.get('user_id')
                assigned_agent_id = processor.get('agent_id')
                
                # æ·»åŠ è°ƒè¯•æ—¥å¿—
                logger.trace(f"ğŸ” [ä»»åŠ¡åˆ›å»º] å¤„ç†å™¨ä¿¡æ¯:")
                logger.trace(f"   - å¤„ç†å™¨åç§°: {processor.get('name', 'Unknown')}")
                logger.trace(f"   - å¤„ç†å™¨ç±»å‹: '{processor_type}' -> ä»»åŠ¡ç±»å‹: {task_type.value}")
                logger.trace(f"   - åˆ†é…ç”¨æˆ·: {assigned_user_id}")
                logger.trace(f"   - åˆ†é…Agent: {assigned_agent_id}")
                
                # åˆ›å»ºä»»åŠ¡å®ä¾‹
                task_title = node['name']
                task_description = node.get('task_description') or node.get('description') or f"æ‰§è¡ŒèŠ‚ç‚¹ {node['name']} çš„ä»»åŠ¡"
                
                task_data = TaskInstanceCreate(
                    workflow_instance_id=workflow_instance_id,
                    node_instance_id=node_instance_id,
                    processor_id=processor.get('processor_id'),
                    task_type=task_type,
                    task_title=task_title,
                    task_description=task_description,
                    assigned_user_id=assigned_user_id,
                    assigned_agent_id=assigned_agent_id,
                    estimated_duration=processor.get('estimated_duration', 30),
                    input_data="{}",  # ç©ºçš„JSONå­—ç¬¦ä¸²
                    context_data=""   # ç©ºå­—ç¬¦ä¸²
                )
                
                task_instance = await self.task_instance_repo.create_task(task_data)
                if task_instance:
                    task_id = task_instance['task_instance_id']
                    logger.trace(f"åˆ›å»ºä»»åŠ¡å®ä¾‹: {task_title} (ID: {task_id}, ç±»å‹: {task_type})")
                else:
                    logger.error(f"åˆ›å»ºä»»åŠ¡å®ä¾‹å¤±è´¥: {task_title}")
                
        except Exception as e:
            logger.error(f"ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹å¤±è´¥: {e}")
            raise
    
    async def _start_workflow_execution_with_new_context(self, 
                                                       workflow_context,
                                                       workflow_instance_id: uuid.UUID,
                                                       workflow_base_id: uuid.UUID):
        """ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ"""
        try:
            # è·å–å‡†å¤‡æ‰§è¡Œçš„èŠ‚ç‚¹ï¼ˆSTARTèŠ‚ç‚¹ï¼‰
            ready_nodes = await workflow_context.get_ready_nodes()
            
            logger.trace(f"æ‰¾åˆ° {len(ready_nodes)} ä¸ªå‡†å¤‡æ‰§è¡Œçš„èŠ‚ç‚¹")
            
            for node_instance_id in ready_nodes:
                try:
                    # æ‰§è¡ŒèŠ‚ç‚¹
                    await self._execute_node_with_new_context(workflow_context, node_instance_id)
                    logger.trace(f"å¯åŠ¨èŠ‚ç‚¹æ‰§è¡Œ: {node_instance_id}")
                    
                except Exception as e:
                    logger.error(f"å¯åŠ¨èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥ {node_instance_id}: {e}")
            
        except Exception as e:
            logger.error(f"ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡å¯åŠ¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    async def _execute_node_with_new_context(self, workflow_context, node_instance_id: uuid.UUID):
        """ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡æ‰§è¡ŒèŠ‚ç‚¹"""
        try:
            # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å‡†å¤‡å¥½æ‰§è¡Œ
            if not workflow_context.is_node_ready_to_execute(node_instance_id):
                logger.warning(f"èŠ‚ç‚¹ {node_instance_id} å°šæœªå‡†å¤‡å¥½æ‰§è¡Œ")
                return
            
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            dep_info = workflow_context.get_node_dependency_info(node_instance_id)
            if not dep_info:
                logger.error(f"æ— æ³•è·å–èŠ‚ç‚¹ {node_instance_id} çš„ä¾èµ–ä¿¡æ¯")
                return
            
            node_id = dep_info['node_id']  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
            
            # æ ‡è®°èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
            await workflow_context.mark_node_executing(node_id, node_instance_id)
            
            # è·å–èŠ‚ç‚¹çš„ä»»åŠ¡å®ä¾‹
            tasks = await self.task_instance_repo.get_tasks_by_node_instance(node_instance_id)
            
            if not tasks:
                # æ— ä»»åŠ¡èŠ‚ç‚¹ï¼ˆå¦‚STARTæˆ–ENDèŠ‚ç‚¹ï¼‰
                output_data = {'message': f'Node {node_id} executed without tasks'}
                triggered_nodes = await workflow_context.mark_node_completed(
                    node_id, node_instance_id, output_data
                )
                
                # å¤„ç†è§¦å‘çš„ä¸‹æ¸¸èŠ‚ç‚¹
                for triggered_node_id in triggered_nodes:
                    await self._execute_node_with_new_context(workflow_context, triggered_node_id)
                
            else:
                # æœ‰ä»»åŠ¡çš„èŠ‚ç‚¹ï¼Œå¯åŠ¨ä»»åŠ¡æ‰§è¡Œ
                for task in tasks:
                    await self._execute_task(task)
                
                logger.trace(f"èŠ‚ç‚¹ {node_id} çš„ {len(tasks)} ä¸ªä»»åŠ¡å·²å¯åŠ¨")
            
        except Exception as e:
            logger.error(f"ä½¿ç”¨æ–°ä¸Šä¸‹æ–‡æ‰§è¡ŒèŠ‚ç‚¹ {node_instance_id} å¤±è´¥: {e}")
            # æ ‡è®°èŠ‚ç‚¹å¤±è´¥
            if 'dep_info' in locals() and dep_info:
                await workflow_context.mark_node_failed(
                    dep_info['node_id'],  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
                    node_instance_id,
                    {'error': str(e)}
                )
            raise
    
    async def _log_workflow_execution_summary_new(self, workflow_context, workflow_instance_id: uuid.UUID):
        """ç”Ÿæˆæ–°æ¶æ„çš„æ‰§è¡Œæ‘˜è¦"""
        try:
            status = await workflow_context.get_workflow_status()
            
            logger.trace(f"\nğŸ“ˆ ã€å·¥ä½œæµæ‰§è¡Œæ‘˜è¦ - æ–°æ¶æ„ã€‘")
            logger.trace(f"  å®ä¾‹ ID: {workflow_instance_id}")
            logger.trace(f"  çŠ¶æ€: {status['status']}")
            logger.trace(f"  æ€»èŠ‚ç‚¹æ•°: {status['total_nodes']}")
            logger.trace(f"  å·²å®Œæˆ: {status['completed_nodes']}")
            logger.trace(f"  æ‰§è¡Œä¸­: {status['executing_nodes']}")
            logger.trace(f"  å¾…æ‰§è¡Œ: {status['pending_nodes']}")
            logger.trace(f"  å¤±è´¥: {status['failed_nodes']}")
            logger.trace(f"  æ¶æ„ç±»å‹: WorkflowInstanceContext")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ–°æ¶æ„æ‰§è¡Œæ‘˜è¦å¤±è´¥: {e}")
    
    async def get_execution_stats(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œå¼•æ“ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'is_running': self.is_running,
            'architecture': 'new_context_management',
            'features': {
                'instance_isolation': True,
                'thread_safe': True,
                'auto_cleanup': True,
                'resource_management': True
            }
        }
        
        if self.instance_manager:
            manager_stats = await self.instance_manager.get_manager_stats()
            stats['instance_manager'] = manager_stats
        
        if self.resource_cleanup_manager:
            cleanup_stats = self.resource_cleanup_manager.get_cleanup_stats()
            stats['resource_cleanup'] = cleanup_stats
        
        return stats

    async def _trigger_downstream_nodes_new_architecture(self, workflow_instance_id: uuid.UUID, completed_node: Dict[str, Any], context):
        """ä½¿ç”¨æ–°æ¶æ„è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹"""
        try:
            node_id = completed_node.get('node_id')
            if not node_id:
                logger.warning("completed_node ç¼ºå°‘ node_id")
                return
            
            # ä½¿ç”¨æ–°æ¶æ„çš„ä¾èµ–è·Ÿè¸ªå™¨è·å–ä¸‹æ¸¸èŠ‚ç‚¹
            workflow_base_id = context.workflow_base_id
            downstream_nodes = await self.dependency_tracker.get_immediate_downstream_nodes(
                workflow_base_id, node_id  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
            )
            
            logger.trace(f"æ‰¾åˆ° {len(downstream_nodes)} ä¸ªä¸‹æ¸¸èŠ‚ç‚¹éœ€è¦æ£€æŸ¥")
            
            for downstream_node_id in downstream_nodes:
                await self._check_and_trigger_node_new_architecture(
                    workflow_instance_id, downstream_node_id, context
                )
            
        except Exception as e:
            logger.error(f"æ–°æ¶æ„è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    async def _check_and_trigger_node_new_architecture(self, workflow_instance_id: uuid.UUID, node_id: uuid.UUID, context):
        """æ£€æŸ¥å¹¶è§¦å‘å•ä¸ªèŠ‚ç‚¹ï¼ˆæ–°æ¶æ„ï¼‰"""
        try:
            # è·å–è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰ä¸Šæ¸¸ä¾èµ–ï¼ˆä½¿ç”¨node_idè€Œä¸æ˜¯node_base_idï¼‰
            upstream_nodes = await self.dependency_tracker.get_immediate_upstream_nodes(
                context.workflow_base_id, node_id
            )
            
            # æ£€æŸ¥æ‰€æœ‰ä¸Šæ¸¸èŠ‚ç‚¹æ˜¯å¦éƒ½å·²å®Œæˆ
            all_upstream_completed = True
            for upstream_node_id in upstream_nodes:
                if upstream_node_id not in context.completed_nodes:
                    all_upstream_completed = False
                    break
            
            if all_upstream_completed:
                # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºpendingå¹¶åˆ›å»ºä»»åŠ¡
                await self._update_node_status_to_pending(workflow_instance_id, node_id)
                logger.trace(f"èŠ‚ç‚¹ {node_id} æ‰€æœ‰ä¾èµ–å·²æ»¡è¶³ï¼ŒçŠ¶æ€æ›´æ–°ä¸ºpending")
            else:
                logger.trace(f"èŠ‚ç‚¹ {node_id} ä»æœ‰æœªå®Œæˆçš„ä¸Šæ¸¸ä¾èµ–")
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥å¹¶è§¦å‘èŠ‚ç‚¹å¤±è´¥: {e}")

    async def _trigger_downstream_nodes_legacy(self, workflow_instance_id: uuid.UUID, completed_node: Dict[str, Any]):
        """ä½¿ç”¨æ—§æ¶æ„è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰"""
        try:
            node_id = completed_node.get('node_id')
            if not node_id:
                logger.warning("completed_node ç¼ºå°‘ node_id")
                return
            
            # é€šè¿‡ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€šçŸ¥èŠ‚ç‚¹å®Œæˆ
            if self.context_manager:
                self.context_manager.mark_node_completed(
                    workflow_instance_id, 
                    node_id,  # ä½¿ç”¨node_idè€Œä¸æ˜¯node_base_id
                    completed_node.get('output_data', {})
                )
                logger.trace(f"é€šè¿‡æ—§æ¶æ„ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ ‡è®°èŠ‚ç‚¹ {node_id} å®Œæˆ")
            
            # æŸ¥è¯¢æ•°æ®åº“è·å–ä¸‹æ¸¸èŠ‚ç‚¹
            workflow_instance = await self.workflow_instance_repo.get_workflow_instance(workflow_instance_id)
            if not workflow_instance:
                logger.error(f"æœªæ‰¾åˆ°å·¥ä½œæµå®ä¾‹: {workflow_instance_id}")
                return
            
            # æŸ¥è¯¢è¯¥å·¥ä½œæµçš„æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹
            all_node_instances_query = """
                SELECT ni.*, n.type as node_type, n.name as node_name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.workflow_instance_id = $1
                AND ni.status = 'pending'
                AND ni.is_deleted = FALSE
            """
            
            waiting_nodes = await self.workflow_instance_repo.db.fetch_all(
                all_node_instances_query, 
                workflow_instance_id
            )
            
            logger.trace(f"æ‰¾åˆ° {len(waiting_nodes)} ä¸ªç­‰å¾…ä¸­çš„èŠ‚ç‚¹")
            
            # æ£€æŸ¥æ¯ä¸ªç­‰å¾…çš„èŠ‚ç‚¹æ˜¯å¦å¯ä»¥æ‰§è¡Œ
            for node in waiting_nodes:
                await self._check_node_dependencies_and_trigger(
                    workflow_instance_id, node['node_instance_id'], node['node_id']
                )
                
        except Exception as e:
            logger.error(f"æ—§æ¶æ„è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    async def _check_node_dependencies_and_trigger(self, workflow_instance_id: uuid.UUID, node_instance_id: uuid.UUID, node_id: uuid.UUID):
        """æ£€æŸ¥èŠ‚ç‚¹ä¾èµ–å¹¶è§¦å‘æ‰§è¡Œ"""
        try:
            # è·å–å·¥ä½œæµç‰ˆæœ¬IDç”¨äºæŸ¥è¯¢è¿æ¥å…³ç³»
            workflow_instance = await self.workflow_instance_repo.get_instance_by_id(workflow_instance_id)
            workflow_id = workflow_instance['workflow_id'] if workflow_instance else None
            
            if not workflow_id:
                logger.error(f"æ— æ³•è·å–å·¥ä½œæµç‰ˆæœ¬ID: {workflow_instance_id}")
                return
            
            # æŸ¥è¯¢è¯¥èŠ‚ç‚¹çš„ä¸Šæ¸¸ä¾èµ–ï¼ˆä½¿ç”¨node_connectionè¡¨ï¼Œè¿™æ˜¯æ­£ç¡®çš„ä¾èµ–å…³ç³»æ¥æºï¼‰
            dependencies_query = """
                SELECT nc.from_node_id as upstream_node_id, ni_upstream.status as upstream_status
                FROM node_connection nc
                LEFT JOIN node_instance ni_upstream ON (
                    nc.from_node_id = ni_upstream.node_id 
                    AND ni_upstream.workflow_instance_id = $1
                )
                WHERE nc.to_node_id = $2 AND nc.workflow_id = $3
            """
            
            dependencies = await self.workflow_instance_repo.db.fetch_all(
                dependencies_query, 
                workflow_instance_id, node_id, workflow_id
            )
            
            # æ£€æŸ¥æ‰€æœ‰ä¸Šæ¸¸èŠ‚ç‚¹æ˜¯å¦å·²å®Œæˆ
            all_dependencies_met = True
            for dep in dependencies:
                if dep['upstream_status'] not in ['completed', 'COMPLETED']:
                    all_dependencies_met = False
                    logger.trace(f"èŠ‚ç‚¹ {node_id} çš„ä¸Šæ¸¸èŠ‚ç‚¹ {dep['upstream_node_id']} çŠ¶æ€ä¸º {dep['upstream_status']}")
                    break
            
            if all_dependencies_met:
                # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºpending
                await self._update_node_status_to_pending(workflow_instance_id, node_id)
                logger.trace(f"èŠ‚ç‚¹ {node_id} æ‰€æœ‰ä¾èµ–å·²æ»¡è¶³ï¼ŒçŠ¶æ€æ›´æ–°ä¸ºpending")
            else:
                logger.trace(f"èŠ‚ç‚¹ {node_id} ä¾èµ–æœªæ»¡è¶³ï¼Œç»§ç»­ç­‰å¾…")
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥èŠ‚ç‚¹ä¾èµ–å¤±è´¥: {e}")

    async def _update_node_status_to_pending(self, workflow_instance_id: uuid.UUID, node_id: uuid.UUID):
        """æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºpendingå¹¶åˆ›å»ºç›¸åº”ä»»åŠ¡"""
        try:
            # æŸ¥æ‰¾èŠ‚ç‚¹å®ä¾‹
            find_node_query = """
                SELECT ni.*, n.type as node_type, n.name as node_name
                FROM node_instance ni
                JOIN node n ON ni.node_id = n.node_id
                WHERE ni.workflow_instance_id = $1 AND ni.node_id = $2
            """
            
            node_instance = await self.workflow_instance_repo.db.fetch_one(
                find_node_query, workflow_instance_id, node_id
            )
            
            if not node_instance:
                logger.error(f"æœªæ‰¾åˆ°èŠ‚ç‚¹å®ä¾‹: workflow_instance_id={workflow_instance_id}, node_id={node_id}")
                return
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
            update_query = """
                UPDATE node_instance 
                SET status = 'pending', updated_at = CURRENT_TIMESTAMP
                WHERE node_instance_id = $1
            """
            
            await self.workflow_instance_repo.db.execute(
                update_query, 
                node_instance['node_instance_id']
            )
            
            # ä¸ºpendingçš„èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡
            await self._create_tasks_for_pending_node(node_instance)
            
            logger.trace(f"èŠ‚ç‚¹ {node_id} çŠ¶æ€å·²æ›´æ–°ä¸ºpendingï¼Œä»»åŠ¡å·²åˆ›å»º")
            
        except Exception as e:
            logger.error(f"æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºpendingå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    async def _create_tasks_for_pending_node(self, node_instance: Dict[str, Any]):
        """ä¸ºpendingçŠ¶æ€çš„èŠ‚ç‚¹åˆ›å»ºä»»åŠ¡"""
        try:
            node_type = node_instance.get('node_type', '').lower()
            node_instance_id = node_instance['node_instance_id']
            
            # æ ¹æ®èŠ‚ç‚¹ç±»å‹åˆ›å»ºç›¸åº”çš„ä»»åŠ¡
            if node_type == 'human':
                task_type = TaskInstanceType.HUMAN
            elif node_type == 'agent':
                task_type = TaskInstanceType.AGENT
            elif node_type == 'mixed':
                task_type = TaskInstanceType.MIXED
            else:
                # å¯¹äºSTART, ENDç­‰èŠ‚ç‚¹ï¼Œåˆ›å»ºSYSTEMä»»åŠ¡
                task_type = TaskInstanceType.SYSTEM
            
            # åˆ›å»ºä»»åŠ¡å®ä¾‹
            task_data = TaskInstanceCreate(
                node_instance_id=node_instance_id,
                type=task_type,
                name=f"Task for {node_instance.get('node_name', 'Unknown')}",
                description=f"Auto-generated task for node {node_instance_id}",
                status=TaskInstanceStatus.PENDING,
                input_data=node_instance.get('input_data', {}),
                config=node_instance.get('config', {})
            )
            
            task_instance = await self.task_instance_repo.create_task(task_data)
            logger.trace(f"ä¸ºèŠ‚ç‚¹ {node_instance_id} åˆ›å»ºäº† {task_type} ç±»å‹çš„ä»»åŠ¡: {task_instance.task_instance_id}")
            
            # å°†ä»»åŠ¡åŠ å…¥æ‰§è¡Œé˜Ÿåˆ—
            await self.execution_queue.put({
                'workflow_instance_id': node_instance['workflow_instance_id'],
                'node_instance_id': node_instance_id,
                'task_instance_id': task_instance.task_instance_id,
                'type': task_type,
                'node_type': node_type
            })
            
        except Exception as e:
            logger.error(f"ä¸ºpendingèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    async def _cancel_running_tasks(self, instance_id: uuid.UUID):
        """å–æ¶ˆæ­£åœ¨è¿è¡Œçš„å¼‚æ­¥ä»»åŠ¡"""
        try:
            # æŸ¥æ‰¾æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡å®ä¾‹
            running_tasks_query = """
                SELECT ti.*, ni.workflow_instance_id
                FROM task_instance ti
                JOIN node_instance ni ON ti.node_instance_id = ni.node_instance_id
                WHERE ni.workflow_instance_id = $1
                AND ti.status IN ('running', 'RUNNING', 'assigned', 'ASSIGNED')
            """
            
            running_tasks = await self.task_instance_repo.db.fetch_all(
                running_tasks_query, 
                instance_id
            )
            
            logger.trace(f"æ‰¾åˆ° {len(running_tasks)} ä¸ªæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡éœ€è¦å–æ¶ˆ")
            
            for task in running_tasks:
                try:
                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå–æ¶ˆ
                    task_id = task['task_instance_id']
                    update_query = """
                        UPDATE task_instance 
                        SET status = 'cancelled', 
                            error_message = 'å·¥ä½œæµè¢«å–æ¶ˆ',
                            updated_at = CURRENT_TIMESTAMP
                        WHERE task_instance_id = $1
                    """
                    
                    await self.task_instance_repo.db.execute(update_query, task_id)
                    logger.trace(f"å·²å–æ¶ˆä»»åŠ¡: {task_id}")
                    
                except Exception as e:
                    logger.error(f"å–æ¶ˆä»»åŠ¡ {task.get('task_instance_id')} å¤±è´¥: {e}")
            
        except Exception as e:
            logger.error(f"å–æ¶ˆè¿è¡Œä»»åŠ¡å¤±è´¥: {e}")

    async def _cancel_instance_context_tasks(self, context):
        """å–æ¶ˆå®ä¾‹ä¸Šä¸‹æ–‡ä¸­çš„ä»»åŠ¡"""
        try:
            # æ ‡è®°æ‰€æœ‰æœªå®Œæˆçš„èŠ‚ç‚¹ä¸ºå–æ¶ˆçŠ¶æ€
            for node_id, node_info in context.node_dependencies.items():
                if node_id not in context.completed_nodes:
                    # æ·»åŠ åˆ°å®ŒæˆèŠ‚ç‚¹é›†åˆä¸­ï¼Œé˜²æ­¢åç»­æ‰§è¡Œ
                    context.completed_nodes.add(node_id)
                    logger.trace(f"æ ‡è®°èŠ‚ç‚¹ {node_id} ä¸ºå·²å–æ¶ˆ")
            
            # æ¸…ç†ä¸Šä¸‹æ–‡çŠ¶æ€
            context.current_executing_nodes.clear()
            
        except Exception as e:
            logger.error(f"å–æ¶ˆå®ä¾‹ä¸Šä¸‹æ–‡ä»»åŠ¡å¤±è´¥: {e}")

    async def _notify_services_workflow_cancelled(self, instance_id: uuid.UUID):
        """é€šçŸ¥ç›¸å…³æœåŠ¡å·¥ä½œæµå·²å–æ¶ˆ"""
        try:
            # é€šçŸ¥Agentä»»åŠ¡æœåŠ¡ï¼ˆå¦‚æœæœ‰ç›¸å…³æ–¹æ³•ï¼‰
            try:
                from .agent_task_service import agent_task_service
                # æ£€æŸ¥æ˜¯å¦æœ‰å–æ¶ˆæ–¹æ³•ï¼Œå¦‚æœæ²¡æœ‰åˆ™è·³è¿‡
                if hasattr(agent_task_service, 'cancel_workflow_tasks'):
                    await agent_task_service.cancel_workflow_tasks(instance_id)
                else:
                    logger.trace("Agentä»»åŠ¡æœåŠ¡æ²¡æœ‰cancel_workflow_tasksæ–¹æ³•ï¼Œè·³è¿‡é€šçŸ¥")
            except Exception as e:
                logger.warning(f"é€šçŸ¥Agentä»»åŠ¡æœåŠ¡å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ: {e}")
            
            # æ¸…ç†æ‰§è¡Œé˜Ÿåˆ—ä¸­çš„ç›¸å…³ä»»åŠ¡
            await self._remove_workflow_from_queue(instance_id)
            
            logger.trace(f"å·²é€šçŸ¥ç›¸å…³æœåŠ¡å·¥ä½œæµ {instance_id} å–æ¶ˆ")
            
        except Exception as e:
            logger.error(f"é€šçŸ¥æœåŠ¡å·¥ä½œæµå–æ¶ˆå¤±è´¥: {e}")

    async def _remove_workflow_from_queue(self, instance_id: uuid.UUID):
        """ä»æ‰§è¡Œé˜Ÿåˆ—ä¸­ç§»é™¤å·¥ä½œæµç›¸å…³ä»»åŠ¡"""
        try:
            # åˆ›å»ºæ–°çš„é˜Ÿåˆ—æ¥å­˜å‚¨ä¸éœ€è¦å–æ¶ˆçš„ä»»åŠ¡
            temp_queue = asyncio.Queue()
            cancelled_count = 0
            
            # å¤„ç†ç°æœ‰é˜Ÿåˆ—ä¸­çš„æ‰€æœ‰é¡¹ç›®
            while not self.execution_queue.empty():
                try:
                    item = self.execution_queue.get_nowait()
                    
                    # æ£€æŸ¥æ˜¯å¦å±äºè¦å–æ¶ˆçš„å·¥ä½œæµ
                    if item.get('workflow_instance_id') == instance_id:
                        cancelled_count += 1
                        logger.trace(f"ä»é˜Ÿåˆ—ä¸­ç§»é™¤ä»»åŠ¡: {item.get('task_instance_id')}")
                    else:
                        # ä¿ç•™å…¶ä»–å·¥ä½œæµçš„ä»»åŠ¡
                        await temp_queue.put(item)
                        
                except asyncio.QueueEmpty:
                    break
            
            # å°†ä¿ç•™çš„ä»»åŠ¡æ”¾å›åŸé˜Ÿåˆ—
            while not temp_queue.empty():
                try:
                    item = temp_queue.get_nowait()
                    await self.execution_queue.put(item)
                except asyncio.QueueEmpty:
                    break
            
            if cancelled_count > 0:
                logger.trace(f"ä»æ‰§è¡Œé˜Ÿåˆ—ä¸­ç§»é™¤äº† {cancelled_count} ä¸ªå¾…æ‰§è¡Œä»»åŠ¡")
                
        except Exception as e:
            logger.error(f"ä»æ‰§è¡Œé˜Ÿåˆ—ç§»é™¤ä»»åŠ¡å¤±è´¥: {e}")


# å…¨å±€æ‰§è¡Œå¼•æ“å®ä¾‹
execution_engine = ExecutionEngine()