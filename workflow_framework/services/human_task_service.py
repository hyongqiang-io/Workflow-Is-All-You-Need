"""
äººå·¥ä»»åŠ¡å¤„ç†æœåŠ¡
Human Task Processing Service
"""

import uuid
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta
from loguru import logger

from ..repositories.instance.task_instance_repository import TaskInstanceRepository
from ..repositories.instance.workflow_instance_repository import WorkflowInstanceRepository
from ..repositories.user.user_repository import UserRepository
from ..models.instance import (
    TaskInstanceUpdate, TaskInstanceStatus, TaskInstanceType
)
from ..utils.helpers import now_utc


class HumanTaskService:
    """äººå·¥ä»»åŠ¡å¤„ç†æœåŠ¡"""
    
    def __init__(self):
        self.task_repo = TaskInstanceRepository()
        self.workflow_instance_repo = WorkflowInstanceRepository()
        self.user_repo = UserRepository()
    
    async def get_user_tasks(self, user_id: uuid.UUID, 
                           status: Optional[TaskInstanceStatus] = None,
                           limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·çš„ä»»åŠ¡åˆ—è¡¨"""
        try:
            tasks = await self.task_repo.get_human_tasks_for_user(user_id, status, limit)
            
            # æ·»åŠ ä»»åŠ¡ä¼˜å…ˆçº§å’Œæˆªæ­¢æ—¶é—´ç­‰é™„åŠ ä¿¡æ¯
            for task in tasks:
                task = await self._enrich_task_info(task)
            
            logger.info(f"è·å–ç”¨æˆ· {user_id} çš„ä»»åŠ¡åˆ—è¡¨ï¼Œå…± {len(tasks)} ä¸ªä»»åŠ¡")
            return tasks
            
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            raise
    
    async def get_task_details(self, task_id: uuid.UUID, user_id: uuid.UUID) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡è¯¦ç»†ä¿¡æ¯"""
        try:
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                return None
            
            # éªŒè¯ä»»åŠ¡æ˜¯å¦åˆ†é…ç»™å½“å‰ç”¨æˆ·
            if task.get('assigned_user_id') != user_id:
                raise PermissionError("æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
            
            # ä¸°å¯Œä»»åŠ¡ä¿¡æ¯
            task = await self._enrich_task_info(task)
            
            # è·å–å·¥ä½œæµä¸Šä¸‹æ–‡ä¿¡æ¯
            workflow_instance = await self.workflow_instance_repo.get_instance_by_id(
                task['workflow_instance_id']
            )
            
            # è·å–å·¥ä½œæµåŸºæœ¬ä¿¡æ¯
            workflow_base = None
            if workflow_instance:
                from ..repositories.workflow.workflow_repository import WorkflowRepository
                workflow_repo = WorkflowRepository()
                workflow_base = await workflow_repo.get_workflow_by_base_id(
                    workflow_instance.get('workflow_base_id')
                )
            
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            node_info = await self._get_node_info(task.get('node_instance_id'))
            
            # è·å–å¤„ç†å™¨ä¿¡æ¯
            processor_info = await self._get_processor_info(task.get('processor_id'))
            
            # æ„å»ºå®Œæ•´çš„ä»»åŠ¡è¯¦æƒ…
            task_details = {
                # ===== ä»»åŠ¡åŸºæœ¬ä¿¡æ¯ =====
                'task_instance_id': task['task_instance_id'],
                'task_title': task.get('task_title', 'æœªå‘½åä»»åŠ¡'),
                'task_description': task.get('task_description', ''),
                'instructions': task.get('instructions', ''),
                'status': task.get('status', 'unknown'),
                'priority': task.get('priority', 0),
                'priority_label': task.get('priority_label', 'æ™®é€šä¼˜å…ˆçº§'),
                'estimated_duration': task.get('estimated_duration', 0),
                'actual_duration': task.get('actual_duration'),
                'current_duration': task.get('current_duration'),
                'estimated_deadline': task.get('estimated_deadline'),
                
                # ===== æ—¶é—´ä¿¡æ¯ =====
                'created_at': task.get('created_at'),
                'assigned_at': task.get('assigned_at'),
                'started_at': task.get('started_at'),
                'completed_at': task.get('completed_at'),
                
                # ===== å·¥ä½œæµä¸Šä¸‹æ–‡ =====
                'workflow_context': {
                    'workflow_name': workflow_base.get('name', 'æœªçŸ¥å·¥ä½œæµ') if workflow_base else 'æœªçŸ¥å·¥ä½œæµ',
                    'workflow_description': workflow_base.get('description', '') if workflow_base else '',
                    'workflow_version': workflow_base.get('version', 1) if workflow_base else 1,
                    'instance_name': workflow_instance.get('instance_name', '') if workflow_instance else '',
                    'instance_description': workflow_instance.get('description', '') if workflow_instance else '',
                    'workflow_input_data': workflow_instance.get('input_data', {}) if workflow_instance else {},
                    'workflow_context_data': workflow_instance.get('context_data', {}) if workflow_instance else {}
                },
                
                # ===== èŠ‚ç‚¹ä¸Šä¸‹æ–‡ =====
                'node_context': {
                    'node_name': node_info.get('node_name', 'æœªçŸ¥èŠ‚ç‚¹') if node_info else 'æœªçŸ¥èŠ‚ç‚¹',
                    'node_description': node_info.get('node_description', '') if node_info else '',
                    'node_type': node_info.get('node_type', '') if node_info else '',
                    'node_instance_id': str(task.get('node_instance_id', '')) if task.get('node_instance_id') else ''
                },
                
                # ===== å¤„ç†å™¨ä¿¡æ¯ =====
                'processor_context': {
                    'processor_name': processor_info.get('name', 'æœªçŸ¥å¤„ç†å™¨') if processor_info else 'æœªçŸ¥å¤„ç†å™¨',
                    'processor_type': processor_info.get('type', 'human') if processor_info else 'human',
                    'processor_description': processor_info.get('description', '') if processor_info else ''
                },
                
                # ===== ä¸Šæ¸¸èŠ‚ç‚¹æ•°æ® =====
                'upstream_context': await self._get_upstream_context(task),
                
                # ===== ä»»åŠ¡æ•°æ® =====
                'input_data': task.get('input_data', {}),
                'output_data': task.get('output_data', {}),
                'result_summary': task.get('result_summary', ''),
                'error_message': task.get('error_message', ''),
                
                # ===== å…¶ä»–ä¿¡æ¯ =====
                'assigned_user_id': task.get('assigned_user_id'),
                'retry_count': task.get('retry_count', 0)
            }
            
            logger.info(f"è·å–ä»»åŠ¡è¯¦æƒ…: {task_details['task_title']} (ID: {task_id})")
            return task_details
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}")
            raise
    
    async def _get_node_info(self, node_instance_id: Optional[uuid.UUID]) -> Optional[Dict[str, Any]]:
        """è·å–èŠ‚ç‚¹ä¿¡æ¯"""
        if not node_instance_id:
            return None
            
        try:
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_instance_repo = NodeInstanceRepository()
            
            query = """
            SELECT ni.*, n.name as node_name, n.task_description as node_description, 
                   n.type as node_type, n.task_description
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.node_instance_id = %s
            """
            
            result = await node_instance_repo.execute_query(query, [node_instance_id])
            return result[0] if result else None
            
        except Exception as e:
            logger.error(f"è·å–èŠ‚ç‚¹ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    async def _get_processor_info(self, processor_id: Optional[uuid.UUID]) -> Optional[Dict[str, Any]]:
        """è·å–å¤„ç†å™¨ä¿¡æ¯"""
        if not processor_id:
            return None
            
        try:
            from ..repositories.processor.processor_repository import ProcessorRepository
            processor_repo = ProcessorRepository()
            
            processor = await processor_repo.get_processor_by_id(processor_id)
            return processor
            
        except Exception as e:
            logger.error(f"è·å–å¤„ç†å™¨ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    async def _get_upstream_context(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡çš„ä¸Šæ¸¸ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        try:
            input_data = task.get('input_data', {})
            
            # è·å–ä¸Šæ¸¸èŠ‚ç‚¹çš„ç›´æ¥æ•°æ®
            immediate_upstream = input_data.get('immediate_upstream', {})
            
            # è·å–å·¥ä½œæµå…¨å±€æ•°æ®
            workflow_global = input_data.get('workflow_global', {})
            
            # è·å–èŠ‚ç‚¹çº§åˆ«ä¿¡æ¯
            node_info = input_data.get('node_info', {})
            
            # æ ¼å¼åŒ–ä¸Šæ¸¸æ•°æ®ä»¥ä¾¿å‰ç«¯å±•ç¤º
            formatted_upstream = {}
            for node_id, node_data in immediate_upstream.items():
                if isinstance(node_data, dict):
                    formatted_upstream[node_id] = {
                        'node_name': node_data.get('node_name', f'èŠ‚ç‚¹_{node_id[:8]}'),
                        'output_data': node_data.get('output_data', {}),
                        'completed_at': node_data.get('completed_at', ''),
                        'summary': self._extract_data_summary(node_data.get('output_data', {}))
                    }
            
            return {
                'immediate_upstream_results': formatted_upstream,
                'upstream_node_count': len(immediate_upstream),
                'workflow_global_data': workflow_global,
                'workflow_execution_path': workflow_global.get('execution_path', []),
                'workflow_start_time': workflow_global.get('execution_start_time', ''),
                'has_upstream_data': len(immediate_upstream) > 0
            }
            
        except Exception as e:
            logger.error(f"è·å–ä¸Šæ¸¸ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return {
                'immediate_upstream_results': {},
                'upstream_node_count': 0,
                'workflow_global_data': {},
                'workflow_execution_path': [],
                'workflow_start_time': '',
                'has_upstream_data': False
            }
    
    def _extract_data_summary(self, output_data: Dict[str, Any]) -> str:
        """ä»è¾“å‡ºæ•°æ®ä¸­æå–æ‘˜è¦ä¿¡æ¯"""
        try:
            if not output_data:
                return "æ— è¾“å‡ºæ•°æ®"
            
            # å°è¯•æå–å¸¸è§çš„æ‘˜è¦å­—æ®µ
            if 'summary' in output_data:
                return str(output_data['summary'])
            elif 'result_summary' in output_data:
                return str(output_data['result_summary'])
            elif 'message' in output_data:
                return str(output_data['message'])
            elif 'description' in output_data:
                return str(output_data['description'])
            else:
                # ç”ŸæˆåŸºäºæ•°æ®å†…å®¹çš„ç®€è¦æ‘˜è¦
                data_keys = list(output_data.keys())
                if len(data_keys) <= 3:
                    return f"åŒ…å«æ•°æ®: {', '.join(data_keys)}"
                else:
                    return f"åŒ…å« {len(data_keys)} é¡¹æ•°æ®: {', '.join(data_keys[:3])}..."
                    
        except Exception as e:
            logger.error(f"æå–æ•°æ®æ‘˜è¦å¤±è´¥: {e}")
            return "æ•°æ®æ‘˜è¦ä¸å¯ç”¨"
    
    async def start_task(self, task_id: uuid.UUID, user_id: uuid.UUID) -> Dict[str, Any]:
        """å¼€å§‹æ‰§è¡Œä»»åŠ¡"""
        try:
            # éªŒè¯ä»»åŠ¡çŠ¶æ€å’Œæƒé™
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task.get('assigned_user_id') != user_id:
                raise PermissionError("æ— æƒæ‰§è¡Œæ­¤ä»»åŠ¡")
            
            if task['status'] not in [TaskInstanceStatus.ASSIGNED.value, TaskInstanceStatus.PENDING.value]:
                raise ValueError(f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸å¼€å§‹æ‰§è¡Œï¼Œå½“å‰çŠ¶æ€: {task['status']}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿›è¡Œä¸­
            update_data = TaskInstanceUpdate(status=TaskInstanceStatus.IN_PROGRESS)
            updated_task = await self.task_repo.update_task(task_id, update_data)
            
            if updated_task:
                logger.info(f"ç”¨æˆ· {user_id} å¼€å§‹æ‰§è¡Œä»»åŠ¡: {updated_task['task_title']}")
                return {
                    'task_id': task_id,
                    'status': TaskInstanceStatus.IN_PROGRESS.value,
                    'started_at': updated_task.get('started_at'),
                    'message': 'ä»»åŠ¡å·²å¼€å§‹æ‰§è¡Œ'
                }
            else:
                raise RuntimeError("æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥")
                
        except Exception as e:
            logger.error(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def submit_task_result(self, task_id: uuid.UUID, user_id: uuid.UUID,
                               result_data: Dict[str, Any], 
                               result_summary: Optional[str] = None) -> Dict[str, Any]:
        """æäº¤ä»»åŠ¡ç»“æœ"""
        try:
            logger.info(f"ğŸš€ å¼€å§‹å¤„ç†ä»»åŠ¡æäº¤:")
            logger.info(f"  ä»»åŠ¡ID: {task_id}")
            logger.info(f"  ç”¨æˆ·ID: {user_id}")
            logger.info(f"  ç»“æœæ•°æ®: {result_data}")
            logger.info(f"  ç»“æœæ‘˜è¦: {result_summary}")
            
            # éªŒè¯ä»»åŠ¡çŠ¶æ€å’Œæƒé™
            logger.info(f"ğŸ“‹ æŸ¥è¯¢ä»»åŠ¡ä¿¡æ¯...")
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                logger.error(f"âŒ ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            logger.info(f"âœ… ä»»åŠ¡æŸ¥è¯¢æˆåŠŸ:")
            logger.info(f"  ä»»åŠ¡æ ‡é¢˜: {task.get('task_title')}")
            logger.info(f"  å½“å‰çŠ¶æ€: {task['status']}")
            logger.info(f"  åˆ†é…ç”¨æˆ·: {task.get('assigned_user_id')}")
            logger.info(f"  å¼€å§‹æ—¶é—´: {task.get('started_at')}")
            
            if task.get('assigned_user_id') != user_id:
                logger.error(f"âŒ æƒé™ä¸è¶³: ä»»åŠ¡åˆ†é…ç»™ {task.get('assigned_user_id')}ï¼Œä½†æäº¤ç”¨æˆ·ä¸º {user_id}")
                raise PermissionError("æ— æƒæäº¤æ­¤ä»»åŠ¡")
            
            if task['status'] != TaskInstanceStatus.IN_PROGRESS.value:
                logger.error(f"âŒ ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æäº¤: æœŸæœ› {TaskInstanceStatus.IN_PROGRESS.value}ï¼Œå®é™… {task['status']}")
                raise ValueError(f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æäº¤ç»“æœï¼Œå½“å‰çŠ¶æ€: {task['status']}")
            
            # è®¡ç®—å®é™…æ‰§è¡Œæ—¶é—´
            actual_duration = None
            if task.get('started_at'):
                try:
                    logger.info(f"ğŸ“… å¤„ç†å¼€å§‹æ—¶é—´: {task['started_at']} (ç±»å‹: {type(task['started_at'])})")
                    started_at = task['started_at']
                    
                    # å¤„ç†ä¸åŒç±»å‹çš„æ—¶é—´æ•°æ®
                    if isinstance(started_at, str):
                        # å­—ç¬¦ä¸²ç±»å‹ï¼Œéœ€è¦è§£æ
                        start_time = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
                    elif hasattr(started_at, 'replace'):
                        # å·²ç»æ˜¯datetimeå¯¹è±¡
                        start_time = started_at
                    else:
                        logger.warning(f"âš ï¸ æ— æ³•å¤„ç†çš„å¼€å§‹æ—¶é—´ç±»å‹: {type(started_at)}")
                        start_time = None
                    
                    if start_time:
                        # ç¡®ä¿æ—¶é—´æœ‰æ—¶åŒºä¿¡æ¯
                        if start_time.tzinfo is None:
                            from ..utils.helpers import now_utc
                            current_time = now_utc()
                        else:
                            current_time = datetime.now().replace(tzinfo=start_time.tzinfo)
                        
                        actual_duration = int((current_time - start_time).total_seconds() / 60)
                        logger.info(f"â±ï¸ è®¡ç®—æ‰§è¡Œæ—¶é—´æˆåŠŸ: {actual_duration} åˆ†é’Ÿ")
                    
                except Exception as time_error:
                    logger.error(f"âŒ æ—¶é—´è®¡ç®—å¤±è´¥: {time_error}")
                    logger.error(f"åŸå§‹æ—¶é—´æ•°æ®: {repr(task['started_at'])}")
                    actual_duration = None
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å®Œæˆ
            logger.info(f"ğŸ“ å‡†å¤‡æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å®Œæˆ...")
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.COMPLETED,
                output_data=result_data,
                result_summary=result_summary or "äººå·¥ä»»åŠ¡å®Œæˆ",
                actual_duration=actual_duration
            )
            logger.info(f"  æ›´æ–°æ•°æ®: {update_data}")
            
            updated_task = await self.task_repo.update_task(task_id, update_data)
            
            if updated_task:
                logger.info(f"âœ… ä»»åŠ¡çŠ¶æ€æ›´æ–°æˆåŠŸ:")
                logger.info(f"  ä»»åŠ¡æ ‡é¢˜: {updated_task['task_title']}")
                logger.info(f"  å®Œæˆæ—¶é—´: {updated_task.get('completed_at')}")
                logger.info(f"  æ‰§è¡Œæ—¶é•¿: {actual_duration} åˆ†é’Ÿ")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘ä¸‹æ¸¸ä»»åŠ¡
                logger.info(f"ğŸ”„ æ£€æŸ¥ä¸‹æ¸¸ä»»åŠ¡...")
                await self._check_downstream_tasks(task_id)
                
                result = {
                    'task_id': task_id,
                    'status': TaskInstanceStatus.COMPLETED.value,
                    'completed_at': updated_task.get('completed_at'),
                    'actual_duration': actual_duration,
                    'message': 'ä»»åŠ¡ç»“æœå·²æäº¤'
                }
                logger.info(f"ğŸ‰ ä»»åŠ¡æäº¤å®Œæˆï¼Œè¿”å›ç»“æœ: {result}")
                return result
            else:
                logger.error(f"âŒ ä»»åŠ¡çŠ¶æ€æ›´æ–°å¤±è´¥: update_taskè¿”å›None")
                raise RuntimeError("æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥")
                
        except Exception as e:
            logger.error(f"ğŸ’¥ æäº¤ä»»åŠ¡ç»“æœå¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def pause_task(self, task_id: uuid.UUID, user_id: uuid.UUID,
                        pause_reason: Optional[str] = None) -> Dict[str, Any]:
        """æš‚åœä»»åŠ¡"""
        try:
            # éªŒè¯ä»»åŠ¡çŠ¶æ€å’Œæƒé™
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task.get('assigned_user_id') != user_id:
                raise PermissionError("æ— æƒæš‚åœæ­¤ä»»åŠ¡")
            
            if task['status'] != TaskInstanceStatus.IN_PROGRESS.value:
                raise ValueError(f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æš‚åœï¼Œå½“å‰çŠ¶æ€: {task['status']}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²åˆ†é…ï¼ˆä»è¿›è¡Œä¸­å›åˆ°åˆ†é…çŠ¶æ€ï¼‰
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.ASSIGNED,
                error_message=f"ä»»åŠ¡æš‚åœ: {pause_reason}" if pause_reason else "ä»»åŠ¡æš‚åœ"
            )
            
            updated_task = await self.task_repo.update_task(task_id, update_data)
            
            if updated_task:
                logger.info(f"ç”¨æˆ· {user_id} æš‚åœä»»åŠ¡: {updated_task['task_title']}")
                return {
                    'task_id': task_id,
                    'status': TaskInstanceStatus.ASSIGNED.value,
                    'message': 'ä»»åŠ¡å·²æš‚åœ'
                }
            else:
                raise RuntimeError("æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥")
                
        except Exception as e:
            logger.error(f"æš‚åœä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def request_help(self, task_id: uuid.UUID, user_id: uuid.UUID,
                          help_message: str) -> Dict[str, Any]:
        """è¯·æ±‚å¸®åŠ©"""
        try:
            # éªŒè¯ä»»åŠ¡æƒé™
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task.get('assigned_user_id') != user_id:
                raise PermissionError("æ— æƒä¸ºæ­¤ä»»åŠ¡è¯·æ±‚å¸®åŠ©")
            
            # è®°å½•å¸®åŠ©è¯·æ±‚ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å¯ä»¥åˆ›å»ºå¸®åŠ©è¯·æ±‚è¡¨ï¼‰
            help_request = {
                'task_id': task_id,
                'user_id': user_id,
                'help_message': help_message,
                'requested_at': now_utc(),
                'status': 'pending'
            }
            
            logger.info(f"ç”¨æˆ· {user_id} ä¸ºä»»åŠ¡ {task_id} è¯·æ±‚å¸®åŠ©: {help_message}")
            
            return {
                'task_id': task_id,
                'help_request_id': str(uuid.uuid4()),  # æ¨¡æ‹Ÿå¸®åŠ©è¯·æ±‚ID
                'message': 'å¸®åŠ©è¯·æ±‚å·²æäº¤'
            }
            
        except Exception as e:
            logger.error(f"è¯·æ±‚å¸®åŠ©å¤±è´¥: {e}")
            raise
    
    async def reject_task(self, task_id: uuid.UUID, user_id: uuid.UUID,
                         reject_reason: str) -> Dict[str, Any]:
        """æ‹’ç»ä»»åŠ¡"""
        try:
            # éªŒè¯ä»»åŠ¡çŠ¶æ€å’Œæƒé™
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task.get('assigned_user_id') != user_id:
                raise PermissionError("æ— æƒæ‹’ç»æ­¤ä»»åŠ¡")
            
            if task['status'] not in [TaskInstanceStatus.ASSIGNED.value, TaskInstanceStatus.PENDING.value]:
                raise ValueError(f"ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æ‹’ç»ï¼Œå½“å‰çŠ¶æ€: {task['status']}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²æ‹’ç»ï¼ˆæ ‡è®°ä¸ºå¤±è´¥çŠ¶æ€ï¼Œå¹¶è®°å½•æ‹’ç»åŸå› ï¼‰
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.FAILED,
                error_message=f"ä»»åŠ¡è¢«æ‹’ç»: {reject_reason}",
                result_summary="ä»»åŠ¡è¢«ç”¨æˆ·æ‹’ç»"
            )
            
            updated_task = await self.task_repo.update_task(task_id, update_data)
            
            if updated_task:
                logger.info(f"ç”¨æˆ· {user_id} æ‹’ç»ä»»åŠ¡: {updated_task['task_title']} - {reject_reason}")
                
                # é€šçŸ¥å·¥ä½œæµå¼•æ“ä»»åŠ¡è¢«æ‹’ç»ï¼Œå¯èƒ½éœ€è¦é‡æ–°åˆ†é…æˆ–å¤„ç†
                await self._notify_task_rejected(task_id, reject_reason)
                
                return {
                    'task_id': task_id,
                    'status': TaskInstanceStatus.FAILED.value,
                    'message': 'ä»»åŠ¡å·²æ‹’ç»'
                }
            else:
                raise RuntimeError("æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥")
                
        except Exception as e:
            logger.error(f"æ‹’ç»ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def cancel_task(self, task_id: uuid.UUID, user_id: uuid.UUID,
                         cancel_reason: Optional[str] = "ç”¨æˆ·å–æ¶ˆ") -> Dict[str, Any]:
        """å–æ¶ˆä»»åŠ¡"""
        try:
            # éªŒè¯ä»»åŠ¡çŠ¶æ€å’Œæƒé™
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
            if task.get('assigned_user_id') != user_id:
                raise PermissionError("æ— æƒå–æ¶ˆæ­¤ä»»åŠ¡")
            
            if task['status'] in [TaskInstanceStatus.COMPLETED.value, TaskInstanceStatus.FAILED.value, TaskInstanceStatus.CANCELLED.value]:
                raise ValueError(f"ä»»åŠ¡å·²å®Œç»“ï¼Œæ— æ³•å–æ¶ˆã€‚å½“å‰çŠ¶æ€: {task['status']}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å–æ¶ˆ
            update_data = TaskInstanceUpdate(
                status=TaskInstanceStatus.CANCELLED,
                error_message=f"ä»»åŠ¡è¢«å–æ¶ˆ: {cancel_reason}",
                result_summary="ä»»åŠ¡è¢«ç”¨æˆ·å–æ¶ˆ"
            )
            
            updated_task = await self.task_repo.update_task(task_id, update_data)
            
            if updated_task:
                logger.info(f"ç”¨æˆ· {user_id} å–æ¶ˆä»»åŠ¡: {updated_task['task_title']} - {cancel_reason}")
                
                # é€šçŸ¥å·¥ä½œæµå¼•æ“ä»»åŠ¡è¢«å–æ¶ˆ
                await self._notify_task_cancelled(task_id, cancel_reason)
                
                return {
                    'task_id': task_id,
                    'status': TaskInstanceStatus.CANCELLED.value,
                    'message': 'ä»»åŠ¡å·²å–æ¶ˆ'
                }
            else:
                raise RuntimeError("æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥")
                
        except Exception as e:
            logger.error(f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def get_task_history(self, user_id: uuid.UUID, 
                             days: int = 30, limit: int = 100) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·ä»»åŠ¡å†å²"""
        try:
            # è·å–æŒ‡å®šå¤©æ•°å†…çš„å·²å®Œæˆä»»åŠ¡
            tasks = await self.task_repo.get_human_tasks_for_user(
                user_id, TaskInstanceStatus.COMPLETED, limit
            )
            
            # è¿‡æ»¤æŒ‡å®šå¤©æ•°å†…çš„ä»»åŠ¡
            cutoff_date = datetime.now() - timedelta(days=days)
            recent_tasks = []
            
            for task in tasks:
                if task.get('completed_at'):
                    completed_at = datetime.fromisoformat(task['completed_at'].replace('Z', '+00:00'))
                    if completed_at.replace(tzinfo=None) >= cutoff_date:
                        recent_tasks.append(task)
            
            logger.info(f"è·å–ç”¨æˆ· {user_id} çš„ä»»åŠ¡å†å²ï¼Œ{days}å¤©å†…å…± {len(recent_tasks)} ä¸ªä»»åŠ¡")
            return recent_tasks
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡å†å²å¤±è´¥: {e}")
            raise
    
    async def get_task_statistics(self, user_id: uuid.UUID) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·ä»»åŠ¡ç»Ÿè®¡"""
        try:
            # è·å–ç”¨æˆ·æ‰€æœ‰ä»»åŠ¡
            all_tasks = await self.task_repo.get_human_tasks_for_user(user_id, None, 1000)
            
            # ç»Ÿè®¡å„ç§çŠ¶æ€çš„ä»»åŠ¡æ•°é‡
            stats = {
                'total_tasks': len(all_tasks),
                'pending_tasks': 0,
                'assigned_tasks': 0,
                'in_progress_tasks': 0,
                'completed_tasks': 0,
                'failed_tasks': 0,
                'cancelled_tasks': 0,
                'average_completion_time': 0,
                'completion_rate': 0
            }
            
            total_duration = 0
            completed_count = 0
            
            for task in all_tasks:
                status = task['status']
                if status == TaskInstanceStatus.PENDING.value:
                    stats['pending_tasks'] += 1
                elif status == TaskInstanceStatus.ASSIGNED.value:
                    stats['assigned_tasks'] += 1
                elif status == TaskInstanceStatus.IN_PROGRESS.value:
                    stats['in_progress_tasks'] += 1
                elif status == TaskInstanceStatus.COMPLETED.value:
                    stats['completed_tasks'] += 1
                    completed_count += 1
                    if task.get('actual_duration'):
                        total_duration += task['actual_duration']
                elif status == TaskInstanceStatus.FAILED.value:
                    stats['failed_tasks'] += 1
                elif status == TaskInstanceStatus.CANCELLED.value:
                    stats['cancelled_tasks'] += 1
            
            # è®¡ç®—å¹³å‡å®Œæˆæ—¶é—´å’Œå®Œæˆç‡
            if completed_count > 0:
                stats['average_completion_time'] = total_duration / completed_count
                stats['completion_rate'] = (completed_count / len(all_tasks)) * 100
            
            logger.info(f"ç”Ÿæˆç”¨æˆ· {user_id} çš„ä»»åŠ¡ç»Ÿè®¡")
            return stats
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {e}")
            raise
    
    async def _enrich_task_info(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸°å¯Œä»»åŠ¡ä¿¡æ¯"""
        try:
            # è®¡ç®—ä»»åŠ¡ä¼˜å…ˆçº§æ ‡ç­¾
            priority = task.get('priority', 0)
            if priority >= 3:
                task['priority_label'] = 'é«˜ä¼˜å…ˆçº§'
            elif priority >= 2:
                task['priority_label'] = 'ä¸­ä¼˜å…ˆçº§'
            else:
                task['priority_label'] = 'ä½ä¼˜å…ˆçº§'
            
            # è®¡ç®—ä»»åŠ¡è€—æ—¶
            if task.get('started_at') and task.get('completed_at'):
                try:
                    # å¤„ç†ä¸åŒç±»å‹çš„æ—¶é—´æ•°æ®
                    started_at = task['started_at']
                    completed_at = task['completed_at']
                    
                    if isinstance(started_at, str):
                        start_time = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
                    else:
                        start_time = started_at
                    
                    if isinstance(completed_at, str):
                        end_time = datetime.fromisoformat(completed_at.replace('Z', '+00:00'))
                    else:
                        end_time = completed_at
                    
                    task['total_duration'] = int((end_time - start_time).total_seconds() / 60)
                except Exception as time_error:
                    logger.error(f"è®¡ç®—æ€»è€—æ—¶å¤±è´¥: {time_error}")
                    task['total_duration'] = 0
                    
            elif task.get('started_at') and task['status'] == TaskInstanceStatus.IN_PROGRESS.value:
                try:
                    started_at = task['started_at']
                    
                    if isinstance(started_at, str):
                        start_time = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
                    else:
                        start_time = started_at
                    
                    now_time = datetime.now().replace(tzinfo=start_time.tzinfo if start_time.tzinfo else None)
                    task['current_duration'] = int((now_time - start_time).total_seconds() / 60)
                except Exception as time_error:
                    logger.error(f"è®¡ç®—å½“å‰è€—æ—¶å¤±è´¥: {time_error}")
                    task['current_duration'] = 0
            
            # æ·»åŠ æˆªæ­¢æ—¶é—´ï¼ˆåŸºäºä¼°è®¡æ—¶é•¿ï¼‰
            if task.get('created_at') and task.get('estimated_duration'):
                try:
                    created_at = task['created_at']
                    
                    if isinstance(created_at, str):
                        created_time = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                    else:
                        created_time = created_at
                    
                    estimated_minutes = task['estimated_duration']
                    task['estimated_deadline'] = (created_time + timedelta(minutes=estimated_minutes)).isoformat()
                except Exception as time_error:
                    logger.error(f"è®¡ç®—æˆªæ­¢æ—¶é—´å¤±è´¥: {time_error}")
                    task['estimated_deadline'] = None
            
            return task
            
        except Exception as e:
            logger.error(f"ä¸°å¯Œä»»åŠ¡ä¿¡æ¯å¤±è´¥: {e}")
            return task
    
    async def _check_downstream_tasks(self, completed_task_id: uuid.UUID):
        """æ£€æŸ¥å¹¶è§¦å‘ä¸‹æ¸¸ä»»åŠ¡"""
        try:
            logger.info(f"ğŸ”„ ä»»åŠ¡ {completed_task_id} å®Œæˆï¼Œå¼€å§‹æ£€æŸ¥ä¸‹æ¸¸æ›´æ–°...")
            
            # 1. è·å–ä»»åŠ¡ä¿¡æ¯å’Œå¯¹åº”çš„èŠ‚ç‚¹å®ä¾‹
            task = await self.task_repo.get_task_by_id(completed_task_id)
            if not task:
                logger.error(f"âŒ æ— æ³•æ‰¾åˆ°ä»»åŠ¡: {completed_task_id}")
                return
            
            logger.info(f"ğŸ“‹ ä»»åŠ¡ä¿¡æ¯:")
            logger.info(f"  ä»»åŠ¡æ ‡é¢˜: {task.get('task_title')}")
            logger.info(f"  èŠ‚ç‚¹å®ä¾‹ID: {task.get('node_instance_id')}")
            logger.info(f"  å·¥ä½œæµå®ä¾‹ID: {task.get('workflow_instance_id')}")
            
            # 2. æ›´æ–°å¯¹åº”çš„èŠ‚ç‚¹å®ä¾‹çŠ¶æ€
            await self._update_node_instance_status(task)
            
            # 3. æ£€æŸ¥å¹¶æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€
            await self._update_workflow_instance_status(task['workflow_instance_id'])
            
            # 4. è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            await self._trigger_downstream_nodes(task)
            
            logger.info(f"âœ… ä¸‹æ¸¸ä»»åŠ¡æ£€æŸ¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"ğŸ’¥ æ£€æŸ¥ä¸‹æ¸¸ä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _update_node_instance_status(self, task: dict):
        """æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€"""
        try:
            node_instance_id = task.get('node_instance_id')
            if not node_instance_id:
                logger.warning(f"âš ï¸ ä»»åŠ¡æ²¡æœ‰å…³è”çš„èŠ‚ç‚¹å®ä¾‹ID")
                return
            
            logger.info(f"ğŸ“¦ æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€: {node_instance_id}")
            
            # æ£€æŸ¥è¯¥èŠ‚ç‚¹å®ä¾‹ä¸‹çš„æ‰€æœ‰ä»»åŠ¡æ˜¯å¦éƒ½å·²å®Œæˆ
            from ..repositories.instance.node_instance_repository import NodeInstanceRepository
            node_repo = NodeInstanceRepository()
            
            # æŸ¥è¯¢è¯¥èŠ‚ç‚¹ä¸‹çš„æ‰€æœ‰ä»»åŠ¡
            node_tasks_query = '''
            SELECT task_instance_id, status, task_title
            FROM task_instance 
            WHERE node_instance_id = $1 AND is_deleted = FALSE
            '''
            node_tasks = await self.task_repo.db.fetch_all(node_tasks_query, node_instance_id)
            
            logger.info(f"  èŠ‚ç‚¹ä¸‹çš„ä»»åŠ¡æ•°é‡: {len(node_tasks)}")
            
            # ç»Ÿè®¡ä»»åŠ¡çŠ¶æ€
            completed_tasks = [t for t in node_tasks if t['status'] == 'completed']
            failed_tasks = [t for t in node_tasks if t['status'] == 'failed']
            
            logger.info(f"  å·²å®Œæˆä»»åŠ¡: {len(completed_tasks)}")
            logger.info(f"  å¤±è´¥ä»»åŠ¡: {len(failed_tasks)}")
            
            # ç¡®å®šèŠ‚ç‚¹çŠ¶æ€
            if len(failed_tasks) > 0:
                node_status = 'failed'
                logger.info(f"  ğŸ”´ èŠ‚ç‚¹çŠ¶æ€è®¾ä¸º: failedï¼ˆæœ‰å¤±è´¥ä»»åŠ¡ï¼‰")
            elif len(completed_tasks) == len(node_tasks):
                node_status = 'completed' 
                logger.info(f"  ğŸŸ¢ èŠ‚ç‚¹çŠ¶æ€è®¾ä¸º: completedï¼ˆæ‰€æœ‰ä»»åŠ¡å®Œæˆï¼‰")
            else:
                node_status = 'running'
                logger.info(f"  ğŸŸ¡ èŠ‚ç‚¹çŠ¶æ€è®¾ä¸º: runningï¼ˆéƒ¨åˆ†ä»»åŠ¡å®Œæˆï¼‰")
            
            # æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€
            update_query = '''
            UPDATE node_instance 
            SET status = $1, updated_at = $2
            WHERE node_instance_id = $3
            '''
            from ..utils.helpers import now_utc
            await self.task_repo.db.execute(update_query, node_status, now_utc(), node_instance_id)
            logger.info(f"  âœ… èŠ‚ç‚¹å®ä¾‹çŠ¶æ€æ›´æ–°æˆåŠŸ: {node_status}")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€å¤±è´¥: {e}")
    
    async def _update_workflow_instance_status(self, workflow_instance_id: uuid.UUID):
        """æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€"""
        try:
            logger.info(f"ğŸ­ æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€: {workflow_instance_id}")
            
            # æŸ¥è¯¢è¯¥å·¥ä½œæµä¸‹çš„æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹
            nodes_query = '''
            SELECT ni.node_instance_id, ni.status, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 AND ni.is_deleted = FALSE
            '''
            nodes = await self.task_repo.db.fetch_all(nodes_query, workflow_instance_id)
            
            logger.info(f"  å·¥ä½œæµä¸‹çš„èŠ‚ç‚¹æ•°é‡: {len(nodes)}")
            
            # ç»Ÿè®¡èŠ‚ç‚¹çŠ¶æ€
            completed_nodes = [n for n in nodes if n['status'] == 'completed']
            failed_nodes = [n for n in nodes if n['status'] == 'failed']
            running_nodes = [n for n in nodes if n['status'] == 'running']
            
            logger.info(f"  å·²å®ŒæˆèŠ‚ç‚¹: {len(completed_nodes)}")
            logger.info(f"  å¤±è´¥èŠ‚ç‚¹: {len(failed_nodes)}")
            logger.info(f"  è¿è¡Œä¸­èŠ‚ç‚¹: {len(running_nodes)}")
            
            # ç¡®å®šå·¥ä½œæµçŠ¶æ€
            if len(failed_nodes) > 0:
                workflow_status = 'failed'
                logger.info(f"  ğŸ”´ å·¥ä½œæµçŠ¶æ€è®¾ä¸º: failedï¼ˆæœ‰å¤±è´¥èŠ‚ç‚¹ï¼‰")
            elif len(completed_nodes) == len(nodes):
                workflow_status = 'completed'
                logger.info(f"  ğŸŸ¢ å·¥ä½œæµçŠ¶æ€è®¾ä¸º: completedï¼ˆæ‰€æœ‰èŠ‚ç‚¹å®Œæˆï¼‰")
            else:
                workflow_status = 'running'
                logger.info(f"  ğŸŸ¡ å·¥ä½œæµçŠ¶æ€è®¾ä¸º: runningï¼ˆéƒ¨åˆ†èŠ‚ç‚¹å®Œæˆï¼‰")
            
            # æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€
            update_query = '''
            UPDATE workflow_instance 
            SET status = $1, updated_at = $2
            WHERE workflow_instance_id = $3
            '''
            from ..utils.helpers import now_utc
            await self.task_repo.db.execute(update_query, workflow_status, now_utc(), workflow_instance_id)
            logger.info(f"  âœ… å·¥ä½œæµå®ä¾‹çŠ¶æ€æ›´æ–°æˆåŠŸ: {workflow_status}")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€å¤±è´¥: {e}")
    
    async def _trigger_downstream_nodes(self, task: dict):
        """è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹æ‰§è¡Œ"""
        try:
            logger.info(f"ğŸš€ æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹...")
            
            workflow_instance_id = task.get('workflow_instance_id')
            current_node_instance_id = task.get('node_instance_id')
            
            logger.info(f"  å½“å‰èŠ‚ç‚¹å®ä¾‹: {current_node_instance_id}")
            logger.info(f"  å·¥ä½œæµå®ä¾‹: {workflow_instance_id}")
            
            # 1. è·å–å½“å‰èŠ‚ç‚¹å®ä¾‹çš„ä¿¡æ¯
            current_node_query = '''
            SELECT ni.*, n.type as node_type, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.node_instance_id = $1
            '''
            current_node = await self.task_repo.db.fetch_one(current_node_query, current_node_instance_id)
            
            if not current_node:
                logger.warning(f"âš ï¸ æ— æ³•æ‰¾åˆ°å½“å‰èŠ‚ç‚¹å®ä¾‹: {current_node_instance_id}")
                return
            
            logger.info(f"  å½“å‰èŠ‚ç‚¹ç±»å‹: {current_node['node_type']}")
            logger.info(f"  å½“å‰èŠ‚ç‚¹åç§°: {current_node['node_name']}")
            
            # 2. æŸ¥æ‰¾ä¸‹æ¸¸èŠ‚ç‚¹ï¼ˆé€šè¿‡node_connectionè¡¨ï¼‰
            downstream_nodes_query = '''
            SELECT ni.*, n.type as node_type, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id  
            JOIN node_connection nc ON nc.to_node_id = n.node_id
            JOIN node source_node ON nc.from_node_id = source_node.node_id
            JOIN node_instance source_ni ON source_ni.node_id = source_node.node_id
            WHERE source_ni.node_instance_id = $1 
            AND ni.workflow_instance_id = $2
            AND ni.status = 'pending'
            '''
            downstream_nodes = await self.task_repo.db.fetch_all(
                downstream_nodes_query, 
                current_node_instance_id, 
                workflow_instance_id
            )
            
            logger.info(f"  æ‰¾åˆ°ä¸‹æ¸¸èŠ‚ç‚¹æ•°é‡: {len(downstream_nodes)}")
            
            # 3. å¤„ç†æ¯ä¸ªä¸‹æ¸¸èŠ‚ç‚¹
            for downstream_node in downstream_nodes:
                await self._process_downstream_node(downstream_node, workflow_instance_id)
            
            # 4. æ£€æŸ¥æ˜¯å¦è§¦å‘äº†ç»“æŸèŠ‚ç‚¹
            await self._check_and_execute_end_nodes(workflow_instance_id)
            
        except Exception as e:
            logger.error(f"âŒ è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _process_downstream_node(self, node: dict, workflow_instance_id: uuid.UUID):
        """å¤„ç†å•ä¸ªä¸‹æ¸¸èŠ‚ç‚¹"""
        try:
            node_instance_id = node['node_instance_id']
            node_type = node['node_type']
            node_name = node['node_name']
            
            logger.info(f"ğŸ“¦ å¤„ç†ä¸‹æ¸¸èŠ‚ç‚¹: {node_name} (ç±»å‹: {node_type})")
            
            # æ£€æŸ¥è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰å‰ç½®æ¡ä»¶æ˜¯å¦æ»¡è¶³
            prerequisites_satisfied = await self._check_node_prerequisites(node_instance_id)
            
            if not prerequisites_satisfied:
                logger.info(f"  â³ å‰ç½®æ¡ä»¶æœªæ»¡è¶³ï¼ŒèŠ‚ç‚¹æš‚ä¸æ‰§è¡Œ: {node_name}")
                return
            
            logger.info(f"  âœ… å‰ç½®æ¡ä»¶å·²æ»¡è¶³ï¼Œå‡†å¤‡æ‰§è¡ŒèŠ‚ç‚¹: {node_name}")
            
            # æ ¹æ®èŠ‚ç‚¹ç±»å‹æ‰§è¡Œä¸åŒçš„é€»è¾‘
            if node_type == 'end':
                # ç»“æŸèŠ‚ç‚¹è‡ªåŠ¨æ‰§è¡Œ
                await self._execute_end_node(node_instance_id, workflow_instance_id)
            elif node_type in ['human', 'agent', 'mix']:
                # ä»»åŠ¡èŠ‚ç‚¹ï¼šåˆ›å»ºä»»åŠ¡å®ä¾‹
                await self._create_node_tasks(node_instance_id)
            else:
                logger.info(f"  âš ï¸ æœªçŸ¥èŠ‚ç‚¹ç±»å‹: {node_type}")
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†ä¸‹æ¸¸èŠ‚ç‚¹å¤±è´¥: {e}")
    
    async def _check_node_prerequisites(self, node_instance_id: uuid.UUID) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹çš„å‰ç½®æ¡ä»¶æ˜¯å¦æ»¡è¶³"""
        try:
            # æŸ¥è¯¢è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰å‰ç½®èŠ‚ç‚¹ï¼ˆé€šè¿‡node_connectionè¡¨ï¼‰
            prerequisite_query = '''
            SELECT ni.node_instance_id, ni.status, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            JOIN node_connection nc ON nc.from_node_id = n.node_id
            JOIN node target_node ON nc.to_node_id = target_node.node_id
            JOIN node_instance target_ni ON target_ni.node_id = target_node.node_id
            WHERE target_ni.node_instance_id = $1
            '''
            prerequisites = await self.task_repo.db.fetch_all(prerequisite_query, node_instance_id)
            
            if not prerequisites:
                # æ²¡æœ‰å‰ç½®èŠ‚ç‚¹ï¼Œå¯ä»¥æ‰§è¡Œ
                logger.info(f"    ğŸ“‹ æ— å‰ç½®èŠ‚ç‚¹ï¼Œå¯ä»¥æ‰§è¡Œ")
                return True
            
            # æ£€æŸ¥æ‰€æœ‰å‰ç½®èŠ‚ç‚¹æ˜¯å¦éƒ½å·²å®Œæˆ
            completed_prerequisites = [p for p in prerequisites if p['status'] == 'completed']
            
            logger.info(f"    ğŸ“‹ å‰ç½®èŠ‚ç‚¹: {len(prerequisites)} ä¸ªï¼Œå·²å®Œæˆ: {len(completed_prerequisites)} ä¸ª")
            
            for prereq in prerequisites:
                status_emoji = "âœ…" if prereq['status'] == 'completed' else "âŒ"
                logger.info(f"      {status_emoji} {prereq['node_name']}: {prereq['status']}")
            
            return len(completed_prerequisites) == len(prerequisites)
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥å‰ç½®æ¡ä»¶å¤±è´¥: {e}")
            return False
    
    async def _execute_end_node(self, node_instance_id: uuid.UUID, workflow_instance_id: uuid.UUID):
        """è‡ªåŠ¨æ‰§è¡Œç»“æŸèŠ‚ç‚¹"""
        try:
            logger.info(f"ğŸ å¼€å§‹æ‰§è¡Œç»“æŸèŠ‚ç‚¹: {node_instance_id}")
            
            # 1. æ›´æ–°ç»“æŸèŠ‚ç‚¹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            update_query = '''
            UPDATE node_instance 
            SET status = 'running', updated_at = $1
            WHERE node_instance_id = $2
            '''
            from ..utils.helpers import now_utc
            await self.task_repo.db.execute(update_query, now_utc(), node_instance_id)
            
            # 2. æ”¶é›†å·¥ä½œæµçš„å®Œæ•´ä¸Šä¸‹æ–‡
            workflow_context = await self._collect_workflow_context(workflow_instance_id)
            
            # 3. æ›´æ–°ç»“æŸèŠ‚ç‚¹çŠ¶æ€ä¸ºå·²å®Œæˆï¼Œå¹¶ä¿å­˜ä¸Šä¸‹æ–‡
            complete_query = '''
            UPDATE node_instance 
            SET status = 'completed', 
                output_data = $1,
                updated_at = $2
            WHERE node_instance_id = $3
            '''
            await self.task_repo.db.execute(
                complete_query, 
                workflow_context, 
                now_utc(), 
                node_instance_id
            )
            
            logger.info(f"  âœ… ç»“æŸèŠ‚ç‚¹æ‰§è¡Œå®Œæˆï¼Œä¸Šä¸‹æ–‡å·²ä¿å­˜")
            logger.info(f"  ğŸ“Š ä¸Šä¸‹æ–‡æ•°æ®å¤§å°: {len(str(workflow_context))} å­—ç¬¦")
            
            # 4. æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºå·²å®Œæˆ
            await self._update_workflow_instance_status(workflow_instance_id)
            
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œç»“æŸèŠ‚ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _collect_workflow_context(self, workflow_instance_id: uuid.UUID) -> dict:
        """æ”¶é›†å·¥ä½œæµçš„å®Œæ•´ä¸Šä¸‹æ–‡å†…å®¹"""
        try:
            logger.info(f"ğŸ“Š å¼€å§‹æ”¶é›†å·¥ä½œæµä¸Šä¸‹æ–‡: {workflow_instance_id}")
            
            # 1. è·å–å·¥ä½œæµå®ä¾‹åŸºæœ¬ä¿¡æ¯
            workflow_query = '''
            SELECT wi.*, w.name as workflow_name, w.description as workflow_description,
                   u.username as executor_username
            FROM workflow_instance wi
            JOIN workflow w ON wi.workflow_base_id = w.workflow_base_id AND w.is_current_version = TRUE
            LEFT JOIN "user" u ON wi.executor_id = u.user_id
            WHERE wi.workflow_instance_id = $1
            '''
            workflow_info = await self.task_repo.db.fetch_one(workflow_query, workflow_instance_id)
            
            # 2. è·å–æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹åŠå…¶è¾“å‡ºæ•°æ®
            nodes_query = '''
            SELECT ni.*, n.name as node_name, n.type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1
            ORDER BY ni.created_at
            '''
            nodes = await self.task_repo.db.fetch_all(nodes_query, workflow_instance_id)
            
            # 3. è·å–æ‰€æœ‰ä»»åŠ¡å®ä¾‹åŠå…¶è¾“å‡ºæ•°æ®
            tasks_query = '''
            SELECT ti.*, ni.node_name
            FROM task_instance ti
            JOIN node_instance ni ON ti.node_instance_id = ni.node_instance_id
            WHERE ni.workflow_instance_id = $1
            ORDER BY ti.created_at
            '''
            tasks = await self.task_repo.db.fetch_all(tasks_query, workflow_instance_id)
            
            # 4. æ„å»ºå®Œæ•´çš„ä¸Šä¸‹æ–‡å¯¹è±¡
            context = {
                'workflow_instance': {
                    'instance_id': str(workflow_instance_id),
                    'instance_name': workflow_info['instance_name'],
                    'workflow_name': workflow_info['workflow_name'],
                    'workflow_description': workflow_info['workflow_description'],
                    'executor_username': workflow_info['executor_username'],
                    'status': workflow_info['status'],
                    'created_at': workflow_info['created_at'].isoformat() if workflow_info['created_at'] else None,
                    'updated_at': workflow_info['updated_at'].isoformat() if workflow_info['updated_at'] else None,
                    'input_data': workflow_info.get('input_data', {}),
                    'context_data': workflow_info.get('context_data', {})
                },
                'execution_summary': {
                    'total_nodes': len(nodes),
                    'completed_nodes': len([n for n in nodes if n['status'] == 'completed']),
                    'total_tasks': len(tasks),
                    'completed_tasks': len([t for t in tasks if t['status'] == 'completed']),
                    'execution_duration_minutes': self._calculate_execution_duration(workflow_info),
                    'completion_time': now_utc().isoformat()
                },
                'nodes_execution': [],
                'tasks_results': [],
                'workflow_output': {}
            }
            
            # 5. æ·»åŠ èŠ‚ç‚¹æ‰§è¡Œä¿¡æ¯
            for node in nodes:
                node_info = {
                    'node_instance_id': str(node['node_instance_id']),
                    'node_name': node['node_name'],
                    'node_type': node['node_type'],
                    'status': node['status'],
                    'input_data': node.get('input_data', {}),
                    'output_data': node.get('output_data', {}),
                    'created_at': node['created_at'].isoformat() if node['created_at'] else None,
                    'updated_at': node['updated_at'].isoformat() if node['updated_at'] else None
                }
                context['nodes_execution'].append(node_info)
            
            # 6. æ·»åŠ ä»»åŠ¡ç»“æœä¿¡æ¯
            for task in tasks:
                task_info = {
                    'task_instance_id': str(task['task_instance_id']),
                    'task_title': task['task_title'],
                    'task_description': task['task_description'],
                    'node_name': task['node_name'],
                    'status': task['status'],
                    'input_data': task.get('input_data', {}),
                    'output_data': task.get('output_data', {}),
                    'result_summary': task.get('result_summary'),
                    'created_at': task['created_at'].isoformat() if task['created_at'] else None,
                    'completed_at': task['completed_at'].isoformat() if task['completed_at'] else None,
                    'actual_duration': task.get('actual_duration')
                }
                context['tasks_results'].append(task_info)
            
            # 7. ç”Ÿæˆå·¥ä½œæµè¾“å‡ºæ‘˜è¦
            context['workflow_output'] = self._generate_workflow_output_summary(context)
            
            logger.info(f"  âœ… ä¸Šä¸‹æ–‡æ”¶é›†å®Œæˆ:")
            logger.info(f"    èŠ‚ç‚¹æ•°é‡: {context['execution_summary']['total_nodes']}")
            logger.info(f"    ä»»åŠ¡æ•°é‡: {context['execution_summary']['total_tasks']}")
            logger.info(f"    æ‰§è¡Œæ—¶é•¿: {context['execution_summary']['execution_duration_minutes']} åˆ†é’Ÿ")
            
            return context
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†å·¥ä½œæµä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return {}
    
    def _calculate_execution_duration(self, workflow_info: dict) -> int:
        """è®¡ç®—å·¥ä½œæµæ‰§è¡Œæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰"""
        try:
            if workflow_info.get('created_at'):
                from ..utils.helpers import now_utc
                start_time = workflow_info['created_at']
                end_time = now_utc()
                duration = (end_time - start_time).total_seconds() / 60
                return int(duration)
            return 0
        except:
            return 0
    
    def _generate_workflow_output_summary(self, context: dict) -> dict:
        """ç”Ÿæˆå·¥ä½œæµè¾“å‡ºæ‘˜è¦"""
        try:
            summary = {
                'execution_status': 'completed',
                'total_execution_time': context['execution_summary']['execution_duration_minutes'],
                'nodes_summary': {},
                'key_results': [],
                'completion_message': f"å·¥ä½œæµ '{context['workflow_instance']['workflow_name']}' æ‰§è¡Œå®Œæˆ"
            }
            
            # æŒ‰èŠ‚ç‚¹ç±»å‹æ±‡æ€»
            for node in context['nodes_execution']:
                node_type = node['node_type']
                if node_type not in summary['nodes_summary']:
                    summary['nodes_summary'][node_type] = {'count': 0, 'completed': 0}
                summary['nodes_summary'][node_type]['count'] += 1
                if node['status'] == 'completed':
                    summary['nodes_summary'][node_type]['completed'] += 1
            
            # æå–å…³é”®ç»“æœ
            for task in context['tasks_results']:
                if task['status'] == 'completed' and task.get('output_data'):
                    summary['key_results'].append({
                        'task': task['task_title'],
                        'node': task['node_name'],
                        'result': task.get('result_summary', 'ä»»åŠ¡å®Œæˆ'),
                        'output_data': task['output_data']
                    })
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆè¾“å‡ºæ‘˜è¦å¤±è´¥: {e}")
            return {'execution_status': 'completed', 'error': str(e)}
    
    async def _check_and_execute_end_nodes(self, workflow_instance_id: uuid.UUID):
        """æ£€æŸ¥å¹¶æ‰§è¡Œå‡†å¤‡å¥½çš„ç»“æŸèŠ‚ç‚¹"""
        try:
            # æŸ¥æ‰¾æ‰€æœ‰ç»“æŸèŠ‚ç‚¹
            end_nodes_query = '''
            SELECT ni.*, n.name as node_name
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.workflow_instance_id = $1 
            AND n.type = 'end'
            AND ni.status = 'pending'
            '''
            end_nodes = await self.task_repo.db.fetch_all(end_nodes_query, workflow_instance_id)
            
            logger.info(f"ğŸ æ£€æŸ¥ç»“æŸèŠ‚ç‚¹: æ‰¾åˆ° {len(end_nodes)} ä¸ªå¾…æ‰§è¡Œçš„ç»“æŸèŠ‚ç‚¹")
            
            for end_node in end_nodes:
                node_instance_id = end_node['node_instance_id']
                node_name = end_node['node_name']
                
                # æ£€æŸ¥å‰ç½®æ¡ä»¶
                if await self._check_node_prerequisites(node_instance_id):
                    logger.info(f"  ğŸš€ æ‰§è¡Œç»“æŸèŠ‚ç‚¹: {node_name}")
                    await self._execute_end_node(node_instance_id, workflow_instance_id)
                else:
                    logger.info(f"  â³ ç»“æŸèŠ‚ç‚¹å‰ç½®æ¡ä»¶æœªæ»¡è¶³: {node_name}")
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ç»“æŸèŠ‚ç‚¹å¤±è´¥: {e}")
    
    async def _create_node_tasks(self, node_instance_id: uuid.UUID):
        """ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹"""
        try:
            logger.info(f"ğŸ“‹ ä¸ºèŠ‚ç‚¹åˆ›å»ºä»»åŠ¡å®ä¾‹: {node_instance_id}")
            
            # è·å–èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯
            node_query = '''
            SELECT ni.*, n.name as node_name, n.type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.node_instance_id = $1
            '''
            node = await self.task_repo.db.fetch_one(node_query, node_instance_id)
            
            if not node:
                logger.error(f"âŒ æ‰¾ä¸åˆ°èŠ‚ç‚¹å®ä¾‹: {node_instance_id}")
                return
            
            logger.info(f"  èŠ‚ç‚¹åç§°: {node['node_name']}")
            logger.info(f"  èŠ‚ç‚¹ç±»å‹: {node['node_type']}")
            
            # æŸ¥è¯¢è¯¥èŠ‚ç‚¹ç»‘å®šçš„å¤„ç†å™¨
            processors_query = '''
            SELECT p.*, nb.binding_type, nb.priority
            FROM processor p
            JOIN node_binding nb ON p.processor_id = nb.processor_id
            WHERE nb.node_id = $1 AND nb.is_active = TRUE
            ORDER BY nb.priority
            '''
            processors = await self.task_repo.db.fetch_all(processors_query, node['node_id'])
            
            logger.info(f"  ç»‘å®šçš„å¤„ç†å™¨æ•°é‡: {len(processors)}")
            
            if not processors:
                logger.warning(f"âš ï¸ èŠ‚ç‚¹æ²¡æœ‰ç»‘å®šå¤„ç†å™¨ï¼Œæ— æ³•åˆ›å»ºä»»åŠ¡")
                return
            
            # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºè¿è¡Œä¸­
            update_node_query = '''
            UPDATE node_instance 
            SET status = 'running', updated_at = $1
            WHERE node_instance_id = $2
            '''
            from ..utils.helpers import now_utc
            await self.task_repo.db.execute(update_node_query, now_utc(), node_instance_id)
            
            # ä¸ºæ¯ä¸ªå¤„ç†å™¨åˆ›å»ºä»»åŠ¡å®ä¾‹
            created_tasks = []
            for processor in processors:
                task_data = {
                    'node_instance_id': node_instance_id,
                    'workflow_instance_id': node['workflow_instance_id'],
                    'task_title': f"{node['node_name']} - {processor['name']}",
                    'task_description': f"æ‰§è¡ŒèŠ‚ç‚¹: {node['node_name']}",
                    'task_type': processor['processor_type'],
                    'processor_id': processor['processor_id'],
                    'priority': processor.get('priority', 1)
                }
                
                # æ ¹æ®å¤„ç†å™¨ç±»å‹åˆ†é…ä»»åŠ¡
                if processor['processor_type'] == 'HUMAN':
                    # åˆ†é…ç»™æŒ‡å®šç”¨æˆ·
                    if processor.get('assigned_user_id'):
                        task_data['assigned_user_id'] = processor['assigned_user_id']
                elif processor['processor_type'] == 'AGENT':
                    # åˆ†é…ç»™æŒ‡å®šä»£ç†
                    if processor.get('assigned_agent_id'):
                        task_data['assigned_agent_id'] = processor['assigned_agent_id']
                
                # åˆ›å»ºä»»åŠ¡å®ä¾‹
                from ..models.instance import TaskInstanceCreate
                task_create = TaskInstanceCreate(**task_data)
                task_id = await self.task_repo.create_task(task_create)
                
                created_tasks.append({
                    'task_id': task_id,
                    'task_title': task_data['task_title'],
                    'processor_type': processor['processor_type'],
                    'processor_name': processor['name']
                })
                
                logger.info(f"    âœ… åˆ›å»ºä»»åŠ¡: {task_data['task_title']} ({processor['processor_type']})")
            
            logger.info(f"  ğŸ¯ èŠ‚ç‚¹ä»»åŠ¡åˆ›å»ºå®Œæˆï¼Œå…±åˆ›å»º {len(created_tasks)} ä¸ªä»»åŠ¡")
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºèŠ‚ç‚¹ä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def cancel_workflow_instance(self, instance_id: uuid.UUID, user_id: uuid.UUID, 
                                     cancel_reason: str = "ç”¨æˆ·å–æ¶ˆ") -> Dict[str, Any]:
        """å–æ¶ˆå·¥ä½œæµå®ä¾‹å¹¶çº§è”å–æ¶ˆæ‰€æœ‰ç›¸å…³ä»»åŠ¡"""
        try:
            logger.info(f"ğŸš« å¼€å§‹å–æ¶ˆå·¥ä½œæµå®ä¾‹:")
            logger.info(f"  å®ä¾‹ID: {instance_id}")
            logger.info(f"  æ“ä½œç”¨æˆ·: {user_id}")
            logger.info(f"  å–æ¶ˆåŸå› : {cancel_reason}")
            
            # 1. éªŒè¯å·¥ä½œæµå®ä¾‹æ˜¯å¦å­˜åœ¨å’Œæƒé™
            workflow_query = '''
            SELECT workflow_instance_id, executor_id, status, instance_name
            FROM workflow_instance 
            WHERE workflow_instance_id = $1 AND is_deleted = FALSE
            '''
            workflow = await self.task_repo.db.fetch_one(workflow_query, instance_id)
            
            if not workflow:
                logger.error(f"âŒ å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨: {instance_id}")
                raise ValueError("å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨")
            
            logger.info(f"âœ… å·¥ä½œæµå®ä¾‹æŸ¥è¯¢æˆåŠŸ:")
            logger.info(f"  å®ä¾‹åç§°: {workflow['instance_name']}")
            logger.info(f"  å½“å‰çŠ¶æ€: {workflow['status']}")
            logger.info(f"  æ‰§è¡Œè€…: {workflow['executor_id']}")
            
            # æ£€æŸ¥æƒé™ï¼ˆåªæœ‰æ‰§è¡Œè€…æˆ–ç®¡ç†å‘˜å¯ä»¥å–æ¶ˆï¼‰
            if workflow['executor_id'] != user_id:
                # TODO: è¿™é‡Œå¯ä»¥æ·»åŠ ç®¡ç†å‘˜æƒé™æ£€æŸ¥
                logger.error(f"âŒ æ— æƒå–æ¶ˆå·¥ä½œæµ: æ‰§è¡Œè€… {workflow['executor_id']}ï¼Œæ“ä½œè€… {user_id}")
                raise PermissionError("æ— æƒå–æ¶ˆæ­¤å·¥ä½œæµå®ä¾‹")
            
            # æ£€æŸ¥çŠ¶æ€æ˜¯å¦å…è®¸å–æ¶ˆ
            if workflow['status'] in ['completed', 'failed', 'cancelled']:
                logger.error(f"âŒ å·¥ä½œæµçŠ¶æ€ä¸å…è®¸å–æ¶ˆ: {workflow['status']}")
                raise ValueError(f"å·¥ä½œæµçŠ¶æ€ä¸å…è®¸å–æ¶ˆï¼Œå½“å‰çŠ¶æ€: {workflow['status']}")
            
            # 2. è·å–å·¥ä½œæµä¸‹çš„æ‰€æœ‰ä»»åŠ¡å®ä¾‹
            tasks_query = '''
            SELECT ti.task_instance_id, ti.status, ti.task_title, ti.assigned_user_id,
                   ni.node_instance_id, ni.node_name
            FROM task_instance ti
            JOIN node_instance ni ON ti.node_instance_id = ni.node_instance_id
            WHERE ni.workflow_instance_id = $1 AND ti.is_deleted = FALSE
            '''
            tasks = await self.task_repo.db.fetch_all(tasks_query, instance_id)
            
            logger.info(f"ğŸ“‹ å·¥ä½œæµä¸‹çš„ä»»åŠ¡æ•°é‡: {len(tasks)}")
            
            # 3. æ‰¹é‡å–æ¶ˆæ‰€æœ‰ç›¸å…³ä»»åŠ¡
            cancelled_tasks = []
            for task in tasks:
                task_id = task['task_instance_id']
                task_status = task['status']
                
                logger.info(f"  å¤„ç†ä»»åŠ¡: {task['task_title']} (çŠ¶æ€: {task_status})")
                
                # åªå–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
                if task_status not in ['completed', 'failed', 'cancelled']:
                    try:
                        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å–æ¶ˆ
                        update_task_query = '''
                        UPDATE task_instance 
                        SET status = 'cancelled', 
                            result_summary = $1,
                            updated_at = $2
                        WHERE task_instance_id = $3
                        '''
                        from ..utils.helpers import now_utc
                        await self.task_repo.db.execute(
                            update_task_query, 
                            f"å·¥ä½œæµå–æ¶ˆ: {cancel_reason}", 
                            now_utc(), 
                            task_id
                        )
                        
                        cancelled_tasks.append({
                            'task_id': task_id,
                            'task_title': task['task_title'],
                            'previous_status': task_status,
                            'assigned_user_id': task['assigned_user_id']
                        })
                        
                        logger.info(f"    âœ… ä»»åŠ¡å·²å–æ¶ˆ: {task['task_title']}")
                        
                    except Exception as task_error:
                        logger.error(f"    âŒ å–æ¶ˆä»»åŠ¡å¤±è´¥: {task_error}")
                else:
                    logger.info(f"    â­ï¸ ä»»åŠ¡å·²å®Œæˆï¼Œè·³è¿‡: {task['task_title']}")
            
            # 4. æ›´æ–°æ‰€æœ‰èŠ‚ç‚¹å®ä¾‹çŠ¶æ€ä¸ºå·²å–æ¶ˆ
            nodes_query = '''
            UPDATE node_instance 
            SET status = 'cancelled', updated_at = $1
            WHERE workflow_instance_id = $2 AND status NOT IN ('completed', 'failed')
            '''
            from ..utils.helpers import now_utc
            await self.task_repo.db.execute(nodes_query, now_utc(), instance_id)
            logger.info(f"  âœ… èŠ‚ç‚¹å®ä¾‹çŠ¶æ€å·²æ›´æ–°ä¸ºcancelled")
            
            # 5. æ›´æ–°å·¥ä½œæµå®ä¾‹çŠ¶æ€ä¸ºå·²å–æ¶ˆ
            workflow_update_query = '''
            UPDATE workflow_instance 
            SET status = 'cancelled', 
                error_message = $1,
                updated_at = $2
            WHERE workflow_instance_id = $3
            '''
            await self.task_repo.db.execute(
                workflow_update_query, 
                cancel_reason, 
                now_utc(), 
                instance_id
            )
            logger.info(f"  âœ… å·¥ä½œæµå®ä¾‹çŠ¶æ€å·²æ›´æ–°ä¸ºcancelled")
            
            # 6. è¿”å›å–æ¶ˆç»“æœ
            result = {
                'workflow_instance_id': instance_id,
                'status': 'cancelled',
                'cancel_reason': cancel_reason,
                'cancelled_tasks_count': len(cancelled_tasks),
                'cancelled_tasks': cancelled_tasks,
                'cancelled_at': now_utc().isoformat(),
                'message': f'å·¥ä½œæµå®ä¾‹å·²å–æ¶ˆï¼Œå…±å–æ¶ˆ {len(cancelled_tasks)} ä¸ªä»»åŠ¡'
            }
            
            logger.info(f"ğŸ¯ å·¥ä½œæµå–æ¶ˆå®Œæˆ:")
            logger.info(f"  å–æ¶ˆçš„ä»»åŠ¡æ•°é‡: {len(cancelled_tasks)}")
            logger.info(f"  ç»“æœ: {result}")
            
            return result
            
        except Exception as e:
            logger.error(f"ğŸ’¥ å–æ¶ˆå·¥ä½œæµå®ä¾‹å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    async def _notify_task_rejected(self, task_id: uuid.UUID, reject_reason: str):
        """é€šçŸ¥å·¥ä½œæµå¼•æ“ä»»åŠ¡è¢«æ‹’ç»"""
        try:
            logger.info(f"ä»»åŠ¡ {task_id} è¢«æ‹’ç»: {reject_reason}")
            
            # è¿™é‡Œå¯ä»¥å®ç°ä»¥ä¸‹é€»è¾‘ï¼š
            # 1. é€šçŸ¥å·¥ä½œæµå¼•æ“ä»»åŠ¡å¤±è´¥
            # 2. å¯èƒ½éœ€è¦é‡æ–°åˆ†é…ä»»åŠ¡ç»™å…¶ä»–ç”¨æˆ·
            # 3. æˆ–è€…æ ‡è®°æ•´ä¸ªå·¥ä½œæµä¸ºå¤±è´¥çŠ¶æ€
            # 4. å‘é€é€šçŸ¥ç»™ç®¡ç†å‘˜æˆ–å…¶ä»–ç›¸å…³äººå‘˜
            
        except Exception as e:
            logger.error(f"é€šçŸ¥ä»»åŠ¡æ‹’ç»å¤±è´¥: {e}")
    
    async def _notify_task_cancelled(self, task_id: uuid.UUID, cancel_reason: str):
        """é€šçŸ¥å·¥ä½œæµå¼•æ“ä»»åŠ¡è¢«å–æ¶ˆ"""
        try:
            logger.info(f"ä»»åŠ¡ {task_id} è¢«å–æ¶ˆ: {cancel_reason}")
            
            # è¿™é‡Œå¯ä»¥å®ç°ä»¥ä¸‹é€»è¾‘ï¼š
            # 1. é€šçŸ¥å·¥ä½œæµå¼•æ“ä»»åŠ¡è¢«å–æ¶ˆ
            # 2. å¯èƒ½éœ€è¦æš‚åœæˆ–å–æ¶ˆæ•´ä¸ªå·¥ä½œæµå®ä¾‹
            # 3. æ¸…ç†ç›¸å…³èµ„æº
            # 4. å‘é€é€šçŸ¥ç»™ç›¸å…³äººå‘˜
            
        except Exception as e:
            logger.error(f"é€šçŸ¥ä»»åŠ¡å–æ¶ˆå¤±è´¥: {e}")
    
    async def assign_task_to_user(self, task_id: uuid.UUID, user_id: uuid.UUID, 
                                assigner_id: uuid.UUID) -> Dict[str, Any]:
        """å°†ä»»åŠ¡åˆ†é…ç»™ç”¨æˆ·ï¼ˆç®¡ç†å‘˜åŠŸèƒ½ï¼‰"""
        try:
            # éªŒè¯åˆ†é…è€…æƒé™ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
            assigner = await self.user_repo.get_user_by_id(assigner_id)
            if not assigner or assigner.get('role') not in ['admin', 'manager']:
                raise PermissionError("æ— æƒåˆ†é…ä»»åŠ¡")
            
            # éªŒè¯è¢«åˆ†é…ç”¨æˆ·å­˜åœ¨
            assignee = await self.user_repo.get_user_by_id(user_id)
            if not assignee:
                raise ValueError("è¢«åˆ†é…ç”¨æˆ·ä¸å­˜åœ¨")
            
            # åˆ†é…ä»»åŠ¡
            result = await self.task_repo.assign_task_to_user(task_id, user_id)
            
            if result:
                logger.info(f"ç®¡ç†å‘˜ {assigner_id} å°†ä»»åŠ¡ {task_id} åˆ†é…ç»™ç”¨æˆ· {user_id}")
                return {
                    'task_id': task_id,
                    'assigned_user_id': user_id,
                    'assigned_user_name': assignee.get('username'),
                    'message': 'ä»»åŠ¡åˆ†é…æˆåŠŸ'
                }
            else:
                raise RuntimeError("ä»»åŠ¡åˆ†é…å¤±è´¥")
                
        except Exception as e:
            logger.error(f"åˆ†é…ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _check_downstream_tasks(self, task_id: uuid.UUID):
        """æ£€æŸ¥ä¸‹æ¸¸ä»»åŠ¡ - å»¶è¿Ÿä»»åŠ¡åˆ›å»ºæœºåˆ¶çš„æ ¸å¿ƒè§¦å‘ç‚¹"""
        try:
            logger.info(f"ğŸ”„ æ£€æŸ¥ä¸‹æ¸¸ä»»åŠ¡: {task_id}")
            
            # 1. è·å–ä»»åŠ¡ä¿¡æ¯å’Œç›¸å…³èŠ‚ç‚¹å®ä¾‹
            task = await self.task_repo.get_task_by_id(task_id)
            if not task:
                logger.error(f"âŒ ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                return
            
            node_instance_id = task['node_instance_id']
            logger.info(f"  ä»»åŠ¡æ‰€å±èŠ‚ç‚¹å®ä¾‹: {node_instance_id}")
            
            # 2. è·å–èŠ‚ç‚¹å®ä¾‹ä¿¡æ¯
            node_query = '''
            SELECT ni.workflow_instance_id, ni.node_id, ni.status as node_status,
                   n.name as node_name, n.type as node_type
            FROM node_instance ni
            JOIN node n ON ni.node_id = n.node_id
            WHERE ni.node_instance_id = $1
            '''
            node_result = await self.task_repo.db.fetch_one(node_query, node_instance_id)
            
            if not node_result:
                logger.error(f"âŒ èŠ‚ç‚¹å®ä¾‹ä¸å­˜åœ¨: {node_instance_id}")
                return
            
            workflow_instance_id = node_result['workflow_instance_id']
            node_name = node_result['node_name']
            logger.info(f"  èŠ‚ç‚¹: {node_name}, å·¥ä½œæµå®ä¾‹: {workflow_instance_id}")
            
            # 3. æ£€æŸ¥è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰ä»»åŠ¡æ˜¯å¦éƒ½å·²å®Œæˆ
            node_tasks_query = '''
            SELECT task_instance_id, status, task_title
            FROM task_instance
            WHERE node_instance_id = $1 AND is_deleted = FALSE
            '''
            node_tasks = await self.task_repo.db.fetch_all(node_tasks_query, node_instance_id)
            
            logger.info(f"  èŠ‚ç‚¹ {node_name} çš„ä»»åŠ¡æ€»æ•°: {len(node_tasks)}")
            
            completed_tasks = [t for t in node_tasks if t['status'] == 'completed']
            failed_tasks = [t for t in node_tasks if t['status'] == 'failed']
            
            logger.info(f"    å·²å®Œæˆä»»åŠ¡: {len(completed_tasks)}")
            logger.info(f"    å¤±è´¥ä»»åŠ¡: {len(failed_tasks)}")
            
            # 4. å¦‚æœæ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆï¼Œæ›´æ–°èŠ‚ç‚¹çŠ¶æ€å¹¶è§¦å‘ä¸‹æ¸¸æ£€æŸ¥
            if len(completed_tasks) == len(node_tasks) and len(node_tasks) > 0:
                logger.info(f"  âœ… èŠ‚ç‚¹ {node_name} çš„æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œæ›´æ–°èŠ‚ç‚¹çŠ¶æ€")
                
                # æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€ä¸ºå·²å®Œæˆ
                await self._update_node_instance_status(node_instance_id, 'completed')
                
                # è§¦å‘ä¸‹æ¸¸èŠ‚ç‚¹çš„ä»»åŠ¡åˆ›å»ºæ£€æŸ¥
                from ..services.execution_service import execution_engine
                await execution_engine._check_downstream_nodes_for_task_creation(workflow_instance_id)
                
                # æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€
                await execution_engine._check_workflow_completion(workflow_instance_id)
                
                logger.info(f"  ğŸ¯ ä¸‹æ¸¸ä»»åŠ¡æ£€æŸ¥å·²è§¦å‘")
                
            elif len(failed_tasks) > 0:
                logger.info(f"  âŒ èŠ‚ç‚¹ {node_name} æœ‰ä»»åŠ¡å¤±è´¥ï¼Œæ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå¤±è´¥")
                await self._update_node_instance_status(node_instance_id, 'failed')
                
                # æ£€æŸ¥å·¥ä½œæµå®ŒæˆçŠ¶æ€ï¼ˆå¯èƒ½æ ‡è®°ä¸ºå¤±è´¥ï¼‰
                from ..services.execution_service import execution_engine
                await execution_engine._check_workflow_completion(workflow_instance_id)
                
            else:
                logger.info(f"  â³ èŠ‚ç‚¹ {node_name} è¿˜æœ‰ä»»åŠ¡æœªå®Œæˆï¼Œç­‰å¾…ä¸­")
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ä¸‹æ¸¸ä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    async def _update_node_instance_status(self, node_instance_id: uuid.UUID, status: str):
        """æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€"""
        try:
            logger.info(f"ğŸ“ æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€: {node_instance_id} -> {status}")
            
            from ..utils.helpers import now_utc
            update_query = '''
            UPDATE node_instance 
            SET status = $1, updated_at = $2
            WHERE node_instance_id = $3
            '''
            await self.task_repo.db.execute(update_query, status, now_utc(), node_instance_id)
            logger.info(f"  âœ… èŠ‚ç‚¹å®ä¾‹çŠ¶æ€æ›´æ–°æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°èŠ‚ç‚¹å®ä¾‹çŠ¶æ€å¤±è´¥: {e}")
            raise