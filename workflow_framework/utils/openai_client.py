"""
OpenAIå®¢æˆ·ç«¯é›†æˆ
OpenAI Client Integration
"""

import json
import asyncio
from typing import Dict, Any, Optional, List
from loguru import logger
from .helpers import safe_json_dumps

# å°è¯•å¯¼å…¥OpenAIï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ¨¡æ‹Ÿç‰ˆæœ¬

from openai import AsyncOpenAI
OPENAI_AVAILABLE = True
logger.info("OpenAIåº“å¯¼å…¥æˆåŠŸ")


class OpenAIClient:
    """OpenAIå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None,
                 model: Optional[str] = None, prompt: Optional[str] = None,
                 temperature: float = 0.7, top_p: float = 0.9):
        self.api_key = api_key or "sk-lkyoyvnbsssstobvfhezidgmiegpwzbykyfkxwebqcmgctyz"  # åº”è¯¥ä»ç¯å¢ƒå˜é‡è·å–
        self.base_url = base_url or "https://api.siliconflow.cn/v1"
        self.model = model or "Pro/deepseek-ai/DeepSeek-V3"
        self.prompt = prompt
        self.temperature = temperature
        self.top_p = top_p
        self.timeout = 30
        
        # åˆå§‹åŒ–AsyncOpenAIå®¢æˆ·ç«¯
        self.aclient = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)
    
    async def process_task(self, task_data: Dict[str, Any], 
                          model: Optional[str] = None) -> Dict[str, Any]:
        """å¤„ç†ä»»åŠ¡è¯·æ±‚"""
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°
            model_name = model or task_data.get('model', self.model)
            
            logger.info(f"ğŸš€ [OPENAI-CLIENT] å¼€å§‹å¤„ç†OpenAIä»»åŠ¡")
            logger.info(f"   - ä½¿ç”¨æ¨¡å‹: {model_name}")
            logger.info(f"   - Base URL: {self.base_url}")
            logger.info(f"   - API Keyå­˜åœ¨: {'æ˜¯' if self.api_key else 'å¦'}")
            
            # ä»task_dataä¸­æå–messages
            messages = task_data.get('messages', [])
            if not messages:
                raise ValueError("task_dataä¸­ç¼ºå°‘messageså­—æ®µ")
            
            # è°ƒç”¨çœŸå®çš„OpenAI API
            result = await self._call_openai_api_with_messages(messages, model_name, task_data)
            
            return {
                'success': True,
                'model': model_name,
                'result': result,
                'usage': result.get('usage', {})
            }
            
        except Exception as e:
            logger.error(f"OpenAIå¤„ç†ä»»åŠ¡å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'model': model or self.model
            }
    
    async def _call_openai_api_with_messages(self, messages: List[Dict[str, str]], 
                                           model: str, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨messagesæ ¼å¼è°ƒç”¨OpenAI API"""
        try:
            # è°ƒç”¨OpenAI API
            response = await asyncio.wait_for(
                self.aclient.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=task_data.get('temperature', self.temperature),
                    max_tokens=task_data.get('max_tokens', 2000),
                    top_p=self.top_p,
                ),
                timeout=30.0  # 30ç§’è¶…æ—¶
            )

            # æå–å“åº”å†…å®¹
            content = response.choices[0].message.content
            usage = {
                'prompt_tokens': response.usage.prompt_tokens,
                'completion_tokens': response.usage.completion_tokens,
                'total_tokens': response.usage.total_tokens
            }
            
            # è¿”å›ç¬¦åˆOpenAIå“åº”æ ¼å¼çš„ç»“æœ
            return {
                'content': content,
                'usage': usage
            }
                
        except Exception as e:
            logger.error(f"è°ƒç”¨OpenAI APIå¤±è´¥: {e}")
            # é™çº§åˆ°æ¨¡æ‹Ÿå¤„ç†
            return await self._simulate_openai_request(messages, model)
    
    async def _call_openai_api(self, prompt: str, model: str) -> Dict[str, Any]:
        """è°ƒç”¨çœŸå®çš„OpenAI API"""
        try:
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = []
            if self.prompt is not None:
                messages.append({
                    "content": self.prompt,
                    "role": "system"
                })

            messages.append({"role": "user", "content": prompt})

            # è°ƒç”¨OpenAI API
            response = await asyncio.wait_for(
                self.aclient.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=self.temperature,
                    top_p=self.top_p,
                ),
                timeout=10.0  # 10ç§’è¶…æ—¶
            )

            # æå–å“åº”å†…å®¹
            content = response.choices[0].message.content
            usage = {
                'prompt_tokens': response.usage.prompt_tokens,
                'completion_tokens': response.usage.completion_tokens,
                'total_tokens': response.usage.total_tokens
            }
            
            # å°è¯•è§£æJSONå“åº”
            try:
                parsed_result = json.loads(content)
                parsed_result['usage'] = usage
                return parsed_result
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œè¿”å›çº¯æ–‡æœ¬ç»“æœ
                return {
                    'analysis': content,
                    'result': {'content': content},
                    'recommendations': [],
                    'confidence': 0.8,
                    'usage': usage
                }
                
        except Exception as e:
            logger.error(f"è°ƒç”¨OpenAI APIå¤±è´¥: {e}")
            # é™çº§åˆ°æ¨¡æ‹Ÿå¤„ç†
            return await self._simulate_openai_request(prompt, model)
    
    async def _simulate_openai_request(self, messages_or_prompt, model: str) -> Dict[str, Any]:
        """æ¨¡æ‹ŸOpenAI APIå“åº”ï¼ˆç”¨äºæµ‹è¯•å’Œé™çº§ï¼‰"""
        try:
            # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
            await asyncio.sleep(0.5)
            
            # æå–ç”¨æˆ·æ¶ˆæ¯å†…å®¹
            if isinstance(messages_or_prompt, list):
                user_content = ""
                for msg in messages_or_prompt:
                    if msg.get('role') == 'user':
                        user_content = msg.get('content', '')
                        break
            else:
                user_content = str(messages_or_prompt)
            
            # ç”Ÿæˆæ¨¡æ‹Ÿçš„JSONå“åº”
            mock_response = {
                "analysis_result": f"åŸºäºæä¾›çš„æ•°æ®å®Œæˆäº†æ·±åº¦åˆ†æã€‚ç”¨æˆ·å†…å®¹é•¿åº¦: {len(user_content)} å­—ç¬¦",
                "key_findings": [
                    "æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥è¿›è¡Œæœ‰æ•ˆåˆ†æ",
                    "ä¸Šæ¸¸èŠ‚ç‚¹æä¾›äº†å……åˆ†çš„ä¸Šä¸‹æ–‡ä¿¡æ¯",
                    "åˆ†æç»“æœå…·æœ‰è¾ƒé«˜çš„å¯ä¿¡åº¦"
                ],
                "recommendations": [
                    "å»ºè®®è¿›ä¸€æ­¥åˆ†ææ•°æ®è¶‹åŠ¿",
                    "å»ºè®®å…³æ³¨å…³é”®æŒ‡æ ‡å˜åŒ–",
                    "å»ºè®®å®šæœŸæ›´æ–°åˆ†ææ¨¡å‹"
                ],
                "confidence_score": 0.87,
                "summary": f"ä½¿ç”¨{model}æ¨¡å‹æˆåŠŸå®Œæˆä»»åŠ¡åˆ†æ"
            }
            
            # è¿”å›ç¬¦åˆOpenAIæ ¼å¼çš„å“åº”
            return {
                "content": safe_json_dumps(mock_response),
                "usage": {
                    "prompt_tokens": 150,
                    "completion_tokens": 200,
                    "total_tokens": 350
                }
            }
            
        except Exception as e:
            logger.error(f"æ¨¡æ‹ŸOpenAIè¯·æ±‚å¤±è´¥: {e}")
            # è¿”å›æœ€åŸºæœ¬çš„å“åº”
            return {
                "content": safe_json_dumps({
                    "analysis_result": "æ¨¡æ‹Ÿåˆ†æå®Œæˆ",
                    "key_findings": ["åŸºç¡€åˆ†æç»“æœ"],
                    "recommendations": ["å»ºè®®ä½¿ç”¨çœŸå®API"],
                    "confidence_score": 0.75,
                    "summary": "æ¨¡æ‹Ÿå¤„ç†å®Œæˆ"
                }, ensure_ascii=False),
                "usage": {"prompt_tokens": 100, "completion_tokens": 100, "total_tokens": 200}
            }
    

# å…¨å±€OpenAIå®¢æˆ·ç«¯å®ä¾‹
openai_client = OpenAIClient()